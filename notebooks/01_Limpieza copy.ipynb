{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Uni√≥n y Limpieza de datos del Dataset  \n",
    "\n",
    "---\n",
    "\n",
    "**Objetivo del Notebook**  \n",
    "Limpieza de datos, columnas innecesarias y valores nulos/blancos \n",
    "\n",
    "**Contexto del an√°lisis**  \n",
    "- Dataset de muestra proporcionado + csv proporcionado unido en un √∫nico excel dataset\n",
    "- Enfoque en aprendizaje, validaci√≥n del pipeline y comprensi√≥n del proceso\n",
    "\n",
    "**Valor devuelto**  \n",
    "- Copia del Dataset de muestra proporcionado completamente limpio y √∫til \n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "import utils\n",
    "# ===============================\n",
    "# LEER EL ARCHIVO LIMPIO\n",
    "# ===============================\n",
    "ruta = r\"C:\\Users\\0017655\\Downloads\\DataSET_SF - V2.xlsx\"\n",
    "dfs = pd.read_excel(ruta, sheet_name=None)\n",
    "\n",
    "# Ver la primera hoja\n",
    "oportunidad = list(dfs.values())[0]\n",
    "cuenta = list(dfs.values())[1]\n",
    "ecb = list(dfs.values())[2]\n",
    "solicitud_ban = list(dfs.values())[3]\n",
    "casos = list(dfs.values())[4]\n",
    "correos = list(dfs.values())[5]\n",
    "historial_actividad = list(dfs.values())[6]\n",
    "historial_etapas = list(dfs.values())[7]\n",
    "\n",
    "\n",
    "print(historial_etapas.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import analisis_na_por_columna\n",
    "analisis_na_por_columna(oportunidad)\n",
    "analisis_na_por_columna(cuenta)\n",
    "analisis_na_por_columna(ecb)\n",
    "analisis_na_por_columna(solicitud_ban)\n",
    "analisis_na_por_columna(casos)\n",
    "analisis_na_por_columna(correos)\n",
    "analisis_na_por_columna(historial_actividad)\n",
    "analisis_na_por_columna(historial_etapas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import analisis_na_por_columna, eliminar_columnas_na\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# LIMPIEZA DE NAS\n",
    "# ===============================\n",
    "\n",
    "oportunidad = eliminar_columnas_na(oportunidad)\n",
    "cuenta = eliminar_columnas_na(cuenta)\n",
    "ecb = eliminar_columnas_na(ecb)\n",
    "solicitud_ban = eliminar_columnas_na(solicitud_ban)\n",
    "casos = eliminar_columnas_na(casos)\n",
    "correos = eliminar_columnas_na(correos)\n",
    "historial_actvidad = eliminar_columnas_na(historial_actividad)\n",
    "historial_etapas = eliminar_columnas_na(historial_etapas)\n",
    "\n",
    "# ===============================\n",
    "# CREACION DEL TARJET\n",
    "# ===============================\n",
    "def crear_target(oportunidad: pd.DataFrame, historial_etapas: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Crea la columna 'target' para cada oportunidad seg√∫n la l√≥gica:\n",
    "    - Existe etapa 'Matr√≠cula OOGG' con estado 'formalizada'\n",
    "    - No existe etapa 'Desmatriculado'\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filtrar historial por Matr√≠cula OOGG y estado formalizada\n",
    "    matricula_formalizada = historial_etapas[\n",
    "        (historial_etapas['PL_Etapa__c'] == 'Matr√≠cula OOGG') &\n",
    "        (historial_etapas['PL_Subetapa__c'] == 'Formalizada')\n",
    "    ]['LK_Oportunidad__c'].unique()\n",
    "    print('Hay un total de '+str(len(matricula_formalizada))+' matr√≠culas formalizadas. Un '+str(round(len(matricula_formalizada)/len(historial_etapas['LK_Oportunidad__c'].unique())*100,2))+'% del total de oportunidades')\n",
    "\n",
    "    \n",
    "    \n",
    "    # Filtrar historial por Desmatriculado\n",
    "    desmatriculado = historial_etapas[\n",
    "        historial_etapas['PL_Subetapa__c'] == 'Desmatriculado'\n",
    "    ]['LK_Oportunidad__c'].unique()\n",
    "    print('Hay un total de '+str(len(desmatriculado))+' desmatriculados. Un '+str(round(len(desmatriculado)/len(matricula_formalizada)*100,2))+'% del total de matriculados')\n",
    "    # Crear target: 1 si est√° en matricula formalizada y no en desmatriculado\n",
    "    oportunidad['target'] = oportunidad['ID'].apply(\n",
    "        lambda x: 1 if (x in matricula_formalizada and x not in desmatriculado) else 0\n",
    "    )\n",
    "    # Crear desmatriculado: 1 si est√° Desmatriculado y 0 en caso contrario\n",
    "    oportunidad['desmatriculado'] = oportunidad['ID'].apply(\n",
    "        lambda x: 1 if (x in desmatriculado) else 0\n",
    "    )\n",
    "    \n",
    "    return oportunidad\n",
    "\n",
    "target = crear_target(oportunidad, historial_etapas)\n",
    "target.columns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An√°lisis descriptivo (Seguimiento 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Resumen num√©rico con c√°lculo de porcentaje\n",
    "resumen_acceso = target.groupby(['PL_CURSO_ACADEMICO', 'PL_ORIGEN_DE_SOLICITUD', 'target'])['ID'].nunique().unstack(fill_value=0)\n",
    "resumen_acceso.columns = ['No Matriculado (0)', 'Matriculado (1)']\n",
    "\n",
    "# Calcular Total y % de Matriculados (Tasa de Conversi√≥n/Fidelidad)\n",
    "resumen_acceso['Total'] = resumen_acceso['No Matriculado (0)'] + resumen_acceso['Matriculado (1)']\n",
    "resumen_acceso['% Fidelidad'] = (resumen_acceso['Matriculado (1)'] / resumen_acceso['Total'] * 100).round(2)\n",
    "\n",
    "\n",
    "# Gr√°fico Global de Acceso\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=target.drop_duplicates('ID'), x='PL_ORIGEN_DE_SOLICITUD', hue='target', palette='viridis')\n",
    "plt.title('Volumen de Oportunidades por Tipo de Acceso')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "resumen_acceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import graficar_top_por_acceso\n",
    "import matplotlib.pyplot as plt\n",
    "# Ejecuci√≥n\n",
    "graficar_top_por_acceso(target, top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Corregimos la lista (quitamos duplicados y a√±adimos comas faltantes)\n",
    "columnas_seleccionadas = [\n",
    "    'ACCOUNTID', 'ID', 'ID18__PC', 'target', 'desmatriculado', 'PL_CURSO_ACADEMICO', 'CH_NACIONAL',\n",
    "    'NU_NOTA_MEDIA_ADMISION', 'NU_NOTA_MEDIA_1_BACH__PC', 'CH_PRUEBAS_CALIFICADAS', \n",
    "    'NU_RESULTADO_ADMISION_PUNTOS', 'PL_RESOLUCION_DEFINITIVA', 'TITULACION', 'CENTROENSENANZA',\n",
    "    'MINIMUMPAYMENTPAYED', 'PAID_AMOUNT', 'PAID_PERCENT', 'CH_PAGO_SUPERIOR', \n",
    "    'CH_MATRICULA_SUJETA_BECA', 'CH_AYUDA_FINANCIACION', 'CU_IMPORTE_TOTAL',\n",
    "    'CH_VISITACAMPUS__PC', 'CH_ENTREVISTA_PERSONAL__PC', 'ACC_DTT_FECHAULTIMAACTIVIDAD', \n",
    "    'NU_PREFERENCIA', 'STAGENAME', 'PL_SUBETAPA',\n",
    "    'CH_HIJO_EMPLEADO__PC', 'CH_HIJO_PROFESOR_ASOCIADO__PC', 'CH_HERMANOS_ESTUDIANDO_UNAV__P', \n",
    "    'CH_HIJO_MEDICO__PC', 'YEARPERSONBIRTHDATE', 'NAMEX', 'CH_FAMILIA_NUMEROSA__PC', \n",
    "    'PL_SITUACION_SOCIO_ECONOMICA', 'LEADSOURCE', 'PL_ORIGEN_DE_SOLICITUD', \n",
    "    'PL_PLAZO_ADMISION', 'RECORDTYPENAME'\n",
    "]\n",
    "\n",
    "# 2. Uni√≥n asegurando que no arrastramos basura\n",
    "df_unido = pd.merge(\n",
    "    target, \n",
    "    cuenta, \n",
    "    left_on='ACCOUNTID', \n",
    "    right_on='ID18', \n",
    "    how='left',\n",
    "    suffixes=('', '_cuenta')\n",
    ")\n",
    "\n",
    "# 3. Filtrado y ELIMINACI√ìN DE COLUMNAS DUPLICADAS (por si acaso)\n",
    "columnas_finales = []\n",
    "for col in columnas_seleccionadas:\n",
    "    if col in df_unido.columns and col not in columnas_finales:\n",
    "        columnas_finales.append(col)\n",
    "\n",
    "df_unido_filtrado = df_unido[columnas_finales].copy()\n",
    "\n",
    "# 4. TRUCO FINAL: Limpiar el √≠ndice para que la funci√≥n no explote\n",
    "df_unido_filtrado = df_unido_filtrado.drop_duplicates(subset=['ID']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import calcular_tiempos_etapas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "historial_etapas_tiempo = calcular_tiempos_etapas(historial_etapas)\n",
    "\n",
    "def limpiar_historial_por_hitos(df_historial, df_principal):\n",
    "    # 1. Asegurar formato datetime y TRABAJAR SOBRE UNA COPIA\n",
    "    df_h = df_historial.copy()\n",
    "    df_h['CreatedDate'] = pd.to_datetime(df_h['CreatedDate'])\n",
    "    \n",
    "    # 2. Hitos (Igual que antes pero asegurando que no haya basura en el index)\n",
    "    hito_acad = df_h[\n",
    "        (df_h['PL_Etapa__c'] == 'Pruebas de admisi√≥n') & \n",
    "        (df_h['PL_Subetapa__c'] == 'Pruebas calificadas')\n",
    "    ].groupby('LK_Oportunidad__c')['CreatedDate'].min().reset_index()\n",
    "    hito_acad.columns = ['LK_Oportunidad__c', 'fecha_pruebas_calificadas']\n",
    "    \n",
    "    hito_econ = df_h[\n",
    "        (df_h['PL_Etapa__c'] == 'Matr√≠cula admisi√≥n') & \n",
    "        (df_h['PL_Subetapa__c'] == 'Pago M√≠nimo')\n",
    "    ].groupby('LK_Oportunidad__c')['CreatedDate'].min().reset_index()\n",
    "    hito_econ.columns = ['LK_Oportunidad__c', 'fecha_matricula_iniciada']\n",
    "    \n",
    "    # 3. Unir hitos\n",
    "    df_merge = pd.merge(df_h, hito_acad, on='LK_Oportunidad__c', how='left')\n",
    "    df_merge = pd.merge(df_merge, hito_econ, on='LK_Oportunidad__c', how='left')\n",
    "    \n",
    "    # 4. PREVENCI√ìN: Antes del merge final, eliminar del df_principal \n",
    "    # las columnas que YA est√°n en df_merge para evitar duplicados (.x, .y)\n",
    "    cols_a_quitar = [c for c in df_principal.columns if c in df_merge.columns and c != 'ID']\n",
    "    df_principal_clean = df_principal.drop(columns=cols_a_quitar)\n",
    "    \n",
    "    # 5. Merge final\n",
    "    df_final = pd.merge(df_merge, df_principal_clean, left_on='LK_Oportunidad__c', right_on='ID', how='left')\n",
    "    \n",
    "    # 6. Definici√≥n de grupos (Aseg√∫rate de que NO hay duplicados aqu√≠)\n",
    "    cols_academicas = list(set([\n",
    "        'NU_NOTA_MEDIA_ADMISION', 'CH_PRUEBAS_CALIFICADAS', \n",
    "        'NU_RESULTADO_ADMISION_PUNTOS', 'PL_RESOLUCION_DEFINITIVA'\n",
    "    ]))\n",
    "    \n",
    "    cols_economicas = list(set([\n",
    "        'MINIMUMPAYMENTPAYED', 'PAID_AMOUNT', 'PAID_PERCENT', 'CH_PAGO_SUPERIOR', \n",
    "        'CH_MATRICULA_SUJETA_BECA', 'CH_AYUDA_FINANCIACION', 'CU_IMPORTE_TOTAL'\n",
    "    ]))\n",
    "    \n",
    "    # 7. Reset index para evitar errores de reindexaci√≥n\n",
    "    df_final = df_final.reset_index(drop=True)\n",
    "    \n",
    "    # 8. Aplicaci√≥n de la l√≥gica temporal\n",
    "    mask_acad = (df_final['fecha_pruebas_calificadas'].isna()) | (df_final['CreatedDate'] < df_final['fecha_pruebas_calificadas'])\n",
    "    df_final.loc[mask_acad, cols_academicas] = np.nan\n",
    "    \n",
    "    mask_econ = (df_final['fecha_matricula_iniciada'].isna()) | (df_final['CreatedDate'] < df_final['fecha_matricula_iniciada'])\n",
    "    df_final.loc[mask_econ, cols_economicas] = np.nan\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "df_final = limpiar_historial_por_hitos(historial_etapas_tiempo, df_unido_filtrado)\n",
    "\n",
    "ejemplo_id = '0066900001k7yTgAAI'\n",
    "\n",
    "columnas_comprobacion = [\n",
    "    'LK_Oportunidad__c', 'CreatedDate', 'PL_Etapa__c', 'PL_Subetapa__c',\n",
    "    'fecha_pruebas_calificadas', 'NU_NOTA_MEDIA_ADMISION',\n",
    "    'fecha_matricula_iniciada', 'PAID_AMOUNT', 'CH_PRUEBAS_CALIFICADAS', \n",
    "        'NU_RESULTADO_ADMISION_PUNTOS', 'PL_RESOLUCION_DEFINITIVA'\n",
    "]\n",
    "\n",
    "print(\"--- COMPROBACI√ìN DE L√ìGICA TEMPORAL ---\")\n",
    "df_final[df_final['LK_Oportunidad__c'] == ejemplo_id][columnas_comprobacion].sort_values('CreatedDate')\n",
    "#df_final.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import integrar_actividades_progresivo_por_curso\n",
    "# Ejecuci√≥n\n",
    "df_final_v3 = integrar_actividades_progresivo_por_curso(df_final, historial_actividad)\n",
    "# ==========================================\n",
    "# EJECUCI√ìN\n",
    "# ==========================================\n",
    "# Print de comprobaci√≥n para ver la evoluci√≥n de un contacto\n",
    "ejemplo_acc = df_final_v3[df_final_v3['num_asistencias_acum'] > 0]['ID18__PC'].iloc[1]\n",
    "cols_print = ['ID','ID18__PC','ACCOUNTID', 'CreatedDate', 'PL_Etapa__c', 'num_asistencias_acum', 'num_solicitudes_acum']\n",
    "\n",
    "print(\"\\n--- COMPROBACI√ìN DE EVOLUCI√ìN DE ACTIVIDADES ---\")\n",
    "df_final_v3[df_final_v3['ID18__PC'] == ejemplo_acc][cols_print].sort_values('CreatedDate')\n",
    "#historial_actividad.loc[historial_actividad['ContactId']=='003690000312P6pAAE',]\n",
    "df_final_v3.head(100)\n",
    "df_integrado = df_final_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 3. GUARDAR EXCEL LIMPIO\n",
    "# ===============================\n",
    "#df_integrado.to_csv(r\"..\\datos\\02. Datos tratamiento preliminar\\01_datos_tratamiento_preliminar - V2.csv\",sep=\";\")\n",
    "\n",
    "print(\"Archivo limpio guardado como '01_datos_tratamiento_preliminar - V2.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Creaci√≥n del Dataset Maestro\n",
    "\n",
    "---\n",
    "\n",
    "**Objetivo del Notebook**  \n",
    "Creacion del dataset maestro una vez obtenido el dataset limpio\n",
    "\n",
    "**Contexto del an√°lisis**  \n",
    "- Dataset limpio en etapas anteriores\n",
    "\n",
    "**Valor devuelto**  \n",
    "- Copia del Dataset de muestra proporcionado completamente funcional\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAREA 1: Comprobar que el conjunto de datos contiene todas las variables importantes de la pesta√±a de cuenta: Variables relacionadas con el origen del alumno: nacional o internacional, colegio de procedencia, si el colegio es af√≠n o no a la UNAV, si es hijo de empleado o de profesor asociado (por los descuentos en matr√≠cula), si es familia numerosa y de qu√© tipo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# VARIABLES CLAVE ESPERADAS (CUENTA)\n",
    "# ===============================\n",
    "\n",
    "variables_cuenta_clave = {\n",
    "    \"Origen del alumno\": [\n",
    "        \"PL_NACIONALIDAD__C\",          # cambiar por colegio\n",
    "        \"PL_TIPO_ALUMNO__C\"            # Nacional / Internacional (alternativa frecuente)\n",
    "    ],\n",
    "    \n",
    "    \"Colegio de procedencia\": [\n",
    "        \"CENTROENSENANZA\",\n",
    "        \"CH_CENTRO_AFIN_UNAV__C\"       # Colegio af√≠n a UNAV, a√±adir nota media 1¬∫ bachillerato, hijo empleado, hijo medico, hijo hermanos en la unav, etc\n",
    "    ],\n",
    "    \n",
    "    \"V√≠nculo con UNAV (descuentos)\": [\n",
    "        \"CH_HIJO_EMPLEADO__PC\",\n",
    "        \"CH_HIJO_PROFESOR_ASOCIADO__C\" # si existe\n",
    "    ],\n",
    "    \n",
    "    \"Familia numerosa\": [\n",
    "        \"CH_FAMILIA_NUMEROSA__PC\",\n",
    "        \"PL_TIPO_FAMILIA_NUMEROSA__C\"  # general / especial, a√±adir n¬∫ miembros de la familia, \n",
    "    ]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# COMPROBACI√ìN DE EXISTENCIA EN CUENTA: verificamos qu√© est√° y qu√© falta realmente en el dataframe cuenta.\n",
    "# ===============================\n",
    "\n",
    "columnas_cuenta = set(cuenta.columns)\n",
    "\n",
    "estado_variables = []\n",
    "\n",
    "for bloque, vars_bloque in variables_cuenta_clave.items():\n",
    "    for var in vars_bloque:\n",
    "        estado_variables.append({\n",
    "            \"Bloque\": bloque,\n",
    "            \"Variable\": var,\n",
    "            \"Existe_en_cuenta\": var in columnas_cuenta\n",
    "        })\n",
    "\n",
    "df_estado_variables = pd.DataFrame(estado_variables)\n",
    "df_estado_variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# COMPROBAR PRESENCIA EN DATASET FINAL: comprobamos si esas variables han sobrevivido al cruce y est√°n en el dataset final.\n",
    "# ===============================\n",
    "\n",
    "columnas_final = set(df_integrado.columns)\n",
    "\n",
    "df_estado_variables[\"Existe_en_df_integrado\"] = (\n",
    "    df_estado_variables[\"Variable\"].isin(columnas_final)\n",
    ")\n",
    "\n",
    "df_estado_variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# CALIDAD DE VARIABLES EXISTENTES: Para las que s√≠ existen en df_integrado, comprobamos si tienen datos √∫tiles.\n",
    "# ===============================\n",
    "\n",
    "vars_validas = df_estado_variables.loc[\n",
    "    df_estado_variables[\"Existe_en_df_integrado\"],\n",
    "    \"Variable\"\n",
    "].tolist()\n",
    "\n",
    "calidad = (\n",
    "    df_integrado[vars_validas]\n",
    "    .isna()\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"Variable\", 0: \"% NA\"})\n",
    ")\n",
    "\n",
    "calidad[\"% NA\"] = (calidad[\"% NA\"] * 100).round(2)\n",
    "calidad.sort_values(\"% NA\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# CONCLUSI√ìN AUTOM√ÅTICA\n",
    "# ===============================\n",
    "\n",
    "conclusion = df_estado_variables.copy()\n",
    "conclusion[\"Estado\"] = np.select(\n",
    "    [\n",
    "        ~conclusion[\"Existe_en_cuenta\"],\n",
    "        conclusion[\"Existe_en_cuenta\"] & ~conclusion[\"Existe_en_df_integrado\"],\n",
    "        conclusion[\"Existe_en_df_integrado\"]\n",
    "    ],\n",
    "    [\n",
    "        \"‚ùå No existe en origen\",\n",
    "        \"‚ö†Ô∏è Existe en cuenta pero no lleg√≥ al dataset final\",\n",
    "        \"‚úÖ Disponible en dataset final\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Mostrar la conclusi√≥n\n",
    "display(conclusion)\n",
    "\n",
    "# ===============================\n",
    "# REVISAR NACIONALIDAD / VARIABLES DIFERENTES\n",
    "# ===============================\n",
    "\n",
    "# Filtrar las variables que no existen en el origen\n",
    "vars_no_origen = conclusion.loc[conclusion[\"Estado\"] == \"‚ùå No existe en origen\", \"Variable\"].tolist()\n",
    "\n",
    "if vars_no_origen:\n",
    "    print(\"\\nVariables que no existen en el origen seg√∫n la base de datos:\")\n",
    "    print(vars_no_origen)\n",
    "\n",
    "    # Revisar si estos nombres aparecen en el Excel con otro nombre\n",
    "    posibles_renombradas = []\n",
    "    for var in vars_no_origen:\n",
    "        # Buscar columnas que contengan partes del nombre\n",
    "        matches = [c for c in cuenta.columns if var.lower() in c.lower() or c.lower() in var.lower()]\n",
    "        if matches:\n",
    "            posibles_renombradas.append((var, matches))\n",
    "    \n",
    "    if posibles_renombradas:\n",
    "        print(\"\\nPosibles coincidencias en el Excel (renombradas o distintas):\")\n",
    "        for original, encontrados in posibles_renombradas:\n",
    "            print(f\"{original} -> {encontrados}\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è No se encontraron coincidencias en el Excel, estas variables habr√≠a que solicitarlas.\")\n",
    "\n",
    "\n",
    "#REVISAR LA NACIONALIDAD POR SI SE LLAMA DISTINTO (EN EL EXCEL)\n",
    "# Juan: aqu√≠ hay que comprobar en el Excel si los valores que no exixsten en el origen est√°n en el Excel y no aparecen porque se llama de otra forma o si es porque directamente no aparecen y habr√≠a que solicitarlos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAREA 2: Comprobar que el target se ha creado correctamente, que no hay valores vac√≠os. En caso de tener valores vac√≠os, comprobar de donde vienen y porqu√© ocurren. Comprobar que las variables importantes de oportunidad aparecen en el conjunto de datos: tipo de solicitud (Informaci√≥n o admisi√≥n), plazo de admisi√≥n(con un tratamiento de si es Diciembre, Marzo o Rolling [que es cuando solicitas la prueba y la haces a los d√≠as, suele aparecer en blanco] y tratar de construir bien esta variable), nu_preferencia (con el orden de preferencia), si ha pagado, el pago m√≠nimo, notas de admisi√≥n, etc. Asegurar que no aparece informaci√≥n de futuro en etapas anteriores. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# ELIMINAR REGISTROS CON TARGET NULO\n",
    "# ===============================\n",
    "\n",
    "# Contar antes\n",
    "num_nulos = df_integrado['target'].isna().sum()\n",
    "print(f\"Eliminando {num_nulos} registros con target nulo...\")\n",
    "\n",
    "# Filtrar el dataframe\n",
    "df_integrado = df_integrado[df_integrado['target'].notna()].copy()\n",
    "\n",
    "# Comprobaci√≥n r√°pida\n",
    "print(\"N√∫mero de registros tras eliminar nulos:\", len(df_integrado))\n",
    "print(\"Valores √∫nicos del target ahora:\")\n",
    "print(df_integrado['target'].value_counts())\n",
    "\n",
    "# Juan: El target que sea nulo hay que eliminarlo, ya que no se puede modelar con target nulo. Este caso es seguro uno de los casos sensibles eliminados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# VARIABLES CLAVE DE OPORTUNIDAD\n",
    "# ===============================\n",
    "\n",
    "variables_op_clave = {\n",
    "    \"Tipo de solicitud\": [\n",
    "        \"PL_ORIGEN_DE_SOLICITUD\",  # Informaci√≥n / Admisi√≥n\n",
    "        \"CH_ORIGEN_ADMISION\",\n",
    "        \"RECORDTYPENAME\"\n",
    "    ],\n",
    "    \n",
    "    \"Plazo de admisi√≥n\": [\n",
    "        \"PL_PLAZO_ADMISION\"\n",
    "    ],\n",
    "    \n",
    "    \"Preferencia\": [\n",
    "        \"NU_PREFERENCIA\"\n",
    "    ],\n",
    "    \n",
    "    \"Pago\": [\n",
    "        \"CH_PAGADO__C\",\n",
    "        \"MINIMUMPAYMENTPAYED\",\n",
    "        \"IMPORTE_MINIMO_PERSONALIZADO\"\n",
    "    ],\n",
    "    \n",
    "    \"Notas admisi√≥n\": [\n",
    "        \"NU_NOTA_MEDIA_ADMISION\",\n",
    "        \"NU_RESULTADO_ADMISION_PUNTOS\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ===============================\n",
    "# EXISTENCIA DE VARIABLES\n",
    "# ===============================\n",
    "\n",
    "estado_op = []\n",
    "\n",
    "for bloque, vars_bloque in variables_op_clave.items():\n",
    "    for var in vars_bloque:\n",
    "        estado_op.append({\n",
    "            \"Bloque\": bloque,\n",
    "            \"Variable\": var,\n",
    "            \"Existe_en_df_integrado\": var in df_integrado.columns\n",
    "        })\n",
    "\n",
    "df_estado_op = pd.DataFrame(estado_op)\n",
    "df_estado_op\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_integrado['PL_TIPOSOLICITUD'] = np.select([df_integrado['RECORDTYPENAME'].str.contains('grado', case=False, na=False), df_integrado['RECORDTYPENAME'].str.contains('m[√°a]ster', case=False, na=False)], ['Grado', 'M√°ster'], default='Otro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# CONSTRUCCI√ìN PLAZO LIMPIO \n",
    "# ===============================\n",
    "\n",
    "def normalizar_plazo(row):\n",
    "    plazo = row['PL_PLAZO_ADMISION']\n",
    "    tipo_carrera = row['PL_TIPOSOLICITUD']  # Aseg√∫rate de tener esta columna (Grado / M√°ster)\n",
    "    \n",
    "    # Master siempre Rolling\n",
    "    if tipo_carrera.lower() == \"master\":\n",
    "        return \"Rolling\"\n",
    "    \n",
    "    # Nulos ‚Üí Rolling\n",
    "    if pd.isna(plazo):\n",
    "        return \"Rolling\"\n",
    "    \n",
    "    # Normalizaci√≥n de otros plazos\n",
    "    plazo = str(plazo).strip().lower()\n",
    "    if \"dic\" in plazo:\n",
    "        return \"Diciembre\"\n",
    "    if \"mar\" in plazo:\n",
    "        return \"Marzo\"\n",
    "    \n",
    "    # Todo lo dem√°s ‚Üí Otros\n",
    "    return \"Otros\"\n",
    "\n",
    "# Aplicamos\n",
    "df_integrado['PLAZO_ADMISION_LIMPIO'] = df_integrado.apply(normalizar_plazo, axis=1)\n",
    "\n",
    "# ===============================\n",
    "# AN√ÅLISIS DE DISTRIBUCI√ìN\n",
    "# ===============================\n",
    "\n",
    "# Por Plazo en bruto\n",
    "print(\"Distribuci√≥n Plazo en bruto:\")\n",
    "print(df_integrado['PL_PLAZO_ADMISION'].value_counts(dropna=False))\n",
    "\n",
    "# Por Plazo limpio\n",
    "print(\"\\nDistribuci√≥n Plazo limpio:\")\n",
    "print(df_integrado['PLAZO_ADMISION_LIMPIO'].value_counts())\n",
    "\n",
    "# Por Plazo limpio y tipo de carrera\n",
    "print(\"\\nDistribuci√≥n Plazo limpio por tipo de carrera:\")\n",
    "display(df_integrado.groupby(['TITULACION','PLAZO_ADMISION_LIMPIO']).size().reset_index(name='count'))\n",
    "\n",
    "\n",
    "#Juan: Aqu√≠ me surge la duda, ya que ellos dijeron que las pruebas son Diciembre, Marzo y Rolling, pero cuando vemos el Plazo de admisi√≥n, hay en casi todos los meses, ¬øentra en la de diciembre la de noviembre? ¬øY en la de marzo entra febrero y abril? o que nos digan c√≥mo podemos detectar cuando es Rolling o no.\n",
    "\n",
    "# Juan: Master ponerlo siempre a Rolling, y el resto dejarlo con la l√≥gica de Diciembre, Marzo y Rolling. Despu√©s hacer un estudio valuecounts por Plazo en bruto, plazo limpio y tipo de carrera: grado o m√°ster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_integrado.columns.tolist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# COMPROBACI√ìN VARIABLES ECON√ìMICAS Y DE PAGO\n",
    "# ===============================\n",
    "\n",
    "# Juan: Variables a NaN\n",
    "# Variables econ√≥micas que queremos analizar\n",
    "vars_pago_esperadas = [\n",
    "    'CU_IMPORTE_TOTAL',\n",
    "    'PAID_AMOUNT',\n",
    "    'PAID_PERCENT'\n",
    "]\n",
    "\n",
    "# Filtrar solo las columnas que existen en df_integrado\n",
    "vars_pago_existentes = [v for v in vars_pago_esperadas if v in df_integrado.columns]\n",
    "\n",
    "# Mostrar cu√°les existen y cu√°les no\n",
    "print(\"Variables encontradas en df_integrado:\", vars_pago_existentes)\n",
    "vars_faltantes = [v for v in vars_pago_esperadas if v not in df_integrado.columns]\n",
    "if vars_faltantes:\n",
    "    print(\"‚ö†Ô∏è Variables no encontradas en df_integrado (no se incluyen en an√°lisis):\", vars_faltantes)\n",
    "\n",
    "# ===============================\n",
    "# NORMALIZAR VARIABLES DE PAGO\n",
    "# ===============================\n",
    "\n",
    "# Convertir a num√©rico las columnas de pago originales (forzando errores a NaN)\n",
    "\n",
    "# ===============================\n",
    "# DESCRIPCI√ìN ESTAD√çSTICA\n",
    "# ===============================\n",
    "\n",
    "print(\"\\n--- Descripci√≥n de las variables de pago existentes ---\")\n",
    "display(df_integrado[['CU_IMPORTE_TOTAL', 'PAID_AMOUNT', 'PAID_PERCENT']].describe())\n",
    "\n",
    "# ===============================\n",
    "# DETECCI√ìN DE INFORMACI√ìN FUTURA\n",
    "# ===============================\n",
    "\n",
    "if 'PAID_AMOUNT' in df_integrado.columns and 'PL_Etapa__c' in df_integrado.columns:\n",
    "    casos_incoherentes = df_integrado[\n",
    "        (df_integrado['PL_Etapa__c'] != 'Matr√≠cula') & \n",
    "        (df_integrado['PAID_AMOUNT'] > 0)\n",
    "    ]\n",
    "    print(f\"\\n‚ö†Ô∏è Casos con pagos antes de Matr√≠cula: {len(casos_incoherentes)}\")\n",
    "    display(casos_incoherentes[['ID', 'PL_Etapa__c', 'PAID_AMOUNT', 'target']])\n",
    "\n",
    "# Revisar registros con pagos positivos\n",
    "pagos_positivos = df_integrado[df_integrado['PAID_AMOUNT'] > 0]\n",
    "print(f\"\\nRegistros con PAID_AMOUNT > 0: {len(pagos_positivos)}\")\n",
    "display(pagos_positivos[['ID','PAID_AMOUNT','PAID_PERCENT','MINIMUMPAYMENTPAYED']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_integrado['NU_PREFERENCIA'].describe()\n",
    "#df_integrado[['CH_PAGADO__C', 'MINIMUMPAYMENTPAYED', 'IMPORTE_MINIMO_PERSONALIZADO']].describe()\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# DETECCI√ìN DE INFORMACI√ìN FUTURA\n",
    "# ===============================\n",
    "\n",
    "casos_incoherentes = df_integrado[\n",
    "    (df_integrado['PL_Etapa__c'] != 'Matr√≠cula') &\n",
    "    (df_integrado['PAID_AMOUNT'] > 0)\n",
    "]\n",
    "\n",
    "print(\"Casos con pago antes de etapa de matr√≠cula:\",\n",
    "      len(casos_incoherentes))\n",
    "\n",
    "df_final_filtrado = df_integrado.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAREA 3: De la pesta√±a ECB nos interesan tres variables por oportunidad: La renta familiar, el coste ordinario (el coste sin aplicar ning√∫n tipo de descuento) y el Importe matr√≠cula a pagar (que es el valor final que es el importe que paga el alumno con todos los descuentos aplicados), el % del total que acaba pagando el alumno (importe matr√≠cula/coste ordinario * 100). Importante que no aparezca esta variable informada antes de que se realice el estudio de la beca, se puede comprobar con la fecha de la etapa en la que se encuentra la oportunidad y la fecha de solicitud de la beca, en el caso que no haya un cruce m√°s sencillo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_integrado = df_final_filtrado.merge(\n",
    "    ecb[\n",
    "        [\n",
    "            'LK_oportunidad__c',\n",
    "            'FO_rentaMEC_for__c',\n",
    "            'FO_rentaFam_ges__c',\n",
    "            'CU_precioOrdinario_def__c',\n",
    "            'CU_precioIncentivado_def__c',\n",
    "            'CU_precioFamNum_def__c',\n",
    "            'PO_descFamNum_def__c',\n",
    "            'CU_precioAplicado_def__c'\n",
    "        ]\n",
    "    ],\n",
    "    left_on='ID',\n",
    "    right_on='LK_oportunidad__c',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# VARIABLES ECON√ìMICAS ECB FINALES\n",
    "# ===============================\n",
    "\n",
    "vars_ecb = [\n",
    "    'FO_rentaFam_ges__c',\n",
    "    'CU_precioOrdinario_def__c',\n",
    "    'CU_precioAplicado_def__c'\n",
    "]\n",
    "\n",
    "print(\"Variables ECB disponibles:\")\n",
    "print([v for v in vars_ecb if v in df_integrado.columns])\n",
    "\n",
    "df_integrado[vars_ecb].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# % PAGADO SOBRE COSTE ORDINARIO\n",
    "# ===============================\n",
    "\n",
    "# Calcular porcentaje pagado\n",
    "df_integrado['PORCENTAJE_PAGADO_FINAL'] = (\n",
    "    df_integrado['CU_precioAplicado_def__c'] /\n",
    "    df_integrado['CU_precioOrdinario_def__c']\n",
    ") * 100\n",
    "\n",
    "# Control de valores no v√°lidos (divisi√≥n por cero, negativos o >100)\n",
    "df_integrado.loc[\n",
    "    (df_integrado['CU_precioOrdinario_def__c'] <= 0) |\n",
    "    (df_integrado['PORCENTAJE_PAGADO_FINAL'] < 0) |\n",
    "    (df_integrado['PORCENTAJE_PAGADO_FINAL'] > 100),\n",
    "    'PORCENTAJE_PAGADO_FINAL'\n",
    "] = np.nan\n",
    "\n",
    "# Estad√≠sticas y comprobaci√≥n\n",
    "print(\"--- Estad√≠sticas PORCENTAJE_PAGADO_FINAL ---\")\n",
    "display(df_integrado['PORCENTAJE_PAGADO_FINAL'].describe())\n",
    "\n",
    "# Mostrar registros fuera de rango (solo si hay)\n",
    "fuera_rango = df_integrado[\n",
    "    (df_integrado['PORCENTAJE_PAGADO_FINAL'] < 0) |\n",
    "    (df_integrado['PORCENTAJE_PAGADO_FINAL'] > 100)\n",
    "]\n",
    "if len(fuera_rango) > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è Registros fuera de 0-100: {len(fuera_rango)}\")\n",
    "    display(fuera_rango[['ID', 'CU_precioAplicado_def__c', 'CU_precioOrdinario_def__c', 'PORCENTAJE_PAGADO_FINAL']])\n",
    "else:\n",
    "    print(\"\\n‚úÖ Todos los valores de PORCENTAJE_PAGADO_FINAL est√°n entre 0 y 100 o son NaN.\")\n",
    "\n",
    "#Juan: Comprobar que el porcentaje pagado final entra dentro de 0-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juan: Me parece m√°s robusto ordenar por fecha de creaci√≥n de las etapas, detectar cual es la primera en la que se paga, y en estapas anteriores a esa comprobar que siempre son NA, mirar construcci√≥n de limpiar_por_historial en Utils\n",
    "\n",
    "# ===============================\n",
    "# DETECCI√ìN DE INFORMACI√ìN FUTURA (BECAS / ECB)\n",
    "# ===============================\n",
    "\n",
    "# Ordenamos las etapas por fecha de creaci√≥n (asumiendo que existe 'fecha_creacion_etapa')\n",
    "df_integrado = df_integrado.sort_values(['ID', 'fecha_creacion_etapa'])\n",
    "\n",
    "# Detectar la primera etapa en la que hay pago aplicado\n",
    "df_integrado['primer_pago'] = df_integrado.groupby('ID')['CU_precioAplicado_def__c'].transform('first')\n",
    "\n",
    "# Casos donde hay pago antes de la primera etapa con pago\n",
    "casos_info_futura = df_integrado[\n",
    "    (df_integrado['CU_precioAplicado_def__c'].notna()) &\n",
    "    (df_integrado['CU_precioAplicado_def__c'] != df_integrado['primer_pago'])\n",
    "]\n",
    "\n",
    "print(\"‚ö†Ô∏è Casos con importe final antes de la primera etapa de pago:\", len(casos_info_futura))\n",
    "\n",
    "display(casos_info_futura[['ID', 'PL_Etapa__c', 'CU_precioAplicado_def__c', 'FO_rentaFam_ges__c']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_integrado.loc[\n",
    "    df_integrado['PL_Etapa__c'].isin(etapas_previas_beca),\n",
    "    ['CU_precioAplicado_def__c', 'PORCENTAJE_PAGADO_FINAL']\n",
    "] = np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAREA 4: De la pesta√±a de etapas, obtener el tiempo que lleva en cada etapa. En caso de ser la etapa actual, que se calcule como el tiempo entre el inicio de la etapa y la fecha de hoy en d√≠as."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utils\n",
    "\n",
    "importlib.reload(utils)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import calcular_tiempos_etapas\n",
    "# ===============================\n",
    "# TIEMPO EN CADA ETAPA (USANDO UTILS)\n",
    "# ===============================\n",
    "\n",
    "df_etapas = calcular_tiempos_etapas(historial_etapas)\n",
    "df_etapas.head()\n",
    "\n",
    "\n",
    "# Juan: Hay una funci√≥n en utils que lo hace: calcular_tiempo_etapas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAREA 5: De la pesta√±a de historial de actividades obtener el n√∫mero de actividades que lleva asistidas hasta esa etapa, comprobar que se calcula bien. Si da tiempo, a√±adir las actividades de la pesta√±a casos que son \"Asistencia familias\" para que se cuente como actividad. Importante comprobar que no se cuentan actividades futuras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# LIMPIEZA ACTIVIDADES\n",
    "# ===============================\n",
    "# Juan: Hay una funci√≥n en utils. Hay que a√±adir las actividades de tipo \"Familiar\" de la pesta√±a \"Casos\"\n",
    "df_act = df_actividades.copy()\n",
    "\n",
    "# Fecha actividad\n",
    "df_act['fecha_actividad'] = pd.to_datetime(\n",
    "    df_act['ActivityDate'],\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# Nos quedamos solo con actividades asistidas / completadas\n",
    "df_act = df_act[\n",
    "    df_act['Status'].isin(['Asistida', 'Completada', 'Completed'])\n",
    "]\n",
    "\n",
    "df_act = df_act[\n",
    "    ['LK_Oportunidad__c', 'fecha_actividad']\n",
    "].dropna()\n",
    "\n",
    "#Restore hasta aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAREA 6: Comprobar varios ejemplos y asegurar que no hay variables informadas con informaci√≥n del futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TAREA 6 ¬∑ COMPROBACI√ìN DE INFORMACI√ìN DEL FUTURO (LEAKAGE)\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"üîç INICIO COMPROBACI√ìN DE INFORMACI√ìN DEL FUTURO\\n\")\n",
    "\n",
    "# ===============================\n",
    "# 1. DEFINICI√ìN DE REGLAS TEMPORALES\n",
    "# ===============================\n",
    "\n",
    "reglas_futuro = {\n",
    "    \"Pago y matr√≠cula\": {\n",
    "        \"etapas_no_permitidas\": [\n",
    "            'Solicitud',\n",
    "            'Pruebas',\n",
    "            'Admisi√≥n acad√©mica'\n",
    "        ],\n",
    "        \"variables\": [\n",
    "            'PAID_AMOUNT',\n",
    "            'MINIMUMPAYMENTPAYED',\n",
    "            'CH_PAGADO__C',\n",
    "            'CU_precioAplicado_def__c',\n",
    "            'PORCENTAJE_PAGADO_FINAL'\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"Resultados finales\": {\n",
    "        \"etapas_no_permitidas\": [\n",
    "            'Solicitud',\n",
    "            'Pruebas'\n",
    "        ],\n",
    "        \"variables\": [\n",
    "            'PL_RESOLUCION_DEFINITIVA'\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# ===============================\n",
    "# 2. DETECCI√ìN AUTOM√ÅTICA\n",
    "# ===============================\n",
    "\n",
    "leakage_detectado = []\n",
    "\n",
    "for bloque, regla in reglas_futuro.items():\n",
    "    \n",
    "    etapas = regla[\"etapas_no_permitidas\"]\n",
    "    variables = [v for v in regla[\"variables\"] if v in df_final.columns]\n",
    "    \n",
    "    if not variables:\n",
    "        continue\n",
    "    \n",
    "    mask = (\n",
    "        df_final['PL_Etapa__c'].isin(etapas) &\n",
    "        df_final[variables].notna().any(axis=1)\n",
    "    )\n",
    "    \n",
    "    casos = df_final.loc[\n",
    "        mask,\n",
    "        ['ID', 'PL_Etapa__c'] + variables\n",
    "    ].copy()\n",
    "    \n",
    "    if not casos.empty:\n",
    "        casos['Bloque'] = bloque\n",
    "        leakage_detectado.append(casos)\n",
    "\n",
    "df_leakage = (\n",
    "    pd.concat(leakage_detectado, ignore_index=True)\n",
    "    if leakage_detectado\n",
    "    else pd.DataFrame()\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# 3. RESULTADOS GENERALES\n",
    "# ===============================\n",
    "\n",
    "if df_leakage.empty:\n",
    "    print(\"‚úÖ No se detecta informaci√≥n del futuro en el dataset.\\n\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Se detectan {df_leakage['ID'].nunique()} oportunidades con posible informaci√≥n futura.\\n\")\n",
    "    display(df_leakage.head(10))\n",
    "\n",
    "# ===============================\n",
    "# 4. REVISI√ìN MANUAL DE EJEMPLOS\n",
    "# ===============================\n",
    "\n",
    "if not df_leakage.empty:\n",
    "    \n",
    "    ejemplos_ids = df_leakage['ID'].unique()[:3]\n",
    "    \n",
    "    columnas_revision = [\n",
    "        'ID',\n",
    "        'CreatedDate',\n",
    "        'PL_Etapa__c',\n",
    "        'PAID_AMOUNT',\n",
    "        'MINIMUMPAYMENTPAYED',\n",
    "        'CU_precioAplicado_def__c',\n",
    "        'PORCENTAJE_PAGADO_FINAL',\n",
    "        'PL_RESOLUCION_DEFINITIVA',\n",
    "        'target'\n",
    "    ]\n",
    "    \n",
    "    columnas_revision = [\n",
    "        c for c in columnas_revision if c in df_integrado.columns\n",
    "    ]\n",
    "    \n",
    "    print(\"üìå REVISI√ìN MANUAL DE EJEMPLOS:\\n\")\n",
    "    \n",
    "    display(\n",
    "        df_integrado[\n",
    "            df_integrado['ID'].isin(ejemplos_ids)\n",
    "        ][columnas_revision]\n",
    "        .sort_values(['ID', 'CreatedDate'])\n",
    "    )\n",
    "\n",
    "# ===============================\n",
    "# 5. CONCLUSI√ìN FINAL\n",
    "# ===============================\n",
    "\n",
    "if df_leakage.empty:\n",
    "    print(\"üéØ CONCLUSI√ìN: Dataset limpio temporalmente. Apto para modelado.\")\n",
    "else:\n",
    "    print(\"üö® CONCLUSI√ìN: Revisar y corregir variables con informaci√≥n futura antes de modelar.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay un total de 15470 matr√≠culas formalizadas. Un 22.03% del total de oportunidades\n",
      "Hay un total de 1495 desmatriculados. Un 9.66% del total de matriculados\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SCRIPT ¬∑ DATASET DE TRATAMIENTO DEFINITIVO FINAL\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import crear_target, eliminar_columnas_na, calcular_tiempos_etapas, integrar_actividades_progresivo_por_curso\n",
    "# ============================================================\n",
    "# 1Ô∏è‚É£ CARGA DE DATOS\n",
    "# ============================================================\n",
    "\n",
    "ruta_excel = r'datos\\01. Datos originales\\DataSET_SF - V2.xlsx'\n",
    "dfs = pd.read_excel(ruta_excel, sheet_name=None)\n",
    "\n",
    "# Asignar cada hoja a un dataframe\n",
    "oportunidad = list(dfs.values())[0]\n",
    "cuenta = list(dfs.values())[1]\n",
    "ecb = list(dfs.values())[2]\n",
    "solicitud_ban = list(dfs.values())[3]\n",
    "casos = list(dfs.values())[4]\n",
    "correos = list(dfs.values())[5]\n",
    "historial_actividad = list(dfs.values())[6]\n",
    "historial_etapas = list(dfs.values())[7]\n",
    "\n",
    "# ============================================================\n",
    "# 2Ô∏è‚É£ LIMPIEZA INICIAL DE NAS Y COLUMNAS\n",
    "# ============================================================\n",
    "\n",
    "def eliminar_columnas_na(df, umbral=0.9):\n",
    "    \"\"\"Elimina columnas con m√°s de un umbral de valores NA\"\"\"\n",
    "    return df.loc[:, df.isna().mean() < umbral]\n",
    "\n",
    "for df in [oportunidad, cuenta, ecb, solicitud_ban, casos, correos, historial_actividad, historial_etapas]:\n",
    "    df = eliminar_columnas_na(df)\n",
    "\n",
    "oportunidad = eliminar_columnas_na(oportunidad)\n",
    "cuenta = eliminar_columnas_na(cuenta)\n",
    "ecb = eliminar_columnas_na(ecb)\n",
    "\n",
    "# ============================================================\n",
    "# 3Ô∏è‚É£ CREACI√ìN DEL TARGET\n",
    "# ============================================================\n",
    "\n",
    "oportunidad = crear_target(oportunidad, historial_etapas)\n",
    "\n",
    "# Uni√≥n con cuenta\n",
    "\n",
    "df_unido = pd.merge(\n",
    "    oportunidad, \n",
    "    cuenta, \n",
    "    left_on='ACCOUNTID', \n",
    "    right_on='ID18', \n",
    "    how='left',\n",
    "    suffixes=('', '_cuenta')\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4Ô∏è‚É£ CONSTRUCCI√ìN VARIABLES DERIVADAS\n",
    "# ============================================================\n",
    "\n",
    "# Limpiar y crear plazo de admisi√≥n\n",
    "def normalizar_plazo(x):\n",
    "    if pd.isna(x): return \"Rolling\"\n",
    "    x = str(x).strip().lower()\n",
    "    if \"dic\" in x: return \"Diciembre\"\n",
    "    if \"mar\" in x: return \"Marzo\"\n",
    "    return \"Otros\"\n",
    "\n",
    "df_unido['PLAZO_ADMISION_LIMPIO'] = df_unido['PL_PLAZO_ADMISION'].apply(normalizar_plazo)\n",
    "\n",
    "# Variables econ√≥micas ECB\n",
    "ecb_vars = ['LK_oportunidad__c', 'FO_rentaFam_ges__c', 'CU_precioOrdinario_def__c', 'CU_precioAplicado_def__c']\n",
    "df_definitivo = pd.merge(\n",
    "    df_unido,\n",
    "    ecb[ecb_vars],\n",
    "    left_on='ID',\n",
    "    right_on='LK_oportunidad__c',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# % pagado\n",
    "df_definitivo['PORCENTAJE_PAGADO_FINAL'] = (\n",
    "    df_definitivo['CU_precioAplicado_def__c'] / df_definitivo['CU_precioOrdinario_def__c'] * 100\n",
    ")\n",
    "df_definitivo.loc[df_definitivo['CU_precioOrdinario_def__c'] <= 0, 'PORCENTAJE_PAGADO_FINAL'] = np.nan\n",
    "\n",
    "ruta_salida = r\"C:\\Users\\0017655\\Downloads\\dataset_analisis_final.csv\"\n",
    "df_definitivo.to_csv(ruta_salida, sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando 536604 filas con l√≥gica de curso y progresi√≥n temporal...\n",
      "Cruzando datos por ID18__PC y Curso Acad√©mico...\n",
      "Aplicando filtro temporal progresivo...\n",
      "Agrupando resultados...\n",
      "Consolidando en el DataFrame maestro...\n",
      "‚úÖ Proceso completado.\n",
      "‚úÖ Dataset de tratamiento definitivo guardado en: C:\\Users\\0017655\\Downloads\\dataset_tratamiento_final.csv\n",
      "Dimensiones: (536604, 48)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACCOUNTID</th>\n",
       "      <th>ID</th>\n",
       "      <th>ID18__PC</th>\n",
       "      <th>target</th>\n",
       "      <th>desmatriculado</th>\n",
       "      <th>PL_CURSO_ACADEMICO</th>\n",
       "      <th>CH_NACIONAL</th>\n",
       "      <th>NU_NOTA_MEDIA_ADMISION</th>\n",
       "      <th>NU_NOTA_MEDIA_1_BACH__PC</th>\n",
       "      <th>CH_PRUEBAS_CALIFICADAS</th>\n",
       "      <th>...</th>\n",
       "      <th>RECORDTYPENAME</th>\n",
       "      <th>PLAZO_ADMISION_LIMPIO</th>\n",
       "      <th>FO_rentaFam_ges__c</th>\n",
       "      <th>CU_precioOrdinario_def__c</th>\n",
       "      <th>CU_precioAplicado_def__c</th>\n",
       "      <th>PORCENTAJE_PAGADO_FINAL</th>\n",
       "      <th>tiempo_etapa_dias</th>\n",
       "      <th>tiempo_entre_etapas_dias</th>\n",
       "      <th>num_asistencias_acum</th>\n",
       "      <th>num_solicitudes_acum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001w000001X8jDhAAJ</td>\n",
       "      <td>0061r00000yz6vuAAA</td>\n",
       "      <td>003w000001knzGTAAY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022/2023</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Solicitud Admisi√≥n Grado</td>\n",
       "      <td>Diciembre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001w000001X8jDhAAJ</td>\n",
       "      <td>0061r00000yz6vuAAA</td>\n",
       "      <td>003w000001knzGTAAY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022/2023</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Solicitud Admisi√≥n Grado</td>\n",
       "      <td>Diciembre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001w000001X8jDhAAJ</td>\n",
       "      <td>0061r00000yz6vuAAA</td>\n",
       "      <td>003w000001knzGTAAY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022/2023</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Solicitud Admisi√≥n Grado</td>\n",
       "      <td>Diciembre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001w000001X8jDhAAJ</td>\n",
       "      <td>0061r00000yz6vuAAA</td>\n",
       "      <td>003w000001knzGTAAY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022/2023</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Solicitud Admisi√≥n Grado</td>\n",
       "      <td>Diciembre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001w000001X8jDhAAJ</td>\n",
       "      <td>0061r00000yz6vuAAA</td>\n",
       "      <td>003w000001knzGTAAY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022/2023</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Solicitud Admisi√≥n Grado</td>\n",
       "      <td>Diciembre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ACCOUNTID                  ID            ID18__PC  target  \\\n",
       "0  001w000001X8jDhAAJ  0061r00000yz6vuAAA  003w000001knzGTAAY     0.0   \n",
       "1  001w000001X8jDhAAJ  0061r00000yz6vuAAA  003w000001knzGTAAY     0.0   \n",
       "2  001w000001X8jDhAAJ  0061r00000yz6vuAAA  003w000001knzGTAAY     0.0   \n",
       "3  001w000001X8jDhAAJ  0061r00000yz6vuAAA  003w000001knzGTAAY     0.0   \n",
       "4  001w000001X8jDhAAJ  0061r00000yz6vuAAA  003w000001knzGTAAY     0.0   \n",
       "\n",
       "   desmatriculado PL_CURSO_ACADEMICO CH_NACIONAL  NU_NOTA_MEDIA_ADMISION  \\\n",
       "0             0.0          2022/2023        True                     NaN   \n",
       "1             0.0          2022/2023        True                     NaN   \n",
       "2             0.0          2022/2023        True                     NaN   \n",
       "3             0.0          2022/2023        True                     NaN   \n",
       "4             0.0          2022/2023        True                     NaN   \n",
       "\n",
       "   NU_NOTA_MEDIA_1_BACH__PC CH_PRUEBAS_CALIFICADAS  ...  \\\n",
       "0                       6.0                  False  ...   \n",
       "1                       6.0                  False  ...   \n",
       "2                       6.0                  False  ...   \n",
       "3                       6.0                  False  ...   \n",
       "4                       6.0                  False  ...   \n",
       "\n",
       "             RECORDTYPENAME PLAZO_ADMISION_LIMPIO FO_rentaFam_ges__c  \\\n",
       "0  Solicitud Admisi√≥n Grado             Diciembre                NaN   \n",
       "1  Solicitud Admisi√≥n Grado             Diciembre                NaN   \n",
       "2  Solicitud Admisi√≥n Grado             Diciembre                NaN   \n",
       "3  Solicitud Admisi√≥n Grado             Diciembre                NaN   \n",
       "4  Solicitud Admisi√≥n Grado             Diciembre                NaN   \n",
       "\n",
       "  CU_precioOrdinario_def__c  CU_precioAplicado_def__c  \\\n",
       "0                       NaN                       NaN   \n",
       "1                       NaN                       NaN   \n",
       "2                       NaN                       NaN   \n",
       "3                       NaN                       NaN   \n",
       "4                       NaN                       NaN   \n",
       "\n",
       "   PORCENTAJE_PAGADO_FINAL  tiempo_etapa_dias tiempo_entre_etapas_dias  \\\n",
       "0                      NaN                  0                        0   \n",
       "1                      NaN                  0                        0   \n",
       "2                      NaN                  0                        0   \n",
       "3                      NaN                  0                        0   \n",
       "4                      NaN                  0                        0   \n",
       "\n",
       "  num_asistencias_acum num_solicitudes_acum  \n",
       "0                    0                    0  \n",
       "1                    0                    0  \n",
       "2                    0                    0  \n",
       "3                    0                    0  \n",
       "4                    0                    0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from utils import calcular_tiempos_etapas, integrar_actividades_progresivo_por_curso\n",
    "\n",
    "# ============================================================\n",
    "# 5Ô∏è‚É£ TIEMPO EN CADA ETAPA\n",
    "# ============================================================\n",
    "\n",
    "historial_etapas_tiempo = calcular_tiempos_etapas(historial_etapas)\n",
    "df_definitivo = historial_etapas_tiempo.merge(df_definitivo, left_on='LK_Oportunidad__c', right_on='ID', how='left')\n",
    "\n",
    "# ============================================================\n",
    "# 6Ô∏è‚É£ HISTORIAL DE ACTIVIDADES\n",
    "# ============================================================\n",
    "\n",
    "df_definitivo = integrar_actividades_progresivo_por_curso(df_definitivo, historial_actividad)\n",
    "\n",
    "# ============================================================\n",
    "# 7Ô∏è‚É£ CONTROL DE INFORMACI√ìN FUTURA (LEAKAGE)\n",
    "# ============================================================\n",
    "\n",
    "etapas_pago = ['Solicitud', 'Pruebas', 'Admisi√≥n acad√©mica']\n",
    "vars_pago = ['PAID_AMOUNT','MINIMUMPAYMENTPAYED','CU_precioAplicado_def__c','PORCENTAJE_PAGADO_FINAL']\n",
    "vars_pago = [v for v in vars_pago if v in df_definitivo.columns]\n",
    "\n",
    "mask_futuro = (df_definitivo['PL_Etapa__c'].isin(etapas_pago)) & (df_definitivo[vars_pago].notna().any(axis=1))\n",
    "df_definitivo.loc[mask_futuro, vars_pago] = np.nan\n",
    "\n",
    "# ============================================================\n",
    "# 8Ô∏è‚É£ SELECCI√ìN VARIABLES FINALES\n",
    "# ============================================================\n",
    "columnas_seleccionadas = [\n",
    "    'ACCOUNTID', 'ID','ID18__PC', 'target', 'desmatriculado', 'PL_CURSO_ACADEMICO', 'CH_NACIONAL',\n",
    "    'NU_NOTA_MEDIA_ADMISION', 'NU_NOTA_MEDIA_1_BACH__PC', 'CH_PRUEBAS_CALIFICADAS', \n",
    "    'NU_RESULTADO_ADMISION_PUNTOS', 'PL_RESOLUCION_DEFINITIVA', 'TITULACION', 'CENTROENSENANZA',\n",
    "    'MINIMUMPAYMENTPAYED', 'PAID_AMOUNT', 'PAID_PERCENT', 'CH_PAGO_SUPERIOR', \n",
    "    'CH_MATRICULA_SUJETA_BECA', 'CH_AYUDA_FINANCIACION', 'CU_IMPORTE_TOTAL',\n",
    "    'CH_VISITACAMPUS__PC', 'CH_ENTREVISTA_PERSONAL__PC', 'ACC_DTT_FECHAULTIMAACTIVIDAD', \n",
    "    'NU_PREFERENCIA', 'STAGENAME', 'PL_SUBETAPA',\n",
    "    'CH_HIJO_EMPLEADO__PC', 'CH_HIJO_PROFESOR_ASOCIADO__PC', 'CH_HERMANOS_ESTUDIANDO_UNAV__P', \n",
    "    'CH_HIJO_MEDICO__PC', 'YEARPERSONBIRTHDATE', 'NAMEX', 'CH_FAMILIA_NUMEROSA__PC', \n",
    "    'PL_SITUACION_SOCIO_ECONOMICA', 'LEADSOURCE', 'PL_ORIGEN_DE_SOLICITUD', \n",
    "    'PL_PLAZO_ADMISION', 'RECORDTYPENAME','PLAZO_ADMISION_LIMPIO','FO_rentaFam_ges__c','CU_precioOrdinario_def__c',\n",
    "    'CU_precioAplicado_def__c','PORCENTAJE_PAGADO_FINAL','tiempo_etapa_dias','tiempo_entre_etapas_dias','num_asistencias_acum', 'num_solicitudes_acum'\n",
    "]\n",
    "\n",
    "\n",
    "#columnas_finales = [c for c in columnas_finales if c in df_definitivo.columns]\n",
    "df_definitivo = df_definitivo[columnas_seleccionadas]\n",
    "\n",
    "# ============================================================\n",
    "# 9Ô∏è‚É£ GUARDAR DATASET TRATAMIENTO DEFINITIVO\n",
    "# ============================================================\n",
    "\n",
    "ruta_salida = r\"C:\\Users\\0017655\\Downloads\\dataset_tratamiento_final.csv\"\n",
    "df_definitivo.to_csv(ruta_salida, sep=\";\", index=False)\n",
    "\n",
    "print(f\"‚úÖ Dataset de tratamiento definitivo guardado en: {ruta_salida}\")\n",
    "print(f\"Dimensiones: {df_definitivo.shape}\")\n",
    "df_definitivo.head()\n",
    "\n",
    "\n",
    "### FIN DEL SCRIPT -> meter en 01 limpieza datasets.py y comentar, generar un 02 de analisis para empezar con correlaciones, clusters, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CODIGO COMPLETAMENTE UNIDO, LIMPIO Y COMENTADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay un total de 15470 matr√≠culas formalizadas. Un 22.03% del total de oportunidades\n",
      "Hay un total de 1495 desmatriculados. Un 9.66% del total de matriculados\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\0021755\\OneDrive - ViewNext\\proyectoUNAV\\gitUNAV\\UNAV\\notebooks\\utils.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oportunidad['target'] = oportunidad['ID'].apply(\n",
      "c:\\Users\\0021755\\OneDrive - ViewNext\\proyectoUNAV\\gitUNAV\\UNAV\\notebooks\\utils.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando 536604 filas con l√≥gica de curso y progresi√≥n temporal...\n",
      "Cruzando datos por ID18__PC y Curso Acad√©mico...\n",
      "Aplicando filtro temporal progresivo...\n",
      "Agrupando resultados...\n",
      "Consolidando en el DataFrame maestro...\n",
      "‚úÖ Proceso completado.\n",
      "‚úÖ Dataset de tratamiento definitivo guardado en: ..\\datos\\01. Datos originales\\dataset_tratamiento_final.csv\n",
      "Dimensiones: (536604, 48)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACCOUNTID</th>\n",
       "      <th>ID</th>\n",
       "      <th>ID18__PC</th>\n",
       "      <th>target</th>\n",
       "      <th>desmatriculado</th>\n",
       "      <th>PL_CURSO_ACADEMICO</th>\n",
       "      <th>CH_NACIONAL</th>\n",
       "      <th>NU_NOTA_MEDIA_ADMISION</th>\n",
       "      <th>NU_NOTA_MEDIA_1_BACH__PC</th>\n",
       "      <th>CH_PRUEBAS_CALIFICADAS</th>\n",
       "      <th>...</th>\n",
       "      <th>RECORDTYPENAME</th>\n",
       "      <th>PLAZO_ADMISION_LIMPIO</th>\n",
       "      <th>FO_rentaFam_ges__c</th>\n",
       "      <th>CU_precioOrdinario_def__c</th>\n",
       "      <th>CU_precioAplicado_def__c</th>\n",
       "      <th>PORCENTAJE_PAGADO_FINAL</th>\n",
       "      <th>tiempo_etapa_dias</th>\n",
       "      <th>tiempo_entre_etapas_dias</th>\n",
       "      <th>num_asistencias_acum</th>\n",
       "      <th>num_solicitudes_acum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001w000001X8jDhAAJ</td>\n",
       "      <td>0061r00000yz6vuAAA</td>\n",
       "      <td>003w000001knzGTAAY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022/2023</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Solicitud Admisi√≥n Grado</td>\n",
       "      <td>Diciembre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001w000001X8jDhAAJ</td>\n",
       "      <td>0061r00000yz6vuAAA</td>\n",
       "      <td>003w000001knzGTAAY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022/2023</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Solicitud Admisi√≥n Grado</td>\n",
       "      <td>Diciembre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001w000001X8jDhAAJ</td>\n",
       "      <td>0061r00000yz6vuAAA</td>\n",
       "      <td>003w000001knzGTAAY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022/2023</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Solicitud Admisi√≥n Grado</td>\n",
       "      <td>Diciembre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001w000001X8jDhAAJ</td>\n",
       "      <td>0061r00000yz6vuAAA</td>\n",
       "      <td>003w000001knzGTAAY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022/2023</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Solicitud Admisi√≥n Grado</td>\n",
       "      <td>Diciembre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001w000001X8jDhAAJ</td>\n",
       "      <td>0061r00000yz6vuAAA</td>\n",
       "      <td>003w000001knzGTAAY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022/2023</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>Solicitud Admisi√≥n Grado</td>\n",
       "      <td>Diciembre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ACCOUNTID                  ID            ID18__PC  target  \\\n",
       "0  001w000001X8jDhAAJ  0061r00000yz6vuAAA  003w000001knzGTAAY     0.0   \n",
       "1  001w000001X8jDhAAJ  0061r00000yz6vuAAA  003w000001knzGTAAY     0.0   \n",
       "2  001w000001X8jDhAAJ  0061r00000yz6vuAAA  003w000001knzGTAAY     0.0   \n",
       "3  001w000001X8jDhAAJ  0061r00000yz6vuAAA  003w000001knzGTAAY     0.0   \n",
       "4  001w000001X8jDhAAJ  0061r00000yz6vuAAA  003w000001knzGTAAY     0.0   \n",
       "\n",
       "   desmatriculado PL_CURSO_ACADEMICO CH_NACIONAL  NU_NOTA_MEDIA_ADMISION  \\\n",
       "0             0.0          2022/2023        True                     NaN   \n",
       "1             0.0          2022/2023        True                     NaN   \n",
       "2             0.0          2022/2023        True                     NaN   \n",
       "3             0.0          2022/2023        True                     NaN   \n",
       "4             0.0          2022/2023        True                     NaN   \n",
       "\n",
       "   NU_NOTA_MEDIA_1_BACH__PC CH_PRUEBAS_CALIFICADAS  ...  \\\n",
       "0                       6.0                  False  ...   \n",
       "1                       6.0                  False  ...   \n",
       "2                       6.0                  False  ...   \n",
       "3                       6.0                  False  ...   \n",
       "4                       6.0                  False  ...   \n",
       "\n",
       "             RECORDTYPENAME PLAZO_ADMISION_LIMPIO FO_rentaFam_ges__c  \\\n",
       "0  Solicitud Admisi√≥n Grado             Diciembre                NaN   \n",
       "1  Solicitud Admisi√≥n Grado             Diciembre                NaN   \n",
       "2  Solicitud Admisi√≥n Grado             Diciembre                NaN   \n",
       "3  Solicitud Admisi√≥n Grado             Diciembre                NaN   \n",
       "4  Solicitud Admisi√≥n Grado             Diciembre                NaN   \n",
       "\n",
       "  CU_precioOrdinario_def__c  CU_precioAplicado_def__c  \\\n",
       "0                       NaN                       NaN   \n",
       "1                       NaN                       NaN   \n",
       "2                       NaN                       NaN   \n",
       "3                       NaN                       NaN   \n",
       "4                       NaN                       NaN   \n",
       "\n",
       "   PORCENTAJE_PAGADO_FINAL  tiempo_etapa_dias tiempo_entre_etapas_dias  \\\n",
       "0                      NaN                  0                        0   \n",
       "1                      NaN                  0                        0   \n",
       "2                      NaN                  0                        0   \n",
       "3                      NaN                  0                        0   \n",
       "4                      NaN                  0                        0   \n",
       "\n",
       "  num_asistencias_acum num_solicitudes_acum  \n",
       "0                    0                    0  \n",
       "1                    0                    0  \n",
       "2                    0                    0  \n",
       "3                    0                    0  \n",
       "4                    0                    0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SCRIPT ¬∑ DATASET DE TRATAMIENTO DEFINITIVO FINAL\n",
    "# ============================================================\n",
    "# Objetivo:\n",
    "#   - Construir el dataset final de modelizaci√≥n a partir de Salesforce\n",
    "#   - Integrar informaci√≥n acad√©mica, econ√≥mica, actividades y tiempos\n",
    "#   - Controlar leakage de informaci√≥n futura\n",
    "#   - Dejar el dataset listo para an√°lisis y ML\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import crear_target, eliminar_columnas_na, calcular_tiempos_etapas, integrar_actividades_progresivo_por_curso\n",
    "\n",
    "# Funciones auxiliares definidas en utils.py\n",
    "# - crear_target: construye la variable objetivo a partir del historial de etapas\n",
    "# - eliminar_columnas_na: elimina columnas con exceso de valores nulos\n",
    "# - calcular_tiempos_etapas: calcula duraci√≥n en cada etapa del funnel\n",
    "# - integrar_actividades_progresivo_por_curso: agrega actividades acumuladas\n",
    "\n",
    "# ============================================================\n",
    "# 1Ô∏è‚É£ CARGA DE DATOS\n",
    "# ============================================================\n",
    "# Se carga el Excel completo de Salesforce\n",
    "# Cada hoja corresponde a una entidad distinta\n",
    "# ============================================================\n",
    "\n",
    "ruta_excel = r\"..\\datos\\01. Datos originales\\DataSET_SF - V2.xlsx\"\n",
    "dfs = pd.read_excel(ruta_excel, sheet_name=None)\n",
    "\n",
    "# Asignar cada hoja a un dataframe independiente\n",
    "# El orden debe coincidir con el Excel original\n",
    "oportunidad = list(dfs.values())[0]\n",
    "cuenta = list(dfs.values())[1]\n",
    "ecb = list(dfs.values())[2]\n",
    "solicitud_ban = list(dfs.values())[3]\n",
    "casos = list(dfs.values())[4]\n",
    "correos = list(dfs.values())[5]\n",
    "historial_actividad = list(dfs.values())[6]\n",
    "historial_etapas = list(dfs.values())[7]\n",
    "\n",
    "# ============================================================\n",
    "# 2Ô∏è‚É£ LIMPIEZA INICIAL DE NAS Y COLUMNAS\n",
    "# ============================================================\n",
    "# Se eliminan columnas con un porcentaje de NA superior al umbral\n",
    "# Esto reduce ruido y dimensionalidad desde el inicio\n",
    "# ============================================================\n",
    "\n",
    "def eliminar_columnas_na(df, umbral=0.9):\n",
    "    \"\"\"Elimina columnas con m√°s de un umbral de valores NA\"\"\"\n",
    "    return df.loc[:, df.isna().mean() < umbral]\n",
    "\n",
    "\n",
    "# Limpieza gen√©rica (no modifica los dataframes originales)\n",
    "for df in [oportunidad, cuenta, ecb, solicitud_ban, casos, correos, historial_actividad, historial_etapas]:\n",
    "    df = eliminar_columnas_na(df)\n",
    "\n",
    "\n",
    "# Limpieza efectiva sobre los dataframes clave\n",
    "oportunidad = eliminar_columnas_na(oportunidad)\n",
    "cuenta = eliminar_columnas_na(cuenta)\n",
    "ecb = eliminar_columnas_na(ecb)\n",
    "\n",
    "# ============================================================\n",
    "# 3Ô∏è‚É£ CREACI√ìN DEL TARGET\n",
    "# ============================================================\n",
    "# Se construye la variable objetivo (target) usando el historial de etapas\n",
    "# ============================================================\n",
    "\n",
    "oportunidad = crear_target(oportunidad, historial_etapas)\n",
    "\n",
    "\n",
    "# Uni√≥n de oportunidad con datos de cuenta/persona\n",
    "# Se hace LEFT JOIN para no perder oportunidades\n",
    "\n",
    "df_unido = pd.merge(\n",
    "    oportunidad, \n",
    "    cuenta, \n",
    "    left_on='ACCOUNTID', \n",
    "    right_on='ID18', \n",
    "    how='left',\n",
    "    suffixes=('', '_cuenta')\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4Ô∏è‚É£ CONSTRUCCI√ìN VARIABLES DERIVADAS\n",
    "# ============================================================\n",
    "# Se crean variables explicativas a partir de campos originales\n",
    "# ============================================================\n",
    "\n",
    "# Normalizaci√≥n del plazo de admisi√≥n\n",
    "# Se agrupan valores heterog√©neos en categor√≠as consistentes\n",
    "def normalizar_plazo(x):\n",
    "    if pd.isna(x): return \"Rolling\"\n",
    "    x = str(x).strip().lower()\n",
    "    if \"dic\" in x: return \"Diciembre\"\n",
    "    if \"mar\" in x: return \"Marzo\"\n",
    "    return \"Otros\"\n",
    "\n",
    "df_unido['PLAZO_ADMISION_LIMPIO'] = df_unido['PL_PLAZO_ADMISION'].apply(normalizar_plazo)\n",
    "\n",
    "# Uni√≥n con informaci√≥n econ√≥mica (ECB)\n",
    "# Se incorporan precios y renta familiar\n",
    "ecb_vars = ['LK_oportunidad__c', 'FO_rentaFam_ges__c', 'CU_precioOrdinario_def__c', 'CU_precioAplicado_def__c']\n",
    "df_definitivo = pd.merge(\n",
    "    df_unido,\n",
    "    ecb[ecb_vars],\n",
    "    left_on='ID',\n",
    "    right_on='LK_oportunidad__c',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "\n",
    "# C√°lculo del porcentaje pagado final\n",
    "# Se controla divisi√≥n por cero\n",
    "df_definitivo['PORCENTAJE_PAGADO_FINAL'] = (\n",
    "    df_definitivo['CU_precioAplicado_def__c'] / df_definitivo['CU_precioOrdinario_def__c'] * 100\n",
    ")\n",
    "df_definitivo.loc[df_definitivo['CU_precioOrdinario_def__c'] <= 0, 'PORCENTAJE_PAGADO_FINAL'] = np.nan\n",
    "\n",
    "\n",
    "# Guardado intermedio (dataset de an√°lisis)\n",
    "ruta_salida = r\"..\\datos\\01. Datos originales\\dataset_analisis_final.csv\"\n",
    "df_definitivo.to_csv(ruta_salida, sep=\";\", index=False)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5Ô∏è‚É£ TIEMPO EN CADA ETAPA\n",
    "# ============================================================\n",
    "# Se calcula el tiempo pasado en cada etapa del funnel\n",
    "# ============================================================\n",
    "\n",
    "historial_etapas_tiempo = calcular_tiempos_etapas(historial_etapas)\n",
    "df_definitivo = historial_etapas_tiempo.merge(df_definitivo, left_on='LK_Oportunidad__c', right_on='ID', how='left')\n",
    "\n",
    "# ============================================================\n",
    "# 6Ô∏è‚É£ HISTORIAL DE ACTIVIDADES\n",
    "# ============================================================\n",
    "# Se integran actividades acumuladas por curso\n",
    "# Evita usar informaci√≥n futura respecto a la etapa\n",
    "# ============================================================\n",
    "\n",
    "df_definitivo = integrar_actividades_progresivo_por_curso(df_definitivo, historial_actividad)\n",
    "\n",
    "# ============================================================\n",
    "# 7Ô∏è‚É£ CONTROL DE INFORMACI√ìN FUTURA (LEAKAGE)\n",
    "# ============================================================\n",
    "# Se eliminan variables econ√≥micas si aparecen en etapas tempranas\n",
    "# ============================================================\n",
    "\n",
    "etapas_pago = ['Solicitud', 'Pruebas', 'Admisi√≥n acad√©mica']\n",
    "vars_pago = ['PAID_AMOUNT','MINIMUMPAYMENTPAYED','CU_precioAplicado_def__c','PORCENTAJE_PAGADO_FINAL']\n",
    "vars_pago = [v for v in vars_pago if v in df_definitivo.columns]\n",
    "\n",
    "mask_futuro = (df_definitivo['PL_Etapa__c'].isin(etapas_pago)) & (df_definitivo[vars_pago].notna().any(axis=1))\n",
    "df_definitivo.loc[mask_futuro, vars_pago] = np.nan\n",
    "\n",
    "# ============================================================\n",
    "# 8Ô∏è‚É£ SELECCI√ìN VARIABLES FINALES\n",
    "# ============================================================\n",
    "# Se define expl√≠citamente el conjunto final de variables\n",
    "# ============================================================\n",
    "columnas_seleccionadas = [\n",
    "    'ACCOUNTID', 'ID','ID18__PC', 'target', 'desmatriculado', 'PL_CURSO_ACADEMICO', 'CH_NACIONAL',\n",
    "    'NU_NOTA_MEDIA_ADMISION', 'NU_NOTA_MEDIA_1_BACH__PC', 'CH_PRUEBAS_CALIFICADAS', \n",
    "    'NU_RESULTADO_ADMISION_PUNTOS', 'PL_RESOLUCION_DEFINITIVA', 'TITULACION', 'CENTROENSENANZA',\n",
    "    'MINIMUMPAYMENTPAYED', 'PAID_AMOUNT', 'PAID_PERCENT', 'CH_PAGO_SUPERIOR', \n",
    "    'CH_MATRICULA_SUJETA_BECA', 'CH_AYUDA_FINANCIACION', 'CU_IMPORTE_TOTAL',\n",
    "    'CH_VISITACAMPUS__PC', 'CH_ENTREVISTA_PERSONAL__PC', 'ACC_DTT_FECHAULTIMAACTIVIDAD', \n",
    "    'NU_PREFERENCIA', 'STAGENAME', 'PL_SUBETAPA',\n",
    "    'CH_HIJO_EMPLEADO__PC', 'CH_HIJO_PROFESOR_ASOCIADO__PC', 'CH_HERMANOS_ESTUDIANDO_UNAV__P', \n",
    "    'CH_HIJO_MEDICO__PC', 'YEARPERSONBIRTHDATE', 'NAMEX', 'CH_FAMILIA_NUMEROSA__PC', \n",
    "    'PL_SITUACION_SOCIO_ECONOMICA', 'LEADSOURCE', 'PL_ORIGEN_DE_SOLICITUD', \n",
    "    'PL_PLAZO_ADMISION', 'RECORDTYPENAME','PLAZO_ADMISION_LIMPIO','FO_rentaFam_ges__c','CU_precioOrdinario_def__c',\n",
    "    'CU_precioAplicado_def__c','PORCENTAJE_PAGADO_FINAL','tiempo_etapa_dias','tiempo_entre_etapas_dias','num_asistencias_acum', 'num_solicitudes_acum'\n",
    "]\n",
    "\n",
    "\n",
    "#columnas_finales = [c for c in columnas_finales if c in df_definitivo.columns]\n",
    "df_definitivo = df_definitivo[columnas_seleccionadas]\n",
    "\n",
    "# ============================================================\n",
    "# 9Ô∏è‚É£ GUARDAR DATASET TRATAMIENTO DEFINITIVO\n",
    "# ============================================================\n",
    "\n",
    "ruta_salida = r\"..\\datos\\01. Datos originales\\dataset_tratamiento_final.csv\"\n",
    "df_definitivo.to_csv(ruta_salida, sep=\";\", index=False)\n",
    "\n",
    "print(f\"‚úÖ Dataset de tratamiento definitivo guardado en: {ruta_salida}\")\n",
    "print(f\"Dimensiones: {df_definitivo.shape}\")\n",
    "df_definitivo.head()\n",
    "\n",
    "# ==============================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_python311_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
