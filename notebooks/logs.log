2026-01-19 10:24:16,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-19 10:24:16,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-19 10:24:16,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-19 10:24:16,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-29 15:21:31,736:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-29 15:21:31,736:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-29 15:21:31,736:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-29 15:21:31,736:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-29 15:21:35,750:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\2388759396.py:16: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-29 15:25:39,783:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\2256906154.py:17: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-29 15:26:50,165:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\1372246288.py:16: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-29 15:26:51,818:INFO:PyCaret ClassificationExperiment
2026-01-29 15:26:51,819:INFO:Logging name: clf-default-name
2026-01-29 15:26:51,819:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-29 15:26:51,820:INFO:version 3.3.2
2026-01-29 15:26:51,820:INFO:Initializing setup()
2026-01-29 15:26:51,820:INFO:self.USI: f012
2026-01-29 15:26:51,820:INFO:self._variable_keys: {'X_test', 'fold_groups_param', 'pipeline', 'fix_imbalance', 'exp_name_log', 'data', 'y_test', 'seed', 'fold_shuffle_param', 'n_jobs_param', 'is_multiclass', 'gpu_n_jobs_param', 'memory', 'log_plots_param', 'logging_param', 'idx', 'y', 'target_param', 'fold_generator', 'y_train', 'gpu_param', 'USI', 'exp_id', '_available_plots', 'X', 'X_train', 'html_param', '_ml_usecase'}
2026-01-29 15:26:51,820:INFO:Checking environment
2026-01-29 15:26:51,820:INFO:python_version: 3.11.11
2026-01-29 15:26:51,821:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-29 15:26:51,821:INFO:machine: AMD64
2026-01-29 15:26:51,821:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-29 15:26:51,821:INFO:Memory: svmem(total=34009374720, available=16823705600, percent=50.5, used=17185669120, free=16823705600)
2026-01-29 15:26:51,822:INFO:Physical Core: 12
2026-01-29 15:26:51,822:INFO:Logical Core: 16
2026-01-29 15:26:51,822:INFO:Checking libraries
2026-01-29 15:26:51,822:INFO:System:
2026-01-29 15:26:51,822:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-29 15:26:51,822:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-29 15:26:51,822:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-29 15:26:51,823:INFO:PyCaret required dependencies:
2026-01-29 15:26:54,258:INFO:                 pip: 25.0
2026-01-29 15:26:54,258:INFO:          setuptools: 75.8.0
2026-01-29 15:26:54,258:INFO:             pycaret: 3.3.2
2026-01-29 15:26:54,258:INFO:             IPython: 9.9.0
2026-01-29 15:26:54,258:INFO:          ipywidgets: 8.1.8
2026-01-29 15:26:54,258:INFO:                tqdm: 4.67.1
2026-01-29 15:26:54,258:INFO:               numpy: 1.26.4
2026-01-29 15:26:54,259:INFO:              pandas: 2.1.4
2026-01-29 15:26:54,259:INFO:              jinja2: 3.1.6
2026-01-29 15:26:54,259:INFO:               scipy: 1.11.4
2026-01-29 15:26:54,259:INFO:              joblib: 1.3.2
2026-01-29 15:26:54,259:INFO:             sklearn: 1.4.2
2026-01-29 15:26:54,259:INFO:                pyod: 2.0.6
2026-01-29 15:26:54,259:INFO:            imblearn: 0.14.1
2026-01-29 15:26:54,259:INFO:   category_encoders: 2.7.0
2026-01-29 15:26:54,259:INFO:            lightgbm: 4.6.0
2026-01-29 15:26:54,259:INFO:               numba: 0.62.1
2026-01-29 15:26:54,259:INFO:            requests: 2.32.3
2026-01-29 15:26:54,259:INFO:          matplotlib: 3.7.5
2026-01-29 15:26:54,259:INFO:          scikitplot: 0.3.7
2026-01-29 15:26:54,259:INFO:         yellowbrick: 1.5
2026-01-29 15:26:54,259:INFO:              plotly: 5.24.1
2026-01-29 15:26:54,259:INFO:    plotly-resampler: Not installed
2026-01-29 15:26:54,259:INFO:             kaleido: 1.2.0
2026-01-29 15:26:54,259:INFO:           schemdraw: 0.15
2026-01-29 15:26:54,259:INFO:         statsmodels: 0.14.6
2026-01-29 15:26:54,259:INFO:              sktime: 0.26.0
2026-01-29 15:26:54,259:INFO:               tbats: 1.1.3
2026-01-29 15:26:54,259:INFO:            pmdarima: 2.0.4
2026-01-29 15:26:54,259:INFO:              psutil: 7.2.1
2026-01-29 15:26:54,260:INFO:          markupsafe: 3.0.3
2026-01-29 15:26:54,260:INFO:             pickle5: Not installed
2026-01-29 15:26:54,260:INFO:         cloudpickle: 3.0.0
2026-01-29 15:26:54,260:INFO:         deprecation: 2.1.0
2026-01-29 15:26:54,260:INFO:              xxhash: 3.6.0
2026-01-29 15:26:54,260:INFO:           wurlitzer: Not installed
2026-01-29 15:26:54,260:INFO:PyCaret optional dependencies:
2026-01-29 15:27:00,934:INFO:                shap: 0.44.1
2026-01-29 15:27:00,934:INFO:           interpret: 0.7.3
2026-01-29 15:27:00,934:INFO:                umap: 0.5.7
2026-01-29 15:27:00,934:INFO:     ydata_profiling: 4.18.1
2026-01-29 15:27:00,934:INFO:  explainerdashboard: 0.5.1
2026-01-29 15:27:00,934:INFO:             autoviz: Not installed
2026-01-29 15:27:00,936:INFO:           fairlearn: 0.7.0
2026-01-29 15:27:00,936:INFO:          deepchecks: Not installed
2026-01-29 15:27:00,936:INFO:             xgboost: Not installed
2026-01-29 15:27:00,936:INFO:            catboost: 1.2.8
2026-01-29 15:27:00,936:INFO:              kmodes: 0.12.2
2026-01-29 15:27:00,936:INFO:             mlxtend: 0.23.4
2026-01-29 15:27:00,936:INFO:       statsforecast: 1.5.0
2026-01-29 15:27:00,936:INFO:        tune_sklearn: Not installed
2026-01-29 15:27:00,936:INFO:                 ray: Not installed
2026-01-29 15:27:00,936:INFO:            hyperopt: 0.2.7
2026-01-29 15:27:00,936:INFO:              optuna: 4.6.0
2026-01-29 15:27:00,936:INFO:               skopt: 0.10.2
2026-01-29 15:27:00,938:INFO:              mlflow: 3.8.1
2026-01-29 15:27:00,938:INFO:              gradio: 6.3.0
2026-01-29 15:27:00,938:INFO:             fastapi: 0.128.0
2026-01-29 15:27:00,938:INFO:             uvicorn: 0.40.0
2026-01-29 15:27:00,938:INFO:              m2cgen: 0.10.0
2026-01-29 15:27:00,939:INFO:           evidently: 0.4.40
2026-01-29 15:27:00,939:INFO:               fugue: 0.8.7
2026-01-29 15:27:00,939:INFO:           streamlit: Not installed
2026-01-29 15:27:00,939:INFO:             prophet: Not installed
2026-01-29 15:27:00,939:INFO:None
2026-01-29 15:27:00,940:INFO:Set up data.
2026-01-29 15:27:02,745:INFO:Set up folding strategy.
2026-01-29 15:27:02,746:INFO:Set up train/test split.
2026-01-29 15:27:03,016:INFO:Set up index.
2026-01-29 15:27:03,029:INFO:Assigning column types.
2026-01-29 15:27:03,163:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-29 15:27:03,188:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 15:27:03,198:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:27:03,235:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:27:03,235:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:27:03,439:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 15:27:03,440:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:27:03,455:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:27:03,456:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:27:03,456:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-29 15:27:03,493:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:27:03,516:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:27:03,516:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:27:03,543:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:27:03,559:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:27:03,560:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:27:03,560:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-29 15:27:03,617:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:27:03,617:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:27:03,661:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:27:03,661:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:27:03,663:INFO:Preparing preprocessing pipeline...
2026-01-29 15:27:03,692:INFO:Set up simple imputation.
2026-01-29 15:27:03,845:INFO:Set up encoding of ordinal features.
2026-01-29 15:27:04,428:INFO:Set up encoding of categorical features.
2026-01-29 15:27:04,430:INFO:Set up column transformation.
2026-01-29 15:27:04,430:INFO:Set up feature normalization.
2026-01-29 15:29:42,743:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\3853355163.py:16: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-29 15:29:43,543:INFO:PyCaret ClassificationExperiment
2026-01-29 15:29:43,544:INFO:Logging name: clf-default-name
2026-01-29 15:29:43,544:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-29 15:29:43,544:INFO:version 3.3.2
2026-01-29 15:29:43,544:INFO:Initializing setup()
2026-01-29 15:29:43,544:INFO:self.USI: 2dfb
2026-01-29 15:29:43,545:INFO:self._variable_keys: {'X_test', 'fold_groups_param', 'pipeline', 'fix_imbalance', 'exp_name_log', 'data', 'y_test', 'seed', 'fold_shuffle_param', 'n_jobs_param', 'is_multiclass', 'gpu_n_jobs_param', 'memory', 'log_plots_param', 'logging_param', 'idx', 'y', 'target_param', 'fold_generator', 'y_train', 'gpu_param', 'USI', 'exp_id', '_available_plots', 'X', 'X_train', 'html_param', '_ml_usecase'}
2026-01-29 15:29:43,545:INFO:Checking environment
2026-01-29 15:29:43,545:INFO:python_version: 3.11.11
2026-01-29 15:29:43,545:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-29 15:29:43,545:INFO:machine: AMD64
2026-01-29 15:29:43,545:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-29 15:29:43,546:INFO:Memory: svmem(total=34009374720, available=16752574464, percent=50.7, used=17256800256, free=16752574464)
2026-01-29 15:29:43,546:INFO:Physical Core: 12
2026-01-29 15:29:43,546:INFO:Logical Core: 16
2026-01-29 15:29:43,546:INFO:Checking libraries
2026-01-29 15:29:43,546:INFO:System:
2026-01-29 15:29:43,546:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-29 15:29:43,546:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-29 15:29:43,546:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-29 15:29:43,546:INFO:PyCaret required dependencies:
2026-01-29 15:29:43,546:INFO:                 pip: 25.0
2026-01-29 15:29:43,546:INFO:          setuptools: 75.8.0
2026-01-29 15:29:43,546:INFO:             pycaret: 3.3.2
2026-01-29 15:29:43,546:INFO:             IPython: 9.9.0
2026-01-29 15:29:43,546:INFO:          ipywidgets: 8.1.8
2026-01-29 15:29:43,547:INFO:                tqdm: 4.67.1
2026-01-29 15:29:43,547:INFO:               numpy: 1.26.4
2026-01-29 15:29:43,547:INFO:              pandas: 2.1.4
2026-01-29 15:29:43,547:INFO:              jinja2: 3.1.6
2026-01-29 15:29:43,547:INFO:               scipy: 1.11.4
2026-01-29 15:29:43,547:INFO:              joblib: 1.3.2
2026-01-29 15:29:43,547:INFO:             sklearn: 1.4.2
2026-01-29 15:29:43,547:INFO:                pyod: 2.0.6
2026-01-29 15:29:43,547:INFO:            imblearn: 0.14.1
2026-01-29 15:29:43,547:INFO:   category_encoders: 2.7.0
2026-01-29 15:29:43,547:INFO:            lightgbm: 4.6.0
2026-01-29 15:29:43,547:INFO:               numba: 0.62.1
2026-01-29 15:29:43,547:INFO:            requests: 2.32.3
2026-01-29 15:29:43,547:INFO:          matplotlib: 3.7.5
2026-01-29 15:29:43,547:INFO:          scikitplot: 0.3.7
2026-01-29 15:29:43,547:INFO:         yellowbrick: 1.5
2026-01-29 15:29:43,547:INFO:              plotly: 5.24.1
2026-01-29 15:29:43,547:INFO:    plotly-resampler: Not installed
2026-01-29 15:29:43,547:INFO:             kaleido: 1.2.0
2026-01-29 15:29:43,547:INFO:           schemdraw: 0.15
2026-01-29 15:29:43,548:INFO:         statsmodels: 0.14.6
2026-01-29 15:29:43,548:INFO:              sktime: 0.26.0
2026-01-29 15:29:43,548:INFO:               tbats: 1.1.3
2026-01-29 15:29:43,548:INFO:            pmdarima: 2.0.4
2026-01-29 15:29:43,548:INFO:              psutil: 7.2.1
2026-01-29 15:29:43,548:INFO:          markupsafe: 3.0.3
2026-01-29 15:29:43,548:INFO:             pickle5: Not installed
2026-01-29 15:29:43,548:INFO:         cloudpickle: 3.0.0
2026-01-29 15:29:43,548:INFO:         deprecation: 2.1.0
2026-01-29 15:29:43,548:INFO:              xxhash: 3.6.0
2026-01-29 15:29:43,548:INFO:           wurlitzer: Not installed
2026-01-29 15:29:43,548:INFO:PyCaret optional dependencies:
2026-01-29 15:29:43,548:INFO:                shap: 0.44.1
2026-01-29 15:29:43,548:INFO:           interpret: 0.7.3
2026-01-29 15:29:43,548:INFO:                umap: 0.5.7
2026-01-29 15:29:43,549:INFO:     ydata_profiling: 4.18.1
2026-01-29 15:29:43,549:INFO:  explainerdashboard: 0.5.1
2026-01-29 15:29:43,549:INFO:             autoviz: Not installed
2026-01-29 15:29:43,549:INFO:           fairlearn: 0.7.0
2026-01-29 15:29:43,549:INFO:          deepchecks: Not installed
2026-01-29 15:29:43,549:INFO:             xgboost: Not installed
2026-01-29 15:29:43,549:INFO:            catboost: 1.2.8
2026-01-29 15:29:43,549:INFO:              kmodes: 0.12.2
2026-01-29 15:29:43,549:INFO:             mlxtend: 0.23.4
2026-01-29 15:29:43,549:INFO:       statsforecast: 1.5.0
2026-01-29 15:29:43,549:INFO:        tune_sklearn: Not installed
2026-01-29 15:29:43,549:INFO:                 ray: Not installed
2026-01-29 15:29:43,549:INFO:            hyperopt: 0.2.7
2026-01-29 15:29:43,549:INFO:              optuna: 4.6.0
2026-01-29 15:29:43,549:INFO:               skopt: 0.10.2
2026-01-29 15:29:43,549:INFO:              mlflow: 3.8.1
2026-01-29 15:29:43,549:INFO:              gradio: 6.3.0
2026-01-29 15:29:43,549:INFO:             fastapi: 0.128.0
2026-01-29 15:29:43,549:INFO:             uvicorn: 0.40.0
2026-01-29 15:29:43,549:INFO:              m2cgen: 0.10.0
2026-01-29 15:29:43,549:INFO:           evidently: 0.4.40
2026-01-29 15:29:43,549:INFO:               fugue: 0.8.7
2026-01-29 15:29:43,549:INFO:           streamlit: Not installed
2026-01-29 15:29:43,549:INFO:             prophet: Not installed
2026-01-29 15:29:43,549:INFO:None
2026-01-29 15:29:43,549:INFO:Set up data.
2026-01-29 15:29:43,754:INFO:Set up folding strategy.
2026-01-29 15:29:43,754:INFO:Set up train/test split.
2026-01-29 15:29:43,990:INFO:Set up index.
2026-01-29 15:29:43,993:INFO:Assigning column types.
2026-01-29 15:29:44,136:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-29 15:29:44,174:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 15:29:44,175:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:29:44,200:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:29:44,200:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:29:44,238:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 15:29:44,239:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:29:44,263:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:29:44,264:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:29:44,265:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-29 15:29:44,304:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:29:44,327:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:29:44,327:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:29:44,359:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:29:44,395:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:29:44,395:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:29:44,396:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-29 15:29:44,471:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:29:44,472:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:29:44,530:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:29:44,530:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:29:44,545:INFO:Preparing preprocessing pipeline...
2026-01-29 15:29:44,564:INFO:Set up simple imputation.
2026-01-29 15:29:44,564:INFO:Set up column transformation.
2026-01-29 15:29:44,564:INFO:Set up feature normalization.
2026-01-29 15:29:46,181:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\numpy\core\_methods.py:176: RuntimeWarning: overflow encountered in multiply

2026-01-29 15:29:47,054:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\preprocessing\_data.py:3408: RuntimeWarning: overflow encountered in power

2026-01-29 15:29:47,057:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\numpy\core\_methods.py:152: RuntimeWarning: overflow encountered in reduce

2026-01-29 15:32:51,925:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\306957030.py:15: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-29 15:33:59,293:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\1040826916.py:15: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-29 15:34:57,609:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\4055341079.py:18: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-29 15:34:59,879:INFO:PyCaret ClassificationExperiment
2026-01-29 15:34:59,879:INFO:Logging name: clf-default-name
2026-01-29 15:34:59,879:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-29 15:34:59,879:INFO:version 3.3.2
2026-01-29 15:34:59,879:INFO:Initializing setup()
2026-01-29 15:34:59,879:INFO:self.USI: 732d
2026-01-29 15:34:59,879:INFO:self._variable_keys: {'X_test', 'fold_groups_param', 'pipeline', 'fix_imbalance', 'exp_name_log', 'data', 'y_test', 'seed', 'fold_shuffle_param', 'n_jobs_param', 'is_multiclass', 'gpu_n_jobs_param', 'memory', 'log_plots_param', 'logging_param', 'idx', 'y', 'target_param', 'fold_generator', 'y_train', 'gpu_param', 'USI', 'exp_id', '_available_plots', 'X', 'X_train', 'html_param', '_ml_usecase'}
2026-01-29 15:34:59,879:INFO:Checking environment
2026-01-29 15:34:59,879:INFO:python_version: 3.11.11
2026-01-29 15:34:59,879:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-29 15:34:59,879:INFO:machine: AMD64
2026-01-29 15:34:59,879:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-29 15:34:59,879:INFO:Memory: svmem(total=34009374720, available=15858475008, percent=53.4, used=18150899712, free=15858475008)
2026-01-29 15:34:59,879:INFO:Physical Core: 12
2026-01-29 15:34:59,879:INFO:Logical Core: 16
2026-01-29 15:34:59,879:INFO:Checking libraries
2026-01-29 15:34:59,879:INFO:System:
2026-01-29 15:34:59,879:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-29 15:34:59,879:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-29 15:34:59,879:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-29 15:34:59,879:INFO:PyCaret required dependencies:
2026-01-29 15:34:59,879:INFO:                 pip: 25.0
2026-01-29 15:34:59,879:INFO:          setuptools: 75.8.0
2026-01-29 15:34:59,879:INFO:             pycaret: 3.3.2
2026-01-29 15:34:59,879:INFO:             IPython: 9.9.0
2026-01-29 15:34:59,879:INFO:          ipywidgets: 8.1.8
2026-01-29 15:34:59,879:INFO:                tqdm: 4.67.1
2026-01-29 15:34:59,879:INFO:               numpy: 1.26.4
2026-01-29 15:34:59,879:INFO:              pandas: 2.1.4
2026-01-29 15:34:59,879:INFO:              jinja2: 3.1.6
2026-01-29 15:34:59,879:INFO:               scipy: 1.11.4
2026-01-29 15:34:59,879:INFO:              joblib: 1.3.2
2026-01-29 15:34:59,879:INFO:             sklearn: 1.4.2
2026-01-29 15:34:59,879:INFO:                pyod: 2.0.6
2026-01-29 15:34:59,879:INFO:            imblearn: 0.14.1
2026-01-29 15:34:59,879:INFO:   category_encoders: 2.7.0
2026-01-29 15:34:59,879:INFO:            lightgbm: 4.6.0
2026-01-29 15:34:59,879:INFO:               numba: 0.62.1
2026-01-29 15:34:59,879:INFO:            requests: 2.32.3
2026-01-29 15:34:59,879:INFO:          matplotlib: 3.7.5
2026-01-29 15:34:59,879:INFO:          scikitplot: 0.3.7
2026-01-29 15:34:59,879:INFO:         yellowbrick: 1.5
2026-01-29 15:34:59,879:INFO:              plotly: 5.24.1
2026-01-29 15:34:59,879:INFO:    plotly-resampler: Not installed
2026-01-29 15:34:59,879:INFO:             kaleido: 1.2.0
2026-01-29 15:34:59,879:INFO:           schemdraw: 0.15
2026-01-29 15:34:59,879:INFO:         statsmodels: 0.14.6
2026-01-29 15:34:59,879:INFO:              sktime: 0.26.0
2026-01-29 15:34:59,879:INFO:               tbats: 1.1.3
2026-01-29 15:34:59,879:INFO:            pmdarima: 2.0.4
2026-01-29 15:34:59,879:INFO:              psutil: 7.2.1
2026-01-29 15:34:59,879:INFO:          markupsafe: 3.0.3
2026-01-29 15:34:59,879:INFO:             pickle5: Not installed
2026-01-29 15:34:59,879:INFO:         cloudpickle: 3.0.0
2026-01-29 15:34:59,879:INFO:         deprecation: 2.1.0
2026-01-29 15:34:59,879:INFO:              xxhash: 3.6.0
2026-01-29 15:34:59,879:INFO:           wurlitzer: Not installed
2026-01-29 15:34:59,879:INFO:PyCaret optional dependencies:
2026-01-29 15:34:59,879:INFO:                shap: 0.44.1
2026-01-29 15:34:59,879:INFO:           interpret: 0.7.3
2026-01-29 15:34:59,879:INFO:                umap: 0.5.7
2026-01-29 15:34:59,888:INFO:     ydata_profiling: 4.18.1
2026-01-29 15:34:59,888:INFO:  explainerdashboard: 0.5.1
2026-01-29 15:34:59,889:INFO:             autoviz: Not installed
2026-01-29 15:34:59,889:INFO:           fairlearn: 0.7.0
2026-01-29 15:34:59,890:INFO:          deepchecks: Not installed
2026-01-29 15:34:59,890:INFO:             xgboost: Not installed
2026-01-29 15:34:59,890:INFO:            catboost: 1.2.8
2026-01-29 15:34:59,890:INFO:              kmodes: 0.12.2
2026-01-29 15:34:59,890:INFO:             mlxtend: 0.23.4
2026-01-29 15:34:59,890:INFO:       statsforecast: 1.5.0
2026-01-29 15:34:59,890:INFO:        tune_sklearn: Not installed
2026-01-29 15:34:59,890:INFO:                 ray: Not installed
2026-01-29 15:34:59,890:INFO:            hyperopt: 0.2.7
2026-01-29 15:34:59,890:INFO:              optuna: 4.6.0
2026-01-29 15:34:59,890:INFO:               skopt: 0.10.2
2026-01-29 15:34:59,890:INFO:              mlflow: 3.8.1
2026-01-29 15:34:59,890:INFO:              gradio: 6.3.0
2026-01-29 15:34:59,890:INFO:             fastapi: 0.128.0
2026-01-29 15:34:59,890:INFO:             uvicorn: 0.40.0
2026-01-29 15:34:59,890:INFO:              m2cgen: 0.10.0
2026-01-29 15:34:59,890:INFO:           evidently: 0.4.40
2026-01-29 15:34:59,890:INFO:               fugue: 0.8.7
2026-01-29 15:34:59,890:INFO:           streamlit: Not installed
2026-01-29 15:34:59,890:INFO:             prophet: Not installed
2026-01-29 15:34:59,890:INFO:None
2026-01-29 15:34:59,890:INFO:Set up data.
2026-01-29 15:34:59,923:INFO:Set up folding strategy.
2026-01-29 15:34:59,923:INFO:Set up train/test split.
2026-01-29 15:35:00,060:INFO:Set up index.
2026-01-29 15:35:00,073:INFO:Assigning column types.
2026-01-29 15:35:00,090:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-29 15:35:00,140:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 15:35:00,140:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:35:00,180:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:35:00,180:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:35:00,227:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 15:35:00,228:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:35:00,257:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:35:00,258:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:35:00,259:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-29 15:35:00,303:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:35:00,329:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:35:00,329:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:35:00,373:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:35:00,396:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:35:00,396:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:35:00,396:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-29 15:35:00,468:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:35:00,468:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:35:00,529:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:35:00,529:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:35:00,529:INFO:Preparing preprocessing pipeline...
2026-01-29 15:35:00,546:INFO:Set up simple imputation.
2026-01-29 15:35:00,546:INFO:Set up feature normalization.
2026-01-29 15:35:00,642:INFO:Finished creating preprocessing pipeline.
2026-01-29 15:35:00,646:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-29 15:35:00,646:INFO:Creating final display dataframe.
2026-01-29 15:35:00,911:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape       (429278, 4)
4        Transformed data shape       (429278, 4)
5   Transformed train set shape       (343422, 4)
6    Transformed test set shape        (85856, 4)
7               Ignore features                58
8              Numeric features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                 5
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              732d
2026-01-29 15:35:00,956:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:35:00,956:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:35:01,023:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:35:01,023:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:35:01,023:INFO:setup() successfully completed in 1.17s...............
2026-01-29 15:35:01,023:INFO:Initializing compare_models()
2026-01-29 15:35:01,023:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-29 15:35:01,023:INFO:Checking exceptions
2026-01-29 15:35:01,057:INFO:Preparing display monitor
2026-01-29 15:35:01,089:INFO:Initializing Logistic Regression
2026-01-29 15:35:01,090:INFO:Total runtime is 1.8715858459472656e-05 minutes
2026-01-29 15:35:01,093:INFO:SubProcess create_model() called ==================================
2026-01-29 15:35:01,094:INFO:Initializing create_model()
2026-01-29 15:35:01,094:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:35:01,094:INFO:Checking exceptions
2026-01-29 15:35:01,094:INFO:Importing libraries
2026-01-29 15:35:01,095:INFO:Copying training dataset
2026-01-29 15:35:01,178:INFO:Defining folds
2026-01-29 15:35:01,178:INFO:Declaring metric variables
2026-01-29 15:35:01,181:INFO:Importing untrained model
2026-01-29 15:35:01,184:INFO:Logistic Regression Imported successfully
2026-01-29 15:35:01,191:INFO:Starting cross validation
2026-01-29 15:35:01,192:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:35:12,429:INFO:Calculating mean and std
2026-01-29 15:35:12,429:INFO:Creating metrics dataframe
2026-01-29 15:35:12,429:INFO:Uploading results into container
2026-01-29 15:35:12,429:INFO:Uploading model into container now
2026-01-29 15:35:12,429:INFO:_master_model_container: 1
2026-01-29 15:35:12,436:INFO:_display_container: 2
2026-01-29 15:35:12,436:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 15:35:12,436:INFO:create_model() successfully completed......................................
2026-01-29 15:35:12,639:INFO:SubProcess create_model() end ==================================
2026-01-29 15:35:12,639:INFO:Creating metrics dataframe
2026-01-29 15:35:12,643:INFO:Initializing K Neighbors Classifier
2026-01-29 15:35:12,643:INFO:Total runtime is 0.1925755222638448 minutes
2026-01-29 15:35:12,645:INFO:SubProcess create_model() called ==================================
2026-01-29 15:35:12,645:INFO:Initializing create_model()
2026-01-29 15:35:12,645:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:35:12,645:INFO:Checking exceptions
2026-01-29 15:35:12,645:INFO:Importing libraries
2026-01-29 15:35:12,646:INFO:Copying training dataset
2026-01-29 15:35:12,695:INFO:Defining folds
2026-01-29 15:35:12,706:INFO:Declaring metric variables
2026-01-29 15:35:12,708:INFO:Importing untrained model
2026-01-29 15:35:12,708:INFO:K Neighbors Classifier Imported successfully
2026-01-29 15:35:12,708:INFO:Starting cross validation
2026-01-29 15:35:12,708:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:52:50,271:INFO:Calculating mean and std
2026-01-29 15:52:50,273:INFO:Creating metrics dataframe
2026-01-29 15:52:50,276:INFO:Uploading results into container
2026-01-29 15:52:50,277:INFO:Uploading model into container now
2026-01-29 15:52:50,277:INFO:_master_model_container: 2
2026-01-29 15:52:50,278:INFO:_display_container: 2
2026-01-29 15:52:50,278:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2026-01-29 15:52:50,278:INFO:create_model() successfully completed......................................
2026-01-29 15:52:50,493:INFO:SubProcess create_model() end ==================================
2026-01-29 15:52:50,493:INFO:Creating metrics dataframe
2026-01-29 15:52:50,498:INFO:Initializing Naive Bayes
2026-01-29 15:52:50,498:INFO:Total runtime is 17.823485747973123 minutes
2026-01-29 15:52:50,501:INFO:SubProcess create_model() called ==================================
2026-01-29 15:52:50,502:INFO:Initializing create_model()
2026-01-29 15:52:50,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:52:50,502:INFO:Checking exceptions
2026-01-29 15:52:50,502:INFO:Importing libraries
2026-01-29 15:52:50,502:INFO:Copying training dataset
2026-01-29 15:52:50,576:INFO:Defining folds
2026-01-29 15:52:50,576:INFO:Declaring metric variables
2026-01-29 15:52:50,581:INFO:Importing untrained model
2026-01-29 15:52:50,581:INFO:Naive Bayes Imported successfully
2026-01-29 15:52:50,595:INFO:Starting cross validation
2026-01-29 15:52:50,596:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:52:52,044:INFO:Calculating mean and std
2026-01-29 15:52:52,047:INFO:Creating metrics dataframe
2026-01-29 15:52:52,052:INFO:Uploading results into container
2026-01-29 15:52:52,053:INFO:Uploading model into container now
2026-01-29 15:52:52,054:INFO:_master_model_container: 3
2026-01-29 15:52:52,056:INFO:_display_container: 2
2026-01-29 15:52:52,057:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-01-29 15:52:52,057:INFO:create_model() successfully completed......................................
2026-01-29 15:52:52,389:INFO:SubProcess create_model() end ==================================
2026-01-29 15:52:52,389:INFO:Creating metrics dataframe
2026-01-29 15:52:52,402:INFO:Initializing Decision Tree Classifier
2026-01-29 15:52:52,402:INFO:Total runtime is 17.855215458075204 minutes
2026-01-29 15:52:52,407:INFO:SubProcess create_model() called ==================================
2026-01-29 15:52:52,408:INFO:Initializing create_model()
2026-01-29 15:52:52,408:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:52:52,409:INFO:Checking exceptions
2026-01-29 15:52:52,409:INFO:Importing libraries
2026-01-29 15:52:52,409:INFO:Copying training dataset
2026-01-29 15:52:52,533:INFO:Defining folds
2026-01-29 15:52:52,533:INFO:Declaring metric variables
2026-01-29 15:52:52,537:INFO:Importing untrained model
2026-01-29 15:52:52,542:INFO:Decision Tree Classifier Imported successfully
2026-01-29 15:52:52,552:INFO:Starting cross validation
2026-01-29 15:52:52,554:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:52:57,251:INFO:Calculating mean and std
2026-01-29 15:52:57,251:INFO:Creating metrics dataframe
2026-01-29 15:52:57,251:INFO:Uploading results into container
2026-01-29 15:52:57,251:INFO:Uploading model into container now
2026-01-29 15:52:57,251:INFO:_master_model_container: 4
2026-01-29 15:52:57,251:INFO:_display_container: 2
2026-01-29 15:52:57,251:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 15:52:57,251:INFO:create_model() successfully completed......................................
2026-01-29 15:52:57,451:INFO:SubProcess create_model() end ==================================
2026-01-29 15:52:57,451:INFO:Creating metrics dataframe
2026-01-29 15:52:57,456:INFO:Initializing SVM - Linear Kernel
2026-01-29 15:52:57,456:INFO:Total runtime is 17.939451269308723 minutes
2026-01-29 15:52:57,459:INFO:SubProcess create_model() called ==================================
2026-01-29 15:52:57,459:INFO:Initializing create_model()
2026-01-29 15:52:57,459:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:52:57,460:INFO:Checking exceptions
2026-01-29 15:52:57,460:INFO:Importing libraries
2026-01-29 15:52:57,460:INFO:Copying training dataset
2026-01-29 15:52:57,538:INFO:Defining folds
2026-01-29 15:52:57,538:INFO:Declaring metric variables
2026-01-29 15:52:57,542:INFO:Importing untrained model
2026-01-29 15:52:57,546:INFO:SVM - Linear Kernel Imported successfully
2026-01-29 15:52:57,550:INFO:Starting cross validation
2026-01-29 15:52:57,550:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:53:05,859:INFO:Calculating mean and std
2026-01-29 15:53:05,860:INFO:Creating metrics dataframe
2026-01-29 15:53:05,862:INFO:Uploading results into container
2026-01-29 15:53:05,862:INFO:Uploading model into container now
2026-01-29 15:53:05,863:INFO:_master_model_container: 5
2026-01-29 15:53:05,863:INFO:_display_container: 2
2026-01-29 15:53:05,864:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2026-01-29 15:53:05,864:INFO:create_model() successfully completed......................................
2026-01-29 15:53:06,108:INFO:SubProcess create_model() end ==================================
2026-01-29 15:53:06,109:INFO:Creating metrics dataframe
2026-01-29 15:53:06,114:INFO:Initializing Ridge Classifier
2026-01-29 15:53:06,114:INFO:Total runtime is 18.083745956420895 minutes
2026-01-29 15:53:06,114:INFO:SubProcess create_model() called ==================================
2026-01-29 15:53:06,114:INFO:Initializing create_model()
2026-01-29 15:53:06,114:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:53:06,114:INFO:Checking exceptions
2026-01-29 15:53:06,114:INFO:Importing libraries
2026-01-29 15:53:06,114:INFO:Copying training dataset
2026-01-29 15:53:06,230:INFO:Defining folds
2026-01-29 15:53:06,230:INFO:Declaring metric variables
2026-01-29 15:53:06,235:INFO:Importing untrained model
2026-01-29 15:53:06,240:INFO:Ridge Classifier Imported successfully
2026-01-29 15:53:06,249:INFO:Starting cross validation
2026-01-29 15:53:06,251:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:53:14,237:INFO:Calculating mean and std
2026-01-29 15:53:14,239:INFO:Creating metrics dataframe
2026-01-29 15:53:14,242:INFO:Uploading results into container
2026-01-29 15:53:14,243:INFO:Uploading model into container now
2026-01-29 15:53:14,243:INFO:_master_model_container: 6
2026-01-29 15:53:14,243:INFO:_display_container: 2
2026-01-29 15:53:14,243:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2026-01-29 15:53:14,243:INFO:create_model() successfully completed......................................
2026-01-29 15:53:14,441:INFO:SubProcess create_model() end ==================================
2026-01-29 15:53:14,442:INFO:Creating metrics dataframe
2026-01-29 15:53:14,443:INFO:Initializing Random Forest Classifier
2026-01-29 15:53:14,443:INFO:Total runtime is 18.222563024361925 minutes
2026-01-29 15:53:14,443:INFO:SubProcess create_model() called ==================================
2026-01-29 15:53:14,443:INFO:Initializing create_model()
2026-01-29 15:53:14,443:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:53:14,443:INFO:Checking exceptions
2026-01-29 15:53:14,443:INFO:Importing libraries
2026-01-29 15:53:14,443:INFO:Copying training dataset
2026-01-29 15:53:14,516:INFO:Defining folds
2026-01-29 15:53:14,523:INFO:Declaring metric variables
2026-01-29 15:53:14,526:INFO:Importing untrained model
2026-01-29 15:53:14,526:INFO:Random Forest Classifier Imported successfully
2026-01-29 15:53:14,533:INFO:Starting cross validation
2026-01-29 15:53:14,533:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:53:24,811:INFO:Calculating mean and std
2026-01-29 15:53:24,811:INFO:Creating metrics dataframe
2026-01-29 15:53:24,811:INFO:Uploading results into container
2026-01-29 15:53:24,811:INFO:Uploading model into container now
2026-01-29 15:53:24,811:INFO:_master_model_container: 7
2026-01-29 15:53:24,811:INFO:_display_container: 2
2026-01-29 15:53:24,811:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 15:53:24,811:INFO:create_model() successfully completed......................................
2026-01-29 15:53:24,985:INFO:SubProcess create_model() end ==================================
2026-01-29 15:53:24,986:INFO:Creating metrics dataframe
2026-01-29 15:53:24,991:INFO:Initializing Quadratic Discriminant Analysis
2026-01-29 15:53:24,991:INFO:Total runtime is 18.3983648498853 minutes
2026-01-29 15:53:24,991:INFO:SubProcess create_model() called ==================================
2026-01-29 15:53:24,991:INFO:Initializing create_model()
2026-01-29 15:53:24,991:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:53:24,991:INFO:Checking exceptions
2026-01-29 15:53:24,991:INFO:Importing libraries
2026-01-29 15:53:24,991:INFO:Copying training dataset
2026-01-29 15:53:25,058:INFO:Defining folds
2026-01-29 15:53:25,059:INFO:Declaring metric variables
2026-01-29 15:53:25,061:INFO:Importing untrained model
2026-01-29 15:53:25,064:INFO:Quadratic Discriminant Analysis Imported successfully
2026-01-29 15:53:25,064:INFO:Starting cross validation
2026-01-29 15:53:25,064:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:53:25,727:INFO:Calculating mean and std
2026-01-29 15:53:25,728:INFO:Creating metrics dataframe
2026-01-29 15:53:25,730:INFO:Uploading results into container
2026-01-29 15:53:25,730:INFO:Uploading model into container now
2026-01-29 15:53:25,730:INFO:_master_model_container: 8
2026-01-29 15:53:25,732:INFO:_display_container: 2
2026-01-29 15:53:25,732:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2026-01-29 15:53:25,732:INFO:create_model() successfully completed......................................
2026-01-29 15:53:25,925:INFO:SubProcess create_model() end ==================================
2026-01-29 15:53:25,925:INFO:Creating metrics dataframe
2026-01-29 15:53:25,932:INFO:Initializing Ada Boost Classifier
2026-01-29 15:53:25,933:INFO:Total runtime is 18.414068611462906 minutes
2026-01-29 15:53:25,936:INFO:SubProcess create_model() called ==================================
2026-01-29 15:53:25,936:INFO:Initializing create_model()
2026-01-29 15:53:25,937:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:53:25,937:INFO:Checking exceptions
2026-01-29 15:53:25,937:INFO:Importing libraries
2026-01-29 15:53:25,937:INFO:Copying training dataset
2026-01-29 15:53:26,012:INFO:Defining folds
2026-01-29 15:53:26,012:INFO:Declaring metric variables
2026-01-29 15:53:26,016:INFO:Importing untrained model
2026-01-29 15:53:26,020:INFO:Ada Boost Classifier Imported successfully
2026-01-29 15:53:26,028:INFO:Starting cross validation
2026-01-29 15:53:26,029:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:53:26,189:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-01-29 15:53:26,215:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-01-29 15:53:26,237:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-01-29 15:53:26,264:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-01-29 15:53:26,282:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-01-29 15:53:33,521:INFO:Calculating mean and std
2026-01-29 15:53:33,524:INFO:Creating metrics dataframe
2026-01-29 15:53:33,527:INFO:Uploading results into container
2026-01-29 15:53:33,528:INFO:Uploading model into container now
2026-01-29 15:53:33,528:INFO:_master_model_container: 9
2026-01-29 15:53:33,530:INFO:_display_container: 2
2026-01-29 15:53:33,531:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2026-01-29 15:53:33,531:INFO:create_model() successfully completed......................................
2026-01-29 15:53:33,725:INFO:SubProcess create_model() end ==================================
2026-01-29 15:53:33,725:INFO:Creating metrics dataframe
2026-01-29 15:53:33,733:INFO:Initializing Gradient Boosting Classifier
2026-01-29 15:53:33,733:INFO:Total runtime is 18.544077916940047 minutes
2026-01-29 15:53:33,737:INFO:SubProcess create_model() called ==================================
2026-01-29 15:53:33,738:INFO:Initializing create_model()
2026-01-29 15:53:33,738:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:53:33,738:INFO:Checking exceptions
2026-01-29 15:53:33,740:INFO:Importing libraries
2026-01-29 15:53:33,740:INFO:Copying training dataset
2026-01-29 15:53:33,822:INFO:Defining folds
2026-01-29 15:53:33,822:INFO:Declaring metric variables
2026-01-29 15:53:33,826:INFO:Importing untrained model
2026-01-29 15:53:33,830:INFO:Gradient Boosting Classifier Imported successfully
2026-01-29 15:53:33,835:INFO:Starting cross validation
2026-01-29 15:53:33,836:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:53:41,968:INFO:Calculating mean and std
2026-01-29 15:53:41,969:INFO:Creating metrics dataframe
2026-01-29 15:53:41,971:INFO:Uploading results into container
2026-01-29 15:53:41,972:INFO:Uploading model into container now
2026-01-29 15:53:41,972:INFO:_master_model_container: 10
2026-01-29 15:53:41,973:INFO:_display_container: 2
2026-01-29 15:53:41,973:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2026-01-29 15:53:41,973:INFO:create_model() successfully completed......................................
2026-01-29 15:53:42,168:INFO:SubProcess create_model() end ==================================
2026-01-29 15:53:42,168:INFO:Creating metrics dataframe
2026-01-29 15:53:42,175:INFO:Initializing Linear Discriminant Analysis
2026-01-29 15:53:42,176:INFO:Total runtime is 18.684785914421074 minutes
2026-01-29 15:53:42,178:INFO:SubProcess create_model() called ==================================
2026-01-29 15:53:42,178:INFO:Initializing create_model()
2026-01-29 15:53:42,178:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:53:42,178:INFO:Checking exceptions
2026-01-29 15:53:42,178:INFO:Importing libraries
2026-01-29 15:53:42,178:INFO:Copying training dataset
2026-01-29 15:53:42,247:INFO:Defining folds
2026-01-29 15:53:42,247:INFO:Declaring metric variables
2026-01-29 15:53:42,250:INFO:Importing untrained model
2026-01-29 15:53:42,250:INFO:Linear Discriminant Analysis Imported successfully
2026-01-29 15:53:42,260:INFO:Starting cross validation
2026-01-29 15:53:42,261:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:53:42,938:INFO:Calculating mean and std
2026-01-29 15:53:42,939:INFO:Creating metrics dataframe
2026-01-29 15:53:42,942:INFO:Uploading results into container
2026-01-29 15:53:42,942:INFO:Uploading model into container now
2026-01-29 15:53:42,943:INFO:_master_model_container: 11
2026-01-29 15:53:42,943:INFO:_display_container: 2
2026-01-29 15:53:42,943:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2026-01-29 15:53:42,943:INFO:create_model() successfully completed......................................
2026-01-29 15:53:43,137:INFO:SubProcess create_model() end ==================================
2026-01-29 15:53:43,138:INFO:Creating metrics dataframe
2026-01-29 15:53:43,145:INFO:Initializing Extra Trees Classifier
2026-01-29 15:53:43,146:INFO:Total runtime is 18.70095623334248 minutes
2026-01-29 15:53:43,149:INFO:SubProcess create_model() called ==================================
2026-01-29 15:53:43,149:INFO:Initializing create_model()
2026-01-29 15:53:43,149:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:53:43,149:INFO:Checking exceptions
2026-01-29 15:53:43,150:INFO:Importing libraries
2026-01-29 15:53:43,150:INFO:Copying training dataset
2026-01-29 15:53:43,242:INFO:Defining folds
2026-01-29 15:53:43,242:INFO:Declaring metric variables
2026-01-29 15:53:43,244:INFO:Importing untrained model
2026-01-29 15:53:43,244:INFO:Extra Trees Classifier Imported successfully
2026-01-29 15:53:43,256:INFO:Starting cross validation
2026-01-29 15:53:43,258:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:53:47,881:INFO:Calculating mean and std
2026-01-29 15:53:47,882:INFO:Creating metrics dataframe
2026-01-29 15:53:47,886:INFO:Uploading results into container
2026-01-29 15:53:47,887:INFO:Uploading model into container now
2026-01-29 15:53:47,887:INFO:_master_model_container: 12
2026-01-29 15:53:47,888:INFO:_display_container: 2
2026-01-29 15:53:47,889:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2026-01-29 15:53:47,889:INFO:create_model() successfully completed......................................
2026-01-29 15:53:48,126:INFO:SubProcess create_model() end ==================================
2026-01-29 15:53:48,126:INFO:Creating metrics dataframe
2026-01-29 15:53:48,135:INFO:Initializing Light Gradient Boosting Machine
2026-01-29 15:53:48,135:INFO:Total runtime is 18.78410774469375 minutes
2026-01-29 15:53:48,139:INFO:SubProcess create_model() called ==================================
2026-01-29 15:53:48,140:INFO:Initializing create_model()
2026-01-29 15:53:48,141:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:53:48,141:INFO:Checking exceptions
2026-01-29 15:53:48,141:INFO:Importing libraries
2026-01-29 15:53:48,141:INFO:Copying training dataset
2026-01-29 15:53:48,246:INFO:Defining folds
2026-01-29 15:53:48,246:INFO:Declaring metric variables
2026-01-29 15:53:48,250:INFO:Importing untrained model
2026-01-29 15:53:48,255:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-29 15:53:48,262:INFO:Starting cross validation
2026-01-29 15:53:48,263:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:53:50,367:INFO:Calculating mean and std
2026-01-29 15:53:50,368:INFO:Creating metrics dataframe
2026-01-29 15:53:50,371:INFO:Uploading results into container
2026-01-29 15:53:50,372:INFO:Uploading model into container now
2026-01-29 15:53:50,372:INFO:_master_model_container: 13
2026-01-29 15:53:50,373:INFO:_display_container: 2
2026-01-29 15:53:50,374:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-29 15:53:50,375:INFO:create_model() successfully completed......................................
2026-01-29 15:53:50,573:INFO:SubProcess create_model() end ==================================
2026-01-29 15:53:50,573:INFO:Creating metrics dataframe
2026-01-29 15:53:50,582:INFO:Initializing CatBoost Classifier
2026-01-29 15:53:50,582:INFO:Total runtime is 18.824895695845278 minutes
2026-01-29 15:53:50,582:INFO:SubProcess create_model() called ==================================
2026-01-29 15:53:50,582:INFO:Initializing create_model()
2026-01-29 15:53:50,582:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:53:50,582:INFO:Checking exceptions
2026-01-29 15:53:50,582:INFO:Importing libraries
2026-01-29 15:53:50,582:INFO:Copying training dataset
2026-01-29 15:53:50,668:INFO:Defining folds
2026-01-29 15:53:50,668:INFO:Declaring metric variables
2026-01-29 15:53:50,672:INFO:Importing untrained model
2026-01-29 15:53:50,675:INFO:CatBoost Classifier Imported successfully
2026-01-29 15:53:50,675:INFO:Starting cross validation
2026-01-29 15:53:50,675:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:54:46,154:INFO:Calculating mean and std
2026-01-29 15:54:46,158:INFO:Creating metrics dataframe
2026-01-29 15:54:46,158:INFO:Uploading results into container
2026-01-29 15:54:46,164:INFO:Uploading model into container now
2026-01-29 15:54:46,165:INFO:_master_model_container: 14
2026-01-29 15:54:46,165:INFO:_display_container: 2
2026-01-29 15:54:46,165:INFO:<catboost.core.CatBoostClassifier object at 0x0000024870CE2650>
2026-01-29 15:54:46,165:INFO:create_model() successfully completed......................................
2026-01-29 15:54:46,341:INFO:SubProcess create_model() end ==================================
2026-01-29 15:54:46,341:INFO:Creating metrics dataframe
2026-01-29 15:54:46,350:INFO:Initializing Dummy Classifier
2026-01-29 15:54:46,357:INFO:Total runtime is 19.754346024990074 minutes
2026-01-29 15:54:46,357:INFO:SubProcess create_model() called ==================================
2026-01-29 15:54:46,357:INFO:Initializing create_model()
2026-01-29 15:54:46,357:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:54:46,357:INFO:Checking exceptions
2026-01-29 15:54:46,357:INFO:Importing libraries
2026-01-29 15:54:46,357:INFO:Copying training dataset
2026-01-29 15:54:46,432:INFO:Defining folds
2026-01-29 15:54:46,432:INFO:Declaring metric variables
2026-01-29 15:54:46,436:INFO:Importing untrained model
2026-01-29 15:54:46,439:INFO:Dummy Classifier Imported successfully
2026-01-29 15:54:46,443:INFO:Starting cross validation
2026-01-29 15:54:46,443:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:54:46,724:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-01-29 15:54:46,745:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-01-29 15:54:46,757:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-01-29 15:54:46,776:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-01-29 15:54:46,808:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-01-29 15:54:47,025:INFO:Calculating mean and std
2026-01-29 15:54:47,025:INFO:Creating metrics dataframe
2026-01-29 15:54:47,025:INFO:Uploading results into container
2026-01-29 15:54:47,025:INFO:Uploading model into container now
2026-01-29 15:54:47,025:INFO:_master_model_container: 15
2026-01-29 15:54:47,025:INFO:_display_container: 2
2026-01-29 15:54:47,025:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2026-01-29 15:54:47,025:INFO:create_model() successfully completed......................................
2026-01-29 15:54:47,207:INFO:SubProcess create_model() end ==================================
2026-01-29 15:54:47,207:INFO:Creating metrics dataframe
2026-01-29 15:54:47,222:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-29 15:54:47,236:INFO:Initializing create_model()
2026-01-29 15:54:47,236:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:54:47,239:INFO:Checking exceptions
2026-01-29 15:54:47,240:INFO:Importing libraries
2026-01-29 15:54:47,240:INFO:Copying training dataset
2026-01-29 15:54:47,336:INFO:Defining folds
2026-01-29 15:54:47,337:INFO:Declaring metric variables
2026-01-29 15:54:47,337:INFO:Importing untrained model
2026-01-29 15:54:47,337:INFO:Declaring custom model
2026-01-29 15:54:47,337:INFO:Logistic Regression Imported successfully
2026-01-29 15:54:47,338:INFO:Cross validation set to False
2026-01-29 15:54:47,338:INFO:Fitting Model
2026-01-29 15:54:47,607:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 15:54:47,607:INFO:create_model() successfully completed......................................
2026-01-29 15:54:47,789:INFO:Initializing create_model()
2026-01-29 15:54:47,790:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:54:47,790:INFO:Checking exceptions
2026-01-29 15:54:47,791:INFO:Importing libraries
2026-01-29 15:54:47,791:INFO:Copying training dataset
2026-01-29 15:54:47,872:INFO:Defining folds
2026-01-29 15:54:47,872:INFO:Declaring metric variables
2026-01-29 15:54:47,872:INFO:Importing untrained model
2026-01-29 15:54:47,872:INFO:Declaring custom model
2026-01-29 15:54:47,872:INFO:Naive Bayes Imported successfully
2026-01-29 15:54:47,872:INFO:Cross validation set to False
2026-01-29 15:54:47,872:INFO:Fitting Model
2026-01-29 15:54:47,940:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-01-29 15:54:47,940:INFO:create_model() successfully completed......................................
2026-01-29 15:54:48,107:INFO:Initializing create_model()
2026-01-29 15:54:48,107:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:54:48,107:INFO:Checking exceptions
2026-01-29 15:54:48,118:INFO:Importing libraries
2026-01-29 15:54:48,118:INFO:Copying training dataset
2026-01-29 15:54:48,179:INFO:Defining folds
2026-01-29 15:54:48,179:INFO:Declaring metric variables
2026-01-29 15:54:48,180:INFO:Importing untrained model
2026-01-29 15:54:48,180:INFO:Declaring custom model
2026-01-29 15:54:48,180:INFO:Decision Tree Classifier Imported successfully
2026-01-29 15:54:48,180:INFO:Cross validation set to False
2026-01-29 15:54:48,180:INFO:Fitting Model
2026-01-29 15:54:48,241:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 15:54:48,241:INFO:create_model() successfully completed......................................
2026-01-29 15:54:48,425:INFO:_master_model_container: 15
2026-01-29 15:54:48,425:INFO:_display_container: 2
2026-01-29 15:54:48,425:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')]
2026-01-29 15:54:48,425:INFO:compare_models() successfully completed......................................
2026-01-29 15:54:48,425:INFO:Initializing tune_model()
2026-01-29 15:54:48,425:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 15:54:48,425:INFO:Checking exceptions
2026-01-29 15:54:48,475:INFO:Copying training dataset
2026-01-29 15:54:48,544:INFO:Checking base model
2026-01-29 15:54:48,544:INFO:Base model : Logistic Regression
2026-01-29 15:54:48,548:INFO:Declaring metric variables
2026-01-29 15:54:48,552:INFO:Defining Hyperparameters
2026-01-29 15:54:48,729:INFO:Tuning with n_jobs=-1
2026-01-29 15:54:48,729:INFO:Initializing RandomizedSearchCV
2026-01-29 15:54:52,415:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 5.682}
2026-01-29 15:54:52,415:INFO:Hyperparameter search completed
2026-01-29 15:54:52,415:INFO:SubProcess create_model() called ==================================
2026-01-29 15:54:52,415:INFO:Initializing create_model()
2026-01-29 15:54:52,415:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002480469E050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 5.682})
2026-01-29 15:54:52,415:INFO:Checking exceptions
2026-01-29 15:54:52,415:INFO:Importing libraries
2026-01-29 15:54:52,415:INFO:Copying training dataset
2026-01-29 15:54:52,490:INFO:Defining folds
2026-01-29 15:54:52,490:INFO:Declaring metric variables
2026-01-29 15:54:52,490:INFO:Importing untrained model
2026-01-29 15:54:52,490:INFO:Declaring custom model
2026-01-29 15:54:52,490:INFO:Logistic Regression Imported successfully
2026-01-29 15:54:52,505:INFO:Starting cross validation
2026-01-29 15:54:52,509:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:54:53,488:INFO:Calculating mean and std
2026-01-29 15:54:53,489:INFO:Creating metrics dataframe
2026-01-29 15:54:53,495:INFO:Finalizing model
2026-01-29 15:54:53,827:INFO:Uploading results into container
2026-01-29 15:54:53,828:INFO:Uploading model into container now
2026-01-29 15:54:53,829:INFO:_master_model_container: 16
2026-01-29 15:54:53,829:INFO:_display_container: 3
2026-01-29 15:54:53,830:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 15:54:53,830:INFO:create_model() successfully completed......................................
2026-01-29 15:54:54,012:INFO:SubProcess create_model() end ==================================
2026-01-29 15:54:54,012:INFO:choose_better activated
2026-01-29 15:54:54,015:INFO:SubProcess create_model() called ==================================
2026-01-29 15:54:54,016:INFO:Initializing create_model()
2026-01-29 15:54:54,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:54:54,016:INFO:Checking exceptions
2026-01-29 15:54:54,018:INFO:Importing libraries
2026-01-29 15:54:54,019:INFO:Copying training dataset
2026-01-29 15:54:54,074:INFO:Defining folds
2026-01-29 15:54:54,074:INFO:Declaring metric variables
2026-01-29 15:54:54,074:INFO:Importing untrained model
2026-01-29 15:54:54,074:INFO:Declaring custom model
2026-01-29 15:54:54,074:INFO:Logistic Regression Imported successfully
2026-01-29 15:54:54,074:INFO:Starting cross validation
2026-01-29 15:54:54,074:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:54:54,963:INFO:Calculating mean and std
2026-01-29 15:54:54,967:INFO:Creating metrics dataframe
2026-01-29 15:54:54,969:INFO:Finalizing model
2026-01-29 15:54:55,205:INFO:Uploading results into container
2026-01-29 15:54:55,206:INFO:Uploading model into container now
2026-01-29 15:54:55,206:INFO:_master_model_container: 17
2026-01-29 15:54:55,206:INFO:_display_container: 4
2026-01-29 15:54:55,207:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 15:54:55,207:INFO:create_model() successfully completed......................................
2026-01-29 15:54:55,422:INFO:SubProcess create_model() end ==================================
2026-01-29 15:54:55,423:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 15:54:55,423:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 15:54:55,423:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2026-01-29 15:54:55,423:INFO:choose_better completed
2026-01-29 15:54:55,424:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 15:54:55,429:INFO:_master_model_container: 17
2026-01-29 15:54:55,429:INFO:_display_container: 3
2026-01-29 15:54:55,429:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 15:54:55,429:INFO:tune_model() successfully completed......................................
2026-01-29 15:54:55,641:INFO:Initializing tune_model()
2026-01-29 15:54:55,641:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 15:54:55,641:INFO:Checking exceptions
2026-01-29 15:54:55,677:INFO:Copying training dataset
2026-01-29 15:54:55,754:INFO:Checking base model
2026-01-29 15:54:55,754:INFO:Base model : Naive Bayes
2026-01-29 15:54:55,758:INFO:Declaring metric variables
2026-01-29 15:54:55,762:INFO:Defining Hyperparameters
2026-01-29 15:54:55,983:INFO:Tuning with n_jobs=-1
2026-01-29 15:54:55,983:INFO:Initializing RandomizedSearchCV
2026-01-29 15:54:57,835:INFO:best_params: {'actual_estimator__var_smoothing': 2e-07}
2026-01-29 15:54:57,836:INFO:Hyperparameter search completed
2026-01-29 15:54:57,836:INFO:SubProcess create_model() called ==================================
2026-01-29 15:54:57,837:INFO:Initializing create_model()
2026-01-29 15:54:57,837:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024804682610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'var_smoothing': 2e-07})
2026-01-29 15:54:57,837:INFO:Checking exceptions
2026-01-29 15:54:57,838:INFO:Importing libraries
2026-01-29 15:54:57,838:INFO:Copying training dataset
2026-01-29 15:54:57,990:INFO:Defining folds
2026-01-29 15:54:57,990:INFO:Declaring metric variables
2026-01-29 15:54:57,995:INFO:Importing untrained model
2026-01-29 15:54:57,995:INFO:Declaring custom model
2026-01-29 15:54:58,000:INFO:Naive Bayes Imported successfully
2026-01-29 15:54:58,010:INFO:Starting cross validation
2026-01-29 15:54:58,011:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:54:58,780:INFO:Calculating mean and std
2026-01-29 15:54:58,780:INFO:Creating metrics dataframe
2026-01-29 15:54:58,790:INFO:Finalizing model
2026-01-29 15:54:58,883:INFO:Uploading results into container
2026-01-29 15:54:58,884:INFO:Uploading model into container now
2026-01-29 15:54:58,885:INFO:_master_model_container: 18
2026-01-29 15:54:58,885:INFO:_display_container: 4
2026-01-29 15:54:58,885:INFO:GaussianNB(priors=None, var_smoothing=2e-07)
2026-01-29 15:54:58,885:INFO:create_model() successfully completed......................................
2026-01-29 15:54:59,109:INFO:SubProcess create_model() end ==================================
2026-01-29 15:54:59,110:INFO:choose_better activated
2026-01-29 15:54:59,112:INFO:SubProcess create_model() called ==================================
2026-01-29 15:54:59,112:INFO:Initializing create_model()
2026-01-29 15:54:59,112:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:54:59,112:INFO:Checking exceptions
2026-01-29 15:54:59,114:INFO:Importing libraries
2026-01-29 15:54:59,114:INFO:Copying training dataset
2026-01-29 15:54:59,188:INFO:Defining folds
2026-01-29 15:54:59,188:INFO:Declaring metric variables
2026-01-29 15:54:59,188:INFO:Importing untrained model
2026-01-29 15:54:59,188:INFO:Declaring custom model
2026-01-29 15:54:59,189:INFO:Naive Bayes Imported successfully
2026-01-29 15:54:59,189:INFO:Starting cross validation
2026-01-29 15:54:59,190:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:54:59,915:INFO:Calculating mean and std
2026-01-29 15:54:59,916:INFO:Creating metrics dataframe
2026-01-29 15:54:59,918:INFO:Finalizing model
2026-01-29 15:54:59,995:INFO:Uploading results into container
2026-01-29 15:54:59,996:INFO:Uploading model into container now
2026-01-29 15:54:59,996:INFO:_master_model_container: 19
2026-01-29 15:54:59,996:INFO:_display_container: 5
2026-01-29 15:54:59,996:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-01-29 15:54:59,997:INFO:create_model() successfully completed......................................
2026-01-29 15:55:00,211:INFO:SubProcess create_model() end ==================================
2026-01-29 15:55:00,211:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for AUC is 0.5369
2026-01-29 15:55:00,212:INFO:GaussianNB(priors=None, var_smoothing=2e-07) result for AUC is 0.5369
2026-01-29 15:55:00,212:INFO:GaussianNB(priors=None, var_smoothing=1e-09) is best model
2026-01-29 15:55:00,212:INFO:choose_better completed
2026-01-29 15:55:00,212:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 15:55:00,223:INFO:_master_model_container: 19
2026-01-29 15:55:00,224:INFO:_display_container: 4
2026-01-29 15:55:00,224:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-01-29 15:55:00,224:INFO:tune_model() successfully completed......................................
2026-01-29 15:55:00,429:INFO:Initializing tune_model()
2026-01-29 15:55:00,430:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 15:55:00,430:INFO:Checking exceptions
2026-01-29 15:55:00,466:INFO:Copying training dataset
2026-01-29 15:55:00,543:INFO:Checking base model
2026-01-29 15:55:00,544:INFO:Base model : Decision Tree Classifier
2026-01-29 15:55:00,548:INFO:Declaring metric variables
2026-01-29 15:55:00,552:INFO:Defining Hyperparameters
2026-01-29 15:55:00,802:INFO:Tuning with n_jobs=-1
2026-01-29 15:55:00,802:INFO:Initializing RandomizedSearchCV
2026-01-29 15:55:02,562:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.0005, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 3, 'actual_estimator__criterion': 'gini'}
2026-01-29 15:55:02,563:INFO:Hyperparameter search completed
2026-01-29 15:55:02,564:INFO:SubProcess create_model() called ==================================
2026-01-29 15:55:02,564:INFO:Initializing create_model()
2026-01-29 15:55:02,565:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024870C3D290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0005, 'max_features': 1.0, 'max_depth': 3, 'criterion': 'gini'})
2026-01-29 15:55:02,566:INFO:Checking exceptions
2026-01-29 15:55:02,566:INFO:Importing libraries
2026-01-29 15:55:02,567:INFO:Copying training dataset
2026-01-29 15:55:02,706:INFO:Defining folds
2026-01-29 15:55:02,706:INFO:Declaring metric variables
2026-01-29 15:55:02,724:INFO:Importing untrained model
2026-01-29 15:55:02,724:INFO:Declaring custom model
2026-01-29 15:55:02,729:INFO:Decision Tree Classifier Imported successfully
2026-01-29 15:55:02,737:INFO:Starting cross validation
2026-01-29 15:55:02,738:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:55:03,450:INFO:Calculating mean and std
2026-01-29 15:55:03,452:INFO:Creating metrics dataframe
2026-01-29 15:55:03,458:INFO:Finalizing model
2026-01-29 15:55:03,607:INFO:Uploading results into container
2026-01-29 15:55:03,609:INFO:Uploading model into container now
2026-01-29 15:55:03,609:INFO:_master_model_container: 20
2026-01-29 15:55:03,609:INFO:_display_container: 5
2026-01-29 15:55:03,610:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 15:55:03,610:INFO:create_model() successfully completed......................................
2026-01-29 15:55:03,874:INFO:SubProcess create_model() end ==================================
2026-01-29 15:55:03,874:INFO:choose_better activated
2026-01-29 15:55:03,880:INFO:SubProcess create_model() called ==================================
2026-01-29 15:55:03,881:INFO:Initializing create_model()
2026-01-29 15:55:03,881:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:55:03,882:INFO:Checking exceptions
2026-01-29 15:55:03,884:INFO:Importing libraries
2026-01-29 15:55:03,884:INFO:Copying training dataset
2026-01-29 15:55:03,986:INFO:Defining folds
2026-01-29 15:55:03,986:INFO:Declaring metric variables
2026-01-29 15:55:03,986:INFO:Importing untrained model
2026-01-29 15:55:03,986:INFO:Declaring custom model
2026-01-29 15:55:03,986:INFO:Decision Tree Classifier Imported successfully
2026-01-29 15:55:03,987:INFO:Starting cross validation
2026-01-29 15:55:03,987:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:55:04,751:INFO:Calculating mean and std
2026-01-29 15:55:04,751:INFO:Creating metrics dataframe
2026-01-29 15:55:04,758:INFO:Finalizing model
2026-01-29 15:55:04,852:INFO:Uploading results into container
2026-01-29 15:55:04,853:INFO:Uploading model into container now
2026-01-29 15:55:04,853:INFO:_master_model_container: 21
2026-01-29 15:55:04,853:INFO:_display_container: 6
2026-01-29 15:55:04,854:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 15:55:04,854:INFO:create_model() successfully completed......................................
2026-01-29 15:55:05,120:INFO:SubProcess create_model() end ==================================
2026-01-29 15:55:05,122:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5369
2026-01-29 15:55:05,123:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5366
2026-01-29 15:55:05,124:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-29 15:55:05,124:INFO:choose_better completed
2026-01-29 15:55:05,125:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 15:55:05,142:INFO:_master_model_container: 21
2026-01-29 15:55:05,142:INFO:_display_container: 5
2026-01-29 15:55:05,144:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 15:55:05,144:INFO:tune_model() successfully completed......................................
2026-01-29 15:55:05,552:INFO:Initializing evaluate_model()
2026-01-29 15:55:05,555:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 15:55:05,613:INFO:Initializing plot_model()
2026-01-29 15:55:05,614:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:55:05,614:INFO:Checking exceptions
2026-01-29 15:55:05,661:INFO:Preloading libraries
2026-01-29 15:55:05,661:INFO:Copying training dataset
2026-01-29 15:55:05,661:INFO:Plot type: pipeline
2026-01-29 15:55:05,825:INFO:Visual Rendered Successfully
2026-01-29 15:55:06,016:INFO:plot_model() successfully completed......................................
2026-01-29 15:55:06,019:INFO:Initializing evaluate_model()
2026-01-29 15:55:06,019:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 15:55:06,050:INFO:Initializing plot_model()
2026-01-29 15:55:06,051:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:55:06,051:INFO:Checking exceptions
2026-01-29 15:55:06,082:INFO:Preloading libraries
2026-01-29 15:55:06,082:INFO:Copying training dataset
2026-01-29 15:55:06,082:INFO:Plot type: pipeline
2026-01-29 15:55:06,148:INFO:Visual Rendered Successfully
2026-01-29 15:55:06,324:INFO:plot_model() successfully completed......................................
2026-01-29 15:55:06,326:INFO:Initializing evaluate_model()
2026-01-29 15:55:06,326:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 15:55:06,370:INFO:Initializing plot_model()
2026-01-29 15:55:06,371:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:55:06,371:INFO:Checking exceptions
2026-01-29 15:55:06,408:INFO:Preloading libraries
2026-01-29 15:55:06,408:INFO:Copying training dataset
2026-01-29 15:55:06,408:INFO:Plot type: pipeline
2026-01-29 15:55:06,476:INFO:Visual Rendered Successfully
2026-01-29 15:55:06,656:INFO:plot_model() successfully completed......................................
2026-01-29 15:55:06,662:INFO:Initializing predict_model()
2026-01-29 15:55:06,662:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000248048BC720>)
2026-01-29 15:55:06,662:INFO:Checking exceptions
2026-01-29 15:55:06,662:INFO:Preloading libraries
2026-01-29 15:55:06,664:INFO:Set up data.
2026-01-29 15:55:06,673:INFO:Set up index.
2026-01-29 15:55:07,155:INFO:Initializing predict_model()
2026-01-29 15:55:07,155:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024810D7FC40>)
2026-01-29 15:55:07,155:INFO:Checking exceptions
2026-01-29 15:55:07,155:INFO:Preloading libraries
2026-01-29 15:55:07,158:INFO:Set up data.
2026-01-29 15:55:07,164:INFO:Set up index.
2026-01-29 15:55:07,640:INFO:Initializing predict_model()
2026-01-29 15:55:07,640:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000248048BC720>)
2026-01-29 15:55:07,640:INFO:Checking exceptions
2026-01-29 15:55:07,640:INFO:Preloading libraries
2026-01-29 15:55:07,640:INFO:Set up data.
2026-01-29 15:55:07,640:INFO:Set up index.
2026-01-29 15:55:08,108:INFO:Initializing plot_model()
2026-01-29 15:55:08,109:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-29 15:55:08,109:INFO:Checking exceptions
2026-01-29 15:55:08,132:INFO:Preloading libraries
2026-01-29 15:55:08,132:INFO:Copying training dataset
2026-01-29 15:55:08,132:INFO:Plot type: feature
2026-01-29 15:55:08,386:INFO:Visual Rendered Successfully
2026-01-29 15:55:08,561:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:15,782:INFO:Initializing plot_model()
2026-01-29 15:57:15,783:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=dimension, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:15,783:INFO:Checking exceptions
2026-01-29 15:57:15,812:INFO:Preloading libraries
2026-01-29 15:57:15,812:INFO:Copying training dataset
2026-01-29 15:57:15,812:INFO:Plot type: dimension
2026-01-29 15:57:15,933:INFO:Fitting StandardScaler()
2026-01-29 15:57:16,020:INFO:Fitting PCA()
2026-01-29 15:57:16,274:INFO:Fitting & Transforming Model
2026-01-29 15:57:16,291:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\yellowbrick\features\radviz.py:199: RuntimeWarning: invalid value encountered in divide

2026-01-29 15:57:21,111:INFO:Visual Rendered Successfully
2026-01-29 15:57:21,307:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:21,319:INFO:Initializing plot_model()
2026-01-29 15:57:21,319:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:21,319:INFO:Checking exceptions
2026-01-29 15:57:21,340:INFO:Preloading libraries
2026-01-29 15:57:21,340:INFO:Copying training dataset
2026-01-29 15:57:21,340:INFO:Plot type: pipeline
2026-01-29 15:57:21,393:INFO:Visual Rendered Successfully
2026-01-29 15:57:21,588:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:27,131:INFO:Initializing plot_model()
2026-01-29 15:57:27,132:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=calibration, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:27,132:INFO:Checking exceptions
2026-01-29 15:57:27,152:INFO:Preloading libraries
2026-01-29 15:57:27,152:INFO:Copying training dataset
2026-01-29 15:57:27,152:INFO:Plot type: calibration
2026-01-29 15:57:27,159:INFO:Scoring test/hold-out set
2026-01-29 15:57:27,297:INFO:Visual Rendered Successfully
2026-01-29 15:57:27,504:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:28,477:INFO:Initializing plot_model()
2026-01-29 15:57:28,477:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:28,477:INFO:Checking exceptions
2026-01-29 15:57:28,499:INFO:Preloading libraries
2026-01-29 15:57:28,499:INFO:Copying training dataset
2026-01-29 15:57:28,499:INFO:Plot type: pipeline
2026-01-29 15:57:28,547:INFO:Visual Rendered Successfully
2026-01-29 15:57:28,750:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:29,658:INFO:Initializing plot_model()
2026-01-29 15:57:29,658:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=calibration, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:29,659:INFO:Checking exceptions
2026-01-29 15:57:29,684:INFO:Preloading libraries
2026-01-29 15:57:29,684:INFO:Copying training dataset
2026-01-29 15:57:29,684:INFO:Plot type: calibration
2026-01-29 15:57:29,691:INFO:Scoring test/hold-out set
2026-01-29 15:57:29,825:INFO:Visual Rendered Successfully
2026-01-29 15:57:30,020:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:33,354:INFO:Initializing plot_model()
2026-01-29 15:57:33,356:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=dimension, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:33,356:INFO:Checking exceptions
2026-01-29 15:57:33,377:INFO:Preloading libraries
2026-01-29 15:57:33,377:INFO:Copying training dataset
2026-01-29 15:57:33,377:INFO:Plot type: dimension
2026-01-29 15:57:33,443:INFO:Fitting StandardScaler()
2026-01-29 15:57:33,513:INFO:Fitting PCA()
2026-01-29 15:57:33,756:INFO:Fitting & Transforming Model
2026-01-29 15:57:33,771:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\yellowbrick\features\radviz.py:199: RuntimeWarning: invalid value encountered in divide

2026-01-29 15:57:41,864:INFO:Visual Rendered Successfully
2026-01-29 15:57:42,103:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:42,136:INFO:Initializing plot_model()
2026-01-29 15:57:42,136:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=tree, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:42,136:INFO:Checking exceptions
2026-01-29 15:57:43,864:INFO:Initializing plot_model()
2026-01-29 15:57:43,864:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=learning, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:43,864:INFO:Checking exceptions
2026-01-29 15:57:43,884:INFO:Preloading libraries
2026-01-29 15:57:43,885:INFO:Copying training dataset
2026-01-29 15:57:43,885:INFO:Plot type: learning
2026-01-29 15:57:44,051:INFO:Fitting Model
2026-01-29 15:57:51,354:INFO:Visual Rendered Successfully
2026-01-29 15:57:51,565:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:51,615:INFO:Initializing plot_model()
2026-01-29 15:57:51,615:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=calibration, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:51,615:INFO:Checking exceptions
2026-01-29 15:57:51,646:INFO:Preloading libraries
2026-01-29 15:57:51,646:INFO:Copying training dataset
2026-01-29 15:57:51,646:INFO:Plot type: calibration
2026-01-29 15:57:51,655:INFO:Scoring test/hold-out set
2026-01-29 15:57:51,848:INFO:Visual Rendered Successfully
2026-01-29 15:57:52,080:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:53,370:INFO:Initializing plot_model()
2026-01-29 15:57:53,371:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:53,371:INFO:Checking exceptions
2026-01-29 15:57:53,391:INFO:Preloading libraries
2026-01-29 15:57:53,391:INFO:Copying training dataset
2026-01-29 15:57:53,391:INFO:Plot type: feature
2026-01-29 15:57:53,580:INFO:Visual Rendered Successfully
2026-01-29 15:57:53,778:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:55,745:INFO:Initializing plot_model()
2026-01-29 15:57:55,745:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature_all, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:55,745:INFO:Checking exceptions
2026-01-29 15:57:55,770:INFO:Preloading libraries
2026-01-29 15:57:55,770:INFO:Copying training dataset
2026-01-29 15:57:55,770:INFO:Plot type: feature_all
2026-01-29 15:57:56,029:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\matplotlib\_tight_bbox.py:67: RuntimeWarning: divide by zero encountered in scalar divide

2026-01-29 15:57:56,029:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\matplotlib\_tight_bbox.py:68: RuntimeWarning: divide by zero encountered in scalar divide

2026-01-29 15:57:56,029:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\matplotlib\patches.py:739: RuntimeWarning: invalid value encountered in scalar add

2026-01-29 15:57:56,029:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\matplotlib\transforms.py:2050: RuntimeWarning: invalid value encountered in scalar add

2026-01-29 15:57:56,046:INFO:Visual Rendered Successfully
2026-01-29 15:57:56,254:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:59,486:INFO:Initializing plot_model()
2026-01-29 15:57:59,487:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=boundary, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:59,487:INFO:Checking exceptions
2026-01-29 15:57:59,514:INFO:Preloading libraries
2026-01-29 15:57:59,514:INFO:Copying training dataset
2026-01-29 15:57:59,514:INFO:Plot type: boundary
2026-01-29 15:57:59,620:INFO:Fitting StandardScaler()
2026-01-29 15:57:59,634:INFO:Fitting PCA()
2026-01-29 15:57:59,813:INFO:Fitting Model
2026-01-29 15:58:01,610:INFO:Visual Rendered Successfully
2026-01-29 15:58:01,860:INFO:plot_model() successfully completed......................................
2026-01-29 15:58:03,737:INFO:Initializing plot_model()
2026-01-29 15:58:03,738:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=gain, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:58:03,739:INFO:Checking exceptions
2026-01-29 15:58:03,761:INFO:Preloading libraries
2026-01-29 15:58:03,761:INFO:Copying training dataset
2026-01-29 15:58:03,761:INFO:Plot type: gain
2026-01-29 15:58:03,761:INFO:Generating predictions / predict_proba on X_test
2026-01-29 15:58:03,925:INFO:Visual Rendered Successfully
2026-01-29 15:58:04,113:INFO:plot_model() successfully completed......................................
2026-01-29 15:58:05,457:INFO:Initializing plot_model()
2026-01-29 15:58:05,457:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=tree, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:58:05,457:INFO:Checking exceptions
2026-01-29 15:58:06,613:INFO:Initializing plot_model()
2026-01-29 15:58:06,613:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=learning, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:58:06,613:INFO:Checking exceptions
2026-01-29 15:58:06,633:INFO:Preloading libraries
2026-01-29 15:58:06,633:INFO:Copying training dataset
2026-01-29 15:58:06,633:INFO:Plot type: learning
2026-01-29 15:58:06,829:INFO:Fitting Model
2026-01-29 15:58:13,907:INFO:Visual Rendered Successfully
2026-01-29 15:58:14,118:INFO:plot_model() successfully completed......................................
2026-01-29 15:58:14,128:INFO:Initializing plot_model()
2026-01-29 15:58:14,128:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=rfe, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:58:14,128:INFO:Checking exceptions
2026-01-29 15:58:14,166:INFO:Preloading libraries
2026-01-29 15:58:14,166:INFO:Copying training dataset
2026-01-29 15:58:14,166:INFO:Plot type: rfe
2026-01-29 15:58:14,382:INFO:Fitting Model
2026-01-29 15:58:19,436:INFO:Visual Rendered Successfully
2026-01-29 15:58:19,632:INFO:plot_model() successfully completed......................................
2026-01-29 15:58:33,959:INFO:Initializing plot_model()
2026-01-29 15:58:33,959:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=gain, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:58:33,959:INFO:Checking exceptions
2026-01-29 15:58:33,999:INFO:Preloading libraries
2026-01-29 15:58:34,000:INFO:Copying training dataset
2026-01-29 15:58:34,000:INFO:Plot type: gain
2026-01-29 15:58:34,000:INFO:Generating predictions / predict_proba on X_test
2026-01-29 15:58:34,216:INFO:Visual Rendered Successfully
2026-01-29 15:58:34,430:INFO:plot_model() successfully completed......................................
2026-01-29 15:58:36,177:INFO:Initializing plot_model()
2026-01-29 15:58:36,177:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=lift, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:58:36,177:INFO:Checking exceptions
2026-01-29 15:58:36,199:INFO:Preloading libraries
2026-01-29 15:58:36,199:INFO:Copying training dataset
2026-01-29 15:58:36,199:INFO:Plot type: lift
2026-01-29 15:58:36,199:INFO:Generating predictions / predict_proba on X_test
2026-01-29 15:58:36,361:INFO:Visual Rendered Successfully
2026-01-29 15:58:36,563:INFO:plot_model() successfully completed......................................
2026-01-29 15:58:55,094:INFO:Initializing plot_model()
2026-01-29 15:58:55,094:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=learning, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:58:55,094:INFO:Checking exceptions
2026-01-29 15:58:55,121:INFO:Preloading libraries
2026-01-29 15:58:55,121:INFO:Copying training dataset
2026-01-29 15:58:55,121:INFO:Plot type: learning
2026-01-29 15:58:55,330:INFO:Fitting Model
2026-01-29 15:58:56,460:INFO:Visual Rendered Successfully
2026-01-29 15:58:56,670:INFO:plot_model() successfully completed......................................
2026-01-29 15:59:04,839:INFO:Initializing plot_model()
2026-01-29 15:59:04,839:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), plot=learning, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:59:04,839:INFO:Checking exceptions
2026-01-29 15:59:04,870:INFO:Preloading libraries
2026-01-29 15:59:04,870:INFO:Copying training dataset
2026-01-29 15:59:04,870:INFO:Plot type: learning
2026-01-29 15:59:05,056:INFO:Fitting Model
2026-01-29 15:59:06,092:INFO:Visual Rendered Successfully
2026-01-29 15:59:06,293:INFO:plot_model() successfully completed......................................
2026-01-29 16:03:10,077:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\1833453759.py:18: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-29 16:03:12,331:INFO:PyCaret ClassificationExperiment
2026-01-29 16:03:12,332:INFO:Logging name: clf-default-name
2026-01-29 16:03:12,332:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-29 16:03:12,332:INFO:version 3.3.2
2026-01-29 16:03:12,332:INFO:Initializing setup()
2026-01-29 16:03:12,332:INFO:self.USI: e0d6
2026-01-29 16:03:12,332:INFO:self._variable_keys: {'X_test', 'fold_groups_param', 'pipeline', 'fix_imbalance', 'exp_name_log', 'data', 'y_test', 'seed', 'fold_shuffle_param', 'n_jobs_param', 'is_multiclass', 'gpu_n_jobs_param', 'memory', 'log_plots_param', 'logging_param', 'idx', 'y', 'target_param', 'fold_generator', 'y_train', 'gpu_param', 'USI', 'exp_id', '_available_plots', 'X', 'X_train', 'html_param', '_ml_usecase'}
2026-01-29 16:03:12,332:INFO:Checking environment
2026-01-29 16:03:12,332:INFO:python_version: 3.11.11
2026-01-29 16:03:12,333:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-29 16:03:12,333:INFO:machine: AMD64
2026-01-29 16:03:12,334:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-29 16:03:12,334:INFO:Memory: svmem(total=34009374720, available=12534964224, percent=63.1, used=21474410496, free=12534964224)
2026-01-29 16:03:12,334:INFO:Physical Core: 12
2026-01-29 16:03:12,334:INFO:Logical Core: 16
2026-01-29 16:03:12,334:INFO:Checking libraries
2026-01-29 16:03:12,334:INFO:System:
2026-01-29 16:03:12,334:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-29 16:03:12,334:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-29 16:03:12,335:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-29 16:03:12,335:INFO:PyCaret required dependencies:
2026-01-29 16:03:12,335:INFO:                 pip: 25.0
2026-01-29 16:03:12,335:INFO:          setuptools: 75.8.0
2026-01-29 16:03:12,335:INFO:             pycaret: 3.3.2
2026-01-29 16:03:12,335:INFO:             IPython: 9.9.0
2026-01-29 16:03:12,335:INFO:          ipywidgets: 8.1.8
2026-01-29 16:03:12,335:INFO:                tqdm: 4.67.1
2026-01-29 16:03:12,335:INFO:               numpy: 1.26.4
2026-01-29 16:03:12,335:INFO:              pandas: 2.1.4
2026-01-29 16:03:12,335:INFO:              jinja2: 3.1.6
2026-01-29 16:03:12,335:INFO:               scipy: 1.11.4
2026-01-29 16:03:12,335:INFO:              joblib: 1.3.2
2026-01-29 16:03:12,335:INFO:             sklearn: 1.4.2
2026-01-29 16:03:12,335:INFO:                pyod: 2.0.6
2026-01-29 16:03:12,335:INFO:            imblearn: 0.14.1
2026-01-29 16:03:12,335:INFO:   category_encoders: 2.7.0
2026-01-29 16:03:12,335:INFO:            lightgbm: 4.6.0
2026-01-29 16:03:12,335:INFO:               numba: 0.62.1
2026-01-29 16:03:12,335:INFO:            requests: 2.32.3
2026-01-29 16:03:12,335:INFO:          matplotlib: 3.7.5
2026-01-29 16:03:12,336:INFO:          scikitplot: 0.3.7
2026-01-29 16:03:12,336:INFO:         yellowbrick: 1.5
2026-01-29 16:03:12,336:INFO:              plotly: 5.24.1
2026-01-29 16:03:12,336:INFO:    plotly-resampler: Not installed
2026-01-29 16:03:12,336:INFO:             kaleido: 1.2.0
2026-01-29 16:03:12,336:INFO:           schemdraw: 0.15
2026-01-29 16:03:12,336:INFO:         statsmodels: 0.14.6
2026-01-29 16:03:12,336:INFO:              sktime: 0.26.0
2026-01-29 16:03:12,336:INFO:               tbats: 1.1.3
2026-01-29 16:03:12,336:INFO:            pmdarima: 2.0.4
2026-01-29 16:03:12,336:INFO:              psutil: 7.2.1
2026-01-29 16:03:12,336:INFO:          markupsafe: 3.0.3
2026-01-29 16:03:12,336:INFO:             pickle5: Not installed
2026-01-29 16:03:12,336:INFO:         cloudpickle: 3.0.0
2026-01-29 16:03:12,336:INFO:         deprecation: 2.1.0
2026-01-29 16:03:12,336:INFO:              xxhash: 3.6.0
2026-01-29 16:03:12,336:INFO:           wurlitzer: Not installed
2026-01-29 16:03:12,336:INFO:PyCaret optional dependencies:
2026-01-29 16:03:12,336:INFO:                shap: 0.44.1
2026-01-29 16:03:12,337:INFO:           interpret: 0.7.3
2026-01-29 16:03:12,338:INFO:                umap: 0.5.7
2026-01-29 16:03:12,338:INFO:     ydata_profiling: 4.18.1
2026-01-29 16:03:12,339:INFO:  explainerdashboard: 0.5.1
2026-01-29 16:03:12,339:INFO:             autoviz: Not installed
2026-01-29 16:03:12,339:INFO:           fairlearn: 0.7.0
2026-01-29 16:03:12,339:INFO:          deepchecks: Not installed
2026-01-29 16:03:12,339:INFO:             xgboost: Not installed
2026-01-29 16:03:12,339:INFO:            catboost: 1.2.8
2026-01-29 16:03:12,339:INFO:              kmodes: 0.12.2
2026-01-29 16:03:12,339:INFO:             mlxtend: 0.23.4
2026-01-29 16:03:12,339:INFO:       statsforecast: 1.5.0
2026-01-29 16:03:12,339:INFO:        tune_sklearn: Not installed
2026-01-29 16:03:12,339:INFO:                 ray: Not installed
2026-01-29 16:03:12,341:INFO:            hyperopt: 0.2.7
2026-01-29 16:03:12,341:INFO:              optuna: 4.6.0
2026-01-29 16:03:12,341:INFO:               skopt: 0.10.2
2026-01-29 16:03:12,341:INFO:              mlflow: 3.8.1
2026-01-29 16:03:12,341:INFO:              gradio: 6.3.0
2026-01-29 16:03:12,341:INFO:             fastapi: 0.128.0
2026-01-29 16:03:12,341:INFO:             uvicorn: 0.40.0
2026-01-29 16:03:12,342:INFO:              m2cgen: 0.10.0
2026-01-29 16:03:12,342:INFO:           evidently: 0.4.40
2026-01-29 16:03:12,342:INFO:               fugue: 0.8.7
2026-01-29 16:03:12,342:INFO:           streamlit: Not installed
2026-01-29 16:03:12,342:INFO:             prophet: Not installed
2026-01-29 16:03:12,342:INFO:None
2026-01-29 16:03:12,342:INFO:Set up data.
2026-01-29 16:03:12,377:INFO:Set up folding strategy.
2026-01-29 16:03:12,377:INFO:Set up train/test split.
2026-01-29 16:03:12,487:INFO:Set up index.
2026-01-29 16:03:12,495:INFO:Assigning column types.
2026-01-29 16:03:12,512:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-29 16:03:12,546:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:03:12,546:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:03:12,564:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:03:12,564:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:03:12,585:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:03:12,585:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:03:12,613:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:03:12,613:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:03:12,614:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-29 16:03:12,634:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:03:12,653:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:03:12,653:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:03:12,684:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:03:12,703:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:03:12,709:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:03:12,709:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-29 16:03:12,753:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:03:12,753:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:03:12,803:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:03:12,803:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:03:12,808:INFO:Preparing preprocessing pipeline...
2026-01-29 16:03:12,815:INFO:Set up simple imputation.
2026-01-29 16:03:12,816:INFO:Set up feature normalization.
2026-01-29 16:03:12,902:INFO:Finished creating preprocessing pipeline.
2026-01-29 16:03:12,914:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-29 16:03:12,914:INFO:Creating final display dataframe.
2026-01-29 16:03:13,181:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape       (429278, 4)
4        Transformed data shape       (429278, 4)
5   Transformed train set shape       (343422, 4)
6    Transformed test set shape        (85856, 4)
7               Ignore features                58
8              Numeric features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                 5
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              e0d6
2026-01-29 16:03:13,230:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:03:13,230:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:03:13,287:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:03:13,289:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:03:13,291:INFO:setup() successfully completed in 0.97s...............
2026-01-29 16:03:13,291:INFO:Initializing compare_models()
2026-01-29 16:03:13,291:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002481F5FA790>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002481F5FA790>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-29 16:03:13,293:INFO:Checking exceptions
2026-01-29 16:03:13,333:INFO:Preparing display monitor
2026-01-29 16:03:13,354:INFO:Initializing Logistic Regression
2026-01-29 16:03:13,355:INFO:Total runtime is 7.474422454833985e-06 minutes
2026-01-29 16:03:13,360:INFO:SubProcess create_model() called ==================================
2026-01-29 16:03:13,360:INFO:Initializing create_model()
2026-01-29 16:03:13,360:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002481F5FA790>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002480EE11E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:03:13,360:INFO:Checking exceptions
2026-01-29 16:03:13,361:INFO:Importing libraries
2026-01-29 16:03:13,361:INFO:Copying training dataset
2026-01-29 16:03:13,481:INFO:Defining folds
2026-01-29 16:03:13,482:INFO:Declaring metric variables
2026-01-29 16:03:13,485:INFO:Importing untrained model
2026-01-29 16:03:13,489:INFO:Logistic Regression Imported successfully
2026-01-29 16:03:13,497:INFO:Starting cross validation
2026-01-29 16:03:13,498:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:03:14,246:INFO:Calculating mean and std
2026-01-29 16:03:14,247:INFO:Creating metrics dataframe
2026-01-29 16:03:14,249:INFO:Uploading results into container
2026-01-29 16:03:14,249:INFO:Uploading model into container now
2026-01-29 16:03:14,250:INFO:_master_model_container: 1
2026-01-29 16:03:14,250:INFO:_display_container: 2
2026-01-29 16:03:14,250:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:03:14,250:INFO:create_model() successfully completed......................................
2026-01-29 16:03:14,536:INFO:SubProcess create_model() end ==================================
2026-01-29 16:03:14,536:INFO:Creating metrics dataframe
2026-01-29 16:03:14,543:INFO:Initializing K Neighbors Classifier
2026-01-29 16:03:14,544:INFO:Total runtime is 0.019810458024342857 minutes
2026-01-29 16:03:14,547:INFO:SubProcess create_model() called ==================================
2026-01-29 16:03:14,548:INFO:Initializing create_model()
2026-01-29 16:03:14,548:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002481F5FA790>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002480EE11E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:03:14,548:INFO:Checking exceptions
2026-01-29 16:03:14,548:INFO:Importing libraries
2026-01-29 16:03:14,548:INFO:Copying training dataset
2026-01-29 16:03:14,649:INFO:Defining folds
2026-01-29 16:03:14,649:INFO:Declaring metric variables
2026-01-29 16:03:14,656:INFO:Importing untrained model
2026-01-29 16:03:14,660:INFO:K Neighbors Classifier Imported successfully
2026-01-29 16:03:14,666:INFO:Starting cross validation
2026-01-29 16:03:14,667:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:09:45,976:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\2961347337.py:18: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-29 16:09:47,884:INFO:PyCaret ClassificationExperiment
2026-01-29 16:09:47,884:INFO:Logging name: clf-default-name
2026-01-29 16:09:47,885:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-29 16:09:47,885:INFO:version 3.3.2
2026-01-29 16:09:47,885:INFO:Initializing setup()
2026-01-29 16:09:47,885:INFO:self.USI: a7a0
2026-01-29 16:09:47,885:INFO:self._variable_keys: {'X_test', 'fold_groups_param', 'pipeline', 'fix_imbalance', 'exp_name_log', 'data', 'y_test', 'seed', 'fold_shuffle_param', 'n_jobs_param', 'is_multiclass', 'gpu_n_jobs_param', 'memory', 'log_plots_param', 'logging_param', 'idx', 'y', 'target_param', 'fold_generator', 'y_train', 'gpu_param', 'USI', 'exp_id', '_available_plots', 'X', 'X_train', 'html_param', '_ml_usecase'}
2026-01-29 16:09:47,886:INFO:Checking environment
2026-01-29 16:09:47,886:INFO:python_version: 3.11.11
2026-01-29 16:09:47,887:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-29 16:09:47,887:INFO:machine: AMD64
2026-01-29 16:09:47,887:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-29 16:09:47,887:INFO:Memory: svmem(total=34009374720, available=15785549824, percent=53.6, used=18223824896, free=15785549824)
2026-01-29 16:09:47,887:INFO:Physical Core: 12
2026-01-29 16:09:47,887:INFO:Logical Core: 16
2026-01-29 16:09:47,887:INFO:Checking libraries
2026-01-29 16:09:47,887:INFO:System:
2026-01-29 16:09:47,887:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-29 16:09:47,887:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-29 16:09:47,887:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-29 16:09:47,887:INFO:PyCaret required dependencies:
2026-01-29 16:09:47,887:INFO:                 pip: 25.0
2026-01-29 16:09:47,888:INFO:          setuptools: 75.8.0
2026-01-29 16:09:47,888:INFO:             pycaret: 3.3.2
2026-01-29 16:09:47,888:INFO:             IPython: 9.9.0
2026-01-29 16:09:47,888:INFO:          ipywidgets: 8.1.8
2026-01-29 16:09:47,888:INFO:                tqdm: 4.67.1
2026-01-29 16:09:47,888:INFO:               numpy: 1.26.4
2026-01-29 16:09:47,888:INFO:              pandas: 2.1.4
2026-01-29 16:09:47,888:INFO:              jinja2: 3.1.6
2026-01-29 16:09:47,888:INFO:               scipy: 1.11.4
2026-01-29 16:09:47,888:INFO:              joblib: 1.3.2
2026-01-29 16:09:47,888:INFO:             sklearn: 1.4.2
2026-01-29 16:09:47,888:INFO:                pyod: 2.0.6
2026-01-29 16:09:47,888:INFO:            imblearn: 0.14.1
2026-01-29 16:09:47,888:INFO:   category_encoders: 2.7.0
2026-01-29 16:09:47,888:INFO:            lightgbm: 4.6.0
2026-01-29 16:09:47,888:INFO:               numba: 0.62.1
2026-01-29 16:09:47,888:INFO:            requests: 2.32.3
2026-01-29 16:09:47,888:INFO:          matplotlib: 3.7.5
2026-01-29 16:09:47,888:INFO:          scikitplot: 0.3.7
2026-01-29 16:09:47,888:INFO:         yellowbrick: 1.5
2026-01-29 16:09:47,888:INFO:              plotly: 5.24.1
2026-01-29 16:09:47,888:INFO:    plotly-resampler: Not installed
2026-01-29 16:09:47,888:INFO:             kaleido: 1.2.0
2026-01-29 16:09:47,888:INFO:           schemdraw: 0.15
2026-01-29 16:09:47,888:INFO:         statsmodels: 0.14.6
2026-01-29 16:09:47,888:INFO:              sktime: 0.26.0
2026-01-29 16:09:47,888:INFO:               tbats: 1.1.3
2026-01-29 16:09:47,888:INFO:            pmdarima: 2.0.4
2026-01-29 16:09:47,888:INFO:              psutil: 7.2.1
2026-01-29 16:09:47,888:INFO:          markupsafe: 3.0.3
2026-01-29 16:09:47,889:INFO:             pickle5: Not installed
2026-01-29 16:09:47,889:INFO:         cloudpickle: 3.0.0
2026-01-29 16:09:47,889:INFO:         deprecation: 2.1.0
2026-01-29 16:09:47,889:INFO:              xxhash: 3.6.0
2026-01-29 16:09:47,889:INFO:           wurlitzer: Not installed
2026-01-29 16:09:47,889:INFO:PyCaret optional dependencies:
2026-01-29 16:09:47,889:INFO:                shap: 0.44.1
2026-01-29 16:09:47,889:INFO:           interpret: 0.7.3
2026-01-29 16:09:47,889:INFO:                umap: 0.5.7
2026-01-29 16:09:47,889:INFO:     ydata_profiling: 4.18.1
2026-01-29 16:09:47,889:INFO:  explainerdashboard: 0.5.1
2026-01-29 16:09:47,889:INFO:             autoviz: Not installed
2026-01-29 16:09:47,889:INFO:           fairlearn: 0.7.0
2026-01-29 16:09:47,889:INFO:          deepchecks: Not installed
2026-01-29 16:09:47,890:INFO:             xgboost: Not installed
2026-01-29 16:09:47,890:INFO:            catboost: 1.2.8
2026-01-29 16:09:47,890:INFO:              kmodes: 0.12.2
2026-01-29 16:09:47,890:INFO:             mlxtend: 0.23.4
2026-01-29 16:09:47,890:INFO:       statsforecast: 1.5.0
2026-01-29 16:09:47,890:INFO:        tune_sklearn: Not installed
2026-01-29 16:09:47,890:INFO:                 ray: Not installed
2026-01-29 16:09:47,890:INFO:            hyperopt: 0.2.7
2026-01-29 16:09:47,890:INFO:              optuna: 4.6.0
2026-01-29 16:09:47,890:INFO:               skopt: 0.10.2
2026-01-29 16:09:47,890:INFO:              mlflow: 3.8.1
2026-01-29 16:09:47,890:INFO:              gradio: 6.3.0
2026-01-29 16:09:47,890:INFO:             fastapi: 0.128.0
2026-01-29 16:09:47,890:INFO:             uvicorn: 0.40.0
2026-01-29 16:09:47,891:INFO:              m2cgen: 0.10.0
2026-01-29 16:09:47,891:INFO:           evidently: 0.4.40
2026-01-29 16:09:47,891:INFO:               fugue: 0.8.7
2026-01-29 16:09:47,891:INFO:           streamlit: Not installed
2026-01-29 16:09:47,891:INFO:             prophet: Not installed
2026-01-29 16:09:47,891:INFO:None
2026-01-29 16:09:47,891:INFO:Set up data.
2026-01-29 16:09:47,923:INFO:Set up folding strategy.
2026-01-29 16:09:47,923:INFO:Set up train/test split.
2026-01-29 16:09:48,043:INFO:Set up index.
2026-01-29 16:09:48,043:INFO:Assigning column types.
2026-01-29 16:09:48,060:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-29 16:09:48,093:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:09:48,093:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:09:48,110:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:09:48,110:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:09:48,160:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:09:48,161:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:09:48,183:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:09:48,184:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:09:48,184:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-29 16:09:48,219:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:09:48,241:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:09:48,241:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:09:48,277:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:09:48,298:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:09:48,298:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:09:48,299:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-29 16:09:48,347:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:09:48,347:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:09:48,409:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:09:48,410:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:09:48,410:INFO:Preparing preprocessing pipeline...
2026-01-29 16:09:48,410:INFO:Set up simple imputation.
2026-01-29 16:09:48,410:INFO:Set up feature normalization.
2026-01-29 16:09:48,510:INFO:Finished creating preprocessing pipeline.
2026-01-29 16:09:48,510:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-29 16:09:48,510:INFO:Creating final display dataframe.
2026-01-29 16:09:48,710:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape       (429278, 4)
4        Transformed data shape       (429278, 4)
5   Transformed train set shape       (343422, 4)
6    Transformed test set shape        (85856, 4)
7               Ignore features                58
8              Numeric features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                 3
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              a7a0
2026-01-29 16:09:48,767:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:09:48,767:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:09:48,826:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:09:48,826:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:09:48,831:INFO:setup() successfully completed in 0.95s...............
2026-01-29 16:09:48,831:INFO:Initializing compare_models()
2026-01-29 16:09:48,831:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-29 16:09:48,831:INFO:Checking exceptions
2026-01-29 16:09:48,860:INFO:Preparing display monitor
2026-01-29 16:09:48,876:INFO:Initializing Logistic Regression
2026-01-29 16:09:48,876:INFO:Total runtime is 0.0 minutes
2026-01-29 16:09:48,878:INFO:SubProcess create_model() called ==================================
2026-01-29 16:09:48,879:INFO:Initializing create_model()
2026-01-29 16:09:48,879:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816D43CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:09:48,879:INFO:Checking exceptions
2026-01-29 16:09:48,879:INFO:Importing libraries
2026-01-29 16:09:48,879:INFO:Copying training dataset
2026-01-29 16:09:48,949:INFO:Defining folds
2026-01-29 16:09:48,950:INFO:Declaring metric variables
2026-01-29 16:09:48,952:INFO:Importing untrained model
2026-01-29 16:09:48,954:INFO:Logistic Regression Imported successfully
2026-01-29 16:09:48,959:INFO:Starting cross validation
2026-01-29 16:09:48,960:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:09:55,362:INFO:Calculating mean and std
2026-01-29 16:09:55,362:INFO:Creating metrics dataframe
2026-01-29 16:09:55,362:INFO:Uploading results into container
2026-01-29 16:09:55,362:INFO:Uploading model into container now
2026-01-29 16:09:55,366:INFO:_master_model_container: 1
2026-01-29 16:09:55,366:INFO:_display_container: 2
2026-01-29 16:09:55,367:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:09:55,368:INFO:create_model() successfully completed......................................
2026-01-29 16:09:55,680:INFO:SubProcess create_model() end ==================================
2026-01-29 16:09:55,680:INFO:Creating metrics dataframe
2026-01-29 16:09:55,686:INFO:Initializing Decision Tree Classifier
2026-01-29 16:09:55,686:INFO:Total runtime is 0.11348706881205241 minutes
2026-01-29 16:09:55,690:INFO:SubProcess create_model() called ==================================
2026-01-29 16:09:55,690:INFO:Initializing create_model()
2026-01-29 16:09:55,691:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816D43CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:09:55,691:INFO:Checking exceptions
2026-01-29 16:09:55,691:INFO:Importing libraries
2026-01-29 16:09:55,691:INFO:Copying training dataset
2026-01-29 16:09:55,760:INFO:Defining folds
2026-01-29 16:09:55,760:INFO:Declaring metric variables
2026-01-29 16:09:55,760:INFO:Importing untrained model
2026-01-29 16:09:55,777:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:09:55,777:INFO:Starting cross validation
2026-01-29 16:09:55,777:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:10:00,720:INFO:Calculating mean and std
2026-01-29 16:10:00,725:INFO:Creating metrics dataframe
2026-01-29 16:10:00,731:INFO:Uploading results into container
2026-01-29 16:10:00,731:INFO:Uploading model into container now
2026-01-29 16:10:00,733:INFO:_master_model_container: 2
2026-01-29 16:10:00,734:INFO:_display_container: 2
2026-01-29 16:10:00,735:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:10:00,735:INFO:create_model() successfully completed......................................
2026-01-29 16:10:00,943:INFO:SubProcess create_model() end ==================================
2026-01-29 16:10:00,943:INFO:Creating metrics dataframe
2026-01-29 16:10:00,943:INFO:Initializing Random Forest Classifier
2026-01-29 16:10:00,943:INFO:Total runtime is 0.2011061708132426 minutes
2026-01-29 16:10:00,951:INFO:SubProcess create_model() called ==================================
2026-01-29 16:10:00,951:INFO:Initializing create_model()
2026-01-29 16:10:00,951:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816D43CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:10:00,951:INFO:Checking exceptions
2026-01-29 16:10:00,951:INFO:Importing libraries
2026-01-29 16:10:00,951:INFO:Copying training dataset
2026-01-29 16:10:01,011:INFO:Defining folds
2026-01-29 16:10:01,011:INFO:Declaring metric variables
2026-01-29 16:10:01,011:INFO:Importing untrained model
2026-01-29 16:10:01,011:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:10:01,026:INFO:Starting cross validation
2026-01-29 16:10:01,027:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:10:08,114:INFO:Calculating mean and std
2026-01-29 16:10:08,114:INFO:Creating metrics dataframe
2026-01-29 16:10:08,114:INFO:Uploading results into container
2026-01-29 16:10:08,114:INFO:Uploading model into container now
2026-01-29 16:10:08,114:INFO:_master_model_container: 3
2026-01-29 16:10:08,114:INFO:_display_container: 2
2026-01-29 16:10:08,114:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:10:08,114:INFO:create_model() successfully completed......................................
2026-01-29 16:10:08,309:INFO:SubProcess create_model() end ==================================
2026-01-29 16:10:08,309:INFO:Creating metrics dataframe
2026-01-29 16:10:08,326:INFO:Initializing Light Gradient Boosting Machine
2026-01-29 16:10:08,326:INFO:Total runtime is 0.32416341304779056 minutes
2026-01-29 16:10:08,326:INFO:SubProcess create_model() called ==================================
2026-01-29 16:10:08,326:INFO:Initializing create_model()
2026-01-29 16:10:08,326:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816D43CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:10:08,326:INFO:Checking exceptions
2026-01-29 16:10:08,326:INFO:Importing libraries
2026-01-29 16:10:08,326:INFO:Copying training dataset
2026-01-29 16:10:08,403:INFO:Defining folds
2026-01-29 16:10:08,403:INFO:Declaring metric variables
2026-01-29 16:10:08,406:INFO:Importing untrained model
2026-01-29 16:10:08,410:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-29 16:10:08,411:INFO:Starting cross validation
2026-01-29 16:10:08,411:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:10:15,067:INFO:Calculating mean and std
2026-01-29 16:10:15,067:INFO:Creating metrics dataframe
2026-01-29 16:10:15,071:INFO:Uploading results into container
2026-01-29 16:10:15,071:INFO:Uploading model into container now
2026-01-29 16:10:15,071:INFO:_master_model_container: 4
2026-01-29 16:10:15,071:INFO:_display_container: 2
2026-01-29 16:10:15,073:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-29 16:10:15,073:INFO:create_model() successfully completed......................................
2026-01-29 16:10:15,276:INFO:SubProcess create_model() end ==================================
2026-01-29 16:10:15,276:INFO:Creating metrics dataframe
2026-01-29 16:10:15,279:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-29 16:10:15,289:INFO:Initializing create_model()
2026-01-29 16:10:15,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:10:15,289:INFO:Checking exceptions
2026-01-29 16:10:15,294:INFO:Importing libraries
2026-01-29 16:10:15,294:INFO:Copying training dataset
2026-01-29 16:10:15,359:INFO:Defining folds
2026-01-29 16:10:15,359:INFO:Declaring metric variables
2026-01-29 16:10:15,359:INFO:Importing untrained model
2026-01-29 16:10:15,359:INFO:Declaring custom model
2026-01-29 16:10:15,359:INFO:Logistic Regression Imported successfully
2026-01-29 16:10:15,359:INFO:Cross validation set to False
2026-01-29 16:10:15,359:INFO:Fitting Model
2026-01-29 16:10:15,576:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:10:15,576:INFO:create_model() successfully completed......................................
2026-01-29 16:10:15,776:INFO:Initializing create_model()
2026-01-29 16:10:15,776:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:10:15,776:INFO:Checking exceptions
2026-01-29 16:10:15,787:INFO:Importing libraries
2026-01-29 16:10:15,787:INFO:Copying training dataset
2026-01-29 16:10:15,843:INFO:Defining folds
2026-01-29 16:10:15,843:INFO:Declaring metric variables
2026-01-29 16:10:15,843:INFO:Importing untrained model
2026-01-29 16:10:15,843:INFO:Declaring custom model
2026-01-29 16:10:15,843:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:10:15,843:INFO:Cross validation set to False
2026-01-29 16:10:15,843:INFO:Fitting Model
2026-01-29 16:10:15,909:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:10:15,909:INFO:create_model() successfully completed......................................
2026-01-29 16:10:16,110:INFO:Initializing create_model()
2026-01-29 16:10:16,110:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:10:16,124:INFO:Checking exceptions
2026-01-29 16:10:16,126:INFO:Importing libraries
2026-01-29 16:10:16,126:INFO:Copying training dataset
2026-01-29 16:10:16,185:INFO:Defining folds
2026-01-29 16:10:16,185:INFO:Declaring metric variables
2026-01-29 16:10:16,185:INFO:Importing untrained model
2026-01-29 16:10:16,185:INFO:Declaring custom model
2026-01-29 16:10:16,186:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:10:16,186:INFO:Cross validation set to False
2026-01-29 16:10:16,186:INFO:Fitting Model
2026-01-29 16:10:17,494:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:10:17,494:INFO:create_model() successfully completed......................................
2026-01-29 16:10:17,719:INFO:_master_model_container: 4
2026-01-29 16:10:17,719:INFO:_display_container: 2
2026-01-29 16:10:17,719:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2026-01-29 16:10:17,719:INFO:compare_models() successfully completed......................................
2026-01-29 16:10:17,719:INFO:Initializing tune_model()
2026-01-29 16:10:17,719:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:10:17,719:INFO:Checking exceptions
2026-01-29 16:10:17,761:INFO:Copying training dataset
2026-01-29 16:10:17,826:INFO:Checking base model
2026-01-29 16:10:17,827:INFO:Base model : Logistic Regression
2026-01-29 16:10:17,831:INFO:Declaring metric variables
2026-01-29 16:10:17,833:INFO:Defining Hyperparameters
2026-01-29 16:10:18,043:INFO:Tuning with n_jobs=-1
2026-01-29 16:10:18,043:INFO:Initializing RandomizedSearchCV
2026-01-29 16:10:24,819:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 5.682}
2026-01-29 16:10:24,819:INFO:Hyperparameter search completed
2026-01-29 16:10:24,819:INFO:SubProcess create_model() called ==================================
2026-01-29 16:10:24,826:INFO:Initializing create_model()
2026-01-29 16:10:24,826:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816DC4BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 5.682})
2026-01-29 16:10:24,827:INFO:Checking exceptions
2026-01-29 16:10:24,827:INFO:Importing libraries
2026-01-29 16:10:24,827:INFO:Copying training dataset
2026-01-29 16:10:24,893:INFO:Defining folds
2026-01-29 16:10:24,893:INFO:Declaring metric variables
2026-01-29 16:10:24,893:INFO:Importing untrained model
2026-01-29 16:10:24,893:INFO:Declaring custom model
2026-01-29 16:10:24,893:INFO:Logistic Regression Imported successfully
2026-01-29 16:10:24,909:INFO:Starting cross validation
2026-01-29 16:10:24,909:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:10:25,795:INFO:Calculating mean and std
2026-01-29 16:10:25,795:INFO:Creating metrics dataframe
2026-01-29 16:10:25,809:INFO:Finalizing model
2026-01-29 16:10:26,120:INFO:Uploading results into container
2026-01-29 16:10:26,121:INFO:Uploading model into container now
2026-01-29 16:10:26,122:INFO:_master_model_container: 5
2026-01-29 16:10:26,122:INFO:_display_container: 3
2026-01-29 16:10:26,122:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:10:26,122:INFO:create_model() successfully completed......................................
2026-01-29 16:10:26,343:INFO:SubProcess create_model() end ==================================
2026-01-29 16:10:26,343:INFO:choose_better activated
2026-01-29 16:10:26,343:INFO:SubProcess create_model() called ==================================
2026-01-29 16:10:26,343:INFO:Initializing create_model()
2026-01-29 16:10:26,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:10:26,343:INFO:Checking exceptions
2026-01-29 16:10:26,343:INFO:Importing libraries
2026-01-29 16:10:26,343:INFO:Copying training dataset
2026-01-29 16:10:26,424:INFO:Defining folds
2026-01-29 16:10:26,426:INFO:Declaring metric variables
2026-01-29 16:10:26,426:INFO:Importing untrained model
2026-01-29 16:10:26,426:INFO:Declaring custom model
2026-01-29 16:10:26,426:INFO:Logistic Regression Imported successfully
2026-01-29 16:10:26,426:INFO:Starting cross validation
2026-01-29 16:10:26,426:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:10:27,222:INFO:Calculating mean and std
2026-01-29 16:10:27,224:INFO:Creating metrics dataframe
2026-01-29 16:10:27,226:INFO:Finalizing model
2026-01-29 16:10:27,446:INFO:Uploading results into container
2026-01-29 16:10:27,460:INFO:Uploading model into container now
2026-01-29 16:10:27,460:INFO:_master_model_container: 6
2026-01-29 16:10:27,460:INFO:_display_container: 4
2026-01-29 16:10:27,460:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:10:27,460:INFO:create_model() successfully completed......................................
2026-01-29 16:10:27,659:INFO:SubProcess create_model() end ==================================
2026-01-29 16:10:27,659:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 16:10:27,659:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 16:10:27,659:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2026-01-29 16:10:27,659:INFO:choose_better completed
2026-01-29 16:10:27,659:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:10:27,676:INFO:_master_model_container: 6
2026-01-29 16:10:27,676:INFO:_display_container: 3
2026-01-29 16:10:27,676:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:10:27,676:INFO:tune_model() successfully completed......................................
2026-01-29 16:10:27,876:INFO:Initializing tune_model()
2026-01-29 16:10:27,876:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:10:27,876:INFO:Checking exceptions
2026-01-29 16:10:27,919:INFO:Copying training dataset
2026-01-29 16:10:28,002:INFO:Checking base model
2026-01-29 16:10:28,003:INFO:Base model : Decision Tree Classifier
2026-01-29 16:10:28,008:INFO:Declaring metric variables
2026-01-29 16:10:28,012:INFO:Defining Hyperparameters
2026-01-29 16:10:28,209:INFO:Tuning with n_jobs=-1
2026-01-29 16:10:28,209:INFO:Initializing RandomizedSearchCV
2026-01-29 16:10:29,211:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.0005, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 3, 'actual_estimator__criterion': 'gini'}
2026-01-29 16:10:29,211:INFO:Hyperparameter search completed
2026-01-29 16:10:29,211:INFO:SubProcess create_model() called ==================================
2026-01-29 16:10:29,211:INFO:Initializing create_model()
2026-01-29 16:10:29,211:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024871ADDC10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0005, 'max_features': 1.0, 'max_depth': 3, 'criterion': 'gini'})
2026-01-29 16:10:29,211:INFO:Checking exceptions
2026-01-29 16:10:29,211:INFO:Importing libraries
2026-01-29 16:10:29,211:INFO:Copying training dataset
2026-01-29 16:10:29,276:INFO:Defining folds
2026-01-29 16:10:29,276:INFO:Declaring metric variables
2026-01-29 16:10:29,276:INFO:Importing untrained model
2026-01-29 16:10:29,276:INFO:Declaring custom model
2026-01-29 16:10:29,276:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:10:29,293:INFO:Starting cross validation
2026-01-29 16:10:29,293:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:10:29,963:INFO:Calculating mean and std
2026-01-29 16:10:29,963:INFO:Creating metrics dataframe
2026-01-29 16:10:29,963:INFO:Finalizing model
2026-01-29 16:10:30,026:INFO:Uploading results into container
2026-01-29 16:10:30,026:INFO:Uploading model into container now
2026-01-29 16:10:30,026:INFO:_master_model_container: 7
2026-01-29 16:10:30,026:INFO:_display_container: 4
2026-01-29 16:10:30,026:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:10:30,026:INFO:create_model() successfully completed......................................
2026-01-29 16:10:30,264:INFO:SubProcess create_model() end ==================================
2026-01-29 16:10:30,264:INFO:choose_better activated
2026-01-29 16:10:30,276:INFO:SubProcess create_model() called ==================================
2026-01-29 16:10:30,276:INFO:Initializing create_model()
2026-01-29 16:10:30,276:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:10:30,276:INFO:Checking exceptions
2026-01-29 16:10:30,276:INFO:Importing libraries
2026-01-29 16:10:30,276:INFO:Copying training dataset
2026-01-29 16:10:30,400:INFO:Defining folds
2026-01-29 16:10:30,400:INFO:Declaring metric variables
2026-01-29 16:10:30,400:INFO:Importing untrained model
2026-01-29 16:10:30,400:INFO:Declaring custom model
2026-01-29 16:10:30,400:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:10:30,400:INFO:Starting cross validation
2026-01-29 16:10:30,400:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:10:31,146:INFO:Calculating mean and std
2026-01-29 16:10:31,147:INFO:Creating metrics dataframe
2026-01-29 16:10:31,148:INFO:Finalizing model
2026-01-29 16:10:31,226:INFO:Uploading results into container
2026-01-29 16:10:31,226:INFO:Uploading model into container now
2026-01-29 16:10:31,226:INFO:_master_model_container: 8
2026-01-29 16:10:31,226:INFO:_display_container: 5
2026-01-29 16:10:31,226:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:10:31,226:INFO:create_model() successfully completed......................................
2026-01-29 16:10:31,493:INFO:SubProcess create_model() end ==================================
2026-01-29 16:10:31,493:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5369
2026-01-29 16:10:31,493:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5366
2026-01-29 16:10:31,493:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-29 16:10:31,493:INFO:choose_better completed
2026-01-29 16:10:31,493:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:10:31,503:INFO:_master_model_container: 8
2026-01-29 16:10:31,503:INFO:_display_container: 4
2026-01-29 16:10:31,503:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:10:31,503:INFO:tune_model() successfully completed......................................
2026-01-29 16:10:31,709:INFO:Initializing tune_model()
2026-01-29 16:10:31,709:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:10:31,709:INFO:Checking exceptions
2026-01-29 16:10:31,743:INFO:Copying training dataset
2026-01-29 16:10:31,816:INFO:Checking base model
2026-01-29 16:10:31,816:INFO:Base model : Random Forest Classifier
2026-01-29 16:10:31,819:INFO:Declaring metric variables
2026-01-29 16:10:31,823:INFO:Defining Hyperparameters
2026-01-29 16:10:32,043:INFO:Tuning with n_jobs=-1
2026-01-29 16:10:32,043:INFO:Initializing RandomizedSearchCV
2026-01-29 16:10:58,903:INFO:best_params: {'actual_estimator__n_estimators': 120, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-29 16:10:58,904:INFO:Hyperparameter search completed
2026-01-29 16:10:58,904:INFO:SubProcess create_model() called ==================================
2026-01-29 16:10:58,904:INFO:Initializing create_model()
2026-01-29 16:10:58,905:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024870A8CF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 120, 'min_samples_split': 5, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': True})
2026-01-29 16:10:58,906:INFO:Checking exceptions
2026-01-29 16:10:58,906:INFO:Importing libraries
2026-01-29 16:10:58,906:INFO:Copying training dataset
2026-01-29 16:10:58,978:INFO:Defining folds
2026-01-29 16:10:58,978:INFO:Declaring metric variables
2026-01-29 16:10:58,981:INFO:Importing untrained model
2026-01-29 16:10:58,981:INFO:Declaring custom model
2026-01-29 16:10:58,981:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:10:58,993:INFO:Starting cross validation
2026-01-29 16:10:58,994:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:11:01,930:INFO:Calculating mean and std
2026-01-29 16:11:01,930:INFO:Creating metrics dataframe
2026-01-29 16:11:01,930:INFO:Finalizing model
2026-01-29 16:11:03,712:INFO:Uploading results into container
2026-01-29 16:11:03,712:INFO:Uploading model into container now
2026-01-29 16:11:03,712:INFO:_master_model_container: 9
2026-01-29 16:11:03,712:INFO:_display_container: 5
2026-01-29 16:11:03,712:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=120, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:11:03,712:INFO:create_model() successfully completed......................................
2026-01-29 16:11:03,960:INFO:SubProcess create_model() end ==================================
2026-01-29 16:11:03,960:INFO:choose_better activated
2026-01-29 16:11:03,975:INFO:SubProcess create_model() called ==================================
2026-01-29 16:11:03,975:INFO:Initializing create_model()
2026-01-29 16:11:03,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:11:03,975:INFO:Checking exceptions
2026-01-29 16:11:03,975:INFO:Importing libraries
2026-01-29 16:11:03,975:INFO:Copying training dataset
2026-01-29 16:11:04,045:INFO:Defining folds
2026-01-29 16:11:04,045:INFO:Declaring metric variables
2026-01-29 16:11:04,045:INFO:Importing untrained model
2026-01-29 16:11:04,045:INFO:Declaring custom model
2026-01-29 16:11:04,045:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:11:04,045:INFO:Starting cross validation
2026-01-29 16:11:04,045:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:11:06,566:INFO:Calculating mean and std
2026-01-29 16:11:06,566:INFO:Creating metrics dataframe
2026-01-29 16:11:06,566:INFO:Finalizing model
2026-01-29 16:11:08,046:INFO:Uploading results into container
2026-01-29 16:11:08,046:INFO:Uploading model into container now
2026-01-29 16:11:08,046:INFO:_master_model_container: 10
2026-01-29 16:11:08,046:INFO:_display_container: 6
2026-01-29 16:11:08,046:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:11:08,046:INFO:create_model() successfully completed......................................
2026-01-29 16:11:08,258:INFO:SubProcess create_model() end ==================================
2026-01-29 16:11:08,258:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.5369
2026-01-29 16:11:08,258:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=120, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.5369
2026-01-29 16:11:08,258:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-29 16:11:08,258:INFO:choose_better completed
2026-01-29 16:11:08,258:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:11:08,272:INFO:_master_model_container: 10
2026-01-29 16:11:08,272:INFO:_display_container: 5
2026-01-29 16:11:08,272:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:11:08,274:INFO:tune_model() successfully completed......................................
2026-01-29 16:11:08,491:INFO:Initializing evaluate_model()
2026-01-29 16:11:08,491:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:11:08,531:INFO:Initializing plot_model()
2026-01-29 16:11:08,531:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:11:08,532:INFO:Checking exceptions
2026-01-29 16:11:08,561:INFO:Preloading libraries
2026-01-29 16:11:08,561:INFO:Copying training dataset
2026-01-29 16:11:08,561:INFO:Plot type: pipeline
2026-01-29 16:11:08,628:INFO:Visual Rendered Successfully
2026-01-29 16:11:08,862:INFO:plot_model() successfully completed......................................
2026-01-29 16:11:08,866:INFO:Initializing evaluate_model()
2026-01-29 16:11:08,867:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:11:08,917:INFO:Initializing plot_model()
2026-01-29 16:11:08,918:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:11:08,918:INFO:Checking exceptions
2026-01-29 16:11:08,964:INFO:Preloading libraries
2026-01-29 16:11:08,964:INFO:Copying training dataset
2026-01-29 16:11:08,964:INFO:Plot type: pipeline
2026-01-29 16:11:09,024:INFO:Visual Rendered Successfully
2026-01-29 16:11:09,224:INFO:plot_model() successfully completed......................................
2026-01-29 16:11:09,240:INFO:Initializing evaluate_model()
2026-01-29 16:11:09,242:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:11:09,283:INFO:Initializing plot_model()
2026-01-29 16:11:09,283:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:11:09,283:INFO:Checking exceptions
2026-01-29 16:11:09,328:INFO:Preloading libraries
2026-01-29 16:11:09,346:INFO:Copying training dataset
2026-01-29 16:11:09,346:INFO:Plot type: pipeline
2026-01-29 16:11:09,412:INFO:Visual Rendered Successfully
2026-01-29 16:11:09,627:INFO:plot_model() successfully completed......................................
2026-01-29 16:11:09,636:INFO:Initializing predict_model()
2026-01-29 16:11:09,636:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024871470B80>)
2026-01-29 16:11:09,637:INFO:Checking exceptions
2026-01-29 16:11:09,637:INFO:Preloading libraries
2026-01-29 16:11:09,638:INFO:Set up data.
2026-01-29 16:11:09,647:INFO:Set up index.
2026-01-29 16:11:10,159:INFO:Initializing predict_model()
2026-01-29 16:11:10,159:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002480475F6A0>)
2026-01-29 16:11:10,159:INFO:Checking exceptions
2026-01-29 16:11:10,159:INFO:Preloading libraries
2026-01-29 16:11:10,175:INFO:Set up data.
2026-01-29 16:11:10,177:INFO:Set up index.
2026-01-29 16:11:10,729:INFO:Initializing predict_model()
2026-01-29 16:11:10,729:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024871470680>)
2026-01-29 16:11:10,729:INFO:Checking exceptions
2026-01-29 16:11:10,729:INFO:Preloading libraries
2026-01-29 16:11:10,731:INFO:Set up data.
2026-01-29 16:11:10,740:INFO:Set up index.
2026-01-29 16:11:11,434:INFO:Initializing plot_model()
2026-01-29 16:11:11,434:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-29 16:11:11,434:INFO:Checking exceptions
2026-01-29 16:11:11,460:INFO:Preloading libraries
2026-01-29 16:11:11,460:INFO:Copying training dataset
2026-01-29 16:11:11,460:INFO:Plot type: feature
2026-01-29 16:11:11,714:INFO:Visual Rendered Successfully
2026-01-29 16:11:11,931:INFO:plot_model() successfully completed......................................
2026-01-29 16:11:11,931:INFO:Initializing save_model()
2026-01-29 16:11:11,931:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=..\modelos\modelo_general, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-29 16:11:11,931:INFO:Adding model into prep_pipe
2026-01-29 16:13:57,407:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\1855575028.py:18: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-29 16:13:59,973:INFO:PyCaret ClassificationExperiment
2026-01-29 16:13:59,973:INFO:Logging name: clf-default-name
2026-01-29 16:13:59,986:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-29 16:13:59,986:INFO:version 3.3.2
2026-01-29 16:13:59,986:INFO:Initializing setup()
2026-01-29 16:13:59,986:INFO:self.USI: b0bf
2026-01-29 16:13:59,986:INFO:self._variable_keys: {'X_test', 'fold_groups_param', 'pipeline', 'fix_imbalance', 'exp_name_log', 'data', 'y_test', 'seed', 'fold_shuffle_param', 'n_jobs_param', 'is_multiclass', 'gpu_n_jobs_param', 'memory', 'log_plots_param', 'logging_param', 'idx', 'y', 'target_param', 'fold_generator', 'y_train', 'gpu_param', 'USI', 'exp_id', '_available_plots', 'X', 'X_train', 'html_param', '_ml_usecase'}
2026-01-29 16:13:59,988:INFO:Checking environment
2026-01-29 16:13:59,988:INFO:python_version: 3.11.11
2026-01-29 16:13:59,988:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-29 16:13:59,988:INFO:machine: AMD64
2026-01-29 16:13:59,988:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-29 16:13:59,988:INFO:Memory: svmem(total=34009374720, available=12933509120, percent=62.0, used=21075865600, free=12933509120)
2026-01-29 16:13:59,989:INFO:Physical Core: 12
2026-01-29 16:13:59,990:INFO:Logical Core: 16
2026-01-29 16:13:59,990:INFO:Checking libraries
2026-01-29 16:13:59,990:INFO:System:
2026-01-29 16:13:59,990:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-29 16:13:59,990:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-29 16:13:59,990:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-29 16:13:59,990:INFO:PyCaret required dependencies:
2026-01-29 16:13:59,990:INFO:                 pip: 25.0
2026-01-29 16:13:59,990:INFO:          setuptools: 75.8.0
2026-01-29 16:13:59,990:INFO:             pycaret: 3.3.2
2026-01-29 16:13:59,990:INFO:             IPython: 9.9.0
2026-01-29 16:13:59,990:INFO:          ipywidgets: 8.1.8
2026-01-29 16:13:59,990:INFO:                tqdm: 4.67.1
2026-01-29 16:13:59,990:INFO:               numpy: 1.26.4
2026-01-29 16:13:59,990:INFO:              pandas: 2.1.4
2026-01-29 16:13:59,990:INFO:              jinja2: 3.1.6
2026-01-29 16:13:59,990:INFO:               scipy: 1.11.4
2026-01-29 16:13:59,990:INFO:              joblib: 1.3.2
2026-01-29 16:13:59,990:INFO:             sklearn: 1.4.2
2026-01-29 16:13:59,990:INFO:                pyod: 2.0.6
2026-01-29 16:13:59,990:INFO:            imblearn: 0.14.1
2026-01-29 16:13:59,990:INFO:   category_encoders: 2.7.0
2026-01-29 16:13:59,990:INFO:            lightgbm: 4.6.0
2026-01-29 16:13:59,990:INFO:               numba: 0.62.1
2026-01-29 16:13:59,990:INFO:            requests: 2.32.3
2026-01-29 16:13:59,990:INFO:          matplotlib: 3.7.5
2026-01-29 16:13:59,990:INFO:          scikitplot: 0.3.7
2026-01-29 16:13:59,990:INFO:         yellowbrick: 1.5
2026-01-29 16:13:59,999:INFO:              plotly: 5.24.1
2026-01-29 16:13:59,999:INFO:    plotly-resampler: Not installed
2026-01-29 16:13:59,999:INFO:             kaleido: 1.2.0
2026-01-29 16:13:59,999:INFO:           schemdraw: 0.15
2026-01-29 16:13:59,999:INFO:         statsmodels: 0.14.6
2026-01-29 16:13:59,999:INFO:              sktime: 0.26.0
2026-01-29 16:13:59,999:INFO:               tbats: 1.1.3
2026-01-29 16:13:59,999:INFO:            pmdarima: 2.0.4
2026-01-29 16:13:59,999:INFO:              psutil: 7.2.1
2026-01-29 16:13:59,999:INFO:          markupsafe: 3.0.3
2026-01-29 16:13:59,999:INFO:             pickle5: Not installed
2026-01-29 16:14:00,005:INFO:         cloudpickle: 3.0.0
2026-01-29 16:14:00,005:INFO:         deprecation: 2.1.0
2026-01-29 16:14:00,006:INFO:              xxhash: 3.6.0
2026-01-29 16:14:00,006:INFO:           wurlitzer: Not installed
2026-01-29 16:14:00,006:INFO:PyCaret optional dependencies:
2026-01-29 16:14:00,006:INFO:                shap: 0.44.1
2026-01-29 16:14:00,007:INFO:           interpret: 0.7.3
2026-01-29 16:14:00,007:INFO:                umap: 0.5.7
2026-01-29 16:14:00,007:INFO:     ydata_profiling: 4.18.1
2026-01-29 16:14:00,007:INFO:  explainerdashboard: 0.5.1
2026-01-29 16:14:00,007:INFO:             autoviz: Not installed
2026-01-29 16:14:00,007:INFO:           fairlearn: 0.7.0
2026-01-29 16:14:00,007:INFO:          deepchecks: Not installed
2026-01-29 16:14:00,007:INFO:             xgboost: Not installed
2026-01-29 16:14:00,007:INFO:            catboost: 1.2.8
2026-01-29 16:14:00,007:INFO:              kmodes: 0.12.2
2026-01-29 16:14:00,007:INFO:             mlxtend: 0.23.4
2026-01-29 16:14:00,007:INFO:       statsforecast: 1.5.0
2026-01-29 16:14:00,007:INFO:        tune_sklearn: Not installed
2026-01-29 16:14:00,007:INFO:                 ray: Not installed
2026-01-29 16:14:00,007:INFO:            hyperopt: 0.2.7
2026-01-29 16:14:00,007:INFO:              optuna: 4.6.0
2026-01-29 16:14:00,007:INFO:               skopt: 0.10.2
2026-01-29 16:14:00,007:INFO:              mlflow: 3.8.1
2026-01-29 16:14:00,007:INFO:              gradio: 6.3.0
2026-01-29 16:14:00,007:INFO:             fastapi: 0.128.0
2026-01-29 16:14:00,007:INFO:             uvicorn: 0.40.0
2026-01-29 16:14:00,007:INFO:              m2cgen: 0.10.0
2026-01-29 16:14:00,007:INFO:           evidently: 0.4.40
2026-01-29 16:14:00,007:INFO:               fugue: 0.8.7
2026-01-29 16:14:00,015:INFO:           streamlit: Not installed
2026-01-29 16:14:00,015:INFO:             prophet: Not installed
2026-01-29 16:14:00,015:INFO:None
2026-01-29 16:14:00,015:INFO:Set up data.
2026-01-29 16:14:00,090:INFO:Set up folding strategy.
2026-01-29 16:14:00,090:INFO:Set up train/test split.
2026-01-29 16:14:00,474:INFO:Set up index.
2026-01-29 16:14:00,507:INFO:Assigning column types.
2026-01-29 16:14:00,586:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-29 16:14:00,686:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:14:00,689:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:14:00,741:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:14:00,741:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:14:00,824:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:14:00,824:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:14:00,873:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:14:00,873:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:14:00,874:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-29 16:14:00,940:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:14:00,973:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:14:00,987:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:14:01,040:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:14:01,090:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:14:01,090:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:14:01,090:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-29 16:14:01,191:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:14:01,191:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:14:01,290:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:14:01,290:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:14:01,290:INFO:Preparing preprocessing pipeline...
2026-01-29 16:14:01,308:INFO:Set up simple imputation.
2026-01-29 16:14:01,308:INFO:Set up feature normalization.
2026-01-29 16:14:01,456:INFO:Finished creating preprocessing pipeline.
2026-01-29 16:14:01,473:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-29 16:14:01,473:INFO:Creating final display dataframe.
2026-01-29 16:14:01,890:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape       (429278, 4)
4        Transformed data shape       (429278, 4)
5   Transformed train set shape       (343422, 4)
6    Transformed test set shape        (85856, 4)
7               Ignore features                58
8              Numeric features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                 3
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              b0bf
2026-01-29 16:14:01,973:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:14:01,973:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:14:02,073:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:14:02,073:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:14:02,073:INFO:setup() successfully completed in 2.1s...............
2026-01-29 16:14:02,073:INFO:Initializing compare_models()
2026-01-29 16:14:02,073:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-29 16:14:02,073:INFO:Checking exceptions
2026-01-29 16:14:02,128:INFO:Preparing display monitor
2026-01-29 16:14:02,166:INFO:Initializing Logistic Regression
2026-01-29 16:14:02,167:INFO:Total runtime is 1.7237663269042968e-05 minutes
2026-01-29 16:14:02,172:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:02,173:INFO:Initializing create_model()
2026-01-29 16:14:02,174:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002481729F910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:02,174:INFO:Checking exceptions
2026-01-29 16:14:02,174:INFO:Importing libraries
2026-01-29 16:14:02,174:INFO:Copying training dataset
2026-01-29 16:14:02,330:INFO:Defining folds
2026-01-29 16:14:02,330:INFO:Declaring metric variables
2026-01-29 16:14:02,340:INFO:Importing untrained model
2026-01-29 16:14:02,340:INFO:Logistic Regression Imported successfully
2026-01-29 16:14:02,359:INFO:Starting cross validation
2026-01-29 16:14:02,361:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:03,601:INFO:Calculating mean and std
2026-01-29 16:14:03,601:INFO:Creating metrics dataframe
2026-01-29 16:14:03,607:INFO:Uploading results into container
2026-01-29 16:14:03,609:INFO:Uploading model into container now
2026-01-29 16:14:03,610:INFO:_master_model_container: 1
2026-01-29 16:14:03,611:INFO:_display_container: 2
2026-01-29 16:14:03,611:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:14:03,612:INFO:create_model() successfully completed......................................
2026-01-29 16:14:03,947:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:03,947:INFO:Creating metrics dataframe
2026-01-29 16:14:03,957:INFO:Initializing Decision Tree Classifier
2026-01-29 16:14:03,957:INFO:Total runtime is 0.029845261573791505 minutes
2026-01-29 16:14:03,957:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:03,957:INFO:Initializing create_model()
2026-01-29 16:14:03,957:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002481729F910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:03,957:INFO:Checking exceptions
2026-01-29 16:14:03,957:INFO:Importing libraries
2026-01-29 16:14:03,957:INFO:Copying training dataset
2026-01-29 16:14:04,061:INFO:Defining folds
2026-01-29 16:14:04,061:INFO:Declaring metric variables
2026-01-29 16:14:04,070:INFO:Importing untrained model
2026-01-29 16:14:04,074:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:14:04,082:INFO:Starting cross validation
2026-01-29 16:14:04,083:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:04,760:INFO:Calculating mean and std
2026-01-29 16:14:04,760:INFO:Creating metrics dataframe
2026-01-29 16:14:04,760:INFO:Uploading results into container
2026-01-29 16:14:04,760:INFO:Uploading model into container now
2026-01-29 16:14:04,765:INFO:_master_model_container: 2
2026-01-29 16:14:04,765:INFO:_display_container: 2
2026-01-29 16:14:04,766:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:14:04,766:INFO:create_model() successfully completed......................................
2026-01-29 16:14:05,022:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:05,023:INFO:Creating metrics dataframe
2026-01-29 16:14:05,023:INFO:Initializing Random Forest Classifier
2026-01-29 16:14:05,023:INFO:Total runtime is 0.047616843382517496 minutes
2026-01-29 16:14:05,023:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:05,023:INFO:Initializing create_model()
2026-01-29 16:14:05,023:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002481729F910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:05,023:INFO:Checking exceptions
2026-01-29 16:14:05,023:INFO:Importing libraries
2026-01-29 16:14:05,023:INFO:Copying training dataset
2026-01-29 16:14:05,110:INFO:Defining folds
2026-01-29 16:14:05,111:INFO:Declaring metric variables
2026-01-29 16:14:05,114:INFO:Importing untrained model
2026-01-29 16:14:05,116:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:14:05,122:INFO:Starting cross validation
2026-01-29 16:14:05,123:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:10,285:INFO:Calculating mean and std
2026-01-29 16:14:10,289:INFO:Creating metrics dataframe
2026-01-29 16:14:10,290:INFO:Uploading results into container
2026-01-29 16:14:10,290:INFO:Uploading model into container now
2026-01-29 16:14:10,294:INFO:_master_model_container: 3
2026-01-29 16:14:10,294:INFO:_display_container: 2
2026-01-29 16:14:10,296:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:14:10,296:INFO:create_model() successfully completed......................................
2026-01-29 16:14:10,540:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:10,540:INFO:Creating metrics dataframe
2026-01-29 16:14:10,559:INFO:Initializing Light Gradient Boosting Machine
2026-01-29 16:14:10,560:INFO:Total runtime is 0.1398939530054728 minutes
2026-01-29 16:14:10,560:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:10,560:INFO:Initializing create_model()
2026-01-29 16:14:10,560:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002481729F910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:10,560:INFO:Checking exceptions
2026-01-29 16:14:10,560:INFO:Importing libraries
2026-01-29 16:14:10,560:INFO:Copying training dataset
2026-01-29 16:14:10,640:INFO:Defining folds
2026-01-29 16:14:10,640:INFO:Declaring metric variables
2026-01-29 16:14:10,640:INFO:Importing untrained model
2026-01-29 16:14:10,640:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-29 16:14:10,655:INFO:Starting cross validation
2026-01-29 16:14:10,657:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:12,436:INFO:Calculating mean and std
2026-01-29 16:14:12,440:INFO:Creating metrics dataframe
2026-01-29 16:14:12,442:INFO:Uploading results into container
2026-01-29 16:14:12,443:INFO:Uploading model into container now
2026-01-29 16:14:12,444:INFO:_master_model_container: 4
2026-01-29 16:14:12,444:INFO:_display_container: 2
2026-01-29 16:14:12,444:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-29 16:14:12,444:INFO:create_model() successfully completed......................................
2026-01-29 16:14:12,673:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:12,673:INFO:Creating metrics dataframe
2026-01-29 16:14:12,691:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-29 16:14:12,697:INFO:Initializing create_model()
2026-01-29 16:14:12,697:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:12,697:INFO:Checking exceptions
2026-01-29 16:14:12,697:INFO:Importing libraries
2026-01-29 16:14:12,697:INFO:Copying training dataset
2026-01-29 16:14:12,802:INFO:Defining folds
2026-01-29 16:14:12,802:INFO:Declaring metric variables
2026-01-29 16:14:12,802:INFO:Importing untrained model
2026-01-29 16:14:12,802:INFO:Declaring custom model
2026-01-29 16:14:12,802:INFO:Logistic Regression Imported successfully
2026-01-29 16:14:12,804:INFO:Cross validation set to False
2026-01-29 16:14:12,804:INFO:Fitting Model
2026-01-29 16:14:13,075:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:14:13,076:INFO:create_model() successfully completed......................................
2026-01-29 16:14:13,308:INFO:Initializing create_model()
2026-01-29 16:14:13,308:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:13,308:INFO:Checking exceptions
2026-01-29 16:14:13,308:INFO:Importing libraries
2026-01-29 16:14:13,313:INFO:Copying training dataset
2026-01-29 16:14:13,373:INFO:Defining folds
2026-01-29 16:14:13,373:INFO:Declaring metric variables
2026-01-29 16:14:13,373:INFO:Importing untrained model
2026-01-29 16:14:13,373:INFO:Declaring custom model
2026-01-29 16:14:13,373:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:14:13,373:INFO:Cross validation set to False
2026-01-29 16:14:13,373:INFO:Fitting Model
2026-01-29 16:14:13,455:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:14:13,455:INFO:create_model() successfully completed......................................
2026-01-29 16:14:13,687:INFO:Initializing create_model()
2026-01-29 16:14:13,687:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:13,687:INFO:Checking exceptions
2026-01-29 16:14:13,691:INFO:Importing libraries
2026-01-29 16:14:13,692:INFO:Copying training dataset
2026-01-29 16:14:13,755:INFO:Defining folds
2026-01-29 16:14:13,755:INFO:Declaring metric variables
2026-01-29 16:14:13,756:INFO:Importing untrained model
2026-01-29 16:14:13,756:INFO:Declaring custom model
2026-01-29 16:14:13,756:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:14:13,756:INFO:Cross validation set to False
2026-01-29 16:14:13,756:INFO:Fitting Model
2026-01-29 16:14:15,632:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:14:15,632:INFO:create_model() successfully completed......................................
2026-01-29 16:14:16,010:INFO:_master_model_container: 4
2026-01-29 16:14:16,010:INFO:_display_container: 2
2026-01-29 16:14:16,010:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2026-01-29 16:14:16,010:INFO:compare_models() successfully completed......................................
2026-01-29 16:14:16,010:INFO:Initializing tune_model()
2026-01-29 16:14:16,010:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:14:16,010:INFO:Checking exceptions
2026-01-29 16:14:16,062:INFO:Copying training dataset
2026-01-29 16:14:16,144:INFO:Checking base model
2026-01-29 16:14:16,145:INFO:Base model : Logistic Regression
2026-01-29 16:14:16,149:INFO:Declaring metric variables
2026-01-29 16:14:16,152:INFO:Defining Hyperparameters
2026-01-29 16:14:16,404:INFO:Tuning with n_jobs=-1
2026-01-29 16:14:16,404:INFO:Initializing RandomizedSearchCV
2026-01-29 16:14:19,085:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 5.682}
2026-01-29 16:14:19,085:INFO:Hyperparameter search completed
2026-01-29 16:14:19,085:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:19,088:INFO:Initializing create_model()
2026-01-29 16:14:19,088:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002481711D210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 5.682})
2026-01-29 16:14:19,088:INFO:Checking exceptions
2026-01-29 16:14:19,088:INFO:Importing libraries
2026-01-29 16:14:19,088:INFO:Copying training dataset
2026-01-29 16:14:19,189:INFO:Defining folds
2026-01-29 16:14:19,189:INFO:Declaring metric variables
2026-01-29 16:14:19,193:INFO:Importing untrained model
2026-01-29 16:14:19,193:INFO:Declaring custom model
2026-01-29 16:14:19,193:INFO:Logistic Regression Imported successfully
2026-01-29 16:14:19,205:INFO:Starting cross validation
2026-01-29 16:14:19,206:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:20,078:INFO:Calculating mean and std
2026-01-29 16:14:20,078:INFO:Creating metrics dataframe
2026-01-29 16:14:20,078:INFO:Finalizing model
2026-01-29 16:14:20,403:INFO:Uploading results into container
2026-01-29 16:14:20,414:INFO:Uploading model into container now
2026-01-29 16:14:20,414:INFO:_master_model_container: 5
2026-01-29 16:14:20,414:INFO:_display_container: 3
2026-01-29 16:14:20,414:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:14:20,414:INFO:create_model() successfully completed......................................
2026-01-29 16:14:20,655:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:20,655:INFO:choose_better activated
2026-01-29 16:14:20,655:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:20,655:INFO:Initializing create_model()
2026-01-29 16:14:20,655:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:20,655:INFO:Checking exceptions
2026-01-29 16:14:20,655:INFO:Importing libraries
2026-01-29 16:14:20,655:INFO:Copying training dataset
2026-01-29 16:14:20,725:INFO:Defining folds
2026-01-29 16:14:20,725:INFO:Declaring metric variables
2026-01-29 16:14:20,725:INFO:Importing untrained model
2026-01-29 16:14:20,725:INFO:Declaring custom model
2026-01-29 16:14:20,725:INFO:Logistic Regression Imported successfully
2026-01-29 16:14:20,725:INFO:Starting cross validation
2026-01-29 16:14:20,725:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:21,370:INFO:Calculating mean and std
2026-01-29 16:14:21,370:INFO:Creating metrics dataframe
2026-01-29 16:14:21,374:INFO:Finalizing model
2026-01-29 16:14:21,576:INFO:Uploading results into container
2026-01-29 16:14:21,576:INFO:Uploading model into container now
2026-01-29 16:14:21,576:INFO:_master_model_container: 6
2026-01-29 16:14:21,576:INFO:_display_container: 4
2026-01-29 16:14:21,576:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:14:21,576:INFO:create_model() successfully completed......................................
2026-01-29 16:14:21,774:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:21,774:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 16:14:21,774:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 16:14:21,774:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2026-01-29 16:14:21,774:INFO:choose_better completed
2026-01-29 16:14:21,774:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:14:21,792:INFO:_master_model_container: 6
2026-01-29 16:14:21,792:INFO:_display_container: 3
2026-01-29 16:14:21,792:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:14:21,792:INFO:tune_model() successfully completed......................................
2026-01-29 16:14:21,993:INFO:Initializing tune_model()
2026-01-29 16:14:21,993:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:14:21,993:INFO:Checking exceptions
2026-01-29 16:14:22,032:INFO:Copying training dataset
2026-01-29 16:14:22,078:INFO:Checking base model
2026-01-29 16:14:22,078:INFO:Base model : Decision Tree Classifier
2026-01-29 16:14:22,081:INFO:Declaring metric variables
2026-01-29 16:14:22,083:INFO:Defining Hyperparameters
2026-01-29 16:14:22,292:INFO:Tuning with n_jobs=-1
2026-01-29 16:14:22,292:INFO:Initializing RandomizedSearchCV
2026-01-29 16:14:23,116:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.0005, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 3, 'actual_estimator__criterion': 'gini'}
2026-01-29 16:14:23,116:INFO:Hyperparameter search completed
2026-01-29 16:14:23,116:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:23,116:INFO:Initializing create_model()
2026-01-29 16:14:23,116:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024870AE0C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0005, 'max_features': 1.0, 'max_depth': 3, 'criterion': 'gini'})
2026-01-29 16:14:23,116:INFO:Checking exceptions
2026-01-29 16:14:23,116:INFO:Importing libraries
2026-01-29 16:14:23,116:INFO:Copying training dataset
2026-01-29 16:14:23,173:INFO:Defining folds
2026-01-29 16:14:23,173:INFO:Declaring metric variables
2026-01-29 16:14:23,173:INFO:Importing untrained model
2026-01-29 16:14:23,173:INFO:Declaring custom model
2026-01-29 16:14:23,173:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:14:23,173:INFO:Starting cross validation
2026-01-29 16:14:23,173:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:23,652:INFO:Calculating mean and std
2026-01-29 16:14:23,652:INFO:Creating metrics dataframe
2026-01-29 16:14:23,659:INFO:Finalizing model
2026-01-29 16:14:23,722:INFO:Uploading results into container
2026-01-29 16:14:23,723:INFO:Uploading model into container now
2026-01-29 16:14:23,724:INFO:_master_model_container: 7
2026-01-29 16:14:23,724:INFO:_display_container: 4
2026-01-29 16:14:23,725:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:14:23,725:INFO:create_model() successfully completed......................................
2026-01-29 16:14:23,925:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:23,925:INFO:choose_better activated
2026-01-29 16:14:23,925:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:23,925:INFO:Initializing create_model()
2026-01-29 16:14:23,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:23,925:INFO:Checking exceptions
2026-01-29 16:14:23,925:INFO:Importing libraries
2026-01-29 16:14:23,925:INFO:Copying training dataset
2026-01-29 16:14:23,989:INFO:Defining folds
2026-01-29 16:14:23,989:INFO:Declaring metric variables
2026-01-29 16:14:23,989:INFO:Importing untrained model
2026-01-29 16:14:23,989:INFO:Declaring custom model
2026-01-29 16:14:23,989:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:14:23,989:INFO:Starting cross validation
2026-01-29 16:14:23,989:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:24,460:INFO:Calculating mean and std
2026-01-29 16:14:24,460:INFO:Creating metrics dataframe
2026-01-29 16:14:24,460:INFO:Finalizing model
2026-01-29 16:14:24,522:INFO:Uploading results into container
2026-01-29 16:14:24,525:INFO:Uploading model into container now
2026-01-29 16:14:24,525:INFO:_master_model_container: 8
2026-01-29 16:14:24,525:INFO:_display_container: 5
2026-01-29 16:14:24,525:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:14:24,525:INFO:create_model() successfully completed......................................
2026-01-29 16:14:24,738:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:24,738:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5369
2026-01-29 16:14:24,738:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5366
2026-01-29 16:14:24,738:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-29 16:14:24,738:INFO:choose_better completed
2026-01-29 16:14:24,738:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:14:24,738:INFO:_master_model_container: 8
2026-01-29 16:14:24,738:INFO:_display_container: 4
2026-01-29 16:14:24,738:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:14:24,738:INFO:tune_model() successfully completed......................................
2026-01-29 16:14:24,953:INFO:Initializing tune_model()
2026-01-29 16:14:24,953:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:14:24,953:INFO:Checking exceptions
2026-01-29 16:14:24,975:INFO:Copying training dataset
2026-01-29 16:14:25,028:INFO:Checking base model
2026-01-29 16:14:25,028:INFO:Base model : Random Forest Classifier
2026-01-29 16:14:25,030:INFO:Declaring metric variables
2026-01-29 16:14:25,032:INFO:Defining Hyperparameters
2026-01-29 16:14:25,240:INFO:Tuning with n_jobs=-1
2026-01-29 16:14:25,240:INFO:Initializing RandomizedSearchCV
2026-01-29 16:14:47,898:INFO:best_params: {'actual_estimator__n_estimators': 120, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-29 16:14:47,900:INFO:Hyperparameter search completed
2026-01-29 16:14:47,900:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:47,900:INFO:Initializing create_model()
2026-01-29 16:14:47,902:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002481B5D2C90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 120, 'min_samples_split': 5, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': True})
2026-01-29 16:14:47,902:INFO:Checking exceptions
2026-01-29 16:14:47,902:INFO:Importing libraries
2026-01-29 16:14:47,902:INFO:Copying training dataset
2026-01-29 16:14:47,975:INFO:Defining folds
2026-01-29 16:14:47,975:INFO:Declaring metric variables
2026-01-29 16:14:47,977:INFO:Importing untrained model
2026-01-29 16:14:47,977:INFO:Declaring custom model
2026-01-29 16:14:47,981:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:14:47,984:INFO:Starting cross validation
2026-01-29 16:14:47,987:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:50,600:INFO:Calculating mean and std
2026-01-29 16:14:50,600:INFO:Creating metrics dataframe
2026-01-29 16:14:50,606:INFO:Finalizing model
2026-01-29 16:14:52,198:INFO:Uploading results into container
2026-01-29 16:14:52,198:INFO:Uploading model into container now
2026-01-29 16:14:52,198:INFO:_master_model_container: 9
2026-01-29 16:14:52,198:INFO:_display_container: 5
2026-01-29 16:14:52,198:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=120, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:14:52,198:INFO:create_model() successfully completed......................................
2026-01-29 16:14:52,421:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:52,421:INFO:choose_better activated
2026-01-29 16:14:52,421:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:52,421:INFO:Initializing create_model()
2026-01-29 16:14:52,421:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:52,421:INFO:Checking exceptions
2026-01-29 16:14:52,421:INFO:Importing libraries
2026-01-29 16:14:52,421:INFO:Copying training dataset
2026-01-29 16:14:52,489:INFO:Defining folds
2026-01-29 16:14:52,489:INFO:Declaring metric variables
2026-01-29 16:14:52,489:INFO:Importing untrained model
2026-01-29 16:14:52,489:INFO:Declaring custom model
2026-01-29 16:14:52,489:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:14:52,489:INFO:Starting cross validation
2026-01-29 16:14:52,489:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:54,667:INFO:Calculating mean and std
2026-01-29 16:14:54,667:INFO:Creating metrics dataframe
2026-01-29 16:14:54,672:INFO:Finalizing model
2026-01-29 16:14:56,041:INFO:Uploading results into container
2026-01-29 16:14:56,043:INFO:Uploading model into container now
2026-01-29 16:14:56,043:INFO:_master_model_container: 10
2026-01-29 16:14:56,043:INFO:_display_container: 6
2026-01-29 16:14:56,043:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:14:56,043:INFO:create_model() successfully completed......................................
2026-01-29 16:14:56,258:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:56,269:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.5369
2026-01-29 16:14:56,269:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=120, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.5369
2026-01-29 16:14:56,269:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-29 16:14:56,269:INFO:choose_better completed
2026-01-29 16:14:56,269:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:14:56,273:INFO:_master_model_container: 10
2026-01-29 16:14:56,273:INFO:_display_container: 5
2026-01-29 16:14:56,273:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:14:56,273:INFO:tune_model() successfully completed......................................
2026-01-29 16:14:56,489:INFO:Initializing evaluate_model()
2026-01-29 16:14:56,489:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:14:56,528:INFO:Initializing plot_model()
2026-01-29 16:14:56,528:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:14:56,528:INFO:Checking exceptions
2026-01-29 16:14:56,556:INFO:Preloading libraries
2026-01-29 16:14:56,556:INFO:Copying training dataset
2026-01-29 16:14:56,556:INFO:Plot type: pipeline
2026-01-29 16:14:56,622:INFO:Visual Rendered Successfully
2026-01-29 16:14:56,822:INFO:plot_model() successfully completed......................................
2026-01-29 16:14:56,838:INFO:Initializing evaluate_model()
2026-01-29 16:14:56,838:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:14:56,889:INFO:Initializing plot_model()
2026-01-29 16:14:56,890:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:14:56,890:INFO:Checking exceptions
2026-01-29 16:14:56,929:INFO:Preloading libraries
2026-01-29 16:14:56,930:INFO:Copying training dataset
2026-01-29 16:14:56,930:INFO:Plot type: pipeline
2026-01-29 16:14:56,989:INFO:Visual Rendered Successfully
2026-01-29 16:14:57,205:INFO:plot_model() successfully completed......................................
2026-01-29 16:14:57,205:INFO:Initializing evaluate_model()
2026-01-29 16:14:57,205:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:14:57,241:INFO:Initializing plot_model()
2026-01-29 16:14:57,241:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:14:57,241:INFO:Checking exceptions
2026-01-29 16:14:57,292:INFO:Preloading libraries
2026-01-29 16:14:57,292:INFO:Copying training dataset
2026-01-29 16:14:57,292:INFO:Plot type: pipeline
2026-01-29 16:14:57,355:INFO:Visual Rendered Successfully
2026-01-29 16:14:57,574:INFO:plot_model() successfully completed......................................
2026-01-29 16:14:57,583:INFO:Initializing predict_model()
2026-01-29 16:14:57,583:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024810D7FE20>)
2026-01-29 16:14:57,583:INFO:Checking exceptions
2026-01-29 16:14:57,583:INFO:Preloading libraries
2026-01-29 16:14:57,585:INFO:Set up data.
2026-01-29 16:14:57,594:INFO:Set up index.
2026-01-29 16:14:58,122:INFO:Initializing predict_model()
2026-01-29 16:14:58,122:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002487E4E7BA0>)
2026-01-29 16:14:58,122:INFO:Checking exceptions
2026-01-29 16:14:58,122:INFO:Preloading libraries
2026-01-29 16:14:58,122:INFO:Set up data.
2026-01-29 16:14:58,122:INFO:Set up index.
2026-01-29 16:14:58,674:INFO:Initializing predict_model()
2026-01-29 16:14:58,674:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002487E426200>)
2026-01-29 16:14:58,674:INFO:Checking exceptions
2026-01-29 16:14:58,674:INFO:Preloading libraries
2026-01-29 16:14:58,674:INFO:Set up data.
2026-01-29 16:14:58,674:INFO:Set up index.
2026-01-29 16:14:59,338:INFO:Initializing plot_model()
2026-01-29 16:14:59,338:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-29 16:14:59,340:INFO:Checking exceptions
2026-01-29 16:14:59,355:INFO:Preloading libraries
2026-01-29 16:14:59,355:INFO:Copying training dataset
2026-01-29 16:14:59,355:INFO:Plot type: feature
2026-01-29 16:14:59,608:INFO:Visual Rendered Successfully
2026-01-29 16:14:59,828:INFO:plot_model() successfully completed......................................
2026-01-29 16:14:59,828:INFO:Initializing save_model()
2026-01-29 16:14:59,828:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=..\datos\04. Modelos, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-29 16:14:59,828:INFO:Adding model into prep_pipe
2026-01-29 16:14:59,838:INFO:..\datos\04. Modelos.pkl saved in current working directory
2026-01-29 16:14:59,838:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(e...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=42,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2026-01-29 16:14:59,838:INFO:save_model() successfully completed......................................
2026-01-29 16:16:46,887:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\2531746454.py:18: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-29 16:16:48,804:INFO:PyCaret ClassificationExperiment
2026-01-29 16:16:48,804:INFO:Logging name: clf-default-name
2026-01-29 16:16:48,804:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-29 16:16:48,804:INFO:version 3.3.2
2026-01-29 16:16:48,804:INFO:Initializing setup()
2026-01-29 16:16:48,804:INFO:self.USI: 8fc6
2026-01-29 16:16:48,807:INFO:self._variable_keys: {'X_test', 'fold_groups_param', 'pipeline', 'fix_imbalance', 'exp_name_log', 'data', 'y_test', 'seed', 'fold_shuffle_param', 'n_jobs_param', 'is_multiclass', 'gpu_n_jobs_param', 'memory', 'log_plots_param', 'logging_param', 'idx', 'y', 'target_param', 'fold_generator', 'y_train', 'gpu_param', 'USI', 'exp_id', '_available_plots', 'X', 'X_train', 'html_param', '_ml_usecase'}
2026-01-29 16:16:48,807:INFO:Checking environment
2026-01-29 16:16:48,807:INFO:python_version: 3.11.11
2026-01-29 16:16:48,807:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-29 16:16:48,807:INFO:machine: AMD64
2026-01-29 16:16:48,807:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-29 16:16:48,807:INFO:Memory: svmem(total=34009374720, available=13133869056, percent=61.4, used=20875505664, free=13133869056)
2026-01-29 16:16:48,807:INFO:Physical Core: 12
2026-01-29 16:16:48,807:INFO:Logical Core: 16
2026-01-29 16:16:48,807:INFO:Checking libraries
2026-01-29 16:16:48,807:INFO:System:
2026-01-29 16:16:48,807:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-29 16:16:48,807:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-29 16:16:48,807:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-29 16:16:48,807:INFO:PyCaret required dependencies:
2026-01-29 16:16:48,807:INFO:                 pip: 25.0
2026-01-29 16:16:48,807:INFO:          setuptools: 75.8.0
2026-01-29 16:16:48,807:INFO:             pycaret: 3.3.2
2026-01-29 16:16:48,807:INFO:             IPython: 9.9.0
2026-01-29 16:16:48,807:INFO:          ipywidgets: 8.1.8
2026-01-29 16:16:48,807:INFO:                tqdm: 4.67.1
2026-01-29 16:16:48,807:INFO:               numpy: 1.26.4
2026-01-29 16:16:48,807:INFO:              pandas: 2.1.4
2026-01-29 16:16:48,807:INFO:              jinja2: 3.1.6
2026-01-29 16:16:48,807:INFO:               scipy: 1.11.4
2026-01-29 16:16:48,807:INFO:              joblib: 1.3.2
2026-01-29 16:16:48,807:INFO:             sklearn: 1.4.2
2026-01-29 16:16:48,807:INFO:                pyod: 2.0.6
2026-01-29 16:16:48,807:INFO:            imblearn: 0.14.1
2026-01-29 16:16:48,807:INFO:   category_encoders: 2.7.0
2026-01-29 16:16:48,807:INFO:            lightgbm: 4.6.0
2026-01-29 16:16:48,807:INFO:               numba: 0.62.1
2026-01-29 16:16:48,807:INFO:            requests: 2.32.3
2026-01-29 16:16:48,807:INFO:          matplotlib: 3.7.5
2026-01-29 16:16:48,807:INFO:          scikitplot: 0.3.7
2026-01-29 16:16:48,807:INFO:         yellowbrick: 1.5
2026-01-29 16:16:48,807:INFO:              plotly: 5.24.1
2026-01-29 16:16:48,807:INFO:    plotly-resampler: Not installed
2026-01-29 16:16:48,807:INFO:             kaleido: 1.2.0
2026-01-29 16:16:48,807:INFO:           schemdraw: 0.15
2026-01-29 16:16:48,807:INFO:         statsmodels: 0.14.6
2026-01-29 16:16:48,807:INFO:              sktime: 0.26.0
2026-01-29 16:16:48,807:INFO:               tbats: 1.1.3
2026-01-29 16:16:48,807:INFO:            pmdarima: 2.0.4
2026-01-29 16:16:48,807:INFO:              psutil: 7.2.1
2026-01-29 16:16:48,807:INFO:          markupsafe: 3.0.3
2026-01-29 16:16:48,807:INFO:             pickle5: Not installed
2026-01-29 16:16:48,807:INFO:         cloudpickle: 3.0.0
2026-01-29 16:16:48,807:INFO:         deprecation: 2.1.0
2026-01-29 16:16:48,807:INFO:              xxhash: 3.6.0
2026-01-29 16:16:48,807:INFO:           wurlitzer: Not installed
2026-01-29 16:16:48,807:INFO:PyCaret optional dependencies:
2026-01-29 16:16:48,807:INFO:                shap: 0.44.1
2026-01-29 16:16:48,807:INFO:           interpret: 0.7.3
2026-01-29 16:16:48,807:INFO:                umap: 0.5.7
2026-01-29 16:16:48,807:INFO:     ydata_profiling: 4.18.1
2026-01-29 16:16:48,807:INFO:  explainerdashboard: 0.5.1
2026-01-29 16:16:48,807:INFO:             autoviz: Not installed
2026-01-29 16:16:48,807:INFO:           fairlearn: 0.7.0
2026-01-29 16:16:48,807:INFO:          deepchecks: Not installed
2026-01-29 16:16:48,807:INFO:             xgboost: Not installed
2026-01-29 16:16:48,807:INFO:            catboost: 1.2.8
2026-01-29 16:16:48,807:INFO:              kmodes: 0.12.2
2026-01-29 16:16:48,807:INFO:             mlxtend: 0.23.4
2026-01-29 16:16:48,807:INFO:       statsforecast: 1.5.0
2026-01-29 16:16:48,807:INFO:        tune_sklearn: Not installed
2026-01-29 16:16:48,820:INFO:                 ray: Not installed
2026-01-29 16:16:48,820:INFO:            hyperopt: 0.2.7
2026-01-29 16:16:48,820:INFO:              optuna: 4.6.0
2026-01-29 16:16:48,820:INFO:               skopt: 0.10.2
2026-01-29 16:16:48,820:INFO:              mlflow: 3.8.1
2026-01-29 16:16:48,820:INFO:              gradio: 6.3.0
2026-01-29 16:16:48,820:INFO:             fastapi: 0.128.0
2026-01-29 16:16:48,820:INFO:             uvicorn: 0.40.0
2026-01-29 16:16:48,820:INFO:              m2cgen: 0.10.0
2026-01-29 16:16:48,820:INFO:           evidently: 0.4.40
2026-01-29 16:16:48,820:INFO:               fugue: 0.8.7
2026-01-29 16:16:48,820:INFO:           streamlit: Not installed
2026-01-29 16:16:48,820:INFO:             prophet: Not installed
2026-01-29 16:16:48,820:INFO:None
2026-01-29 16:16:48,820:INFO:Set up data.
2026-01-29 16:16:48,841:INFO:Set up folding strategy.
2026-01-29 16:16:48,841:INFO:Set up train/test split.
2026-01-29 16:16:48,939:INFO:Set up index.
2026-01-29 16:16:48,939:INFO:Assigning column types.
2026-01-29 16:16:48,970:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-29 16:16:48,986:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:16:48,986:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:16:49,017:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:16:49,017:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:16:49,040:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:16:49,040:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:16:49,070:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:16:49,070:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:16:49,070:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-29 16:16:49,117:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:16:49,135:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:16:49,135:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:16:49,172:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:16:49,188:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:16:49,188:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:16:49,188:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-29 16:16:49,240:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:16:49,240:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:16:49,286:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:16:49,286:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:16:49,286:INFO:Preparing preprocessing pipeline...
2026-01-29 16:16:49,286:INFO:Set up simple imputation.
2026-01-29 16:16:49,302:INFO:Set up feature normalization.
2026-01-29 16:16:49,388:INFO:Finished creating preprocessing pipeline.
2026-01-29 16:16:49,390:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-29 16:16:49,390:INFO:Creating final display dataframe.
2026-01-29 16:16:49,588:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape       (429278, 4)
4        Transformed data shape       (429278, 4)
5   Transformed train set shape       (343422, 4)
6    Transformed test set shape        (85856, 4)
7               Ignore features                58
8              Numeric features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                 3
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              8fc6
2026-01-29 16:16:49,636:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:16:49,636:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:16:49,673:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:16:49,673:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:16:49,673:INFO:setup() successfully completed in 0.88s...............
2026-01-29 16:16:49,673:INFO:Initializing compare_models()
2026-01-29 16:16:49,673:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-29 16:16:49,673:INFO:Checking exceptions
2026-01-29 16:16:49,710:INFO:Preparing display monitor
2026-01-29 16:16:49,738:INFO:Initializing Logistic Regression
2026-01-29 16:16:49,738:INFO:Total runtime is 0.0 minutes
2026-01-29 16:16:49,742:INFO:SubProcess create_model() called ==================================
2026-01-29 16:16:49,742:INFO:Initializing create_model()
2026-01-29 16:16:49,742:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816CE95D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:16:49,742:INFO:Checking exceptions
2026-01-29 16:16:49,744:INFO:Importing libraries
2026-01-29 16:16:49,744:INFO:Copying training dataset
2026-01-29 16:16:49,817:INFO:Defining folds
2026-01-29 16:16:49,817:INFO:Declaring metric variables
2026-01-29 16:16:49,820:INFO:Importing untrained model
2026-01-29 16:16:49,825:INFO:Logistic Regression Imported successfully
2026-01-29 16:16:49,825:INFO:Starting cross validation
2026-01-29 16:16:49,825:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:16:50,495:INFO:Calculating mean and std
2026-01-29 16:16:50,495:INFO:Creating metrics dataframe
2026-01-29 16:16:50,495:INFO:Uploading results into container
2026-01-29 16:16:50,495:INFO:Uploading model into container now
2026-01-29 16:16:50,495:INFO:_master_model_container: 1
2026-01-29 16:16:50,495:INFO:_display_container: 2
2026-01-29 16:16:50,495:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:16:50,495:INFO:create_model() successfully completed......................................
2026-01-29 16:16:50,712:INFO:SubProcess create_model() end ==================================
2026-01-29 16:16:50,712:INFO:Creating metrics dataframe
2026-01-29 16:16:50,723:INFO:Initializing Decision Tree Classifier
2026-01-29 16:16:50,723:INFO:Total runtime is 0.016418596108754475 minutes
2026-01-29 16:16:50,723:INFO:SubProcess create_model() called ==================================
2026-01-29 16:16:50,723:INFO:Initializing create_model()
2026-01-29 16:16:50,723:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816CE95D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:16:50,723:INFO:Checking exceptions
2026-01-29 16:16:50,723:INFO:Importing libraries
2026-01-29 16:16:50,723:INFO:Copying training dataset
2026-01-29 16:16:50,787:INFO:Defining folds
2026-01-29 16:16:50,788:INFO:Declaring metric variables
2026-01-29 16:16:50,791:INFO:Importing untrained model
2026-01-29 16:16:50,791:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:16:50,791:INFO:Starting cross validation
2026-01-29 16:16:50,791:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:16:51,325:INFO:Calculating mean and std
2026-01-29 16:16:51,326:INFO:Creating metrics dataframe
2026-01-29 16:16:51,327:INFO:Uploading results into container
2026-01-29 16:16:51,328:INFO:Uploading model into container now
2026-01-29 16:16:51,328:INFO:_master_model_container: 2
2026-01-29 16:16:51,328:INFO:_display_container: 2
2026-01-29 16:16:51,329:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:16:51,329:INFO:create_model() successfully completed......................................
2026-01-29 16:16:51,550:INFO:SubProcess create_model() end ==================================
2026-01-29 16:16:51,550:INFO:Creating metrics dataframe
2026-01-29 16:16:51,556:INFO:Initializing Random Forest Classifier
2026-01-29 16:16:51,556:INFO:Total runtime is 0.030309824148813884 minutes
2026-01-29 16:16:51,558:INFO:SubProcess create_model() called ==================================
2026-01-29 16:16:51,558:INFO:Initializing create_model()
2026-01-29 16:16:51,558:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816CE95D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:16:51,558:INFO:Checking exceptions
2026-01-29 16:16:51,558:INFO:Importing libraries
2026-01-29 16:16:51,558:INFO:Copying training dataset
2026-01-29 16:16:51,631:INFO:Defining folds
2026-01-29 16:16:51,631:INFO:Declaring metric variables
2026-01-29 16:16:51,635:INFO:Importing untrained model
2026-01-29 16:16:51,638:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:16:51,643:INFO:Starting cross validation
2026-01-29 16:16:51,643:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:16:54,095:INFO:Calculating mean and std
2026-01-29 16:16:54,095:INFO:Creating metrics dataframe
2026-01-29 16:16:54,102:INFO:Uploading results into container
2026-01-29 16:16:54,102:INFO:Uploading model into container now
2026-01-29 16:16:54,103:INFO:_master_model_container: 3
2026-01-29 16:16:54,103:INFO:_display_container: 2
2026-01-29 16:16:54,104:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:16:54,105:INFO:create_model() successfully completed......................................
2026-01-29 16:16:54,317:INFO:SubProcess create_model() end ==================================
2026-01-29 16:16:54,317:INFO:Creating metrics dataframe
2026-01-29 16:16:54,321:INFO:Initializing Light Gradient Boosting Machine
2026-01-29 16:16:54,321:INFO:Total runtime is 0.07638957500457763 minutes
2026-01-29 16:16:54,321:INFO:SubProcess create_model() called ==================================
2026-01-29 16:16:54,321:INFO:Initializing create_model()
2026-01-29 16:16:54,321:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816CE95D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:16:54,321:INFO:Checking exceptions
2026-01-29 16:16:54,321:INFO:Importing libraries
2026-01-29 16:16:54,321:INFO:Copying training dataset
2026-01-29 16:16:54,390:INFO:Defining folds
2026-01-29 16:16:54,390:INFO:Declaring metric variables
2026-01-29 16:16:54,407:INFO:Importing untrained model
2026-01-29 16:16:54,407:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-29 16:16:54,407:INFO:Starting cross validation
2026-01-29 16:16:54,407:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:16:55,803:INFO:Calculating mean and std
2026-01-29 16:16:55,807:INFO:Creating metrics dataframe
2026-01-29 16:16:55,812:INFO:Uploading results into container
2026-01-29 16:16:55,813:INFO:Uploading model into container now
2026-01-29 16:16:55,813:INFO:_master_model_container: 4
2026-01-29 16:16:55,813:INFO:_display_container: 2
2026-01-29 16:16:55,813:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-29 16:16:55,813:INFO:create_model() successfully completed......................................
2026-01-29 16:16:56,004:INFO:SubProcess create_model() end ==================================
2026-01-29 16:16:56,004:INFO:Creating metrics dataframe
2026-01-29 16:16:56,020:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-29 16:16:56,025:INFO:Initializing create_model()
2026-01-29 16:16:56,025:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:16:56,025:INFO:Checking exceptions
2026-01-29 16:16:56,025:INFO:Importing libraries
2026-01-29 16:16:56,025:INFO:Copying training dataset
2026-01-29 16:16:56,071:INFO:Defining folds
2026-01-29 16:16:56,071:INFO:Declaring metric variables
2026-01-29 16:16:56,071:INFO:Importing untrained model
2026-01-29 16:16:56,071:INFO:Declaring custom model
2026-01-29 16:16:56,071:INFO:Logistic Regression Imported successfully
2026-01-29 16:16:56,071:INFO:Cross validation set to False
2026-01-29 16:16:56,071:INFO:Fitting Model
2026-01-29 16:16:56,290:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:16:56,290:INFO:create_model() successfully completed......................................
2026-01-29 16:16:56,505:INFO:Initializing create_model()
2026-01-29 16:16:56,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:16:56,505:INFO:Checking exceptions
2026-01-29 16:16:56,511:INFO:Importing libraries
2026-01-29 16:16:56,512:INFO:Copying training dataset
2026-01-29 16:16:56,568:INFO:Defining folds
2026-01-29 16:16:56,568:INFO:Declaring metric variables
2026-01-29 16:16:56,568:INFO:Importing untrained model
2026-01-29 16:16:56,568:INFO:Declaring custom model
2026-01-29 16:16:56,568:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:16:56,569:INFO:Cross validation set to False
2026-01-29 16:16:56,569:INFO:Fitting Model
2026-01-29 16:16:56,621:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:16:56,621:INFO:create_model() successfully completed......................................
2026-01-29 16:16:56,841:INFO:Initializing create_model()
2026-01-29 16:16:56,841:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:16:56,841:INFO:Checking exceptions
2026-01-29 16:16:56,845:INFO:Importing libraries
2026-01-29 16:16:56,845:INFO:Copying training dataset
2026-01-29 16:16:56,920:INFO:Defining folds
2026-01-29 16:16:56,920:INFO:Declaring metric variables
2026-01-29 16:16:56,920:INFO:Importing untrained model
2026-01-29 16:16:56,920:INFO:Declaring custom model
2026-01-29 16:16:56,920:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:16:56,920:INFO:Cross validation set to False
2026-01-29 16:16:56,920:INFO:Fitting Model
2026-01-29 16:16:58,137:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:16:58,137:INFO:create_model() successfully completed......................................
2026-01-29 16:16:58,359:INFO:_master_model_container: 4
2026-01-29 16:16:58,359:INFO:_display_container: 2
2026-01-29 16:16:58,359:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2026-01-29 16:16:58,359:INFO:compare_models() successfully completed......................................
2026-01-29 16:16:58,371:INFO:Initializing tune_model()
2026-01-29 16:16:58,371:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:16:58,371:INFO:Checking exceptions
2026-01-29 16:16:58,409:INFO:Copying training dataset
2026-01-29 16:16:58,490:INFO:Checking base model
2026-01-29 16:16:58,491:INFO:Base model : Logistic Regression
2026-01-29 16:16:58,493:INFO:Declaring metric variables
2026-01-29 16:16:58,495:INFO:Defining Hyperparameters
2026-01-29 16:16:58,687:INFO:Tuning with n_jobs=-1
2026-01-29 16:16:58,687:INFO:Initializing RandomizedSearchCV
2026-01-29 16:17:00,322:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 5.682}
2026-01-29 16:17:00,322:INFO:Hyperparameter search completed
2026-01-29 16:17:00,322:INFO:SubProcess create_model() called ==================================
2026-01-29 16:17:00,322:INFO:Initializing create_model()
2026-01-29 16:17:00,322:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024871B10E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 5.682})
2026-01-29 16:17:00,322:INFO:Checking exceptions
2026-01-29 16:17:00,322:INFO:Importing libraries
2026-01-29 16:17:00,322:INFO:Copying training dataset
2026-01-29 16:17:00,387:INFO:Defining folds
2026-01-29 16:17:00,387:INFO:Declaring metric variables
2026-01-29 16:17:00,387:INFO:Importing untrained model
2026-01-29 16:17:00,387:INFO:Declaring custom model
2026-01-29 16:17:00,402:INFO:Logistic Regression Imported successfully
2026-01-29 16:17:00,407:INFO:Starting cross validation
2026-01-29 16:17:00,407:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:17:01,161:INFO:Calculating mean and std
2026-01-29 16:17:01,161:INFO:Creating metrics dataframe
2026-01-29 16:17:01,170:INFO:Finalizing model
2026-01-29 16:17:01,448:INFO:Uploading results into container
2026-01-29 16:17:01,448:INFO:Uploading model into container now
2026-01-29 16:17:01,448:INFO:_master_model_container: 5
2026-01-29 16:17:01,448:INFO:_display_container: 3
2026-01-29 16:17:01,448:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:17:01,448:INFO:create_model() successfully completed......................................
2026-01-29 16:17:01,654:INFO:SubProcess create_model() end ==================================
2026-01-29 16:17:01,654:INFO:choose_better activated
2026-01-29 16:17:01,654:INFO:SubProcess create_model() called ==================================
2026-01-29 16:17:01,654:INFO:Initializing create_model()
2026-01-29 16:17:01,654:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:17:01,654:INFO:Checking exceptions
2026-01-29 16:17:01,654:INFO:Importing libraries
2026-01-29 16:17:01,654:INFO:Copying training dataset
2026-01-29 16:17:01,721:INFO:Defining folds
2026-01-29 16:17:01,721:INFO:Declaring metric variables
2026-01-29 16:17:01,721:INFO:Importing untrained model
2026-01-29 16:17:01,721:INFO:Declaring custom model
2026-01-29 16:17:01,721:INFO:Logistic Regression Imported successfully
2026-01-29 16:17:01,721:INFO:Starting cross validation
2026-01-29 16:17:01,721:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:17:02,373:INFO:Calculating mean and std
2026-01-29 16:17:02,375:INFO:Creating metrics dataframe
2026-01-29 16:17:02,377:INFO:Finalizing model
2026-01-29 16:17:02,610:INFO:Uploading results into container
2026-01-29 16:17:02,610:INFO:Uploading model into container now
2026-01-29 16:17:02,610:INFO:_master_model_container: 6
2026-01-29 16:17:02,610:INFO:_display_container: 4
2026-01-29 16:17:02,610:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:17:02,610:INFO:create_model() successfully completed......................................
2026-01-29 16:17:02,820:INFO:SubProcess create_model() end ==================================
2026-01-29 16:17:02,820:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 16:17:02,820:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 16:17:02,820:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2026-01-29 16:17:02,820:INFO:choose_better completed
2026-01-29 16:17:02,820:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:17:02,825:INFO:_master_model_container: 6
2026-01-29 16:17:02,825:INFO:_display_container: 3
2026-01-29 16:17:02,825:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:17:02,825:INFO:tune_model() successfully completed......................................
2026-01-29 16:17:03,039:INFO:Initializing tune_model()
2026-01-29 16:17:03,039:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:17:03,040:INFO:Checking exceptions
2026-01-29 16:17:03,068:INFO:Copying training dataset
2026-01-29 16:17:03,129:INFO:Checking base model
2026-01-29 16:17:03,130:INFO:Base model : Decision Tree Classifier
2026-01-29 16:17:03,133:INFO:Declaring metric variables
2026-01-29 16:17:03,138:INFO:Defining Hyperparameters
2026-01-29 16:17:03,353:INFO:Tuning with n_jobs=-1
2026-01-29 16:17:03,353:INFO:Initializing RandomizedSearchCV
2026-01-29 16:17:04,328:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.0005, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 3, 'actual_estimator__criterion': 'gini'}
2026-01-29 16:17:04,328:INFO:Hyperparameter search completed
2026-01-29 16:17:04,328:INFO:SubProcess create_model() called ==================================
2026-01-29 16:17:04,328:INFO:Initializing create_model()
2026-01-29 16:17:04,328:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002487DF698D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0005, 'max_features': 1.0, 'max_depth': 3, 'criterion': 'gini'})
2026-01-29 16:17:04,328:INFO:Checking exceptions
2026-01-29 16:17:04,328:INFO:Importing libraries
2026-01-29 16:17:04,328:INFO:Copying training dataset
2026-01-29 16:17:04,387:INFO:Defining folds
2026-01-29 16:17:04,387:INFO:Declaring metric variables
2026-01-29 16:17:04,387:INFO:Importing untrained model
2026-01-29 16:17:04,387:INFO:Declaring custom model
2026-01-29 16:17:04,387:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:17:04,404:INFO:Starting cross validation
2026-01-29 16:17:04,404:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:17:04,946:INFO:Calculating mean and std
2026-01-29 16:17:04,948:INFO:Creating metrics dataframe
2026-01-29 16:17:04,954:INFO:Finalizing model
2026-01-29 16:17:05,030:INFO:Uploading results into container
2026-01-29 16:17:05,030:INFO:Uploading model into container now
2026-01-29 16:17:05,030:INFO:_master_model_container: 7
2026-01-29 16:17:05,030:INFO:_display_container: 4
2026-01-29 16:17:05,034:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:17:05,034:INFO:create_model() successfully completed......................................
2026-01-29 16:17:05,276:INFO:SubProcess create_model() end ==================================
2026-01-29 16:17:05,276:INFO:choose_better activated
2026-01-29 16:17:05,279:INFO:SubProcess create_model() called ==================================
2026-01-29 16:17:05,279:INFO:Initializing create_model()
2026-01-29 16:17:05,279:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:17:05,280:INFO:Checking exceptions
2026-01-29 16:17:05,281:INFO:Importing libraries
2026-01-29 16:17:05,282:INFO:Copying training dataset
2026-01-29 16:17:05,364:INFO:Defining folds
2026-01-29 16:17:05,364:INFO:Declaring metric variables
2026-01-29 16:17:05,365:INFO:Importing untrained model
2026-01-29 16:17:05,365:INFO:Declaring custom model
2026-01-29 16:17:05,365:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:17:05,365:INFO:Starting cross validation
2026-01-29 16:17:05,366:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:17:05,959:INFO:Calculating mean and std
2026-01-29 16:17:05,959:INFO:Creating metrics dataframe
2026-01-29 16:17:05,959:INFO:Finalizing model
2026-01-29 16:17:06,040:INFO:Uploading results into container
2026-01-29 16:17:06,040:INFO:Uploading model into container now
2026-01-29 16:17:06,040:INFO:_master_model_container: 8
2026-01-29 16:17:06,040:INFO:_display_container: 5
2026-01-29 16:17:06,040:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:17:06,040:INFO:create_model() successfully completed......................................
2026-01-29 16:17:06,270:INFO:SubProcess create_model() end ==================================
2026-01-29 16:17:06,270:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5369
2026-01-29 16:17:06,270:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5366
2026-01-29 16:17:06,270:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-29 16:17:06,270:INFO:choose_better completed
2026-01-29 16:17:06,270:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:17:06,287:INFO:_master_model_container: 8
2026-01-29 16:17:06,287:INFO:_display_container: 4
2026-01-29 16:17:06,287:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:17:06,287:INFO:tune_model() successfully completed......................................
2026-01-29 16:17:06,503:INFO:Initializing tune_model()
2026-01-29 16:17:06,503:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:17:06,503:INFO:Checking exceptions
2026-01-29 16:17:06,553:INFO:Copying training dataset
2026-01-29 16:17:06,620:INFO:Checking base model
2026-01-29 16:17:06,620:INFO:Base model : Random Forest Classifier
2026-01-29 16:17:06,626:INFO:Declaring metric variables
2026-01-29 16:17:06,630:INFO:Defining Hyperparameters
2026-01-29 16:17:06,869:INFO:Tuning with n_jobs=-1
2026-01-29 16:17:06,869:INFO:Initializing RandomizedSearchCV
2026-01-29 16:17:34,874:INFO:best_params: {'actual_estimator__n_estimators': 120, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-29 16:17:34,874:INFO:Hyperparameter search completed
2026-01-29 16:17:34,874:INFO:SubProcess create_model() called ==================================
2026-01-29 16:17:34,874:INFO:Initializing create_model()
2026-01-29 16:17:34,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024827B0F5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 120, 'min_samples_split': 5, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': True})
2026-01-29 16:17:34,874:INFO:Checking exceptions
2026-01-29 16:17:34,874:INFO:Importing libraries
2026-01-29 16:17:34,874:INFO:Copying training dataset
2026-01-29 16:17:34,953:INFO:Defining folds
2026-01-29 16:17:34,953:INFO:Declaring metric variables
2026-01-29 16:17:34,956:INFO:Importing untrained model
2026-01-29 16:17:34,956:INFO:Declaring custom model
2026-01-29 16:17:34,956:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:17:34,971:INFO:Starting cross validation
2026-01-29 16:17:34,972:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:17:38,064:INFO:Calculating mean and std
2026-01-29 16:17:38,064:INFO:Creating metrics dataframe
2026-01-29 16:17:38,073:INFO:Finalizing model
2026-01-29 16:17:39,755:INFO:Uploading results into container
2026-01-29 16:17:39,756:INFO:Uploading model into container now
2026-01-29 16:17:39,756:INFO:_master_model_container: 9
2026-01-29 16:17:39,756:INFO:_display_container: 5
2026-01-29 16:17:39,756:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=120, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:17:39,756:INFO:create_model() successfully completed......................................
2026-01-29 16:17:39,984:INFO:SubProcess create_model() end ==================================
2026-01-29 16:17:39,984:INFO:choose_better activated
2026-01-29 16:17:39,984:INFO:SubProcess create_model() called ==================================
2026-01-29 16:17:39,984:INFO:Initializing create_model()
2026-01-29 16:17:39,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:17:39,984:INFO:Checking exceptions
2026-01-29 16:17:39,984:INFO:Importing libraries
2026-01-29 16:17:39,984:INFO:Copying training dataset
2026-01-29 16:17:40,053:INFO:Defining folds
2026-01-29 16:17:40,053:INFO:Declaring metric variables
2026-01-29 16:17:40,053:INFO:Importing untrained model
2026-01-29 16:17:40,053:INFO:Declaring custom model
2026-01-29 16:17:40,053:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:17:40,053:INFO:Starting cross validation
2026-01-29 16:17:40,053:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:17:42,552:INFO:Calculating mean and std
2026-01-29 16:17:42,552:INFO:Creating metrics dataframe
2026-01-29 16:17:42,558:INFO:Finalizing model
2026-01-29 16:17:43,833:INFO:Uploading results into container
2026-01-29 16:17:43,833:INFO:Uploading model into container now
2026-01-29 16:17:43,833:INFO:_master_model_container: 10
2026-01-29 16:17:43,833:INFO:_display_container: 6
2026-01-29 16:17:43,833:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:17:43,833:INFO:create_model() successfully completed......................................
2026-01-29 16:17:44,038:INFO:SubProcess create_model() end ==================================
2026-01-29 16:17:44,038:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.5369
2026-01-29 16:17:44,038:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=120, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.5369
2026-01-29 16:17:44,038:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-29 16:17:44,038:INFO:choose_better completed
2026-01-29 16:17:44,038:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:17:44,053:INFO:_master_model_container: 10
2026-01-29 16:17:44,053:INFO:_display_container: 5
2026-01-29 16:17:44,053:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:17:44,053:INFO:tune_model() successfully completed......................................
2026-01-29 16:17:44,254:INFO:Initializing evaluate_model()
2026-01-29 16:17:44,254:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:17:44,294:INFO:Initializing plot_model()
2026-01-29 16:17:44,294:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:17:44,295:INFO:Checking exceptions
2026-01-29 16:17:44,321:INFO:Preloading libraries
2026-01-29 16:17:44,321:INFO:Copying training dataset
2026-01-29 16:17:44,321:INFO:Plot type: pipeline
2026-01-29 16:17:44,371:INFO:Visual Rendered Successfully
2026-01-29 16:17:44,572:INFO:plot_model() successfully completed......................................
2026-01-29 16:17:44,572:INFO:Initializing evaluate_model()
2026-01-29 16:17:44,585:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:17:44,617:INFO:Initializing plot_model()
2026-01-29 16:17:44,617:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:17:44,617:INFO:Checking exceptions
2026-01-29 16:17:44,657:INFO:Preloading libraries
2026-01-29 16:17:44,658:INFO:Copying training dataset
2026-01-29 16:17:44,658:INFO:Plot type: pipeline
2026-01-29 16:17:44,750:INFO:Visual Rendered Successfully
2026-01-29 16:17:44,955:INFO:plot_model() successfully completed......................................
2026-01-29 16:17:44,955:INFO:Initializing evaluate_model()
2026-01-29 16:17:44,955:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:17:44,995:INFO:Initializing plot_model()
2026-01-29 16:17:44,995:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:17:44,995:INFO:Checking exceptions
2026-01-29 16:17:45,038:INFO:Preloading libraries
2026-01-29 16:17:45,038:INFO:Copying training dataset
2026-01-29 16:17:45,038:INFO:Plot type: pipeline
2026-01-29 16:17:45,101:INFO:Visual Rendered Successfully
2026-01-29 16:17:45,301:INFO:plot_model() successfully completed......................................
2026-01-29 16:17:45,312:INFO:Initializing predict_model()
2026-01-29 16:17:45,312:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002481E4E31A0>)
2026-01-29 16:17:45,312:INFO:Checking exceptions
2026-01-29 16:17:45,312:INFO:Preloading libraries
2026-01-29 16:17:45,314:INFO:Set up data.
2026-01-29 16:17:45,320:INFO:Set up index.
2026-01-29 16:17:45,803:INFO:Initializing predict_model()
2026-01-29 16:17:45,803:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000248172B4720>)
2026-01-29 16:17:45,803:INFO:Checking exceptions
2026-01-29 16:17:45,803:INFO:Preloading libraries
2026-01-29 16:17:45,803:INFO:Set up data.
2026-01-29 16:17:45,819:INFO:Set up index.
2026-01-29 16:17:46,305:INFO:Initializing predict_model()
2026-01-29 16:17:46,305:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002480F570EA0>)
2026-01-29 16:17:46,305:INFO:Checking exceptions
2026-01-29 16:17:46,305:INFO:Preloading libraries
2026-01-29 16:17:46,305:INFO:Set up data.
2026-01-29 16:17:46,305:INFO:Set up index.
2026-01-29 16:17:47,093:INFO:Initializing plot_model()
2026-01-29 16:17:47,093:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-29 16:17:47,093:INFO:Checking exceptions
2026-01-29 16:17:47,156:INFO:Preloading libraries
2026-01-29 16:17:47,156:INFO:Copying training dataset
2026-01-29 16:17:47,156:INFO:Plot type: feature
2026-01-29 16:17:47,476:INFO:Visual Rendered Successfully
2026-01-29 16:17:47,725:INFO:plot_model() successfully completed......................................
2026-01-29 16:17:47,725:INFO:Initializing save_model()
2026-01-29 16:17:47,725:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=..\datos\04. Modelos, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-29 16:17:47,725:INFO:Adding model into prep_pipe
2026-01-29 16:17:47,740:INFO:..\datos\04. Modelos.pkl saved in current working directory
2026-01-29 16:17:47,741:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(e...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=42,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2026-01-29 16:17:47,741:INFO:save_model() successfully completed......................................
2026-01-29 16:19:05,735:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\1878984716.py:18: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-29 16:19:07,449:INFO:PyCaret ClassificationExperiment
2026-01-29 16:19:07,449:INFO:Logging name: clf-default-name
2026-01-29 16:19:07,449:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-29 16:19:07,449:INFO:version 3.3.2
2026-01-29 16:19:07,451:INFO:Initializing setup()
2026-01-29 16:19:07,451:INFO:self.USI: e4f4
2026-01-29 16:19:07,451:INFO:self._variable_keys: {'X_test', 'fold_groups_param', 'pipeline', 'fix_imbalance', 'exp_name_log', 'data', 'y_test', 'seed', 'fold_shuffle_param', 'n_jobs_param', 'is_multiclass', 'gpu_n_jobs_param', 'memory', 'log_plots_param', 'logging_param', 'idx', 'y', 'target_param', 'fold_generator', 'y_train', 'gpu_param', 'USI', 'exp_id', '_available_plots', 'X', 'X_train', 'html_param', '_ml_usecase'}
2026-01-29 16:19:07,451:INFO:Checking environment
2026-01-29 16:19:07,451:INFO:python_version: 3.11.11
2026-01-29 16:19:07,451:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-29 16:19:07,451:INFO:machine: AMD64
2026-01-29 16:19:07,451:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-29 16:19:07,451:INFO:Memory: svmem(total=34009374720, available=13444653056, percent=60.5, used=20564721664, free=13444653056)
2026-01-29 16:19:07,451:INFO:Physical Core: 12
2026-01-29 16:19:07,452:INFO:Logical Core: 16
2026-01-29 16:19:07,452:INFO:Checking libraries
2026-01-29 16:19:07,452:INFO:System:
2026-01-29 16:19:07,452:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-29 16:19:07,452:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-29 16:19:07,452:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-29 16:19:07,452:INFO:PyCaret required dependencies:
2026-01-29 16:19:07,452:INFO:                 pip: 25.0
2026-01-29 16:19:07,452:INFO:          setuptools: 75.8.0
2026-01-29 16:19:07,452:INFO:             pycaret: 3.3.2
2026-01-29 16:19:07,452:INFO:             IPython: 9.9.0
2026-01-29 16:19:07,452:INFO:          ipywidgets: 8.1.8
2026-01-29 16:19:07,452:INFO:                tqdm: 4.67.1
2026-01-29 16:19:07,452:INFO:               numpy: 1.26.4
2026-01-29 16:19:07,452:INFO:              pandas: 2.1.4
2026-01-29 16:19:07,452:INFO:              jinja2: 3.1.6
2026-01-29 16:19:07,452:INFO:               scipy: 1.11.4
2026-01-29 16:19:07,452:INFO:              joblib: 1.3.2
2026-01-29 16:19:07,452:INFO:             sklearn: 1.4.2
2026-01-29 16:19:07,452:INFO:                pyod: 2.0.6
2026-01-29 16:19:07,452:INFO:            imblearn: 0.14.1
2026-01-29 16:19:07,452:INFO:   category_encoders: 2.7.0
2026-01-29 16:19:07,452:INFO:            lightgbm: 4.6.0
2026-01-29 16:19:07,452:INFO:               numba: 0.62.1
2026-01-29 16:19:07,452:INFO:            requests: 2.32.3
2026-01-29 16:19:07,452:INFO:          matplotlib: 3.7.5
2026-01-29 16:19:07,452:INFO:          scikitplot: 0.3.7
2026-01-29 16:19:07,452:INFO:         yellowbrick: 1.5
2026-01-29 16:19:07,452:INFO:              plotly: 5.24.1
2026-01-29 16:19:07,452:INFO:    plotly-resampler: Not installed
2026-01-29 16:19:07,452:INFO:             kaleido: 1.2.0
2026-01-29 16:19:07,452:INFO:           schemdraw: 0.15
2026-01-29 16:19:07,452:INFO:         statsmodels: 0.14.6
2026-01-29 16:19:07,452:INFO:              sktime: 0.26.0
2026-01-29 16:19:07,452:INFO:               tbats: 1.1.3
2026-01-29 16:19:07,452:INFO:            pmdarima: 2.0.4
2026-01-29 16:19:07,452:INFO:              psutil: 7.2.1
2026-01-29 16:19:07,452:INFO:          markupsafe: 3.0.3
2026-01-29 16:19:07,452:INFO:             pickle5: Not installed
2026-01-29 16:19:07,452:INFO:         cloudpickle: 3.0.0
2026-01-29 16:19:07,452:INFO:         deprecation: 2.1.0
2026-01-29 16:19:07,452:INFO:              xxhash: 3.6.0
2026-01-29 16:19:07,452:INFO:           wurlitzer: Not installed
2026-01-29 16:19:07,452:INFO:PyCaret optional dependencies:
2026-01-29 16:19:07,452:INFO:                shap: 0.44.1
2026-01-29 16:19:07,452:INFO:           interpret: 0.7.3
2026-01-29 16:19:07,452:INFO:                umap: 0.5.7
2026-01-29 16:19:07,452:INFO:     ydata_profiling: 4.18.1
2026-01-29 16:19:07,452:INFO:  explainerdashboard: 0.5.1
2026-01-29 16:19:07,452:INFO:             autoviz: Not installed
2026-01-29 16:19:07,452:INFO:           fairlearn: 0.7.0
2026-01-29 16:19:07,452:INFO:          deepchecks: Not installed
2026-01-29 16:19:07,452:INFO:             xgboost: Not installed
2026-01-29 16:19:07,452:INFO:            catboost: 1.2.8
2026-01-29 16:19:07,452:INFO:              kmodes: 0.12.2
2026-01-29 16:19:07,452:INFO:             mlxtend: 0.23.4
2026-01-29 16:19:07,452:INFO:       statsforecast: 1.5.0
2026-01-29 16:19:07,452:INFO:        tune_sklearn: Not installed
2026-01-29 16:19:07,452:INFO:                 ray: Not installed
2026-01-29 16:19:07,452:INFO:            hyperopt: 0.2.7
2026-01-29 16:19:07,452:INFO:              optuna: 4.6.0
2026-01-29 16:19:07,452:INFO:               skopt: 0.10.2
2026-01-29 16:19:07,452:INFO:              mlflow: 3.8.1
2026-01-29 16:19:07,452:INFO:              gradio: 6.3.0
2026-01-29 16:19:07,452:INFO:             fastapi: 0.128.0
2026-01-29 16:19:07,452:INFO:             uvicorn: 0.40.0
2026-01-29 16:19:07,452:INFO:              m2cgen: 0.10.0
2026-01-29 16:19:07,452:INFO:           evidently: 0.4.40
2026-01-29 16:19:07,452:INFO:               fugue: 0.8.7
2026-01-29 16:19:07,452:INFO:           streamlit: Not installed
2026-01-29 16:19:07,452:INFO:             prophet: Not installed
2026-01-29 16:19:07,452:INFO:None
2026-01-29 16:19:07,452:INFO:Set up data.
2026-01-29 16:19:07,485:INFO:Set up folding strategy.
2026-01-29 16:19:07,485:INFO:Set up train/test split.
2026-01-29 16:19:07,585:INFO:Set up index.
2026-01-29 16:19:07,585:INFO:Assigning column types.
2026-01-29 16:19:07,602:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-29 16:19:07,635:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:19:07,635:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:19:07,656:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:19:07,656:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:19:07,684:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:19:07,685:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:19:07,702:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:19:07,702:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:19:07,702:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-29 16:19:07,719:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:19:07,735:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:19:07,735:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:19:07,769:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:19:07,785:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:19:07,785:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:19:07,785:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-29 16:19:07,835:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:19:07,835:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:19:07,885:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:19:07,885:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:19:07,885:INFO:Preparing preprocessing pipeline...
2026-01-29 16:19:07,895:INFO:Set up simple imputation.
2026-01-29 16:19:07,895:INFO:Set up feature normalization.
2026-01-29 16:19:07,971:INFO:Finished creating preprocessing pipeline.
2026-01-29 16:19:07,971:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-29 16:19:07,971:INFO:Creating final display dataframe.
2026-01-29 16:19:08,186:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape       (429278, 4)
4        Transformed data shape       (429278, 4)
5   Transformed train set shape       (343422, 4)
6    Transformed test set shape        (85856, 4)
7               Ignore features                58
8              Numeric features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                 3
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              e4f4
2026-01-29 16:19:08,236:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:19:08,236:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:19:08,285:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:19:08,286:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:19:08,287:INFO:setup() successfully completed in 0.85s...............
2026-01-29 16:19:08,287:INFO:Initializing compare_models()
2026-01-29 16:19:08,287:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-29 16:19:08,287:INFO:Checking exceptions
2026-01-29 16:19:08,302:INFO:Preparing display monitor
2026-01-29 16:19:08,330:INFO:Initializing Logistic Regression
2026-01-29 16:19:08,330:INFO:Total runtime is 6.67572021484375e-06 minutes
2026-01-29 16:19:08,332:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:08,333:INFO:Initializing create_model()
2026-01-29 16:19:08,333:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002480E442290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:08,333:INFO:Checking exceptions
2026-01-29 16:19:08,333:INFO:Importing libraries
2026-01-29 16:19:08,333:INFO:Copying training dataset
2026-01-29 16:19:08,417:INFO:Defining folds
2026-01-29 16:19:08,417:INFO:Declaring metric variables
2026-01-29 16:19:08,420:INFO:Importing untrained model
2026-01-29 16:19:08,422:INFO:Logistic Regression Imported successfully
2026-01-29 16:19:08,427:INFO:Starting cross validation
2026-01-29 16:19:08,428:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:08,980:INFO:Calculating mean and std
2026-01-29 16:19:08,980:INFO:Creating metrics dataframe
2026-01-29 16:19:08,980:INFO:Uploading results into container
2026-01-29 16:19:08,980:INFO:Uploading model into container now
2026-01-29 16:19:08,984:INFO:_master_model_container: 1
2026-01-29 16:19:08,984:INFO:_display_container: 2
2026-01-29 16:19:08,984:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:19:08,984:INFO:create_model() successfully completed......................................
2026-01-29 16:19:09,185:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:09,185:INFO:Creating metrics dataframe
2026-01-29 16:19:09,185:INFO:Initializing Decision Tree Classifier
2026-01-29 16:19:09,185:INFO:Total runtime is 0.014251784483591715 minutes
2026-01-29 16:19:09,185:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:09,185:INFO:Initializing create_model()
2026-01-29 16:19:09,185:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002480E442290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:09,185:INFO:Checking exceptions
2026-01-29 16:19:09,185:INFO:Importing libraries
2026-01-29 16:19:09,185:INFO:Copying training dataset
2026-01-29 16:19:09,238:INFO:Defining folds
2026-01-29 16:19:09,251:INFO:Declaring metric variables
2026-01-29 16:19:09,253:INFO:Importing untrained model
2026-01-29 16:19:09,253:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:19:09,253:INFO:Starting cross validation
2026-01-29 16:19:09,253:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:09,718:INFO:Calculating mean and std
2026-01-29 16:19:09,719:INFO:Creating metrics dataframe
2026-01-29 16:19:09,719:INFO:Uploading results into container
2026-01-29 16:19:09,719:INFO:Uploading model into container now
2026-01-29 16:19:09,719:INFO:_master_model_container: 2
2026-01-29 16:19:09,723:INFO:_display_container: 2
2026-01-29 16:19:09,724:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:19:09,724:INFO:create_model() successfully completed......................................
2026-01-29 16:19:09,919:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:09,919:INFO:Creating metrics dataframe
2026-01-29 16:19:09,919:INFO:Initializing Random Forest Classifier
2026-01-29 16:19:09,919:INFO:Total runtime is 0.02647436459859212 minutes
2026-01-29 16:19:09,934:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:09,935:INFO:Initializing create_model()
2026-01-29 16:19:09,935:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002480E442290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:09,935:INFO:Checking exceptions
2026-01-29 16:19:09,935:INFO:Importing libraries
2026-01-29 16:19:09,935:INFO:Copying training dataset
2026-01-29 16:19:09,987:INFO:Defining folds
2026-01-29 16:19:09,987:INFO:Declaring metric variables
2026-01-29 16:19:09,987:INFO:Importing untrained model
2026-01-29 16:19:09,987:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:19:09,987:INFO:Starting cross validation
2026-01-29 16:19:09,987:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:12,204:INFO:Calculating mean and std
2026-01-29 16:19:12,204:INFO:Creating metrics dataframe
2026-01-29 16:19:12,217:INFO:Uploading results into container
2026-01-29 16:19:12,219:INFO:Uploading model into container now
2026-01-29 16:19:12,220:INFO:_master_model_container: 3
2026-01-29 16:19:12,220:INFO:_display_container: 2
2026-01-29 16:19:12,220:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:19:12,220:INFO:create_model() successfully completed......................................
2026-01-29 16:19:12,419:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:12,419:INFO:Creating metrics dataframe
2026-01-29 16:19:12,419:INFO:Initializing Light Gradient Boosting Machine
2026-01-29 16:19:12,419:INFO:Total runtime is 0.0681542714436849 minutes
2026-01-29 16:19:12,419:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:12,435:INFO:Initializing create_model()
2026-01-29 16:19:12,435:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002480E442290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:12,435:INFO:Checking exceptions
2026-01-29 16:19:12,435:INFO:Importing libraries
2026-01-29 16:19:12,435:INFO:Copying training dataset
2026-01-29 16:19:12,486:INFO:Defining folds
2026-01-29 16:19:12,486:INFO:Declaring metric variables
2026-01-29 16:19:12,486:INFO:Importing untrained model
2026-01-29 16:19:12,486:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-29 16:19:12,486:INFO:Starting cross validation
2026-01-29 16:19:12,502:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:13,632:INFO:Calculating mean and std
2026-01-29 16:19:13,632:INFO:Creating metrics dataframe
2026-01-29 16:19:13,632:INFO:Uploading results into container
2026-01-29 16:19:13,632:INFO:Uploading model into container now
2026-01-29 16:19:13,632:INFO:_master_model_container: 4
2026-01-29 16:19:13,632:INFO:_display_container: 2
2026-01-29 16:19:13,636:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-29 16:19:13,636:INFO:create_model() successfully completed......................................
2026-01-29 16:19:13,839:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:13,839:INFO:Creating metrics dataframe
2026-01-29 16:19:13,845:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-29 16:19:13,854:INFO:Initializing create_model()
2026-01-29 16:19:13,854:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:13,854:INFO:Checking exceptions
2026-01-29 16:19:13,854:INFO:Importing libraries
2026-01-29 16:19:13,854:INFO:Copying training dataset
2026-01-29 16:19:13,920:INFO:Defining folds
2026-01-29 16:19:13,920:INFO:Declaring metric variables
2026-01-29 16:19:13,920:INFO:Importing untrained model
2026-01-29 16:19:13,920:INFO:Declaring custom model
2026-01-29 16:19:13,921:INFO:Logistic Regression Imported successfully
2026-01-29 16:19:13,921:INFO:Cross validation set to False
2026-01-29 16:19:13,921:INFO:Fitting Model
2026-01-29 16:19:14,117:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:19:14,117:INFO:create_model() successfully completed......................................
2026-01-29 16:19:14,333:INFO:Initializing create_model()
2026-01-29 16:19:14,333:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:14,333:INFO:Checking exceptions
2026-01-29 16:19:14,345:INFO:Importing libraries
2026-01-29 16:19:14,345:INFO:Copying training dataset
2026-01-29 16:19:14,402:INFO:Defining folds
2026-01-29 16:19:14,402:INFO:Declaring metric variables
2026-01-29 16:19:14,402:INFO:Importing untrained model
2026-01-29 16:19:14,402:INFO:Declaring custom model
2026-01-29 16:19:14,402:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:19:14,402:INFO:Cross validation set to False
2026-01-29 16:19:14,402:INFO:Fitting Model
2026-01-29 16:19:14,469:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:19:14,469:INFO:create_model() successfully completed......................................
2026-01-29 16:19:14,671:INFO:Initializing create_model()
2026-01-29 16:19:14,671:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:14,671:INFO:Checking exceptions
2026-01-29 16:19:14,676:INFO:Importing libraries
2026-01-29 16:19:14,676:INFO:Copying training dataset
2026-01-29 16:19:14,735:INFO:Defining folds
2026-01-29 16:19:14,735:INFO:Declaring metric variables
2026-01-29 16:19:14,735:INFO:Importing untrained model
2026-01-29 16:19:14,735:INFO:Declaring custom model
2026-01-29 16:19:14,735:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:19:14,735:INFO:Cross validation set to False
2026-01-29 16:19:14,735:INFO:Fitting Model
2026-01-29 16:19:15,867:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:19:15,867:INFO:create_model() successfully completed......................................
2026-01-29 16:19:16,086:INFO:_master_model_container: 4
2026-01-29 16:19:16,086:INFO:_display_container: 2
2026-01-29 16:19:16,086:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2026-01-29 16:19:16,086:INFO:compare_models() successfully completed......................................
2026-01-29 16:19:16,086:INFO:Initializing tune_model()
2026-01-29 16:19:16,086:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:19:16,086:INFO:Checking exceptions
2026-01-29 16:19:16,134:INFO:Copying training dataset
2026-01-29 16:19:16,196:INFO:Checking base model
2026-01-29 16:19:16,196:INFO:Base model : Logistic Regression
2026-01-29 16:19:16,199:INFO:Declaring metric variables
2026-01-29 16:19:16,201:INFO:Defining Hyperparameters
2026-01-29 16:19:16,418:INFO:Tuning with n_jobs=-1
2026-01-29 16:19:16,418:INFO:Initializing RandomizedSearchCV
2026-01-29 16:19:17,823:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 5.682}
2026-01-29 16:19:17,823:INFO:Hyperparameter search completed
2026-01-29 16:19:17,823:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:17,823:INFO:Initializing create_model()
2026-01-29 16:19:17,823:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816DB8910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 5.682})
2026-01-29 16:19:17,823:INFO:Checking exceptions
2026-01-29 16:19:17,823:INFO:Importing libraries
2026-01-29 16:19:17,823:INFO:Copying training dataset
2026-01-29 16:19:17,886:INFO:Defining folds
2026-01-29 16:19:17,886:INFO:Declaring metric variables
2026-01-29 16:19:17,886:INFO:Importing untrained model
2026-01-29 16:19:17,886:INFO:Declaring custom model
2026-01-29 16:19:17,886:INFO:Logistic Regression Imported successfully
2026-01-29 16:19:17,901:INFO:Starting cross validation
2026-01-29 16:19:17,901:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:18,608:INFO:Calculating mean and std
2026-01-29 16:19:18,608:INFO:Creating metrics dataframe
2026-01-29 16:19:18,608:INFO:Finalizing model
2026-01-29 16:19:18,909:INFO:Uploading results into container
2026-01-29 16:19:18,911:INFO:Uploading model into container now
2026-01-29 16:19:18,911:INFO:_master_model_container: 5
2026-01-29 16:19:18,911:INFO:_display_container: 3
2026-01-29 16:19:18,911:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:19:18,911:INFO:create_model() successfully completed......................................
2026-01-29 16:19:19,120:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:19,120:INFO:choose_better activated
2026-01-29 16:19:19,120:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:19,120:INFO:Initializing create_model()
2026-01-29 16:19:19,120:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:19,120:INFO:Checking exceptions
2026-01-29 16:19:19,120:INFO:Importing libraries
2026-01-29 16:19:19,120:INFO:Copying training dataset
2026-01-29 16:19:19,185:INFO:Defining folds
2026-01-29 16:19:19,185:INFO:Declaring metric variables
2026-01-29 16:19:19,185:INFO:Importing untrained model
2026-01-29 16:19:19,185:INFO:Declaring custom model
2026-01-29 16:19:19,185:INFO:Logistic Regression Imported successfully
2026-01-29 16:19:19,189:INFO:Starting cross validation
2026-01-29 16:19:19,189:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:19,920:INFO:Calculating mean and std
2026-01-29 16:19:19,920:INFO:Creating metrics dataframe
2026-01-29 16:19:19,920:INFO:Finalizing model
2026-01-29 16:19:20,154:INFO:Uploading results into container
2026-01-29 16:19:20,154:INFO:Uploading model into container now
2026-01-29 16:19:20,154:INFO:_master_model_container: 6
2026-01-29 16:19:20,154:INFO:_display_container: 4
2026-01-29 16:19:20,154:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:19:20,154:INFO:create_model() successfully completed......................................
2026-01-29 16:19:20,371:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:20,371:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 16:19:20,371:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 16:19:20,371:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2026-01-29 16:19:20,371:INFO:choose_better completed
2026-01-29 16:19:20,371:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:19:20,371:INFO:_master_model_container: 6
2026-01-29 16:19:20,371:INFO:_display_container: 3
2026-01-29 16:19:20,371:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:19:20,371:INFO:tune_model() successfully completed......................................
2026-01-29 16:19:20,592:INFO:Initializing tune_model()
2026-01-29 16:19:20,592:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:19:20,592:INFO:Checking exceptions
2026-01-29 16:19:20,619:INFO:Copying training dataset
2026-01-29 16:19:20,690:INFO:Checking base model
2026-01-29 16:19:20,692:INFO:Base model : Decision Tree Classifier
2026-01-29 16:19:20,694:INFO:Declaring metric variables
2026-01-29 16:19:20,697:INFO:Defining Hyperparameters
2026-01-29 16:19:20,903:INFO:Tuning with n_jobs=-1
2026-01-29 16:19:20,903:INFO:Initializing RandomizedSearchCV
2026-01-29 16:19:21,772:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.0005, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 3, 'actual_estimator__criterion': 'gini'}
2026-01-29 16:19:21,772:INFO:Hyperparameter search completed
2026-01-29 16:19:21,772:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:21,772:INFO:Initializing create_model()
2026-01-29 16:19:21,772:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002487E3F3ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0005, 'max_features': 1.0, 'max_depth': 3, 'criterion': 'gini'})
2026-01-29 16:19:21,772:INFO:Checking exceptions
2026-01-29 16:19:21,772:INFO:Importing libraries
2026-01-29 16:19:21,772:INFO:Copying training dataset
2026-01-29 16:19:21,834:INFO:Defining folds
2026-01-29 16:19:21,834:INFO:Declaring metric variables
2026-01-29 16:19:21,834:INFO:Importing untrained model
2026-01-29 16:19:21,834:INFO:Declaring custom model
2026-01-29 16:19:21,834:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:19:21,834:INFO:Starting cross validation
2026-01-29 16:19:21,834:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:22,491:INFO:Calculating mean and std
2026-01-29 16:19:22,491:INFO:Creating metrics dataframe
2026-01-29 16:19:22,501:INFO:Finalizing model
2026-01-29 16:19:22,568:INFO:Uploading results into container
2026-01-29 16:19:22,568:INFO:Uploading model into container now
2026-01-29 16:19:22,568:INFO:_master_model_container: 7
2026-01-29 16:19:22,568:INFO:_display_container: 4
2026-01-29 16:19:22,568:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:19:22,568:INFO:create_model() successfully completed......................................
2026-01-29 16:19:22,817:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:22,818:INFO:choose_better activated
2026-01-29 16:19:22,821:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:22,822:INFO:Initializing create_model()
2026-01-29 16:19:22,822:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:22,822:INFO:Checking exceptions
2026-01-29 16:19:22,822:INFO:Importing libraries
2026-01-29 16:19:22,822:INFO:Copying training dataset
2026-01-29 16:19:22,894:INFO:Defining folds
2026-01-29 16:19:22,894:INFO:Declaring metric variables
2026-01-29 16:19:22,894:INFO:Importing untrained model
2026-01-29 16:19:22,894:INFO:Declaring custom model
2026-01-29 16:19:22,896:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:19:22,896:INFO:Starting cross validation
2026-01-29 16:19:22,896:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:23,496:INFO:Calculating mean and std
2026-01-29 16:19:23,496:INFO:Creating metrics dataframe
2026-01-29 16:19:23,500:INFO:Finalizing model
2026-01-29 16:19:23,563:INFO:Uploading results into container
2026-01-29 16:19:23,570:INFO:Uploading model into container now
2026-01-29 16:19:23,570:INFO:_master_model_container: 8
2026-01-29 16:19:23,570:INFO:_display_container: 5
2026-01-29 16:19:23,570:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:19:23,570:INFO:create_model() successfully completed......................................
2026-01-29 16:19:23,786:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:23,786:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5369
2026-01-29 16:19:23,786:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5366
2026-01-29 16:19:23,786:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-29 16:19:23,786:INFO:choose_better completed
2026-01-29 16:19:23,786:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:19:23,801:INFO:_master_model_container: 8
2026-01-29 16:19:23,802:INFO:_display_container: 4
2026-01-29 16:19:23,802:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:19:23,802:INFO:tune_model() successfully completed......................................
2026-01-29 16:19:24,019:INFO:Initializing tune_model()
2026-01-29 16:19:24,019:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:19:24,019:INFO:Checking exceptions
2026-01-29 16:19:24,054:INFO:Copying training dataset
2026-01-29 16:19:24,109:INFO:Checking base model
2026-01-29 16:19:24,109:INFO:Base model : Random Forest Classifier
2026-01-29 16:19:24,112:INFO:Declaring metric variables
2026-01-29 16:19:24,115:INFO:Defining Hyperparameters
2026-01-29 16:19:24,335:INFO:Tuning with n_jobs=-1
2026-01-29 16:19:24,335:INFO:Initializing RandomizedSearchCV
2026-01-29 16:19:48,174:INFO:best_params: {'actual_estimator__n_estimators': 120, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-29 16:19:48,174:INFO:Hyperparameter search completed
2026-01-29 16:19:48,174:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:48,174:INFO:Initializing create_model()
2026-01-29 16:19:48,174:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816D828D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 120, 'min_samples_split': 5, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': True})
2026-01-29 16:19:48,174:INFO:Checking exceptions
2026-01-29 16:19:48,174:INFO:Importing libraries
2026-01-29 16:19:48,174:INFO:Copying training dataset
2026-01-29 16:19:48,289:INFO:Defining folds
2026-01-29 16:19:48,289:INFO:Declaring metric variables
2026-01-29 16:19:48,292:INFO:Importing untrained model
2026-01-29 16:19:48,292:INFO:Declaring custom model
2026-01-29 16:19:48,297:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:19:48,306:INFO:Starting cross validation
2026-01-29 16:19:48,306:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:51,069:INFO:Calculating mean and std
2026-01-29 16:19:51,069:INFO:Creating metrics dataframe
2026-01-29 16:19:51,069:INFO:Finalizing model
2026-01-29 16:19:52,812:INFO:Uploading results into container
2026-01-29 16:19:52,812:INFO:Uploading model into container now
2026-01-29 16:19:52,812:INFO:_master_model_container: 9
2026-01-29 16:19:52,812:INFO:_display_container: 5
2026-01-29 16:19:52,812:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=120, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:19:52,812:INFO:create_model() successfully completed......................................
2026-01-29 16:19:53,037:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:53,037:INFO:choose_better activated
2026-01-29 16:19:53,037:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:53,037:INFO:Initializing create_model()
2026-01-29 16:19:53,037:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:53,037:INFO:Checking exceptions
2026-01-29 16:19:53,037:INFO:Importing libraries
2026-01-29 16:19:53,037:INFO:Copying training dataset
2026-01-29 16:19:53,102:INFO:Defining folds
2026-01-29 16:19:53,102:INFO:Declaring metric variables
2026-01-29 16:19:53,102:INFO:Importing untrained model
2026-01-29 16:19:53,102:INFO:Declaring custom model
2026-01-29 16:19:53,102:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:19:53,102:INFO:Starting cross validation
2026-01-29 16:19:53,102:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:55,455:INFO:Calculating mean and std
2026-01-29 16:19:55,455:INFO:Creating metrics dataframe
2026-01-29 16:19:55,455:INFO:Finalizing model
2026-01-29 16:19:56,823:INFO:Uploading results into container
2026-01-29 16:19:56,823:INFO:Uploading model into container now
2026-01-29 16:19:56,823:INFO:_master_model_container: 10
2026-01-29 16:19:56,823:INFO:_display_container: 6
2026-01-29 16:19:56,823:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:19:56,823:INFO:create_model() successfully completed......................................
2026-01-29 16:19:57,035:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:57,035:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.5369
2026-01-29 16:19:57,035:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=120, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.5369
2026-01-29 16:19:57,035:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-29 16:19:57,035:INFO:choose_better completed
2026-01-29 16:19:57,035:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:19:57,051:INFO:_master_model_container: 10
2026-01-29 16:19:57,051:INFO:_display_container: 5
2026-01-29 16:19:57,051:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:19:57,051:INFO:tune_model() successfully completed......................................
2026-01-29 16:19:57,302:INFO:Initializing evaluate_model()
2026-01-29 16:19:57,302:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:19:57,338:INFO:Initializing plot_model()
2026-01-29 16:19:57,339:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:19:57,339:INFO:Checking exceptions
2026-01-29 16:19:57,371:INFO:Preloading libraries
2026-01-29 16:19:57,371:INFO:Copying training dataset
2026-01-29 16:19:57,371:INFO:Plot type: pipeline
2026-01-29 16:19:57,435:INFO:Visual Rendered Successfully
2026-01-29 16:19:57,701:INFO:plot_model() successfully completed......................................
2026-01-29 16:19:57,701:INFO:Initializing evaluate_model()
2026-01-29 16:19:57,701:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:19:57,754:INFO:Initializing plot_model()
2026-01-29 16:19:57,754:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:19:57,754:INFO:Checking exceptions
2026-01-29 16:19:57,786:INFO:Preloading libraries
2026-01-29 16:19:57,786:INFO:Copying training dataset
2026-01-29 16:19:57,786:INFO:Plot type: pipeline
2026-01-29 16:19:57,895:INFO:Visual Rendered Successfully
2026-01-29 16:19:58,118:INFO:plot_model() successfully completed......................................
2026-01-29 16:19:58,126:INFO:Initializing evaluate_model()
2026-01-29 16:19:58,127:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:19:58,162:INFO:Initializing plot_model()
2026-01-29 16:19:58,163:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:19:58,163:INFO:Checking exceptions
2026-01-29 16:19:58,239:INFO:Preloading libraries
2026-01-29 16:19:58,239:INFO:Copying training dataset
2026-01-29 16:19:58,239:INFO:Plot type: pipeline
2026-01-29 16:19:58,325:INFO:Visual Rendered Successfully
2026-01-29 16:19:58,540:INFO:plot_model() successfully completed......................................
2026-01-29 16:19:58,551:INFO:Initializing predict_model()
2026-01-29 16:19:58,552:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000248488BA8E0>)
2026-01-29 16:19:58,552:INFO:Checking exceptions
2026-01-29 16:19:58,552:INFO:Preloading libraries
2026-01-29 16:19:58,553:INFO:Set up data.
2026-01-29 16:19:58,564:INFO:Set up index.
2026-01-29 16:19:59,152:INFO:Initializing predict_model()
2026-01-29 16:19:59,152:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002480F572AC0>)
2026-01-29 16:19:59,152:INFO:Checking exceptions
2026-01-29 16:19:59,152:INFO:Preloading libraries
2026-01-29 16:19:59,154:INFO:Set up data.
2026-01-29 16:19:59,154:INFO:Set up index.
2026-01-29 16:19:59,685:INFO:Initializing predict_model()
2026-01-29 16:19:59,685:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002487FF34220>)
2026-01-29 16:19:59,685:INFO:Checking exceptions
2026-01-29 16:19:59,685:INFO:Preloading libraries
2026-01-29 16:19:59,685:INFO:Set up data.
2026-01-29 16:19:59,685:INFO:Set up index.
2026-01-29 16:20:00,418:INFO:Initializing plot_model()
2026-01-29 16:20:00,419:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-29 16:20:00,419:INFO:Checking exceptions
2026-01-29 16:20:00,442:INFO:Preloading libraries
2026-01-29 16:20:00,442:INFO:Copying training dataset
2026-01-29 16:20:00,442:INFO:Plot type: feature
2026-01-29 16:20:00,728:INFO:Visual Rendered Successfully
2026-01-29 16:20:00,970:INFO:plot_model() successfully completed......................................
2026-01-29 16:20:00,973:INFO:Initializing save_model()
2026-01-29 16:20:00,973:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=..\datos\04. Modelos, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-29 16:20:00,973:INFO:Adding model into prep_pipe
2026-01-29 16:20:00,973:INFO:..\datos\04. Modelos.pkl saved in current working directory
2026-01-29 16:20:00,988:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(e...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=42,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2026-01-29 16:20:00,988:INFO:save_model() successfully completed......................................
2026-01-29 17:15:41,175:INFO:Initializing plot_model()
2026-01-29 17:15:41,178:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=rfe, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 17:15:41,179:INFO:Checking exceptions
2026-01-29 17:15:41,218:INFO:Preloading libraries
2026-01-29 17:15:41,219:INFO:Copying training dataset
2026-01-29 17:15:41,219:INFO:Plot type: rfe
2026-01-29 17:15:41,446:INFO:Fitting Model
2026-01-29 17:15:44,103:INFO:Visual Rendered Successfully
2026-01-29 17:15:44,349:INFO:plot_model() successfully completed......................................
2026-01-30 08:51:44,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-30 08:51:44,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-30 08:51:44,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-30 08:51:44,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-30 08:57:28,953:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\417549131.py:20: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-30 08:57:31,166:INFO:PyCaret ClassificationExperiment
2026-01-30 08:57:31,166:INFO:Logging name: clf-default-name
2026-01-30 08:57:31,166:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-30 08:57:31,166:INFO:version 3.3.2
2026-01-30 08:57:31,168:INFO:Initializing setup()
2026-01-30 08:57:31,168:INFO:self.USI: 0660
2026-01-30 08:57:31,168:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'n_jobs_param', 'data', 'X', 'idx', 'y_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'USI', 'target_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'y_train', 'X_test', 'seed', 'gpu_param', 'gpu_n_jobs_param', 'y', 'logging_param', 'pipeline', 'fold_generator', 'exp_id'}
2026-01-30 08:57:31,170:INFO:Checking environment
2026-01-30 08:57:31,170:INFO:python_version: 3.11.11
2026-01-30 08:57:31,170:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-30 08:57:31,170:INFO:machine: AMD64
2026-01-30 08:57:31,170:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-30 08:57:31,170:INFO:Memory: svmem(total=34009374720, available=16781463552, percent=50.7, used=17227911168, free=16781463552)
2026-01-30 08:57:31,170:INFO:Physical Core: 12
2026-01-30 08:57:31,170:INFO:Logical Core: 16
2026-01-30 08:57:31,170:INFO:Checking libraries
2026-01-30 08:57:31,170:INFO:System:
2026-01-30 08:57:31,170:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-30 08:57:31,172:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-30 08:57:31,173:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-30 08:57:31,173:INFO:PyCaret required dependencies:
2026-01-30 08:57:32,242:INFO:                 pip: 25.0
2026-01-30 08:57:32,243:INFO:          setuptools: 75.8.0
2026-01-30 08:57:32,243:INFO:             pycaret: 3.3.2
2026-01-30 08:57:32,243:INFO:             IPython: 9.9.0
2026-01-30 08:57:32,243:INFO:          ipywidgets: 8.1.8
2026-01-30 08:57:32,243:INFO:                tqdm: 4.67.1
2026-01-30 08:57:32,243:INFO:               numpy: 1.26.4
2026-01-30 08:57:32,243:INFO:              pandas: 2.1.4
2026-01-30 08:57:32,243:INFO:              jinja2: 3.1.6
2026-01-30 08:57:32,243:INFO:               scipy: 1.11.4
2026-01-30 08:57:32,243:INFO:              joblib: 1.3.2
2026-01-30 08:57:32,243:INFO:             sklearn: 1.4.2
2026-01-30 08:57:32,243:INFO:                pyod: 2.0.6
2026-01-30 08:57:32,243:INFO:            imblearn: 0.14.1
2026-01-30 08:57:32,243:INFO:   category_encoders: 2.7.0
2026-01-30 08:57:32,243:INFO:            lightgbm: 4.6.0
2026-01-30 08:57:32,243:INFO:               numba: 0.62.1
2026-01-30 08:57:32,243:INFO:            requests: 2.32.3
2026-01-30 08:57:32,243:INFO:          matplotlib: 3.7.5
2026-01-30 08:57:32,243:INFO:          scikitplot: 0.3.7
2026-01-30 08:57:32,243:INFO:         yellowbrick: 1.5
2026-01-30 08:57:32,243:INFO:              plotly: 5.24.1
2026-01-30 08:57:32,243:INFO:    plotly-resampler: Not installed
2026-01-30 08:57:32,243:INFO:             kaleido: 1.2.0
2026-01-30 08:57:32,243:INFO:           schemdraw: 0.15
2026-01-30 08:57:32,243:INFO:         statsmodels: 0.14.6
2026-01-30 08:57:32,243:INFO:              sktime: 0.26.0
2026-01-30 08:57:32,243:INFO:               tbats: 1.1.3
2026-01-30 08:57:32,243:INFO:            pmdarima: 2.0.4
2026-01-30 08:57:32,244:INFO:              psutil: 7.2.1
2026-01-30 08:57:32,244:INFO:          markupsafe: 3.0.3
2026-01-30 08:57:32,244:INFO:             pickle5: Not installed
2026-01-30 08:57:32,244:INFO:         cloudpickle: 3.0.0
2026-01-30 08:57:32,244:INFO:         deprecation: 2.1.0
2026-01-30 08:57:32,244:INFO:              xxhash: 3.6.0
2026-01-30 08:57:32,244:INFO:           wurlitzer: Not installed
2026-01-30 08:57:32,244:INFO:PyCaret optional dependencies:
2026-01-30 08:57:39,269:INFO:                shap: 0.44.1
2026-01-30 08:57:39,269:INFO:           interpret: 0.7.3
2026-01-30 08:57:39,269:INFO:                umap: 0.5.7
2026-01-30 08:57:39,269:INFO:     ydata_profiling: 4.18.1
2026-01-30 08:57:39,270:INFO:  explainerdashboard: 0.5.1
2026-01-30 08:57:39,270:INFO:             autoviz: Not installed
2026-01-30 08:57:39,270:INFO:           fairlearn: 0.7.0
2026-01-30 08:57:39,270:INFO:          deepchecks: Not installed
2026-01-30 08:57:39,270:INFO:             xgboost: Not installed
2026-01-30 08:57:39,271:INFO:            catboost: 1.2.8
2026-01-30 08:57:39,271:INFO:              kmodes: 0.12.2
2026-01-30 08:57:39,271:INFO:             mlxtend: 0.23.4
2026-01-30 08:57:39,271:INFO:       statsforecast: 1.5.0
2026-01-30 08:57:39,271:INFO:        tune_sklearn: Not installed
2026-01-30 08:57:39,271:INFO:                 ray: Not installed
2026-01-30 08:57:39,271:INFO:            hyperopt: 0.2.7
2026-01-30 08:57:39,271:INFO:              optuna: 4.6.0
2026-01-30 08:57:39,271:INFO:               skopt: 0.10.2
2026-01-30 08:57:39,271:INFO:              mlflow: 3.8.1
2026-01-30 08:57:39,271:INFO:              gradio: 6.3.0
2026-01-30 08:57:39,271:INFO:             fastapi: 0.128.0
2026-01-30 08:57:39,271:INFO:             uvicorn: 0.40.0
2026-01-30 08:57:39,271:INFO:              m2cgen: 0.10.0
2026-01-30 08:57:39,271:INFO:           evidently: 0.4.40
2026-01-30 08:57:39,271:INFO:               fugue: 0.8.7
2026-01-30 08:57:39,271:INFO:           streamlit: Not installed
2026-01-30 08:57:39,271:INFO:             prophet: Not installed
2026-01-30 08:57:39,272:INFO:None
2026-01-30 08:57:39,272:INFO:Set up data.
2026-01-30 08:57:39,402:INFO:Set up folding strategy.
2026-01-30 08:57:39,402:INFO:Set up train/test split.
2026-01-30 08:57:39,626:INFO:Set up index.
2026-01-30 08:57:39,646:INFO:Assigning column types.
2026-01-30 08:57:39,787:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-30 08:57:39,824:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 08:57:39,827:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 08:57:40,010:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 08:57:40,010:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 08:57:40,239:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 08:57:40,240:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 08:57:40,272:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 08:57:40,274:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 08:57:40,274:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-30 08:57:40,314:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 08:57:40,324:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 08:57:40,324:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 08:57:40,374:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 08:57:40,404:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 08:57:40,404:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 08:57:40,405:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-30 08:57:40,475:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 08:57:40,475:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 08:57:40,540:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 08:57:40,540:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 08:57:40,540:INFO:Preparing preprocessing pipeline...
2026-01-30 08:57:40,577:INFO:Set up simple imputation.
2026-01-30 08:57:40,577:INFO:Set up feature normalization.
2026-01-30 08:57:41,019:INFO:Finished creating preprocessing pipeline.
2026-01-30 08:57:41,024:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'MINIMUMPAYMENTPAYED',
                                             'PAID_PERCENT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'YEARPERSONBIRTHDATE',
                                             'PL_SI...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-30 08:57:41,024:INFO:Creating final display dataframe.
2026-01-30 08:57:42,491:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape      (429278, 20)
4        Transformed data shape      (429278, 20)
5   Transformed train set shape      (300494, 20)
6    Transformed test set shape      (128784, 20)
7              Numeric features                15
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                 3
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              0660
2026-01-30 08:57:42,560:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 08:57:42,561:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 08:57:42,624:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 08:57:42,624:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 08:57:42,624:INFO:setup() successfully completed in 11.47s...............
2026-01-30 08:57:42,624:INFO:Initializing compare_models()
2026-01-30 08:57:42,624:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-30 08:57:42,624:INFO:Checking exceptions
2026-01-30 08:57:42,741:INFO:Preparing display monitor
2026-01-30 08:57:42,761:INFO:Initializing Logistic Regression
2026-01-30 08:57:42,762:INFO:Total runtime is 1.6895929972330728e-05 minutes
2026-01-30 08:57:42,762:INFO:SubProcess create_model() called ==================================
2026-01-30 08:57:42,762:INFO:Initializing create_model()
2026-01-30 08:57:42,762:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C28A7710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 08:57:42,763:INFO:Checking exceptions
2026-01-30 08:57:42,763:INFO:Importing libraries
2026-01-30 08:57:42,763:INFO:Copying training dataset
2026-01-30 08:57:42,958:INFO:Defining folds
2026-01-30 08:57:42,958:INFO:Declaring metric variables
2026-01-30 08:57:42,958:INFO:Importing untrained model
2026-01-30 08:57:42,959:INFO:Logistic Regression Imported successfully
2026-01-30 08:57:42,959:INFO:Starting cross validation
2026-01-30 08:57:42,960:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 08:57:50,916:INFO:Calculating mean and std
2026-01-30 08:57:50,916:INFO:Creating metrics dataframe
2026-01-30 08:57:50,924:INFO:Uploading results into container
2026-01-30 08:57:50,924:INFO:Uploading model into container now
2026-01-30 08:57:50,925:INFO:_master_model_container: 1
2026-01-30 08:57:50,925:INFO:_display_container: 2
2026-01-30 08:57:50,925:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-30 08:57:50,925:INFO:create_model() successfully completed......................................
2026-01-30 08:57:51,042:INFO:SubProcess create_model() end ==================================
2026-01-30 08:57:51,042:INFO:Creating metrics dataframe
2026-01-30 08:57:51,042:INFO:Initializing Decision Tree Classifier
2026-01-30 08:57:51,042:INFO:Total runtime is 0.1380051891009013 minutes
2026-01-30 08:57:51,042:INFO:SubProcess create_model() called ==================================
2026-01-30 08:57:51,042:INFO:Initializing create_model()
2026-01-30 08:57:51,042:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C28A7710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 08:57:51,042:INFO:Checking exceptions
2026-01-30 08:57:51,042:INFO:Importing libraries
2026-01-30 08:57:51,042:INFO:Copying training dataset
2026-01-30 08:57:51,173:INFO:Defining folds
2026-01-30 08:57:51,173:INFO:Declaring metric variables
2026-01-30 08:57:51,173:INFO:Importing untrained model
2026-01-30 08:57:51,173:INFO:Decision Tree Classifier Imported successfully
2026-01-30 08:57:51,173:INFO:Starting cross validation
2026-01-30 08:57:51,173:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 08:57:57,063:INFO:Calculating mean and std
2026-01-30 08:57:57,063:INFO:Creating metrics dataframe
2026-01-30 08:57:57,063:INFO:Uploading results into container
2026-01-30 08:57:57,067:INFO:Uploading model into container now
2026-01-30 08:57:57,067:INFO:_master_model_container: 2
2026-01-30 08:57:57,067:INFO:_display_container: 2
2026-01-30 08:57:57,067:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 08:57:57,067:INFO:create_model() successfully completed......................................
2026-01-30 08:57:57,173:INFO:SubProcess create_model() end ==================================
2026-01-30 08:57:57,173:INFO:Creating metrics dataframe
2026-01-30 08:57:57,188:INFO:Initializing Random Forest Classifier
2026-01-30 08:57:57,188:INFO:Total runtime is 0.2404475728670756 minutes
2026-01-30 08:57:57,188:INFO:SubProcess create_model() called ==================================
2026-01-30 08:57:57,189:INFO:Initializing create_model()
2026-01-30 08:57:57,189:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C28A7710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 08:57:57,189:INFO:Checking exceptions
2026-01-30 08:57:57,189:INFO:Importing libraries
2026-01-30 08:57:57,189:INFO:Copying training dataset
2026-01-30 08:57:57,319:INFO:Defining folds
2026-01-30 08:57:57,319:INFO:Declaring metric variables
2026-01-30 08:57:57,319:INFO:Importing untrained model
2026-01-30 08:57:57,319:INFO:Random Forest Classifier Imported successfully
2026-01-30 08:57:57,321:INFO:Starting cross validation
2026-01-30 08:57:57,321:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 08:58:09,085:INFO:Calculating mean and std
2026-01-30 08:58:09,089:INFO:Creating metrics dataframe
2026-01-30 08:58:09,091:INFO:Uploading results into container
2026-01-30 08:58:09,092:INFO:Uploading model into container now
2026-01-30 08:58:09,092:INFO:_master_model_container: 3
2026-01-30 08:58:09,092:INFO:_display_container: 2
2026-01-30 08:58:09,093:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 08:58:09,093:INFO:create_model() successfully completed......................................
2026-01-30 08:58:09,209:INFO:SubProcess create_model() end ==================================
2026-01-30 08:58:09,209:INFO:Creating metrics dataframe
2026-01-30 08:58:09,223:INFO:Initializing Light Gradient Boosting Machine
2026-01-30 08:58:09,223:INFO:Total runtime is 0.44102354447046915 minutes
2026-01-30 08:58:09,223:INFO:SubProcess create_model() called ==================================
2026-01-30 08:58:09,223:INFO:Initializing create_model()
2026-01-30 08:58:09,223:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C28A7710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 08:58:09,223:INFO:Checking exceptions
2026-01-30 08:58:09,223:INFO:Importing libraries
2026-01-30 08:58:09,223:INFO:Copying training dataset
2026-01-30 08:58:09,367:INFO:Defining folds
2026-01-30 08:58:09,367:INFO:Declaring metric variables
2026-01-30 08:58:09,367:INFO:Importing untrained model
2026-01-30 08:58:09,367:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 08:58:09,367:INFO:Starting cross validation
2026-01-30 08:58:09,367:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 08:58:17,273:INFO:Calculating mean and std
2026-01-30 08:58:17,273:INFO:Creating metrics dataframe
2026-01-30 08:58:17,273:INFO:Uploading results into container
2026-01-30 08:58:17,273:INFO:Uploading model into container now
2026-01-30 08:58:17,273:INFO:_master_model_container: 4
2026-01-30 08:58:17,273:INFO:_display_container: 2
2026-01-30 08:58:17,273:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 08:58:17,273:INFO:create_model() successfully completed......................................
2026-01-30 08:58:17,402:INFO:SubProcess create_model() end ==================================
2026-01-30 08:58:17,403:INFO:Creating metrics dataframe
2026-01-30 08:58:17,406:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-30 08:58:17,406:INFO:Initializing create_model()
2026-01-30 08:58:17,406:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 08:58:17,406:INFO:Checking exceptions
2026-01-30 08:58:17,406:INFO:Importing libraries
2026-01-30 08:58:17,406:INFO:Copying training dataset
2026-01-30 08:58:17,740:INFO:Defining folds
2026-01-30 08:58:17,740:INFO:Declaring metric variables
2026-01-30 08:58:17,740:INFO:Importing untrained model
2026-01-30 08:58:17,740:INFO:Declaring custom model
2026-01-30 08:58:17,740:INFO:Random Forest Classifier Imported successfully
2026-01-30 08:58:17,740:INFO:Cross validation set to False
2026-01-30 08:58:17,740:INFO:Fitting Model
2026-01-30 08:58:22,099:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 08:58:22,099:INFO:create_model() successfully completed......................................
2026-01-30 08:58:22,232:INFO:Initializing create_model()
2026-01-30 08:58:22,233:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 08:58:22,233:INFO:Checking exceptions
2026-01-30 08:58:22,234:INFO:Importing libraries
2026-01-30 08:58:22,234:INFO:Copying training dataset
2026-01-30 08:58:22,473:INFO:Defining folds
2026-01-30 08:58:22,473:INFO:Declaring metric variables
2026-01-30 08:58:22,473:INFO:Importing untrained model
2026-01-30 08:58:22,473:INFO:Declaring custom model
2026-01-30 08:58:22,473:INFO:Decision Tree Classifier Imported successfully
2026-01-30 08:58:22,473:INFO:Cross validation set to False
2026-01-30 08:58:22,473:INFO:Fitting Model
2026-01-30 08:58:23,772:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 08:58:23,772:INFO:create_model() successfully completed......................................
2026-01-30 08:58:23,906:INFO:Initializing create_model()
2026-01-30 08:58:23,906:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 08:58:23,906:INFO:Checking exceptions
2026-01-30 08:58:23,906:INFO:Importing libraries
2026-01-30 08:58:23,906:INFO:Copying training dataset
2026-01-30 08:58:24,072:INFO:Defining folds
2026-01-30 08:58:24,072:INFO:Declaring metric variables
2026-01-30 08:58:24,072:INFO:Importing untrained model
2026-01-30 08:58:24,072:INFO:Declaring custom model
2026-01-30 08:58:24,072:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 08:58:24,072:INFO:Cross validation set to False
2026-01-30 08:58:24,072:INFO:Fitting Model
2026-01-30 08:58:24,608:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 08:58:24,649:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009199 seconds.
2026-01-30 08:58:24,649:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 08:58:24,649:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 08:58:24,649:INFO:[LightGBM] [Info] Total Bins 1967
2026-01-30 08:58:24,649:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 19
2026-01-30 08:58:24,652:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 08:58:24,652:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 08:58:25,160:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 08:58:25,160:INFO:create_model() successfully completed......................................
2026-01-30 08:58:25,322:INFO:_master_model_container: 4
2026-01-30 08:58:25,322:INFO:_display_container: 2
2026-01-30 08:58:25,322:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)]
2026-01-30 08:58:25,322:INFO:compare_models() successfully completed......................................
2026-01-30 08:58:25,322:INFO:Initializing tune_model()
2026-01-30 08:58:25,322:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 08:58:25,322:INFO:Checking exceptions
2026-01-30 08:58:25,390:INFO:Copying training dataset
2026-01-30 08:58:25,514:INFO:Checking base model
2026-01-30 08:58:25,514:INFO:Base model : Random Forest Classifier
2026-01-30 08:58:25,515:INFO:Declaring metric variables
2026-01-30 08:58:25,516:INFO:Defining Hyperparameters
2026-01-30 08:58:25,643:INFO:Tuning with n_jobs=-1
2026-01-30 08:58:25,643:INFO:Initializing RandomizedSearchCV
2026-01-30 08:59:43,741:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-30 08:59:43,741:INFO:Hyperparameter search completed
2026-01-30 08:59:43,741:INFO:SubProcess create_model() called ==================================
2026-01-30 08:59:43,741:INFO:Initializing create_model()
2026-01-30 08:59:43,741:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A06D69FCD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': True})
2026-01-30 08:59:43,741:INFO:Checking exceptions
2026-01-30 08:59:43,741:INFO:Importing libraries
2026-01-30 08:59:43,741:INFO:Copying training dataset
2026-01-30 08:59:43,999:INFO:Defining folds
2026-01-30 08:59:43,999:INFO:Declaring metric variables
2026-01-30 08:59:43,999:INFO:Importing untrained model
2026-01-30 08:59:43,999:INFO:Declaring custom model
2026-01-30 08:59:44,004:INFO:Random Forest Classifier Imported successfully
2026-01-30 08:59:44,004:INFO:Starting cross validation
2026-01-30 08:59:44,006:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:00:04,177:INFO:Calculating mean and std
2026-01-30 09:00:04,177:INFO:Creating metrics dataframe
2026-01-30 09:00:04,190:INFO:Finalizing model
2026-01-30 09:00:16,415:INFO:Uploading results into container
2026-01-30 09:00:16,423:INFO:Uploading model into container now
2026-01-30 09:00:16,430:INFO:_master_model_container: 5
2026-01-30 09:00:16,431:INFO:_display_container: 3
2026-01-30 09:00:16,441:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:00:16,447:INFO:create_model() successfully completed......................................
2026-01-30 09:00:16,716:INFO:SubProcess create_model() end ==================================
2026-01-30 09:00:16,717:INFO:choose_better activated
2026-01-30 09:00:16,718:INFO:SubProcess create_model() called ==================================
2026-01-30 09:00:16,719:INFO:Initializing create_model()
2026-01-30 09:00:16,719:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:00:16,719:INFO:Checking exceptions
2026-01-30 09:00:16,721:INFO:Importing libraries
2026-01-30 09:00:16,721:INFO:Copying training dataset
2026-01-30 09:00:17,238:INFO:Defining folds
2026-01-30 09:00:17,238:INFO:Declaring metric variables
2026-01-30 09:00:17,239:INFO:Importing untrained model
2026-01-30 09:00:17,239:INFO:Declaring custom model
2026-01-30 09:00:17,240:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:00:17,241:INFO:Starting cross validation
2026-01-30 09:00:17,242:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:00:34,584:INFO:Calculating mean and std
2026-01-30 09:00:34,586:INFO:Creating metrics dataframe
2026-01-30 09:00:34,590:INFO:Finalizing model
2026-01-30 09:00:44,903:INFO:Uploading results into container
2026-01-30 09:00:44,905:INFO:Uploading model into container now
2026-01-30 09:00:44,905:INFO:_master_model_container: 6
2026-01-30 09:00:44,906:INFO:_display_container: 4
2026-01-30 09:00:44,907:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:00:44,907:INFO:create_model() successfully completed......................................
2026-01-30 09:00:45,137:INFO:SubProcess create_model() end ==================================
2026-01-30 09:00:45,138:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9993
2026-01-30 09:00:45,139:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9934
2026-01-30 09:00:45,140:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-30 09:00:45,140:INFO:choose_better completed
2026-01-30 09:00:45,140:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 09:00:45,145:INFO:_master_model_container: 6
2026-01-30 09:00:45,145:INFO:_display_container: 3
2026-01-30 09:00:45,145:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:00:45,146:INFO:tune_model() successfully completed......................................
2026-01-30 09:00:45,376:INFO:Initializing tune_model()
2026-01-30 09:00:45,376:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:00:45,377:INFO:Checking exceptions
2026-01-30 09:00:45,557:INFO:Copying training dataset
2026-01-30 09:00:45,883:INFO:Checking base model
2026-01-30 09:00:45,884:INFO:Base model : Decision Tree Classifier
2026-01-30 09:00:45,885:INFO:Declaring metric variables
2026-01-30 09:00:45,885:INFO:Defining Hyperparameters
2026-01-30 09:00:46,106:INFO:Tuning with n_jobs=-1
2026-01-30 09:00:46,106:INFO:Initializing RandomizedSearchCV
2026-01-30 09:00:57,353:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 15, 'actual_estimator__criterion': 'gini'}
2026-01-30 09:00:57,354:INFO:Hyperparameter search completed
2026-01-30 09:00:57,355:INFO:SubProcess create_model() called ==================================
2026-01-30 09:00:57,358:INFO:Initializing create_model()
2026-01-30 09:00:57,358:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A06E84A250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 2, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 15, 'criterion': 'gini'})
2026-01-30 09:00:57,358:INFO:Checking exceptions
2026-01-30 09:00:57,359:INFO:Importing libraries
2026-01-30 09:00:57,359:INFO:Copying training dataset
2026-01-30 09:00:57,809:INFO:Defining folds
2026-01-30 09:00:57,810:INFO:Declaring metric variables
2026-01-30 09:00:57,810:INFO:Importing untrained model
2026-01-30 09:00:57,810:INFO:Declaring custom model
2026-01-30 09:00:57,811:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:00:57,811:INFO:Starting cross validation
2026-01-30 09:00:57,812:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:01:00,281:INFO:Calculating mean and std
2026-01-30 09:01:00,285:INFO:Creating metrics dataframe
2026-01-30 09:01:00,289:INFO:Finalizing model
2026-01-30 09:01:01,773:INFO:Uploading results into container
2026-01-30 09:01:01,774:INFO:Uploading model into container now
2026-01-30 09:01:01,775:INFO:_master_model_container: 7
2026-01-30 09:01:01,775:INFO:_display_container: 4
2026-01-30 09:01:01,776:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:01:01,776:INFO:create_model() successfully completed......................................
2026-01-30 09:01:01,993:INFO:SubProcess create_model() end ==================================
2026-01-30 09:01:01,993:INFO:choose_better activated
2026-01-30 09:01:01,995:INFO:SubProcess create_model() called ==================================
2026-01-30 09:01:01,995:INFO:Initializing create_model()
2026-01-30 09:01:01,995:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:01:01,997:INFO:Checking exceptions
2026-01-30 09:01:01,997:INFO:Importing libraries
2026-01-30 09:01:01,998:INFO:Copying training dataset
2026-01-30 09:01:02,388:INFO:Defining folds
2026-01-30 09:01:02,388:INFO:Declaring metric variables
2026-01-30 09:01:02,388:INFO:Importing untrained model
2026-01-30 09:01:02,389:INFO:Declaring custom model
2026-01-30 09:01:02,389:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:01:02,390:INFO:Starting cross validation
2026-01-30 09:01:02,391:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:01:04,980:INFO:Calculating mean and std
2026-01-30 09:01:04,981:INFO:Creating metrics dataframe
2026-01-30 09:01:04,983:INFO:Finalizing model
2026-01-30 09:01:07,011:INFO:Uploading results into container
2026-01-30 09:01:07,011:INFO:Uploading model into container now
2026-01-30 09:01:07,013:INFO:_master_model_container: 8
2026-01-30 09:01:07,013:INFO:_display_container: 5
2026-01-30 09:01:07,013:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:01:07,013:INFO:create_model() successfully completed......................................
2026-01-30 09:01:07,193:INFO:SubProcess create_model() end ==================================
2026-01-30 09:01:07,194:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9988
2026-01-30 09:01:07,194:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9876
2026-01-30 09:01:07,194:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-30 09:01:07,194:INFO:choose_better completed
2026-01-30 09:01:07,195:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 09:01:07,198:INFO:_master_model_container: 8
2026-01-30 09:01:07,198:INFO:_display_container: 4
2026-01-30 09:01:07,199:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:01:07,199:INFO:tune_model() successfully completed......................................
2026-01-30 09:01:07,369:INFO:Initializing tune_model()
2026-01-30 09:01:07,369:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:01:07,369:INFO:Checking exceptions
2026-01-30 09:01:07,510:INFO:Copying training dataset
2026-01-30 09:01:07,765:INFO:Checking base model
2026-01-30 09:01:07,766:INFO:Base model : Light Gradient Boosting Machine
2026-01-30 09:01:07,767:INFO:Declaring metric variables
2026-01-30 09:01:07,767:INFO:Defining Hyperparameters
2026-01-30 09:01:07,955:INFO:Tuning with n_jobs=-1
2026-01-30 09:01:07,956:INFO:Initializing RandomizedSearchCV
2026-01-30 09:02:50,262:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2026-01-30 09:02:50,264:INFO:Hyperparameter search completed
2026-01-30 09:02:50,264:INFO:SubProcess create_model() called ==================================
2026-01-30 09:02:50,267:INFO:Initializing create_model()
2026-01-30 09:02:50,267:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A06E54AC90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2026-01-30 09:02:50,267:INFO:Checking exceptions
2026-01-30 09:02:50,267:INFO:Importing libraries
2026-01-30 09:02:50,267:INFO:Copying training dataset
2026-01-30 09:02:50,798:INFO:Defining folds
2026-01-30 09:02:50,798:INFO:Declaring metric variables
2026-01-30 09:02:50,799:INFO:Importing untrained model
2026-01-30 09:02:50,799:INFO:Declaring custom model
2026-01-30 09:02:50,800:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:02:50,802:INFO:Starting cross validation
2026-01-30 09:02:50,804:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:03:17,057:INFO:Calculating mean and std
2026-01-30 09:03:17,059:INFO:Creating metrics dataframe
2026-01-30 09:03:17,062:INFO:Finalizing model
2026-01-30 09:03:17,824:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 09:03:17,824:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 09:03:17,824:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 09:03:18,485:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 09:03:18,486:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 09:03:18,487:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 09:03:18,493:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 09:03:18,661:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036028 seconds.
2026-01-30 09:03:18,661:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:03:18,661:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:03:18,662:INFO:[LightGBM] [Info] Total Bins 1967
2026-01-30 09:03:18,664:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 19
2026-01-30 09:03:18,676:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 09:03:18,676:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 09:03:25,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-01-30 09:03:25,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-01-30 09:03:25,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-01-30 09:03:26,769:INFO:Uploading results into container
2026-01-30 09:03:26,770:INFO:Uploading model into container now
2026-01-30 09:03:26,772:INFO:_master_model_container: 9
2026-01-30 09:03:26,773:INFO:_display_container: 5
2026-01-30 09:03:26,775:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:03:26,776:INFO:create_model() successfully completed......................................
2026-01-30 09:03:27,057:INFO:SubProcess create_model() end ==================================
2026-01-30 09:03:27,059:INFO:choose_better activated
2026-01-30 09:03:27,059:INFO:SubProcess create_model() called ==================================
2026-01-30 09:03:27,060:INFO:Initializing create_model()
2026-01-30 09:03:27,060:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:03:27,060:INFO:Checking exceptions
2026-01-30 09:03:27,062:INFO:Importing libraries
2026-01-30 09:03:27,062:INFO:Copying training dataset
2026-01-30 09:03:27,520:INFO:Defining folds
2026-01-30 09:03:27,520:INFO:Declaring metric variables
2026-01-30 09:03:27,520:INFO:Importing untrained model
2026-01-30 09:03:27,521:INFO:Declaring custom model
2026-01-30 09:03:27,523:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:03:27,523:INFO:Starting cross validation
2026-01-30 09:03:27,524:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:03:38,369:INFO:Calculating mean and std
2026-01-30 09:03:38,370:INFO:Creating metrics dataframe
2026-01-30 09:03:38,374:INFO:Finalizing model
2026-01-30 09:03:39,810:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 09:03:39,905:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023140 seconds.
2026-01-30 09:03:39,906:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:03:39,906:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:03:39,906:INFO:[LightGBM] [Info] Total Bins 1967
2026-01-30 09:03:39,908:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 19
2026-01-30 09:03:39,912:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 09:03:39,912:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 09:03:42,586:INFO:Uploading results into container
2026-01-30 09:03:42,587:INFO:Uploading model into container now
2026-01-30 09:03:42,588:INFO:_master_model_container: 10
2026-01-30 09:03:42,588:INFO:_display_container: 6
2026-01-30 09:03:42,590:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:03:42,590:INFO:create_model() successfully completed......................................
2026-01-30 09:03:42,843:INFO:SubProcess create_model() end ==================================
2026-01-30 09:03:42,846:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9966
2026-01-30 09:03:42,848:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9992
2026-01-30 09:03:42,849:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2026-01-30 09:03:42,849:INFO:choose_better completed
2026-01-30 09:03:42,856:INFO:_master_model_container: 10
2026-01-30 09:03:42,856:INFO:_display_container: 5
2026-01-30 09:03:42,858:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:03:42,858:INFO:tune_model() successfully completed......................................
2026-01-30 09:03:43,109:INFO:Initializing predict_model()
2026-01-30 09:03:43,110:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A01562A5C0>)
2026-01-30 09:03:43,110:INFO:Checking exceptions
2026-01-30 09:03:43,110:INFO:Preloading libraries
2026-01-30 09:03:43,110:INFO:Set up data.
2026-01-30 09:03:43,233:INFO:Set up index.
2026-01-30 09:03:46,032:INFO:Initializing predict_model()
2026-01-30 09:03:46,033:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A01562A5C0>)
2026-01-30 09:03:46,033:INFO:Checking exceptions
2026-01-30 09:03:46,033:INFO:Preloading libraries
2026-01-30 09:03:46,034:INFO:Set up data.
2026-01-30 09:03:46,102:INFO:Set up index.
2026-01-30 09:03:47,218:INFO:Initializing predict_model()
2026-01-30 09:03:47,218:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A03C546160>)
2026-01-30 09:03:47,219:INFO:Checking exceptions
2026-01-30 09:03:47,219:INFO:Preloading libraries
2026-01-30 09:03:47,219:INFO:Set up data.
2026-01-30 09:03:47,269:INFO:Set up index.
2026-01-30 09:03:49,802:INFO:Initializing plot_model()
2026-01-30 09:03:49,803:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 09:03:49,803:INFO:Checking exceptions
2026-01-30 09:03:50,212:INFO:Preloading libraries
2026-01-30 09:03:50,346:INFO:Copying training dataset
2026-01-30 09:03:50,346:INFO:Plot type: feature
2026-01-30 09:03:50,346:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 09:03:51,430:INFO:Visual Rendered Successfully
2026-01-30 09:03:51,639:INFO:plot_model() successfully completed......................................
2026-01-30 09:03:51,652:INFO:Initializing plot_model()
2026-01-30 09:03:51,652:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature_all, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 09:03:51,652:INFO:Checking exceptions
2026-01-30 09:03:52,050:INFO:Preloading libraries
2026-01-30 09:03:52,174:INFO:Copying training dataset
2026-01-30 09:03:52,174:INFO:Plot type: feature_all
2026-01-30 09:03:52,636:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 09:03:53,616:INFO:Visual Rendered Successfully
2026-01-30 09:03:53,861:INFO:plot_model() successfully completed......................................
2026-01-30 09:03:53,888:INFO:Initializing save_model()
2026-01-30 09:03:53,889:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), model_name=..\datos\04. Modelos\modelo_final_explicable, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'MINIMUMPAYMENTPAYED',
                                             'PAID_PERCENT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'YEARPERSONBIRTHDATE',
                                             'PL_SI...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-30 09:03:53,889:INFO:Adding model into prep_pipe
2026-01-30 09:03:54,285:INFO:..\datos\04. Modelos\modelo_final_explicable.pkl saved in current working directory
2026-01-30 09:03:54,294:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'MINIMUMPAYMENTPAYED',
                                             'PAID_PERCENT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'YEARPERSONBIRTHDATE',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges_...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=42, verbose=0,
                                        warm_start=False))],
         verbose=False)
2026-01-30 09:03:54,294:INFO:save_model() successfully completed......................................
2026-01-30 09:11:22,347:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\2920816646.py:20: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-30 09:11:24,345:INFO:PyCaret ClassificationExperiment
2026-01-30 09:11:24,345:INFO:Logging name: clf-default-name
2026-01-30 09:11:24,345:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-30 09:11:24,345:INFO:version 3.3.2
2026-01-30 09:11:24,345:INFO:Initializing setup()
2026-01-30 09:11:24,345:INFO:self.USI: 3c14
2026-01-30 09:11:24,345:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'n_jobs_param', 'data', 'X', 'idx', 'y_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'USI', 'target_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'y_train', 'X_test', 'seed', 'gpu_param', 'gpu_n_jobs_param', 'y', 'logging_param', 'pipeline', 'fold_generator', 'exp_id'}
2026-01-30 09:11:24,345:INFO:Checking environment
2026-01-30 09:11:24,345:INFO:python_version: 3.11.11
2026-01-30 09:11:24,345:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-30 09:11:24,345:INFO:machine: AMD64
2026-01-30 09:11:24,345:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-30 09:11:24,345:INFO:Memory: svmem(total=34009374720, available=16202559488, percent=52.4, used=17806815232, free=16202559488)
2026-01-30 09:11:24,345:INFO:Physical Core: 12
2026-01-30 09:11:24,345:INFO:Logical Core: 16
2026-01-30 09:11:24,345:INFO:Checking libraries
2026-01-30 09:11:24,345:INFO:System:
2026-01-30 09:11:24,345:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-30 09:11:24,345:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-30 09:11:24,345:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-30 09:11:24,345:INFO:PyCaret required dependencies:
2026-01-30 09:11:24,345:INFO:                 pip: 25.0
2026-01-30 09:11:24,345:INFO:          setuptools: 75.8.0
2026-01-30 09:11:24,345:INFO:             pycaret: 3.3.2
2026-01-30 09:11:24,345:INFO:             IPython: 9.9.0
2026-01-30 09:11:24,345:INFO:          ipywidgets: 8.1.8
2026-01-30 09:11:24,345:INFO:                tqdm: 4.67.1
2026-01-30 09:11:24,345:INFO:               numpy: 1.26.4
2026-01-30 09:11:24,345:INFO:              pandas: 2.1.4
2026-01-30 09:11:24,345:INFO:              jinja2: 3.1.6
2026-01-30 09:11:24,345:INFO:               scipy: 1.11.4
2026-01-30 09:11:24,345:INFO:              joblib: 1.3.2
2026-01-30 09:11:24,345:INFO:             sklearn: 1.4.2
2026-01-30 09:11:24,345:INFO:                pyod: 2.0.6
2026-01-30 09:11:24,345:INFO:            imblearn: 0.14.1
2026-01-30 09:11:24,345:INFO:   category_encoders: 2.7.0
2026-01-30 09:11:24,345:INFO:            lightgbm: 4.6.0
2026-01-30 09:11:24,345:INFO:               numba: 0.62.1
2026-01-30 09:11:24,345:INFO:            requests: 2.32.3
2026-01-30 09:11:24,345:INFO:          matplotlib: 3.7.5
2026-01-30 09:11:24,345:INFO:          scikitplot: 0.3.7
2026-01-30 09:11:24,345:INFO:         yellowbrick: 1.5
2026-01-30 09:11:24,345:INFO:              plotly: 5.24.1
2026-01-30 09:11:24,345:INFO:    plotly-resampler: Not installed
2026-01-30 09:11:24,345:INFO:             kaleido: 1.2.0
2026-01-30 09:11:24,345:INFO:           schemdraw: 0.15
2026-01-30 09:11:24,345:INFO:         statsmodels: 0.14.6
2026-01-30 09:11:24,345:INFO:              sktime: 0.26.0
2026-01-30 09:11:24,345:INFO:               tbats: 1.1.3
2026-01-30 09:11:24,345:INFO:            pmdarima: 2.0.4
2026-01-30 09:11:24,345:INFO:              psutil: 7.2.1
2026-01-30 09:11:24,345:INFO:          markupsafe: 3.0.3
2026-01-30 09:11:24,345:INFO:             pickle5: Not installed
2026-01-30 09:11:24,345:INFO:         cloudpickle: 3.0.0
2026-01-30 09:11:24,345:INFO:         deprecation: 2.1.0
2026-01-30 09:11:24,345:INFO:              xxhash: 3.6.0
2026-01-30 09:11:24,345:INFO:           wurlitzer: Not installed
2026-01-30 09:11:24,345:INFO:PyCaret optional dependencies:
2026-01-30 09:11:24,345:INFO:                shap: 0.44.1
2026-01-30 09:11:24,345:INFO:           interpret: 0.7.3
2026-01-30 09:11:24,345:INFO:                umap: 0.5.7
2026-01-30 09:11:24,345:INFO:     ydata_profiling: 4.18.1
2026-01-30 09:11:24,345:INFO:  explainerdashboard: 0.5.1
2026-01-30 09:11:24,345:INFO:             autoviz: Not installed
2026-01-30 09:11:24,345:INFO:           fairlearn: 0.7.0
2026-01-30 09:11:24,345:INFO:          deepchecks: Not installed
2026-01-30 09:11:24,345:INFO:             xgboost: Not installed
2026-01-30 09:11:24,345:INFO:            catboost: 1.2.8
2026-01-30 09:11:24,345:INFO:              kmodes: 0.12.2
2026-01-30 09:11:24,345:INFO:             mlxtend: 0.23.4
2026-01-30 09:11:24,345:INFO:       statsforecast: 1.5.0
2026-01-30 09:11:24,345:INFO:        tune_sklearn: Not installed
2026-01-30 09:11:24,345:INFO:                 ray: Not installed
2026-01-30 09:11:24,345:INFO:            hyperopt: 0.2.7
2026-01-30 09:11:24,345:INFO:              optuna: 4.6.0
2026-01-30 09:11:24,345:INFO:               skopt: 0.10.2
2026-01-30 09:11:24,345:INFO:              mlflow: 3.8.1
2026-01-30 09:11:24,345:INFO:              gradio: 6.3.0
2026-01-30 09:11:24,345:INFO:             fastapi: 0.128.0
2026-01-30 09:11:24,345:INFO:             uvicorn: 0.40.0
2026-01-30 09:11:24,345:INFO:              m2cgen: 0.10.0
2026-01-30 09:11:24,345:INFO:           evidently: 0.4.40
2026-01-30 09:11:24,345:INFO:               fugue: 0.8.7
2026-01-30 09:11:24,345:INFO:           streamlit: Not installed
2026-01-30 09:11:24,345:INFO:             prophet: Not installed
2026-01-30 09:11:24,345:INFO:None
2026-01-30 09:11:24,345:INFO:Set up data.
2026-01-30 09:11:24,448:INFO:Set up folding strategy.
2026-01-30 09:11:24,449:INFO:Set up train/test split.
2026-01-30 09:11:24,608:INFO:Set up index.
2026-01-30 09:11:24,618:INFO:Assigning column types.
2026-01-30 09:11:24,717:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-30 09:11:24,743:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 09:11:24,744:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:11:24,761:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:11:24,761:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:11:24,787:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 09:11:24,788:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:11:24,795:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:11:24,795:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:11:24,795:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-30 09:11:24,828:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:11:24,846:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:11:24,847:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:11:24,862:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:11:24,886:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:11:24,886:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:11:24,886:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-30 09:11:24,928:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:11:24,928:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:11:24,965:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:11:24,965:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:11:24,965:INFO:Preparing preprocessing pipeline...
2026-01-30 09:11:24,987:INFO:Set up simple imputation.
2026-01-30 09:11:24,987:INFO:Set up feature normalization.
2026-01-30 09:11:25,195:INFO:Finished creating preprocessing pipeline.
2026-01-30 09:11:25,195:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'MINIMUMPAYMENTPAYED',
                                             'PAID_PERCENT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'YEARPERSONBIRTHDATE',
                                             'PL_SI...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-30 09:11:25,195:INFO:Creating final display dataframe.
2026-01-30 09:11:25,584:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape      (429278, 20)
4        Transformed data shape      (429278, 20)
5   Transformed train set shape      (300494, 20)
6    Transformed test set shape      (128784, 20)
7              Numeric features                15
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                 3
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              3c14
2026-01-30 09:11:25,618:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:11:25,618:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:11:25,668:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:11:25,668:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:11:25,670:INFO:setup() successfully completed in 1.33s...............
2026-01-30 09:11:25,670:INFO:Initializing compare_models()
2026-01-30 09:11:25,670:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-30 09:11:25,670:INFO:Checking exceptions
2026-01-30 09:11:25,762:INFO:Preparing display monitor
2026-01-30 09:11:25,762:INFO:Initializing Logistic Regression
2026-01-30 09:11:25,762:INFO:Total runtime is 0.0 minutes
2026-01-30 09:11:25,762:INFO:SubProcess create_model() called ==================================
2026-01-30 09:11:25,762:INFO:Initializing create_model()
2026-01-30 09:11:25,762:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03DDCEE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:11:25,762:INFO:Checking exceptions
2026-01-30 09:11:25,762:INFO:Importing libraries
2026-01-30 09:11:25,762:INFO:Copying training dataset
2026-01-30 09:11:25,930:INFO:Defining folds
2026-01-30 09:11:25,930:INFO:Declaring metric variables
2026-01-30 09:11:25,930:INFO:Importing untrained model
2026-01-30 09:11:25,930:INFO:Logistic Regression Imported successfully
2026-01-30 09:11:25,930:INFO:Starting cross validation
2026-01-30 09:11:25,930:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:11:33,531:INFO:Calculating mean and std
2026-01-30 09:11:33,531:INFO:Creating metrics dataframe
2026-01-30 09:11:33,531:INFO:Uploading results into container
2026-01-30 09:11:33,531:INFO:Uploading model into container now
2026-01-30 09:11:33,531:INFO:_master_model_container: 1
2026-01-30 09:11:33,531:INFO:_display_container: 2
2026-01-30 09:11:33,531:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-30 09:11:33,531:INFO:create_model() successfully completed......................................
2026-01-30 09:11:33,645:INFO:SubProcess create_model() end ==================================
2026-01-30 09:11:33,645:INFO:Creating metrics dataframe
2026-01-30 09:11:33,645:INFO:Initializing Decision Tree Classifier
2026-01-30 09:11:33,645:INFO:Total runtime is 0.13138734499613444 minutes
2026-01-30 09:11:33,645:INFO:SubProcess create_model() called ==================================
2026-01-30 09:11:33,645:INFO:Initializing create_model()
2026-01-30 09:11:33,645:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03DDCEE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:11:33,645:INFO:Checking exceptions
2026-01-30 09:11:33,645:INFO:Importing libraries
2026-01-30 09:11:33,645:INFO:Copying training dataset
2026-01-30 09:11:33,778:INFO:Defining folds
2026-01-30 09:11:33,778:INFO:Declaring metric variables
2026-01-30 09:11:33,778:INFO:Importing untrained model
2026-01-30 09:11:33,778:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:11:33,778:INFO:Starting cross validation
2026-01-30 09:11:33,778:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:11:38,720:INFO:Calculating mean and std
2026-01-30 09:11:38,720:INFO:Creating metrics dataframe
2026-01-30 09:11:38,720:INFO:Uploading results into container
2026-01-30 09:11:38,720:INFO:Uploading model into container now
2026-01-30 09:11:38,720:INFO:_master_model_container: 2
2026-01-30 09:11:38,727:INFO:_display_container: 2
2026-01-30 09:11:38,727:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:11:38,727:INFO:create_model() successfully completed......................................
2026-01-30 09:11:38,845:INFO:SubProcess create_model() end ==================================
2026-01-30 09:11:38,845:INFO:Creating metrics dataframe
2026-01-30 09:11:38,845:INFO:Initializing Random Forest Classifier
2026-01-30 09:11:38,845:INFO:Total runtime is 0.21805393298467002 minutes
2026-01-30 09:11:38,845:INFO:SubProcess create_model() called ==================================
2026-01-30 09:11:38,845:INFO:Initializing create_model()
2026-01-30 09:11:38,845:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03DDCEE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:11:38,845:INFO:Checking exceptions
2026-01-30 09:11:38,845:INFO:Importing libraries
2026-01-30 09:11:38,845:INFO:Copying training dataset
2026-01-30 09:11:38,978:INFO:Defining folds
2026-01-30 09:11:38,978:INFO:Declaring metric variables
2026-01-30 09:11:38,978:INFO:Importing untrained model
2026-01-30 09:11:38,978:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:11:38,978:INFO:Starting cross validation
2026-01-30 09:11:38,978:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:11:50,912:INFO:Calculating mean and std
2026-01-30 09:11:50,912:INFO:Creating metrics dataframe
2026-01-30 09:11:50,912:INFO:Uploading results into container
2026-01-30 09:11:50,912:INFO:Uploading model into container now
2026-01-30 09:11:50,912:INFO:_master_model_container: 3
2026-01-30 09:11:50,912:INFO:_display_container: 2
2026-01-30 09:11:50,912:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:11:50,912:INFO:create_model() successfully completed......................................
2026-01-30 09:11:51,031:INFO:SubProcess create_model() end ==================================
2026-01-30 09:11:51,031:INFO:Creating metrics dataframe
2026-01-30 09:11:51,031:INFO:Initializing Light Gradient Boosting Machine
2026-01-30 09:11:51,031:INFO:Total runtime is 0.42115186452865605 minutes
2026-01-30 09:11:51,044:INFO:SubProcess create_model() called ==================================
2026-01-30 09:11:51,044:INFO:Initializing create_model()
2026-01-30 09:11:51,044:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03DDCEE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:11:51,044:INFO:Checking exceptions
2026-01-30 09:11:51,044:INFO:Importing libraries
2026-01-30 09:11:51,044:INFO:Copying training dataset
2026-01-30 09:11:51,178:INFO:Defining folds
2026-01-30 09:11:51,178:INFO:Declaring metric variables
2026-01-30 09:11:51,178:INFO:Importing untrained model
2026-01-30 09:11:51,178:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:11:51,178:INFO:Starting cross validation
2026-01-30 09:11:51,178:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:11:57,631:INFO:Calculating mean and std
2026-01-30 09:11:57,631:INFO:Creating metrics dataframe
2026-01-30 09:11:57,631:INFO:Uploading results into container
2026-01-30 09:11:57,631:INFO:Uploading model into container now
2026-01-30 09:11:57,631:INFO:_master_model_container: 4
2026-01-30 09:11:57,631:INFO:_display_container: 2
2026-01-30 09:11:57,631:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:11:57,631:INFO:create_model() successfully completed......................................
2026-01-30 09:11:57,744:INFO:SubProcess create_model() end ==================================
2026-01-30 09:11:57,744:INFO:Creating metrics dataframe
2026-01-30 09:11:57,760:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-30 09:11:57,761:INFO:Initializing create_model()
2026-01-30 09:11:57,761:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:11:57,761:INFO:Checking exceptions
2026-01-30 09:11:57,761:INFO:Importing libraries
2026-01-30 09:11:57,761:INFO:Copying training dataset
2026-01-30 09:11:57,894:INFO:Defining folds
2026-01-30 09:11:57,894:INFO:Declaring metric variables
2026-01-30 09:11:57,894:INFO:Importing untrained model
2026-01-30 09:11:57,894:INFO:Declaring custom model
2026-01-30 09:11:57,894:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:11:57,894:INFO:Cross validation set to False
2026-01-30 09:11:57,894:INFO:Fitting Model
2026-01-30 09:12:02,813:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:12:02,813:INFO:create_model() successfully completed......................................
2026-01-30 09:12:02,962:INFO:Initializing create_model()
2026-01-30 09:12:02,962:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:12:02,962:INFO:Checking exceptions
2026-01-30 09:12:02,962:INFO:Importing libraries
2026-01-30 09:12:02,962:INFO:Copying training dataset
2026-01-30 09:12:03,153:INFO:Defining folds
2026-01-30 09:12:03,153:INFO:Declaring metric variables
2026-01-30 09:12:03,153:INFO:Importing untrained model
2026-01-30 09:12:03,154:INFO:Declaring custom model
2026-01-30 09:12:03,154:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:12:03,155:INFO:Cross validation set to False
2026-01-30 09:12:03,155:INFO:Fitting Model
2026-01-30 09:12:04,494:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:12:04,494:INFO:create_model() successfully completed......................................
2026-01-30 09:12:04,695:INFO:Initializing create_model()
2026-01-30 09:12:04,695:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:12:04,695:INFO:Checking exceptions
2026-01-30 09:12:04,697:INFO:Importing libraries
2026-01-30 09:12:04,697:INFO:Copying training dataset
2026-01-30 09:12:04,881:INFO:Defining folds
2026-01-30 09:12:04,881:INFO:Declaring metric variables
2026-01-30 09:12:04,881:INFO:Importing untrained model
2026-01-30 09:12:04,881:INFO:Declaring custom model
2026-01-30 09:12:04,881:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:12:04,881:INFO:Cross validation set to False
2026-01-30 09:12:04,881:INFO:Fitting Model
2026-01-30 09:12:05,484:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 09:12:05,517:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007788 seconds.
2026-01-30 09:12:05,517:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:12:05,519:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:12:05,519:INFO:[LightGBM] [Info] Total Bins 1967
2026-01-30 09:12:05,519:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 19
2026-01-30 09:12:05,521:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 09:12:05,521:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 09:12:06,065:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:12:06,065:INFO:create_model() successfully completed......................................
2026-01-30 09:12:06,237:INFO:_master_model_container: 4
2026-01-30 09:12:06,237:INFO:_display_container: 2
2026-01-30 09:12:06,237:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)]
2026-01-30 09:12:06,237:INFO:compare_models() successfully completed......................................
2026-01-30 09:12:06,244:INFO:Initializing tune_model()
2026-01-30 09:12:06,244:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:12:06,244:INFO:Checking exceptions
2026-01-30 09:12:06,327:INFO:Copying training dataset
2026-01-30 09:12:06,461:INFO:Checking base model
2026-01-30 09:12:06,461:INFO:Base model : Random Forest Classifier
2026-01-30 09:12:06,461:INFO:Declaring metric variables
2026-01-30 09:12:06,461:INFO:Defining Hyperparameters
2026-01-30 09:12:06,611:INFO:Tuning with n_jobs=-1
2026-01-30 09:12:06,611:INFO:Initializing RandomizedSearchCV
2026-01-30 09:13:29,731:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-30 09:13:29,732:INFO:Hyperparameter search completed
2026-01-30 09:13:29,733:INFO:SubProcess create_model() called ==================================
2026-01-30 09:13:29,736:INFO:Initializing create_model()
2026-01-30 09:13:29,736:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A06E702090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': True})
2026-01-30 09:13:29,736:INFO:Checking exceptions
2026-01-30 09:13:29,736:INFO:Importing libraries
2026-01-30 09:13:29,736:INFO:Copying training dataset
2026-01-30 09:13:29,945:INFO:Defining folds
2026-01-30 09:13:29,945:INFO:Declaring metric variables
2026-01-30 09:13:29,945:INFO:Importing untrained model
2026-01-30 09:13:29,945:INFO:Declaring custom model
2026-01-30 09:13:29,945:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:13:29,945:INFO:Starting cross validation
2026-01-30 09:13:29,945:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:13:46,361:INFO:Calculating mean and std
2026-01-30 09:13:46,362:INFO:Creating metrics dataframe
2026-01-30 09:13:46,364:INFO:Finalizing model
2026-01-30 09:13:54,279:INFO:Uploading results into container
2026-01-30 09:13:54,279:INFO:Uploading model into container now
2026-01-30 09:13:54,279:INFO:_master_model_container: 5
2026-01-30 09:13:54,279:INFO:_display_container: 3
2026-01-30 09:13:54,279:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:13:54,279:INFO:create_model() successfully completed......................................
2026-01-30 09:13:54,410:INFO:SubProcess create_model() end ==================================
2026-01-30 09:13:54,410:INFO:choose_better activated
2026-01-30 09:13:54,410:INFO:SubProcess create_model() called ==================================
2026-01-30 09:13:54,410:INFO:Initializing create_model()
2026-01-30 09:13:54,410:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:13:54,410:INFO:Checking exceptions
2026-01-30 09:13:54,410:INFO:Importing libraries
2026-01-30 09:13:54,410:INFO:Copying training dataset
2026-01-30 09:13:54,565:INFO:Defining folds
2026-01-30 09:13:54,565:INFO:Declaring metric variables
2026-01-30 09:13:54,565:INFO:Importing untrained model
2026-01-30 09:13:54,565:INFO:Declaring custom model
2026-01-30 09:13:54,565:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:13:54,566:INFO:Starting cross validation
2026-01-30 09:13:54,566:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:14:04,937:INFO:Calculating mean and std
2026-01-30 09:14:04,937:INFO:Creating metrics dataframe
2026-01-30 09:14:04,937:INFO:Finalizing model
2026-01-30 09:14:09,803:INFO:Uploading results into container
2026-01-30 09:14:09,804:INFO:Uploading model into container now
2026-01-30 09:14:09,805:INFO:_master_model_container: 6
2026-01-30 09:14:09,805:INFO:_display_container: 4
2026-01-30 09:14:09,806:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:14:09,806:INFO:create_model() successfully completed......................................
2026-01-30 09:14:09,944:INFO:SubProcess create_model() end ==================================
2026-01-30 09:14:09,945:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9993
2026-01-30 09:14:09,945:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9934
2026-01-30 09:14:09,946:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-30 09:14:09,946:INFO:choose_better completed
2026-01-30 09:14:09,946:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 09:14:09,948:INFO:_master_model_container: 6
2026-01-30 09:14:09,948:INFO:_display_container: 3
2026-01-30 09:14:09,949:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:14:09,949:INFO:tune_model() successfully completed......................................
2026-01-30 09:14:10,079:INFO:Initializing tune_model()
2026-01-30 09:14:10,079:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:14:10,079:INFO:Checking exceptions
2026-01-30 09:14:10,126:INFO:Copying training dataset
2026-01-30 09:14:10,254:INFO:Checking base model
2026-01-30 09:14:10,254:INFO:Base model : Decision Tree Classifier
2026-01-30 09:14:10,254:INFO:Declaring metric variables
2026-01-30 09:14:10,254:INFO:Defining Hyperparameters
2026-01-30 09:14:10,376:INFO:Tuning with n_jobs=-1
2026-01-30 09:14:10,376:INFO:Initializing RandomizedSearchCV
2026-01-30 09:14:15,029:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 15, 'actual_estimator__criterion': 'gini'}
2026-01-30 09:14:15,031:INFO:Hyperparameter search completed
2026-01-30 09:14:15,031:INFO:SubProcess create_model() called ==================================
2026-01-30 09:14:15,031:INFO:Initializing create_model()
2026-01-30 09:14:15,031:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A06E4C1350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 2, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 15, 'criterion': 'gini'})
2026-01-30 09:14:15,031:INFO:Checking exceptions
2026-01-30 09:14:15,031:INFO:Importing libraries
2026-01-30 09:14:15,031:INFO:Copying training dataset
2026-01-30 09:14:15,216:INFO:Defining folds
2026-01-30 09:14:15,216:INFO:Declaring metric variables
2026-01-30 09:14:15,217:INFO:Importing untrained model
2026-01-30 09:14:15,217:INFO:Declaring custom model
2026-01-30 09:14:15,218:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:14:15,218:INFO:Starting cross validation
2026-01-30 09:14:15,219:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:14:16,901:INFO:Calculating mean and std
2026-01-30 09:14:16,903:INFO:Creating metrics dataframe
2026-01-30 09:14:16,906:INFO:Finalizing model
2026-01-30 09:14:17,783:INFO:Uploading results into container
2026-01-30 09:14:17,784:INFO:Uploading model into container now
2026-01-30 09:14:17,784:INFO:_master_model_container: 7
2026-01-30 09:14:17,784:INFO:_display_container: 4
2026-01-30 09:14:17,785:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:14:17,785:INFO:create_model() successfully completed......................................
2026-01-30 09:14:17,909:INFO:SubProcess create_model() end ==================================
2026-01-30 09:14:17,915:INFO:choose_better activated
2026-01-30 09:14:17,915:INFO:SubProcess create_model() called ==================================
2026-01-30 09:14:17,915:INFO:Initializing create_model()
2026-01-30 09:14:17,915:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:14:17,915:INFO:Checking exceptions
2026-01-30 09:14:17,915:INFO:Importing libraries
2026-01-30 09:14:17,915:INFO:Copying training dataset
2026-01-30 09:14:18,064:INFO:Defining folds
2026-01-30 09:14:18,064:INFO:Declaring metric variables
2026-01-30 09:14:18,064:INFO:Importing untrained model
2026-01-30 09:14:18,064:INFO:Declaring custom model
2026-01-30 09:14:18,064:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:14:18,064:INFO:Starting cross validation
2026-01-30 09:14:18,075:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:14:20,164:INFO:Calculating mean and std
2026-01-30 09:14:20,165:INFO:Creating metrics dataframe
2026-01-30 09:14:20,166:INFO:Finalizing model
2026-01-30 09:14:21,429:INFO:Uploading results into container
2026-01-30 09:14:21,429:INFO:Uploading model into container now
2026-01-30 09:14:21,429:INFO:_master_model_container: 8
2026-01-30 09:14:21,429:INFO:_display_container: 5
2026-01-30 09:14:21,429:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:14:21,429:INFO:create_model() successfully completed......................................
2026-01-30 09:14:21,557:INFO:SubProcess create_model() end ==================================
2026-01-30 09:14:21,558:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9988
2026-01-30 09:14:21,559:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9876
2026-01-30 09:14:21,559:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-30 09:14:21,559:INFO:choose_better completed
2026-01-30 09:14:21,559:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 09:14:21,563:INFO:_master_model_container: 8
2026-01-30 09:14:21,563:INFO:_display_container: 4
2026-01-30 09:14:21,563:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:14:21,563:INFO:tune_model() successfully completed......................................
2026-01-30 09:14:21,684:INFO:Initializing tune_model()
2026-01-30 09:14:21,684:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:14:21,684:INFO:Checking exceptions
2026-01-30 09:14:21,747:INFO:Copying training dataset
2026-01-30 09:14:21,867:INFO:Checking base model
2026-01-30 09:14:21,868:INFO:Base model : Light Gradient Boosting Machine
2026-01-30 09:14:21,868:INFO:Declaring metric variables
2026-01-30 09:14:21,869:INFO:Defining Hyperparameters
2026-01-30 09:14:21,975:INFO:Tuning with n_jobs=-1
2026-01-30 09:14:21,975:INFO:Initializing RandomizedSearchCV
2026-01-30 09:14:53,219:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2026-01-30 09:14:53,219:INFO:Hyperparameter search completed
2026-01-30 09:14:53,225:INFO:SubProcess create_model() called ==================================
2026-01-30 09:14:53,226:INFO:Initializing create_model()
2026-01-30 09:14:53,226:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C8B3D810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2026-01-30 09:14:53,226:INFO:Checking exceptions
2026-01-30 09:14:53,226:INFO:Importing libraries
2026-01-30 09:14:53,227:INFO:Copying training dataset
2026-01-30 09:14:53,410:INFO:Defining folds
2026-01-30 09:14:53,410:INFO:Declaring metric variables
2026-01-30 09:14:53,410:INFO:Importing untrained model
2026-01-30 09:14:53,410:INFO:Declaring custom model
2026-01-30 09:14:53,410:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:14:53,410:INFO:Starting cross validation
2026-01-30 09:14:53,410:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:15:02,138:INFO:Calculating mean and std
2026-01-30 09:15:02,142:INFO:Creating metrics dataframe
2026-01-30 09:15:02,146:INFO:Finalizing model
2026-01-30 09:15:02,511:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 09:15:02,511:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 09:15:02,511:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 09:15:02,674:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 09:15:02,674:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 09:15:02,674:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 09:15:02,675:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 09:15:02,713:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006680 seconds.
2026-01-30 09:15:02,713:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:15:02,713:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:15:02,714:INFO:[LightGBM] [Info] Total Bins 1967
2026-01-30 09:15:02,715:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 19
2026-01-30 09:15:02,718:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 09:15:02,718:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 09:15:04,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-01-30 09:15:04,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-01-30 09:15:05,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-01-30 09:15:05,318:INFO:Uploading results into container
2026-01-30 09:15:05,319:INFO:Uploading model into container now
2026-01-30 09:15:05,320:INFO:_master_model_container: 9
2026-01-30 09:15:05,321:INFO:_display_container: 5
2026-01-30 09:15:05,322:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:15:05,323:INFO:create_model() successfully completed......................................
2026-01-30 09:15:05,510:INFO:SubProcess create_model() end ==================================
2026-01-30 09:15:05,510:INFO:choose_better activated
2026-01-30 09:15:05,510:INFO:SubProcess create_model() called ==================================
2026-01-30 09:15:05,510:INFO:Initializing create_model()
2026-01-30 09:15:05,510:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:15:05,510:INFO:Checking exceptions
2026-01-30 09:15:05,512:INFO:Importing libraries
2026-01-30 09:15:05,512:INFO:Copying training dataset
2026-01-30 09:15:05,698:INFO:Defining folds
2026-01-30 09:15:05,699:INFO:Declaring metric variables
2026-01-30 09:15:05,699:INFO:Importing untrained model
2026-01-30 09:15:05,699:INFO:Declaring custom model
2026-01-30 09:15:05,700:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:15:05,700:INFO:Starting cross validation
2026-01-30 09:15:05,700:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:15:10,180:INFO:Calculating mean and std
2026-01-30 09:15:10,180:INFO:Creating metrics dataframe
2026-01-30 09:15:10,182:INFO:Finalizing model
2026-01-30 09:15:10,714:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 09:15:10,746:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006799 seconds.
2026-01-30 09:15:10,746:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:15:10,746:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:15:10,746:INFO:[LightGBM] [Info] Total Bins 1967
2026-01-30 09:15:10,747:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 19
2026-01-30 09:15:10,749:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 09:15:10,749:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 09:15:11,521:INFO:Uploading results into container
2026-01-30 09:15:11,521:INFO:Uploading model into container now
2026-01-30 09:15:11,523:INFO:_master_model_container: 10
2026-01-30 09:15:11,523:INFO:_display_container: 6
2026-01-30 09:15:11,524:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:15:11,525:INFO:create_model() successfully completed......................................
2026-01-30 09:15:11,709:INFO:SubProcess create_model() end ==================================
2026-01-30 09:15:11,713:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9966
2026-01-30 09:15:11,713:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9992
2026-01-30 09:15:11,713:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2026-01-30 09:15:11,713:INFO:choose_better completed
2026-01-30 09:15:11,718:INFO:_master_model_container: 10
2026-01-30 09:15:11,718:INFO:_display_container: 5
2026-01-30 09:15:11,718:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:15:11,718:INFO:tune_model() successfully completed......................................
2026-01-30 09:15:11,893:INFO:Initializing predict_model()
2026-01-30 09:15:11,907:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A0D01FAF20>)
2026-01-30 09:15:11,907:INFO:Checking exceptions
2026-01-30 09:15:11,907:INFO:Preloading libraries
2026-01-30 09:15:11,907:INFO:Set up data.
2026-01-30 09:15:11,925:INFO:Set up index.
2026-01-30 09:15:12,810:INFO:Initializing predict_model()
2026-01-30 09:15:12,810:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A06E850F40>)
2026-01-30 09:15:12,810:INFO:Checking exceptions
2026-01-30 09:15:12,810:INFO:Preloading libraries
2026-01-30 09:15:12,811:INFO:Set up data.
2026-01-30 09:15:12,826:INFO:Set up index.
2026-01-30 09:15:13,291:INFO:Initializing predict_model()
2026-01-30 09:15:13,291:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A06E7DB100>)
2026-01-30 09:15:13,291:INFO:Checking exceptions
2026-01-30 09:15:13,291:INFO:Preloading libraries
2026-01-30 09:15:13,291:INFO:Set up data.
2026-01-30 09:15:13,327:INFO:Set up index.
2026-01-30 09:15:14,342:INFO:Initializing plot_model()
2026-01-30 09:15:14,342:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 09:15:14,342:INFO:Checking exceptions
2026-01-30 09:15:14,430:INFO:Preloading libraries
2026-01-30 09:15:14,463:INFO:Copying training dataset
2026-01-30 09:15:14,464:INFO:Plot type: feature
2026-01-30 09:15:14,464:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 09:15:14,709:INFO:Visual Rendered Successfully
2026-01-30 09:15:14,826:INFO:plot_model() successfully completed......................................
2026-01-30 09:15:14,847:INFO:Initializing plot_model()
2026-01-30 09:15:14,847:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature_all, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 09:15:14,847:INFO:Checking exceptions
2026-01-30 09:15:14,925:INFO:Preloading libraries
2026-01-30 09:15:14,964:INFO:Copying training dataset
2026-01-30 09:15:14,964:INFO:Plot type: feature_all
2026-01-30 09:15:15,089:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 09:15:15,392:INFO:Visual Rendered Successfully
2026-01-30 09:15:15,511:INFO:plot_model() successfully completed......................................
2026-01-30 09:15:15,524:INFO:Initializing save_model()
2026-01-30 09:15:15,524:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), model_name=..\datos\04. Modelos\modelo_final_explicable, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'MINIMUMPAYMENTPAYED',
                                             'PAID_PERCENT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'YEARPERSONBIRTHDATE',
                                             'PL_SI...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-30 09:15:15,524:INFO:Adding model into prep_pipe
2026-01-30 09:15:15,641:INFO:..\datos\04. Modelos\modelo_final_explicable.pkl saved in current working directory
2026-01-30 09:15:15,646:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'MINIMUMPAYMENTPAYED',
                                             'PAID_PERCENT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'YEARPERSONBIRTHDATE',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges_...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=42, verbose=0,
                                        warm_start=False))],
         verbose=False)
2026-01-30 09:15:15,646:INFO:save_model() successfully completed......................................
2026-01-30 09:17:59,181:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\729519084.py:23: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-30 09:18:01,251:INFO:PyCaret ClassificationExperiment
2026-01-30 09:18:01,251:INFO:Logging name: clf-default-name
2026-01-30 09:18:01,252:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-30 09:18:01,252:INFO:version 3.3.2
2026-01-30 09:18:01,252:INFO:Initializing setup()
2026-01-30 09:18:01,252:INFO:self.USI: 66cd
2026-01-30 09:18:01,252:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'n_jobs_param', 'data', 'X', 'idx', 'y_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'USI', 'target_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'y_train', 'X_test', 'seed', 'gpu_param', 'gpu_n_jobs_param', 'y', 'logging_param', 'pipeline', 'fold_generator', 'exp_id'}
2026-01-30 09:18:01,252:INFO:Checking environment
2026-01-30 09:18:01,253:INFO:python_version: 3.11.11
2026-01-30 09:18:01,254:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-30 09:18:01,254:INFO:machine: AMD64
2026-01-30 09:18:01,254:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-30 09:18:01,254:INFO:Memory: svmem(total=34009374720, available=12782919680, percent=62.4, used=21226455040, free=12782919680)
2026-01-30 09:18:01,254:INFO:Physical Core: 12
2026-01-30 09:18:01,254:INFO:Logical Core: 16
2026-01-30 09:18:01,254:INFO:Checking libraries
2026-01-30 09:18:01,254:INFO:System:
2026-01-30 09:18:01,254:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-30 09:18:01,254:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-30 09:18:01,254:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-30 09:18:01,254:INFO:PyCaret required dependencies:
2026-01-30 09:18:01,254:INFO:                 pip: 25.0
2026-01-30 09:18:01,254:INFO:          setuptools: 75.8.0
2026-01-30 09:18:01,255:INFO:             pycaret: 3.3.2
2026-01-30 09:18:01,255:INFO:             IPython: 9.9.0
2026-01-30 09:18:01,255:INFO:          ipywidgets: 8.1.8
2026-01-30 09:18:01,255:INFO:                tqdm: 4.67.1
2026-01-30 09:18:01,255:INFO:               numpy: 1.26.4
2026-01-30 09:18:01,255:INFO:              pandas: 2.1.4
2026-01-30 09:18:01,255:INFO:              jinja2: 3.1.6
2026-01-30 09:18:01,255:INFO:               scipy: 1.11.4
2026-01-30 09:18:01,255:INFO:              joblib: 1.3.2
2026-01-30 09:18:01,255:INFO:             sklearn: 1.4.2
2026-01-30 09:18:01,255:INFO:                pyod: 2.0.6
2026-01-30 09:18:01,255:INFO:            imblearn: 0.14.1
2026-01-30 09:18:01,255:INFO:   category_encoders: 2.7.0
2026-01-30 09:18:01,255:INFO:            lightgbm: 4.6.0
2026-01-30 09:18:01,255:INFO:               numba: 0.62.1
2026-01-30 09:18:01,255:INFO:            requests: 2.32.3
2026-01-30 09:18:01,255:INFO:          matplotlib: 3.7.5
2026-01-30 09:18:01,255:INFO:          scikitplot: 0.3.7
2026-01-30 09:18:01,255:INFO:         yellowbrick: 1.5
2026-01-30 09:18:01,255:INFO:              plotly: 5.24.1
2026-01-30 09:18:01,255:INFO:    plotly-resampler: Not installed
2026-01-30 09:18:01,255:INFO:             kaleido: 1.2.0
2026-01-30 09:18:01,255:INFO:           schemdraw: 0.15
2026-01-30 09:18:01,255:INFO:         statsmodels: 0.14.6
2026-01-30 09:18:01,255:INFO:              sktime: 0.26.0
2026-01-30 09:18:01,255:INFO:               tbats: 1.1.3
2026-01-30 09:18:01,255:INFO:            pmdarima: 2.0.4
2026-01-30 09:18:01,255:INFO:              psutil: 7.2.1
2026-01-30 09:18:01,255:INFO:          markupsafe: 3.0.3
2026-01-30 09:18:01,255:INFO:             pickle5: Not installed
2026-01-30 09:18:01,255:INFO:         cloudpickle: 3.0.0
2026-01-30 09:18:01,256:INFO:         deprecation: 2.1.0
2026-01-30 09:18:01,256:INFO:              xxhash: 3.6.0
2026-01-30 09:18:01,256:INFO:           wurlitzer: Not installed
2026-01-30 09:18:01,256:INFO:PyCaret optional dependencies:
2026-01-30 09:18:01,256:INFO:                shap: 0.44.1
2026-01-30 09:18:01,257:INFO:           interpret: 0.7.3
2026-01-30 09:18:01,257:INFO:                umap: 0.5.7
2026-01-30 09:18:01,257:INFO:     ydata_profiling: 4.18.1
2026-01-30 09:18:01,257:INFO:  explainerdashboard: 0.5.1
2026-01-30 09:18:01,257:INFO:             autoviz: Not installed
2026-01-30 09:18:01,257:INFO:           fairlearn: 0.7.0
2026-01-30 09:18:01,257:INFO:          deepchecks: Not installed
2026-01-30 09:18:01,257:INFO:             xgboost: Not installed
2026-01-30 09:18:01,257:INFO:            catboost: 1.2.8
2026-01-30 09:18:01,257:INFO:              kmodes: 0.12.2
2026-01-30 09:18:01,257:INFO:             mlxtend: 0.23.4
2026-01-30 09:18:01,257:INFO:       statsforecast: 1.5.0
2026-01-30 09:18:01,257:INFO:        tune_sklearn: Not installed
2026-01-30 09:18:01,257:INFO:                 ray: Not installed
2026-01-30 09:18:01,257:INFO:            hyperopt: 0.2.7
2026-01-30 09:18:01,257:INFO:              optuna: 4.6.0
2026-01-30 09:18:01,257:INFO:               skopt: 0.10.2
2026-01-30 09:18:01,257:INFO:              mlflow: 3.8.1
2026-01-30 09:18:01,258:INFO:              gradio: 6.3.0
2026-01-30 09:18:01,259:INFO:             fastapi: 0.128.0
2026-01-30 09:18:01,259:INFO:             uvicorn: 0.40.0
2026-01-30 09:18:01,259:INFO:              m2cgen: 0.10.0
2026-01-30 09:18:01,259:INFO:           evidently: 0.4.40
2026-01-30 09:18:01,259:INFO:               fugue: 0.8.7
2026-01-30 09:18:01,259:INFO:           streamlit: Not installed
2026-01-30 09:18:01,259:INFO:             prophet: Not installed
2026-01-30 09:18:01,259:INFO:None
2026-01-30 09:18:01,260:INFO:Set up data.
2026-01-30 09:18:01,371:INFO:Set up folding strategy.
2026-01-30 09:18:01,371:INFO:Set up train/test split.
2026-01-30 09:18:01,551:INFO:Set up index.
2026-01-30 09:18:01,561:INFO:Assigning column types.
2026-01-30 09:18:01,666:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-30 09:18:01,696:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 09:18:01,697:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:18:01,709:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:18:01,709:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:18:01,741:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 09:18:01,742:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:18:01,758:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:18:01,758:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:18:01,758:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-30 09:18:01,773:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:18:01,802:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:18:01,802:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:18:01,831:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:18:01,848:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:18:01,848:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:18:01,849:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-30 09:18:01,893:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:18:01,893:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:18:01,937:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:18:01,937:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:18:01,938:INFO:Preparing preprocessing pipeline...
2026-01-30 09:18:01,957:INFO:Set up simple imputation.
2026-01-30 09:18:01,957:INFO:Set up feature normalization.
2026-01-30 09:18:02,188:INFO:Finished creating preprocessing pipeline.
2026-01-30 09:18:02,190:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'MINIMUMPAYMENTPAYED',
                                             'PAID_PERCENT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'YEARPERSONBIRTHDATE',
                                             'PL_SI...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-30 09:18:02,190:INFO:Creating final display dataframe.
2026-01-30 09:18:02,586:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape      (429278, 20)
4        Transformed data shape      (429278, 20)
5   Transformed train set shape      (300494, 20)
6    Transformed test set shape      (128784, 20)
7              Numeric features                15
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                 3
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              66cd
2026-01-30 09:18:02,630:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:18:02,630:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:18:02,678:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:18:02,678:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:18:02,680:INFO:setup() successfully completed in 1.44s...............
2026-01-30 09:18:02,680:INFO:Initializing compare_models()
2026-01-30 09:18:02,680:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-30 09:18:02,680:INFO:Checking exceptions
2026-01-30 09:18:02,793:INFO:Preparing display monitor
2026-01-30 09:18:02,793:INFO:Initializing Logistic Regression
2026-01-30 09:18:02,793:INFO:Total runtime is 0.0 minutes
2026-01-30 09:18:02,793:INFO:SubProcess create_model() called ==================================
2026-01-30 09:18:02,793:INFO:Initializing create_model()
2026-01-30 09:18:02,793:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C71A0490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:18:02,793:INFO:Checking exceptions
2026-01-30 09:18:02,793:INFO:Importing libraries
2026-01-30 09:18:02,793:INFO:Copying training dataset
2026-01-30 09:18:03,006:INFO:Defining folds
2026-01-30 09:18:03,006:INFO:Declaring metric variables
2026-01-30 09:18:03,006:INFO:Importing untrained model
2026-01-30 09:18:03,006:INFO:Logistic Regression Imported successfully
2026-01-30 09:18:03,006:INFO:Starting cross validation
2026-01-30 09:18:03,006:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:18:05,182:INFO:Calculating mean and std
2026-01-30 09:18:05,183:INFO:Creating metrics dataframe
2026-01-30 09:18:05,185:INFO:Uploading results into container
2026-01-30 09:18:05,185:INFO:Uploading model into container now
2026-01-30 09:18:05,186:INFO:_master_model_container: 1
2026-01-30 09:18:05,186:INFO:_display_container: 2
2026-01-30 09:18:05,187:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-30 09:18:05,187:INFO:create_model() successfully completed......................................
2026-01-30 09:18:05,389:INFO:SubProcess create_model() end ==================================
2026-01-30 09:18:05,389:INFO:Creating metrics dataframe
2026-01-30 09:18:05,389:INFO:Initializing Decision Tree Classifier
2026-01-30 09:18:05,389:INFO:Total runtime is 0.043268076578776044 minutes
2026-01-30 09:18:05,389:INFO:SubProcess create_model() called ==================================
2026-01-30 09:18:05,389:INFO:Initializing create_model()
2026-01-30 09:18:05,389:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C71A0490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:18:05,389:INFO:Checking exceptions
2026-01-30 09:18:05,389:INFO:Importing libraries
2026-01-30 09:18:05,389:INFO:Copying training dataset
2026-01-30 09:18:05,590:INFO:Defining folds
2026-01-30 09:18:05,606:INFO:Declaring metric variables
2026-01-30 09:18:05,606:INFO:Importing untrained model
2026-01-30 09:18:05,606:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:18:05,606:INFO:Starting cross validation
2026-01-30 09:18:05,608:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:18:07,669:INFO:Calculating mean and std
2026-01-30 09:18:07,672:INFO:Creating metrics dataframe
2026-01-30 09:18:07,676:INFO:Uploading results into container
2026-01-30 09:18:07,676:INFO:Uploading model into container now
2026-01-30 09:18:07,676:INFO:_master_model_container: 2
2026-01-30 09:18:07,676:INFO:_display_container: 2
2026-01-30 09:18:07,676:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:18:07,676:INFO:create_model() successfully completed......................................
2026-01-30 09:18:07,810:INFO:SubProcess create_model() end ==================================
2026-01-30 09:18:07,810:INFO:Creating metrics dataframe
2026-01-30 09:18:07,812:INFO:Initializing Random Forest Classifier
2026-01-30 09:18:07,812:INFO:Total runtime is 0.08364590803782146 minutes
2026-01-30 09:18:07,813:INFO:SubProcess create_model() called ==================================
2026-01-30 09:18:07,813:INFO:Initializing create_model()
2026-01-30 09:18:07,813:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C71A0490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:18:07,813:INFO:Checking exceptions
2026-01-30 09:18:07,813:INFO:Importing libraries
2026-01-30 09:18:07,813:INFO:Copying training dataset
2026-01-30 09:18:07,960:INFO:Defining folds
2026-01-30 09:18:07,960:INFO:Declaring metric variables
2026-01-30 09:18:07,960:INFO:Importing untrained model
2026-01-30 09:18:07,960:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:18:07,960:INFO:Starting cross validation
2026-01-30 09:18:07,960:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:18:17,590:INFO:Calculating mean and std
2026-01-30 09:18:17,593:INFO:Creating metrics dataframe
2026-01-30 09:18:17,596:INFO:Uploading results into container
2026-01-30 09:18:17,597:INFO:Uploading model into container now
2026-01-30 09:18:17,597:INFO:_master_model_container: 3
2026-01-30 09:18:17,599:INFO:_display_container: 2
2026-01-30 09:18:17,599:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:18:17,600:INFO:create_model() successfully completed......................................
2026-01-30 09:18:17,755:INFO:SubProcess create_model() end ==================================
2026-01-30 09:18:17,756:INFO:Creating metrics dataframe
2026-01-30 09:18:17,758:INFO:Initializing Light Gradient Boosting Machine
2026-01-30 09:18:17,758:INFO:Total runtime is 0.2494127074877421 minutes
2026-01-30 09:18:17,758:INFO:SubProcess create_model() called ==================================
2026-01-30 09:18:17,759:INFO:Initializing create_model()
2026-01-30 09:18:17,759:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C71A0490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:18:17,759:INFO:Checking exceptions
2026-01-30 09:18:17,759:INFO:Importing libraries
2026-01-30 09:18:17,759:INFO:Copying training dataset
2026-01-30 09:18:17,972:INFO:Defining folds
2026-01-30 09:18:17,972:INFO:Declaring metric variables
2026-01-30 09:18:17,972:INFO:Importing untrained model
2026-01-30 09:18:17,972:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:18:17,972:INFO:Starting cross validation
2026-01-30 09:18:17,972:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:18:20,815:INFO:Calculating mean and std
2026-01-30 09:18:20,815:INFO:Creating metrics dataframe
2026-01-30 09:18:20,815:INFO:Uploading results into container
2026-01-30 09:18:20,815:INFO:Uploading model into container now
2026-01-30 09:18:20,815:INFO:_master_model_container: 4
2026-01-30 09:18:20,815:INFO:_display_container: 2
2026-01-30 09:18:20,821:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:18:20,821:INFO:create_model() successfully completed......................................
2026-01-30 09:18:20,973:INFO:SubProcess create_model() end ==================================
2026-01-30 09:18:20,973:INFO:Creating metrics dataframe
2026-01-30 09:18:20,988:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-30 09:18:20,991:INFO:Initializing create_model()
2026-01-30 09:18:20,991:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:18:20,991:INFO:Checking exceptions
2026-01-30 09:18:20,992:INFO:Importing libraries
2026-01-30 09:18:20,992:INFO:Copying training dataset
2026-01-30 09:18:21,266:INFO:Defining folds
2026-01-30 09:18:21,267:INFO:Declaring metric variables
2026-01-30 09:18:21,267:INFO:Importing untrained model
2026-01-30 09:18:21,267:INFO:Declaring custom model
2026-01-30 09:18:21,268:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:18:21,268:INFO:Cross validation set to False
2026-01-30 09:18:21,268:INFO:Fitting Model
2026-01-30 09:18:25,677:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:18:25,677:INFO:create_model() successfully completed......................................
2026-01-30 09:18:25,809:INFO:Initializing create_model()
2026-01-30 09:18:25,809:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:18:25,809:INFO:Checking exceptions
2026-01-30 09:18:25,809:INFO:Importing libraries
2026-01-30 09:18:25,809:INFO:Copying training dataset
2026-01-30 09:18:25,956:INFO:Defining folds
2026-01-30 09:18:25,956:INFO:Declaring metric variables
2026-01-30 09:18:25,956:INFO:Importing untrained model
2026-01-30 09:18:25,956:INFO:Declaring custom model
2026-01-30 09:18:25,956:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:18:25,956:INFO:Cross validation set to False
2026-01-30 09:18:25,956:INFO:Fitting Model
2026-01-30 09:18:27,181:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:18:27,181:INFO:create_model() successfully completed......................................
2026-01-30 09:18:27,327:INFO:Initializing create_model()
2026-01-30 09:18:27,328:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:18:27,328:INFO:Checking exceptions
2026-01-30 09:18:27,328:INFO:Importing libraries
2026-01-30 09:18:27,328:INFO:Copying training dataset
2026-01-30 09:18:27,503:INFO:Defining folds
2026-01-30 09:18:27,504:INFO:Declaring metric variables
2026-01-30 09:18:27,504:INFO:Importing untrained model
2026-01-30 09:18:27,504:INFO:Declaring custom model
2026-01-30 09:18:27,506:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:18:27,506:INFO:Cross validation set to False
2026-01-30 09:18:27,506:INFO:Fitting Model
2026-01-30 09:18:28,026:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 09:18:28,059:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005837 seconds.
2026-01-30 09:18:28,059:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:18:28,059:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:18:28,059:INFO:[LightGBM] [Info] Total Bins 1967
2026-01-30 09:18:28,060:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 19
2026-01-30 09:18:28,062:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 09:18:28,062:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 09:18:28,556:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:18:28,557:INFO:create_model() successfully completed......................................
2026-01-30 09:18:28,731:INFO:_master_model_container: 4
2026-01-30 09:18:28,732:INFO:_display_container: 2
2026-01-30 09:18:28,733:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)]
2026-01-30 09:18:28,733:INFO:compare_models() successfully completed......................................
2026-01-30 09:18:28,739:INFO:Initializing tune_model()
2026-01-30 09:18:28,739:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:18:28,739:INFO:Checking exceptions
2026-01-30 09:18:28,808:INFO:Copying training dataset
2026-01-30 09:18:28,927:INFO:Checking base model
2026-01-30 09:18:28,927:INFO:Base model : Random Forest Classifier
2026-01-30 09:18:28,928:INFO:Declaring metric variables
2026-01-30 09:18:28,928:INFO:Defining Hyperparameters
2026-01-30 09:18:29,052:INFO:Tuning with n_jobs=-1
2026-01-30 09:18:29,053:INFO:Initializing RandomizedSearchCV
2026-01-30 09:19:42,892:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-30 09:19:42,893:INFO:Hyperparameter search completed
2026-01-30 09:19:42,893:INFO:SubProcess create_model() called ==================================
2026-01-30 09:19:42,893:INFO:Initializing create_model()
2026-01-30 09:19:42,893:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03CD1EED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': True})
2026-01-30 09:19:42,894:INFO:Checking exceptions
2026-01-30 09:19:42,894:INFO:Importing libraries
2026-01-30 09:19:42,894:INFO:Copying training dataset
2026-01-30 09:19:43,121:INFO:Defining folds
2026-01-30 09:19:43,121:INFO:Declaring metric variables
2026-01-30 09:19:43,121:INFO:Importing untrained model
2026-01-30 09:19:43,121:INFO:Declaring custom model
2026-01-30 09:19:43,121:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:19:43,121:INFO:Starting cross validation
2026-01-30 09:19:43,121:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:19:58,929:INFO:Calculating mean and std
2026-01-30 09:19:58,929:INFO:Creating metrics dataframe
2026-01-30 09:19:58,929:INFO:Finalizing model
2026-01-30 09:20:06,979:INFO:Uploading results into container
2026-01-30 09:20:06,986:INFO:Uploading model into container now
2026-01-30 09:20:06,986:INFO:_master_model_container: 5
2026-01-30 09:20:06,987:INFO:_display_container: 3
2026-01-30 09:20:06,987:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:20:06,988:INFO:create_model() successfully completed......................................
2026-01-30 09:20:07,152:INFO:SubProcess create_model() end ==================================
2026-01-30 09:20:07,152:INFO:choose_better activated
2026-01-30 09:20:07,153:INFO:SubProcess create_model() called ==================================
2026-01-30 09:20:07,154:INFO:Initializing create_model()
2026-01-30 09:20:07,154:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:20:07,154:INFO:Checking exceptions
2026-01-30 09:20:07,155:INFO:Importing libraries
2026-01-30 09:20:07,155:INFO:Copying training dataset
2026-01-30 09:20:07,358:INFO:Defining folds
2026-01-30 09:20:07,358:INFO:Declaring metric variables
2026-01-30 09:20:07,358:INFO:Importing untrained model
2026-01-30 09:20:07,358:INFO:Declaring custom model
2026-01-30 09:20:07,359:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:20:07,359:INFO:Starting cross validation
2026-01-30 09:20:07,360:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:20:17,307:INFO:Calculating mean and std
2026-01-30 09:20:17,308:INFO:Creating metrics dataframe
2026-01-30 09:20:17,310:INFO:Finalizing model
2026-01-30 09:20:22,027:INFO:Uploading results into container
2026-01-30 09:20:22,028:INFO:Uploading model into container now
2026-01-30 09:20:22,029:INFO:_master_model_container: 6
2026-01-30 09:20:22,029:INFO:_display_container: 4
2026-01-30 09:20:22,030:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:20:22,030:INFO:create_model() successfully completed......................................
2026-01-30 09:20:22,157:INFO:SubProcess create_model() end ==================================
2026-01-30 09:20:22,158:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9993
2026-01-30 09:20:22,158:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9934
2026-01-30 09:20:22,158:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-30 09:20:22,158:INFO:choose_better completed
2026-01-30 09:20:22,159:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 09:20:22,161:INFO:_master_model_container: 6
2026-01-30 09:20:22,161:INFO:_display_container: 3
2026-01-30 09:20:22,161:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:20:22,161:INFO:tune_model() successfully completed......................................
2026-01-30 09:20:22,282:INFO:Initializing tune_model()
2026-01-30 09:20:22,282:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:20:22,282:INFO:Checking exceptions
2026-01-30 09:20:22,338:INFO:Copying training dataset
2026-01-30 09:20:22,454:INFO:Checking base model
2026-01-30 09:20:22,454:INFO:Base model : Decision Tree Classifier
2026-01-30 09:20:22,454:INFO:Declaring metric variables
2026-01-30 09:20:22,454:INFO:Defining Hyperparameters
2026-01-30 09:20:22,585:INFO:Tuning with n_jobs=-1
2026-01-30 09:20:22,586:INFO:Initializing RandomizedSearchCV
2026-01-30 09:20:26,459:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 15, 'actual_estimator__criterion': 'gini'}
2026-01-30 09:20:26,460:INFO:Hyperparameter search completed
2026-01-30 09:20:26,461:INFO:SubProcess create_model() called ==================================
2026-01-30 09:20:26,461:INFO:Initializing create_model()
2026-01-30 09:20:26,462:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A06E849510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 2, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 15, 'criterion': 'gini'})
2026-01-30 09:20:26,462:INFO:Checking exceptions
2026-01-30 09:20:26,462:INFO:Importing libraries
2026-01-30 09:20:26,462:INFO:Copying training dataset
2026-01-30 09:20:26,742:INFO:Defining folds
2026-01-30 09:20:26,742:INFO:Declaring metric variables
2026-01-30 09:20:26,742:INFO:Importing untrained model
2026-01-30 09:20:26,742:INFO:Declaring custom model
2026-01-30 09:20:26,743:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:20:26,743:INFO:Starting cross validation
2026-01-30 09:20:26,744:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:20:28,331:INFO:Calculating mean and std
2026-01-30 09:20:28,333:INFO:Creating metrics dataframe
2026-01-30 09:20:28,334:INFO:Finalizing model
2026-01-30 09:20:29,310:INFO:Uploading results into container
2026-01-30 09:20:29,311:INFO:Uploading model into container now
2026-01-30 09:20:29,312:INFO:_master_model_container: 7
2026-01-30 09:20:29,312:INFO:_display_container: 4
2026-01-30 09:20:29,313:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:20:29,313:INFO:create_model() successfully completed......................................
2026-01-30 09:20:29,438:INFO:SubProcess create_model() end ==================================
2026-01-30 09:20:29,438:INFO:choose_better activated
2026-01-30 09:20:29,438:INFO:SubProcess create_model() called ==================================
2026-01-30 09:20:29,438:INFO:Initializing create_model()
2026-01-30 09:20:29,438:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:20:29,438:INFO:Checking exceptions
2026-01-30 09:20:29,438:INFO:Importing libraries
2026-01-30 09:20:29,438:INFO:Copying training dataset
2026-01-30 09:20:29,606:INFO:Defining folds
2026-01-30 09:20:29,606:INFO:Declaring metric variables
2026-01-30 09:20:29,606:INFO:Importing untrained model
2026-01-30 09:20:29,606:INFO:Declaring custom model
2026-01-30 09:20:29,606:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:20:29,606:INFO:Starting cross validation
2026-01-30 09:20:29,606:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:20:31,473:INFO:Calculating mean and std
2026-01-30 09:20:31,474:INFO:Creating metrics dataframe
2026-01-30 09:20:31,475:INFO:Finalizing model
2026-01-30 09:20:33,160:INFO:Uploading results into container
2026-01-30 09:20:33,160:INFO:Uploading model into container now
2026-01-30 09:20:33,160:INFO:_master_model_container: 8
2026-01-30 09:20:33,160:INFO:_display_container: 5
2026-01-30 09:20:33,160:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:20:33,160:INFO:create_model() successfully completed......................................
2026-01-30 09:20:33,298:INFO:SubProcess create_model() end ==================================
2026-01-30 09:20:33,299:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9988
2026-01-30 09:20:33,299:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9876
2026-01-30 09:20:33,299:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-30 09:20:33,299:INFO:choose_better completed
2026-01-30 09:20:33,299:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 09:20:33,301:INFO:_master_model_container: 8
2026-01-30 09:20:33,301:INFO:_display_container: 4
2026-01-30 09:20:33,302:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:20:33,302:INFO:tune_model() successfully completed......................................
2026-01-30 09:20:33,434:INFO:Initializing tune_model()
2026-01-30 09:20:33,434:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:20:33,434:INFO:Checking exceptions
2026-01-30 09:20:33,504:INFO:Copying training dataset
2026-01-30 09:20:33,646:INFO:Checking base model
2026-01-30 09:20:33,646:INFO:Base model : Light Gradient Boosting Machine
2026-01-30 09:20:33,648:INFO:Declaring metric variables
2026-01-30 09:20:33,648:INFO:Defining Hyperparameters
2026-01-30 09:20:33,824:INFO:Tuning with n_jobs=-1
2026-01-30 09:20:33,824:INFO:Initializing RandomizedSearchCV
2026-01-30 09:21:00,479:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2026-01-30 09:21:00,480:INFO:Hyperparameter search completed
2026-01-30 09:21:00,481:INFO:SubProcess create_model() called ==================================
2026-01-30 09:21:00,482:INFO:Initializing create_model()
2026-01-30 09:21:00,482:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A06E702410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2026-01-30 09:21:00,482:INFO:Checking exceptions
2026-01-30 09:21:00,482:INFO:Importing libraries
2026-01-30 09:21:00,482:INFO:Copying training dataset
2026-01-30 09:21:00,663:INFO:Defining folds
2026-01-30 09:21:00,663:INFO:Declaring metric variables
2026-01-30 09:21:00,664:INFO:Importing untrained model
2026-01-30 09:21:00,664:INFO:Declaring custom model
2026-01-30 09:21:00,665:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:21:00,665:INFO:Starting cross validation
2026-01-30 09:21:00,666:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:21:08,046:INFO:Calculating mean and std
2026-01-30 09:21:08,046:INFO:Creating metrics dataframe
2026-01-30 09:21:08,051:INFO:Finalizing model
2026-01-30 09:21:08,477:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 09:21:08,477:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 09:21:08,477:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 09:21:08,663:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 09:21:08,663:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 09:21:08,663:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 09:21:08,664:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 09:21:08,706:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010122 seconds.
2026-01-30 09:21:08,706:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:21:08,706:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:21:08,707:INFO:[LightGBM] [Info] Total Bins 1967
2026-01-30 09:21:08,707:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 19
2026-01-30 09:21:08,711:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 09:21:08,711:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 09:21:10,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-01-30 09:21:10,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-01-30 09:21:10,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-01-30 09:21:10,904:INFO:Uploading results into container
2026-01-30 09:21:10,906:INFO:Uploading model into container now
2026-01-30 09:21:10,907:INFO:_master_model_container: 9
2026-01-30 09:21:10,907:INFO:_display_container: 5
2026-01-30 09:21:10,908:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:21:10,908:INFO:create_model() successfully completed......................................
2026-01-30 09:21:11,083:INFO:SubProcess create_model() end ==================================
2026-01-30 09:21:11,083:INFO:choose_better activated
2026-01-30 09:21:11,084:INFO:SubProcess create_model() called ==================================
2026-01-30 09:21:11,085:INFO:Initializing create_model()
2026-01-30 09:21:11,085:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:21:11,085:INFO:Checking exceptions
2026-01-30 09:21:11,087:INFO:Importing libraries
2026-01-30 09:21:11,087:INFO:Copying training dataset
2026-01-30 09:21:11,256:INFO:Defining folds
2026-01-30 09:21:11,256:INFO:Declaring metric variables
2026-01-30 09:21:11,256:INFO:Importing untrained model
2026-01-30 09:21:11,256:INFO:Declaring custom model
2026-01-30 09:21:11,256:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:21:11,256:INFO:Starting cross validation
2026-01-30 09:21:11,256:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:21:14,773:INFO:Calculating mean and std
2026-01-30 09:21:14,773:INFO:Creating metrics dataframe
2026-01-30 09:21:14,773:INFO:Finalizing model
2026-01-30 09:21:15,382:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 09:21:15,426:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008562 seconds.
2026-01-30 09:21:15,426:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:21:15,426:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:21:15,427:INFO:[LightGBM] [Info] Total Bins 1967
2026-01-30 09:21:15,427:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 19
2026-01-30 09:21:15,430:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 09:21:15,430:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 09:21:16,072:INFO:Uploading results into container
2026-01-30 09:21:16,072:INFO:Uploading model into container now
2026-01-30 09:21:16,074:INFO:_master_model_container: 10
2026-01-30 09:21:16,074:INFO:_display_container: 6
2026-01-30 09:21:16,074:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:21:16,074:INFO:create_model() successfully completed......................................
2026-01-30 09:21:16,235:INFO:SubProcess create_model() end ==================================
2026-01-30 09:21:16,236:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9966
2026-01-30 09:21:16,237:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9992
2026-01-30 09:21:16,238:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2026-01-30 09:21:16,238:INFO:choose_better completed
2026-01-30 09:21:16,240:INFO:_master_model_container: 10
2026-01-30 09:21:16,240:INFO:_display_container: 5
2026-01-30 09:21:16,240:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:21:16,240:INFO:tune_model() successfully completed......................................
2026-01-30 09:21:16,381:INFO:Initializing predict_model()
2026-01-30 09:21:16,381:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A0C3C9E700>)
2026-01-30 09:21:16,381:INFO:Checking exceptions
2026-01-30 09:21:16,381:INFO:Preloading libraries
2026-01-30 09:21:16,381:INFO:Set up data.
2026-01-30 09:21:16,412:INFO:Set up index.
2026-01-30 09:21:17,339:INFO:Initializing predict_model()
2026-01-30 09:21:17,339:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A036A98220>)
2026-01-30 09:21:17,339:INFO:Checking exceptions
2026-01-30 09:21:17,339:INFO:Preloading libraries
2026-01-30 09:21:17,339:INFO:Set up data.
2026-01-30 09:21:17,383:INFO:Set up index.
2026-01-30 09:21:17,944:INFO:Initializing predict_model()
2026-01-30 09:21:17,945:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A036A98220>)
2026-01-30 09:21:17,945:INFO:Checking exceptions
2026-01-30 09:21:17,945:INFO:Preloading libraries
2026-01-30 09:21:17,945:INFO:Set up data.
2026-01-30 09:21:17,979:INFO:Set up index.
2026-01-30 09:21:19,008:INFO:Initializing plot_model()
2026-01-30 09:21:19,008:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 09:21:19,008:INFO:Checking exceptions
2026-01-30 09:21:19,103:INFO:Preloading libraries
2026-01-30 09:21:19,156:INFO:Copying training dataset
2026-01-30 09:21:19,156:INFO:Plot type: feature
2026-01-30 09:21:19,157:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 09:21:19,459:INFO:Visual Rendered Successfully
2026-01-30 09:21:19,591:INFO:plot_model() successfully completed......................................
2026-01-30 09:21:19,593:INFO:Initializing plot_model()
2026-01-30 09:21:19,593:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature_all, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 09:21:19,593:INFO:Checking exceptions
2026-01-30 09:21:19,693:INFO:Preloading libraries
2026-01-30 09:21:19,703:INFO:Copying training dataset
2026-01-30 09:21:19,719:INFO:Plot type: feature_all
2026-01-30 09:21:19,859:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 09:21:20,203:INFO:Visual Rendered Successfully
2026-01-30 09:21:20,342:INFO:plot_model() successfully completed......................................
2026-01-30 09:21:20,359:INFO:Initializing save_model()
2026-01-30 09:21:20,359:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), model_name=..\datos\04. Modelos\modelo_final_explicable, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'MINIMUMPAYMENTPAYED',
                                             'PAID_PERCENT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'YEARPERSONBIRTHDATE',
                                             'PL_SI...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-30 09:21:20,359:INFO:Adding model into prep_pipe
2026-01-30 09:21:20,438:INFO:..\datos\04. Modelos\modelo_final_explicable.pkl saved in current working directory
2026-01-30 09:21:20,443:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'MINIMUMPAYMENTPAYED',
                                             'PAID_PERCENT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'YEARPERSONBIRTHDATE',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges_...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=42, verbose=0,
                                        warm_start=False))],
         verbose=False)
2026-01-30 09:21:20,443:INFO:save_model() successfully completed......................................
2026-01-30 09:28:58,546:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\472289403.py:23: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-30 09:29:00,567:INFO:PyCaret ClassificationExperiment
2026-01-30 09:29:00,567:INFO:Logging name: clf-default-name
2026-01-30 09:29:00,567:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-30 09:29:00,567:INFO:version 3.3.2
2026-01-30 09:29:00,567:INFO:Initializing setup()
2026-01-30 09:29:00,567:INFO:self.USI: 8d13
2026-01-30 09:29:00,567:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'n_jobs_param', 'data', 'X', 'idx', 'y_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'USI', 'target_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'y_train', 'X_test', 'seed', 'gpu_param', 'gpu_n_jobs_param', 'y', 'logging_param', 'pipeline', 'fold_generator', 'exp_id'}
2026-01-30 09:29:00,567:INFO:Checking environment
2026-01-30 09:29:00,567:INFO:python_version: 3.11.11
2026-01-30 09:29:00,567:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-30 09:29:00,567:INFO:machine: AMD64
2026-01-30 09:29:00,567:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-30 09:29:00,567:INFO:Memory: svmem(total=34009374720, available=16086147072, percent=52.7, used=17923227648, free=16086147072)
2026-01-30 09:29:00,567:INFO:Physical Core: 12
2026-01-30 09:29:00,567:INFO:Logical Core: 16
2026-01-30 09:29:00,567:INFO:Checking libraries
2026-01-30 09:29:00,567:INFO:System:
2026-01-30 09:29:00,567:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-30 09:29:00,567:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-30 09:29:00,567:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-30 09:29:00,567:INFO:PyCaret required dependencies:
2026-01-30 09:29:00,567:INFO:                 pip: 25.0
2026-01-30 09:29:00,567:INFO:          setuptools: 75.8.0
2026-01-30 09:29:00,567:INFO:             pycaret: 3.3.2
2026-01-30 09:29:00,567:INFO:             IPython: 9.9.0
2026-01-30 09:29:00,567:INFO:          ipywidgets: 8.1.8
2026-01-30 09:29:00,567:INFO:                tqdm: 4.67.1
2026-01-30 09:29:00,567:INFO:               numpy: 1.26.4
2026-01-30 09:29:00,567:INFO:              pandas: 2.1.4
2026-01-30 09:29:00,567:INFO:              jinja2: 3.1.6
2026-01-30 09:29:00,567:INFO:               scipy: 1.11.4
2026-01-30 09:29:00,567:INFO:              joblib: 1.3.2
2026-01-30 09:29:00,567:INFO:             sklearn: 1.4.2
2026-01-30 09:29:00,567:INFO:                pyod: 2.0.6
2026-01-30 09:29:00,567:INFO:            imblearn: 0.14.1
2026-01-30 09:29:00,567:INFO:   category_encoders: 2.7.0
2026-01-30 09:29:00,567:INFO:            lightgbm: 4.6.0
2026-01-30 09:29:00,567:INFO:               numba: 0.62.1
2026-01-30 09:29:00,567:INFO:            requests: 2.32.3
2026-01-30 09:29:00,567:INFO:          matplotlib: 3.7.5
2026-01-30 09:29:00,567:INFO:          scikitplot: 0.3.7
2026-01-30 09:29:00,567:INFO:         yellowbrick: 1.5
2026-01-30 09:29:00,567:INFO:              plotly: 5.24.1
2026-01-30 09:29:00,567:INFO:    plotly-resampler: Not installed
2026-01-30 09:29:00,567:INFO:             kaleido: 1.2.0
2026-01-30 09:29:00,567:INFO:           schemdraw: 0.15
2026-01-30 09:29:00,567:INFO:         statsmodels: 0.14.6
2026-01-30 09:29:00,567:INFO:              sktime: 0.26.0
2026-01-30 09:29:00,567:INFO:               tbats: 1.1.3
2026-01-30 09:29:00,567:INFO:            pmdarima: 2.0.4
2026-01-30 09:29:00,567:INFO:              psutil: 7.2.1
2026-01-30 09:29:00,567:INFO:          markupsafe: 3.0.3
2026-01-30 09:29:00,567:INFO:             pickle5: Not installed
2026-01-30 09:29:00,567:INFO:         cloudpickle: 3.0.0
2026-01-30 09:29:00,567:INFO:         deprecation: 2.1.0
2026-01-30 09:29:00,567:INFO:              xxhash: 3.6.0
2026-01-30 09:29:00,567:INFO:           wurlitzer: Not installed
2026-01-30 09:29:00,567:INFO:PyCaret optional dependencies:
2026-01-30 09:29:00,567:INFO:                shap: 0.44.1
2026-01-30 09:29:00,567:INFO:           interpret: 0.7.3
2026-01-30 09:29:00,567:INFO:                umap: 0.5.7
2026-01-30 09:29:00,567:INFO:     ydata_profiling: 4.18.1
2026-01-30 09:29:00,567:INFO:  explainerdashboard: 0.5.1
2026-01-30 09:29:00,567:INFO:             autoviz: Not installed
2026-01-30 09:29:00,567:INFO:           fairlearn: 0.7.0
2026-01-30 09:29:00,567:INFO:          deepchecks: Not installed
2026-01-30 09:29:00,567:INFO:             xgboost: Not installed
2026-01-30 09:29:00,567:INFO:            catboost: 1.2.8
2026-01-30 09:29:00,567:INFO:              kmodes: 0.12.2
2026-01-30 09:29:00,567:INFO:             mlxtend: 0.23.4
2026-01-30 09:29:00,567:INFO:       statsforecast: 1.5.0
2026-01-30 09:29:00,567:INFO:        tune_sklearn: Not installed
2026-01-30 09:29:00,567:INFO:                 ray: Not installed
2026-01-30 09:29:00,567:INFO:            hyperopt: 0.2.7
2026-01-30 09:29:00,567:INFO:              optuna: 4.6.0
2026-01-30 09:29:00,567:INFO:               skopt: 0.10.2
2026-01-30 09:29:00,567:INFO:              mlflow: 3.8.1
2026-01-30 09:29:00,567:INFO:              gradio: 6.3.0
2026-01-30 09:29:00,567:INFO:             fastapi: 0.128.0
2026-01-30 09:29:00,567:INFO:             uvicorn: 0.40.0
2026-01-30 09:29:00,567:INFO:              m2cgen: 0.10.0
2026-01-30 09:29:00,567:INFO:           evidently: 0.4.40
2026-01-30 09:29:00,567:INFO:               fugue: 0.8.7
2026-01-30 09:29:00,567:INFO:           streamlit: Not installed
2026-01-30 09:29:00,567:INFO:             prophet: Not installed
2026-01-30 09:29:00,567:INFO:None
2026-01-30 09:29:00,567:INFO:Set up data.
2026-01-30 09:29:00,667:INFO:Set up folding strategy.
2026-01-30 09:29:00,667:INFO:Set up train/test split.
2026-01-30 09:29:00,835:INFO:Set up index.
2026-01-30 09:29:00,847:INFO:Assigning column types.
2026-01-30 09:29:00,935:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-30 09:29:00,963:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 09:29:00,963:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:29:00,983:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:29:00,983:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:29:01,012:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 09:29:01,013:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:29:01,029:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:29:01,030:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:29:01,030:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-30 09:29:01,046:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:29:01,063:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:29:01,063:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:29:01,098:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:29:01,113:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:29:01,113:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:29:01,113:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-30 09:29:01,147:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:29:01,147:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:29:01,195:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:29:01,196:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:29:01,197:INFO:Preparing preprocessing pipeline...
2026-01-30 09:29:01,213:INFO:Set up simple imputation.
2026-01-30 09:29:01,213:INFO:Set up feature normalization.
2026-01-30 09:29:01,436:INFO:Finished creating preprocessing pipeline.
2026-01-30 09:29:01,436:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'MINIMUMPAYMENTPAYED',
                                             'PAID_PERCENT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'YEARPERSONBIRTHDATE',
                                             'PL_SI...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-30 09:29:01,436:INFO:Creating final display dataframe.
2026-01-30 09:29:01,813:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape      (429278, 20)
4        Transformed data shape      (429278, 20)
5   Transformed train set shape      (300494, 20)
6    Transformed test set shape      (128784, 20)
7              Numeric features                15
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                 3
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              8d13
2026-01-30 09:29:01,863:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:29:01,863:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:29:01,897:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:29:01,897:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:29:01,897:INFO:setup() successfully completed in 1.35s...............
2026-01-30 09:29:01,897:INFO:Initializing compare_models()
2026-01-30 09:29:01,897:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-30 09:29:01,897:INFO:Checking exceptions
2026-01-30 09:29:01,980:INFO:Preparing display monitor
2026-01-30 09:29:01,980:INFO:Initializing Logistic Regression
2026-01-30 09:29:01,980:INFO:Total runtime is 0.0 minutes
2026-01-30 09:29:01,980:INFO:SubProcess create_model() called ==================================
2026-01-30 09:29:01,980:INFO:Initializing create_model()
2026-01-30 09:29:01,980:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03C347350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:29:01,980:INFO:Checking exceptions
2026-01-30 09:29:01,980:INFO:Importing libraries
2026-01-30 09:29:01,980:INFO:Copying training dataset
2026-01-30 09:29:02,133:INFO:Defining folds
2026-01-30 09:29:02,134:INFO:Declaring metric variables
2026-01-30 09:29:02,134:INFO:Importing untrained model
2026-01-30 09:29:02,135:INFO:Logistic Regression Imported successfully
2026-01-30 09:29:02,135:INFO:Starting cross validation
2026-01-30 09:29:02,135:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:29:14,299:INFO:Calculating mean and std
2026-01-30 09:29:14,303:INFO:Creating metrics dataframe
2026-01-30 09:29:14,307:INFO:Uploading results into container
2026-01-30 09:29:14,310:INFO:Uploading model into container now
2026-01-30 09:29:14,310:INFO:_master_model_container: 1
2026-01-30 09:29:14,310:INFO:_display_container: 2
2026-01-30 09:29:14,310:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-30 09:29:14,313:INFO:create_model() successfully completed......................................
2026-01-30 09:29:14,481:INFO:SubProcess create_model() end ==================================
2026-01-30 09:29:14,482:INFO:Creating metrics dataframe
2026-01-30 09:29:14,485:INFO:Initializing Decision Tree Classifier
2026-01-30 09:29:14,485:INFO:Total runtime is 0.20842784643173218 minutes
2026-01-30 09:29:14,485:INFO:SubProcess create_model() called ==================================
2026-01-30 09:29:14,485:INFO:Initializing create_model()
2026-01-30 09:29:14,485:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03C347350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:29:14,485:INFO:Checking exceptions
2026-01-30 09:29:14,485:INFO:Importing libraries
2026-01-30 09:29:14,485:INFO:Copying training dataset
2026-01-30 09:29:14,682:INFO:Defining folds
2026-01-30 09:29:14,682:INFO:Declaring metric variables
2026-01-30 09:29:14,682:INFO:Importing untrained model
2026-01-30 09:29:14,682:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:29:14,682:INFO:Starting cross validation
2026-01-30 09:29:14,682:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:29:20,812:INFO:Calculating mean and std
2026-01-30 09:29:20,813:INFO:Creating metrics dataframe
2026-01-30 09:29:20,815:INFO:Uploading results into container
2026-01-30 09:29:20,815:INFO:Uploading model into container now
2026-01-30 09:29:20,816:INFO:_master_model_container: 2
2026-01-30 09:29:20,816:INFO:_display_container: 2
2026-01-30 09:29:20,817:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:29:20,817:INFO:create_model() successfully completed......................................
2026-01-30 09:29:20,970:INFO:SubProcess create_model() end ==================================
2026-01-30 09:29:20,970:INFO:Creating metrics dataframe
2026-01-30 09:29:20,970:INFO:Initializing Random Forest Classifier
2026-01-30 09:29:20,970:INFO:Total runtime is 0.3165002743403117 minutes
2026-01-30 09:29:20,970:INFO:SubProcess create_model() called ==================================
2026-01-30 09:29:20,970:INFO:Initializing create_model()
2026-01-30 09:29:20,970:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03C347350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:29:20,970:INFO:Checking exceptions
2026-01-30 09:29:20,970:INFO:Importing libraries
2026-01-30 09:29:20,970:INFO:Copying training dataset
2026-01-30 09:29:21,143:INFO:Defining folds
2026-01-30 09:29:21,145:INFO:Declaring metric variables
2026-01-30 09:29:21,147:INFO:Importing untrained model
2026-01-30 09:29:21,147:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:29:21,148:INFO:Starting cross validation
2026-01-30 09:29:21,149:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:29:34,164:INFO:Calculating mean and std
2026-01-30 09:29:34,166:INFO:Creating metrics dataframe
2026-01-30 09:29:34,167:INFO:Uploading results into container
2026-01-30 09:29:34,167:INFO:Uploading model into container now
2026-01-30 09:29:34,167:INFO:_master_model_container: 3
2026-01-30 09:29:34,167:INFO:_display_container: 2
2026-01-30 09:29:34,167:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:29:34,167:INFO:create_model() successfully completed......................................
2026-01-30 09:29:34,305:INFO:SubProcess create_model() end ==================================
2026-01-30 09:29:34,305:INFO:Creating metrics dataframe
2026-01-30 09:29:34,306:INFO:Initializing Light Gradient Boosting Machine
2026-01-30 09:29:34,306:INFO:Total runtime is 0.5387771089871725 minutes
2026-01-30 09:29:34,307:INFO:SubProcess create_model() called ==================================
2026-01-30 09:29:34,307:INFO:Initializing create_model()
2026-01-30 09:29:34,307:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03C347350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:29:34,307:INFO:Checking exceptions
2026-01-30 09:29:34,307:INFO:Importing libraries
2026-01-30 09:29:34,307:INFO:Copying training dataset
2026-01-30 09:29:34,446:INFO:Defining folds
2026-01-30 09:29:34,446:INFO:Declaring metric variables
2026-01-30 09:29:34,446:INFO:Importing untrained model
2026-01-30 09:29:34,446:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:29:34,446:INFO:Starting cross validation
2026-01-30 09:29:34,446:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:29:41,909:INFO:Calculating mean and std
2026-01-30 09:29:41,915:INFO:Creating metrics dataframe
2026-01-30 09:29:41,917:INFO:Uploading results into container
2026-01-30 09:29:41,917:INFO:Uploading model into container now
2026-01-30 09:29:41,919:INFO:_master_model_container: 4
2026-01-30 09:29:41,919:INFO:_display_container: 2
2026-01-30 09:29:41,919:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:29:41,919:INFO:create_model() successfully completed......................................
2026-01-30 09:29:42,029:INFO:SubProcess create_model() end ==================================
2026-01-30 09:29:42,029:INFO:Creating metrics dataframe
2026-01-30 09:29:42,044:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-30 09:29:42,046:INFO:Initializing create_model()
2026-01-30 09:29:42,046:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:29:42,046:INFO:Checking exceptions
2026-01-30 09:29:42,046:INFO:Importing libraries
2026-01-30 09:29:42,046:INFO:Copying training dataset
2026-01-30 09:29:42,188:INFO:Defining folds
2026-01-30 09:29:42,188:INFO:Declaring metric variables
2026-01-30 09:29:42,188:INFO:Importing untrained model
2026-01-30 09:29:42,188:INFO:Declaring custom model
2026-01-30 09:29:42,189:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:29:42,189:INFO:Cross validation set to False
2026-01-30 09:29:42,189:INFO:Fitting Model
2026-01-30 09:29:47,099:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:29:47,099:INFO:create_model() successfully completed......................................
2026-01-30 09:29:47,234:INFO:Initializing create_model()
2026-01-30 09:29:47,234:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:29:47,235:INFO:Checking exceptions
2026-01-30 09:29:47,235:INFO:Importing libraries
2026-01-30 09:29:47,235:INFO:Copying training dataset
2026-01-30 09:29:47,374:INFO:Defining folds
2026-01-30 09:29:47,375:INFO:Declaring metric variables
2026-01-30 09:29:47,375:INFO:Importing untrained model
2026-01-30 09:29:47,375:INFO:Declaring custom model
2026-01-30 09:29:47,375:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:29:47,376:INFO:Cross validation set to False
2026-01-30 09:29:47,376:INFO:Fitting Model
2026-01-30 09:29:48,542:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:29:48,542:INFO:create_model() successfully completed......................................
2026-01-30 09:29:48,669:INFO:Initializing create_model()
2026-01-30 09:29:48,669:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:29:48,669:INFO:Checking exceptions
2026-01-30 09:29:48,670:INFO:Importing libraries
2026-01-30 09:29:48,670:INFO:Copying training dataset
2026-01-30 09:29:48,814:INFO:Defining folds
2026-01-30 09:29:48,814:INFO:Declaring metric variables
2026-01-30 09:29:48,814:INFO:Importing untrained model
2026-01-30 09:29:48,815:INFO:Declaring custom model
2026-01-30 09:29:48,815:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:29:48,816:INFO:Cross validation set to False
2026-01-30 09:29:48,816:INFO:Fitting Model
2026-01-30 09:29:49,304:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 09:29:49,346:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007317 seconds.
2026-01-30 09:29:49,347:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:29:49,347:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:29:49,347:INFO:[LightGBM] [Info] Total Bins 1967
2026-01-30 09:29:49,348:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 19
2026-01-30 09:29:49,350:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 09:29:49,350:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 09:29:49,879:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:29:49,879:INFO:create_model() successfully completed......................................
2026-01-30 09:29:50,064:INFO:_master_model_container: 4
2026-01-30 09:29:50,064:INFO:_display_container: 2
2026-01-30 09:29:50,066:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)]
2026-01-30 09:29:50,066:INFO:compare_models() successfully completed......................................
2026-01-30 09:29:50,072:INFO:Initializing tune_model()
2026-01-30 09:29:50,072:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:29:50,073:INFO:Checking exceptions
2026-01-30 09:29:50,136:INFO:Copying training dataset
2026-01-30 09:29:50,228:INFO:Checking base model
2026-01-30 09:29:50,229:INFO:Base model : Random Forest Classifier
2026-01-30 09:29:50,229:INFO:Declaring metric variables
2026-01-30 09:29:50,229:INFO:Defining Hyperparameters
2026-01-30 09:29:50,362:INFO:Tuning with n_jobs=-1
2026-01-30 09:29:50,362:INFO:Initializing RandomizedSearchCV
2026-01-30 09:31:11,486:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-30 09:31:11,486:INFO:Hyperparameter search completed
2026-01-30 09:31:11,486:INFO:SubProcess create_model() called ==================================
2026-01-30 09:31:11,486:INFO:Initializing create_model()
2026-01-30 09:31:11,486:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03C3BF610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': True})
2026-01-30 09:31:11,486:INFO:Checking exceptions
2026-01-30 09:31:11,486:INFO:Importing libraries
2026-01-30 09:31:11,486:INFO:Copying training dataset
2026-01-30 09:31:11,714:INFO:Defining folds
2026-01-30 09:31:11,714:INFO:Declaring metric variables
2026-01-30 09:31:11,714:INFO:Importing untrained model
2026-01-30 09:31:11,714:INFO:Declaring custom model
2026-01-30 09:31:11,714:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:31:11,714:INFO:Starting cross validation
2026-01-30 09:31:11,724:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:31:29,109:INFO:Calculating mean and std
2026-01-30 09:31:29,111:INFO:Creating metrics dataframe
2026-01-30 09:31:29,113:INFO:Finalizing model
2026-01-30 09:31:37,745:INFO:Uploading results into container
2026-01-30 09:31:37,746:INFO:Uploading model into container now
2026-01-30 09:31:37,747:INFO:_master_model_container: 5
2026-01-30 09:31:37,747:INFO:_display_container: 3
2026-01-30 09:31:37,748:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:31:37,748:INFO:create_model() successfully completed......................................
2026-01-30 09:31:37,896:INFO:SubProcess create_model() end ==================================
2026-01-30 09:31:37,897:INFO:choose_better activated
2026-01-30 09:31:37,897:INFO:SubProcess create_model() called ==================================
2026-01-30 09:31:37,897:INFO:Initializing create_model()
2026-01-30 09:31:37,897:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:31:37,897:INFO:Checking exceptions
2026-01-30 09:31:37,898:INFO:Importing libraries
2026-01-30 09:31:37,898:INFO:Copying training dataset
2026-01-30 09:31:38,045:INFO:Defining folds
2026-01-30 09:31:38,045:INFO:Declaring metric variables
2026-01-30 09:31:38,045:INFO:Importing untrained model
2026-01-30 09:31:38,045:INFO:Declaring custom model
2026-01-30 09:31:38,045:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:31:38,045:INFO:Starting cross validation
2026-01-30 09:31:38,045:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:31:49,414:INFO:Calculating mean and std
2026-01-30 09:31:49,414:INFO:Creating metrics dataframe
2026-01-30 09:31:49,416:INFO:Finalizing model
2026-01-30 09:31:55,199:INFO:Uploading results into container
2026-01-30 09:31:55,200:INFO:Uploading model into container now
2026-01-30 09:31:55,200:INFO:_master_model_container: 6
2026-01-30 09:31:55,201:INFO:_display_container: 4
2026-01-30 09:31:55,201:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:31:55,201:INFO:create_model() successfully completed......................................
2026-01-30 09:31:55,358:INFO:SubProcess create_model() end ==================================
2026-01-30 09:31:55,359:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9993
2026-01-30 09:31:55,360:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9934
2026-01-30 09:31:55,360:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-30 09:31:55,360:INFO:choose_better completed
2026-01-30 09:31:55,361:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 09:31:55,364:INFO:_master_model_container: 6
2026-01-30 09:31:55,365:INFO:_display_container: 3
2026-01-30 09:31:55,365:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:31:55,365:INFO:tune_model() successfully completed......................................
2026-01-30 09:31:55,520:INFO:Initializing tune_model()
2026-01-30 09:31:55,520:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:31:55,520:INFO:Checking exceptions
2026-01-30 09:31:55,603:INFO:Copying training dataset
2026-01-30 09:31:55,799:INFO:Checking base model
2026-01-30 09:31:55,800:INFO:Base model : Decision Tree Classifier
2026-01-30 09:31:55,801:INFO:Declaring metric variables
2026-01-30 09:31:55,801:INFO:Defining Hyperparameters
2026-01-30 09:31:56,002:INFO:Tuning with n_jobs=-1
2026-01-30 09:31:56,003:INFO:Initializing RandomizedSearchCV
2026-01-30 09:32:00,866:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 15, 'actual_estimator__criterion': 'gini'}
2026-01-30 09:32:00,866:INFO:Hyperparameter search completed
2026-01-30 09:32:00,866:INFO:SubProcess create_model() called ==================================
2026-01-30 09:32:00,866:INFO:Initializing create_model()
2026-01-30 09:32:00,866:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A07F31BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 2, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 15, 'criterion': 'gini'})
2026-01-30 09:32:00,866:INFO:Checking exceptions
2026-01-30 09:32:00,866:INFO:Importing libraries
2026-01-30 09:32:00,866:INFO:Copying training dataset
2026-01-30 09:32:01,028:INFO:Defining folds
2026-01-30 09:32:01,028:INFO:Declaring metric variables
2026-01-30 09:32:01,028:INFO:Importing untrained model
2026-01-30 09:32:01,028:INFO:Declaring custom model
2026-01-30 09:32:01,028:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:32:01,028:INFO:Starting cross validation
2026-01-30 09:32:01,028:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:32:02,673:INFO:Calculating mean and std
2026-01-30 09:32:02,676:INFO:Creating metrics dataframe
2026-01-30 09:32:02,677:INFO:Finalizing model
2026-01-30 09:32:03,544:INFO:Uploading results into container
2026-01-30 09:32:03,545:INFO:Uploading model into container now
2026-01-30 09:32:03,546:INFO:_master_model_container: 7
2026-01-30 09:32:03,546:INFO:_display_container: 4
2026-01-30 09:32:03,547:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:32:03,547:INFO:create_model() successfully completed......................................
2026-01-30 09:32:03,660:INFO:SubProcess create_model() end ==================================
2026-01-30 09:32:03,660:INFO:choose_better activated
2026-01-30 09:32:03,660:INFO:SubProcess create_model() called ==================================
2026-01-30 09:32:03,660:INFO:Initializing create_model()
2026-01-30 09:32:03,660:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:32:03,660:INFO:Checking exceptions
2026-01-30 09:32:03,660:INFO:Importing libraries
2026-01-30 09:32:03,660:INFO:Copying training dataset
2026-01-30 09:32:03,815:INFO:Defining folds
2026-01-30 09:32:03,815:INFO:Declaring metric variables
2026-01-30 09:32:03,816:INFO:Importing untrained model
2026-01-30 09:32:03,816:INFO:Declaring custom model
2026-01-30 09:32:03,816:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:32:03,816:INFO:Starting cross validation
2026-01-30 09:32:03,817:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:32:05,785:INFO:Calculating mean and std
2026-01-30 09:32:05,785:INFO:Creating metrics dataframe
2026-01-30 09:32:05,785:INFO:Finalizing model
2026-01-30 09:32:07,076:INFO:Uploading results into container
2026-01-30 09:32:07,077:INFO:Uploading model into container now
2026-01-30 09:32:07,077:INFO:_master_model_container: 8
2026-01-30 09:32:07,077:INFO:_display_container: 5
2026-01-30 09:32:07,077:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:32:07,077:INFO:create_model() successfully completed......................................
2026-01-30 09:32:07,200:INFO:SubProcess create_model() end ==================================
2026-01-30 09:32:07,200:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9988
2026-01-30 09:32:07,202:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9876
2026-01-30 09:32:07,202:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-30 09:32:07,202:INFO:choose_better completed
2026-01-30 09:32:07,202:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 09:32:07,204:INFO:_master_model_container: 8
2026-01-30 09:32:07,204:INFO:_display_container: 4
2026-01-30 09:32:07,204:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:32:07,204:INFO:tune_model() successfully completed......................................
2026-01-30 09:32:07,327:INFO:Initializing tune_model()
2026-01-30 09:32:07,327:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:32:07,327:INFO:Checking exceptions
2026-01-30 09:32:07,382:INFO:Copying training dataset
2026-01-30 09:32:07,485:INFO:Checking base model
2026-01-30 09:32:07,485:INFO:Base model : Light Gradient Boosting Machine
2026-01-30 09:32:07,486:INFO:Declaring metric variables
2026-01-30 09:32:07,486:INFO:Defining Hyperparameters
2026-01-30 09:32:07,615:INFO:Tuning with n_jobs=-1
2026-01-30 09:32:07,615:INFO:Initializing RandomizedSearchCV
2026-01-30 09:32:38,676:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2026-01-30 09:32:38,677:INFO:Hyperparameter search completed
2026-01-30 09:32:38,677:INFO:SubProcess create_model() called ==================================
2026-01-30 09:32:38,679:INFO:Initializing create_model()
2026-01-30 09:32:38,679:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C3C17F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2026-01-30 09:32:38,679:INFO:Checking exceptions
2026-01-30 09:32:38,679:INFO:Importing libraries
2026-01-30 09:32:38,680:INFO:Copying training dataset
2026-01-30 09:32:38,860:INFO:Defining folds
2026-01-30 09:32:38,860:INFO:Declaring metric variables
2026-01-30 09:32:38,860:INFO:Importing untrained model
2026-01-30 09:32:38,860:INFO:Declaring custom model
2026-01-30 09:32:38,875:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:32:38,876:INFO:Starting cross validation
2026-01-30 09:32:38,876:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:32:47,399:INFO:Calculating mean and std
2026-01-30 09:32:47,402:INFO:Creating metrics dataframe
2026-01-30 09:32:47,405:INFO:Finalizing model
2026-01-30 09:32:47,786:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 09:32:47,786:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 09:32:47,786:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 09:32:47,932:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 09:32:47,932:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 09:32:47,932:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 09:32:47,934:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 09:32:47,964:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008276 seconds.
2026-01-30 09:32:47,964:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:32:47,964:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:32:47,967:INFO:[LightGBM] [Info] Total Bins 1967
2026-01-30 09:32:47,967:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 19
2026-01-30 09:32:47,971:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 09:32:47,971:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 09:32:50,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-01-30 09:32:50,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-01-30 09:32:50,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-01-30 09:32:50,728:INFO:Uploading results into container
2026-01-30 09:32:50,730:INFO:Uploading model into container now
2026-01-30 09:32:50,730:INFO:_master_model_container: 9
2026-01-30 09:32:50,730:INFO:_display_container: 5
2026-01-30 09:32:50,732:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:32:50,732:INFO:create_model() successfully completed......................................
2026-01-30 09:32:50,926:INFO:SubProcess create_model() end ==================================
2026-01-30 09:32:50,926:INFO:choose_better activated
2026-01-30 09:32:50,926:INFO:SubProcess create_model() called ==================================
2026-01-30 09:32:50,926:INFO:Initializing create_model()
2026-01-30 09:32:50,926:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:32:50,926:INFO:Checking exceptions
2026-01-30 09:32:50,926:INFO:Importing libraries
2026-01-30 09:32:50,926:INFO:Copying training dataset
2026-01-30 09:32:51,093:INFO:Defining folds
2026-01-30 09:32:51,093:INFO:Declaring metric variables
2026-01-30 09:32:51,093:INFO:Importing untrained model
2026-01-30 09:32:51,093:INFO:Declaring custom model
2026-01-30 09:32:51,093:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:32:51,093:INFO:Starting cross validation
2026-01-30 09:32:51,093:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:32:55,122:INFO:Calculating mean and std
2026-01-30 09:32:55,123:INFO:Creating metrics dataframe
2026-01-30 09:32:55,127:INFO:Finalizing model
2026-01-30 09:32:55,712:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 09:32:55,751:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008999 seconds.
2026-01-30 09:32:55,751:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:32:55,751:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:32:55,751:INFO:[LightGBM] [Info] Total Bins 1967
2026-01-30 09:32:55,752:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 19
2026-01-30 09:32:55,754:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 09:32:55,755:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 09:32:56,615:INFO:Uploading results into container
2026-01-30 09:32:56,616:INFO:Uploading model into container now
2026-01-30 09:32:56,617:INFO:_master_model_container: 10
2026-01-30 09:32:56,617:INFO:_display_container: 6
2026-01-30 09:32:56,618:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:32:56,618:INFO:create_model() successfully completed......................................
2026-01-30 09:32:56,806:INFO:SubProcess create_model() end ==================================
2026-01-30 09:32:56,807:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9966
2026-01-30 09:32:56,807:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9992
2026-01-30 09:32:56,808:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2026-01-30 09:32:56,808:INFO:choose_better completed
2026-01-30 09:32:56,812:INFO:_master_model_container: 10
2026-01-30 09:32:56,812:INFO:_display_container: 5
2026-01-30 09:32:56,813:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:32:56,813:INFO:tune_model() successfully completed......................................
2026-01-30 09:32:56,962:INFO:Initializing predict_model()
2026-01-30 09:32:56,963:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A069E44EA0>)
2026-01-30 09:32:56,963:INFO:Checking exceptions
2026-01-30 09:32:56,963:INFO:Preloading libraries
2026-01-30 09:32:56,963:INFO:Set up data.
2026-01-30 09:32:56,998:INFO:Set up index.
2026-01-30 09:32:57,876:INFO:Initializing predict_model()
2026-01-30 09:32:57,876:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A069E44EA0>)
2026-01-30 09:32:57,876:INFO:Checking exceptions
2026-01-30 09:32:57,876:INFO:Preloading libraries
2026-01-30 09:32:57,876:INFO:Set up data.
2026-01-30 09:32:57,895:INFO:Set up index.
2026-01-30 09:32:58,359:INFO:Initializing predict_model()
2026-01-30 09:32:58,359:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A069E44EA0>)
2026-01-30 09:32:58,359:INFO:Checking exceptions
2026-01-30 09:32:58,359:INFO:Preloading libraries
2026-01-30 09:32:58,359:INFO:Set up data.
2026-01-30 09:32:58,396:INFO:Set up index.
2026-01-30 09:32:59,410:INFO:Initializing plot_model()
2026-01-30 09:32:59,410:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 09:32:59,410:INFO:Checking exceptions
2026-01-30 09:32:59,493:INFO:Preloading libraries
2026-01-30 09:32:59,526:INFO:Copying training dataset
2026-01-30 09:32:59,526:INFO:Plot type: feature
2026-01-30 09:32:59,526:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 09:32:59,776:INFO:Visual Rendered Successfully
2026-01-30 09:32:59,908:INFO:plot_model() successfully completed......................................
2026-01-30 09:32:59,909:INFO:Initializing plot_model()
2026-01-30 09:32:59,909:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature_all, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 09:32:59,910:INFO:Checking exceptions
2026-01-30 09:33:00,004:INFO:Preloading libraries
2026-01-30 09:33:00,026:INFO:Copying training dataset
2026-01-30 09:33:00,026:INFO:Plot type: feature_all
2026-01-30 09:33:00,143:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 09:33:00,426:INFO:Visual Rendered Successfully
2026-01-30 09:33:00,543:INFO:plot_model() successfully completed......................................
2026-01-30 09:33:00,561:INFO:Initializing save_model()
2026-01-30 09:33:00,561:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), model_name=..\datos\04. Modelos\modelo_final_explicable, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'MINIMUMPAYMENTPAYED',
                                             'PAID_PERCENT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'YEARPERSONBIRTHDATE',
                                             'PL_SI...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-30 09:33:00,561:INFO:Adding model into prep_pipe
2026-01-30 09:33:00,627:INFO:..\datos\04. Modelos\modelo_final_explicable.pkl saved in current working directory
2026-01-30 09:33:00,631:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'MINIMUMPAYMENTPAYED',
                                             'PAID_PERCENT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'YEARPERSONBIRTHDATE',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges_...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=42, verbose=0,
                                        warm_start=False))],
         verbose=False)
2026-01-30 09:33:00,631:INFO:save_model() successfully completed......................................
2026-01-30 09:39:02,378:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\1844400550.py:23: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-30 09:39:04,349:INFO:PyCaret ClassificationExperiment
2026-01-30 09:39:04,349:INFO:Logging name: clf-default-name
2026-01-30 09:39:04,349:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-30 09:39:04,349:INFO:version 3.3.2
2026-01-30 09:39:04,349:INFO:Initializing setup()
2026-01-30 09:39:04,353:INFO:self.USI: a68c
2026-01-30 09:39:04,353:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'n_jobs_param', 'data', 'X', 'idx', 'y_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'USI', 'target_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'y_train', 'X_test', 'seed', 'gpu_param', 'gpu_n_jobs_param', 'y', 'logging_param', 'pipeline', 'fold_generator', 'exp_id'}
2026-01-30 09:39:04,353:INFO:Checking environment
2026-01-30 09:39:04,354:INFO:python_version: 3.11.11
2026-01-30 09:39:04,355:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-30 09:39:04,355:INFO:machine: AMD64
2026-01-30 09:39:04,355:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-30 09:39:04,355:INFO:Memory: svmem(total=34009374720, available=15912980480, percent=53.2, used=18096394240, free=15912980480)
2026-01-30 09:39:04,356:INFO:Physical Core: 12
2026-01-30 09:39:04,356:INFO:Logical Core: 16
2026-01-30 09:39:04,356:INFO:Checking libraries
2026-01-30 09:39:04,356:INFO:System:
2026-01-30 09:39:04,356:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-30 09:39:04,357:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-30 09:39:04,357:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-30 09:39:04,357:INFO:PyCaret required dependencies:
2026-01-30 09:39:04,357:INFO:                 pip: 25.0
2026-01-30 09:39:04,357:INFO:          setuptools: 75.8.0
2026-01-30 09:39:04,357:INFO:             pycaret: 3.3.2
2026-01-30 09:39:04,357:INFO:             IPython: 9.9.0
2026-01-30 09:39:04,357:INFO:          ipywidgets: 8.1.8
2026-01-30 09:39:04,357:INFO:                tqdm: 4.67.1
2026-01-30 09:39:04,357:INFO:               numpy: 1.26.4
2026-01-30 09:39:04,357:INFO:              pandas: 2.1.4
2026-01-30 09:39:04,357:INFO:              jinja2: 3.1.6
2026-01-30 09:39:04,357:INFO:               scipy: 1.11.4
2026-01-30 09:39:04,357:INFO:              joblib: 1.3.2
2026-01-30 09:39:04,357:INFO:             sklearn: 1.4.2
2026-01-30 09:39:04,357:INFO:                pyod: 2.0.6
2026-01-30 09:39:04,358:INFO:            imblearn: 0.14.1
2026-01-30 09:39:04,358:INFO:   category_encoders: 2.7.0
2026-01-30 09:39:04,358:INFO:            lightgbm: 4.6.0
2026-01-30 09:39:04,358:INFO:               numba: 0.62.1
2026-01-30 09:39:04,358:INFO:            requests: 2.32.3
2026-01-30 09:39:04,358:INFO:          matplotlib: 3.7.5
2026-01-30 09:39:04,358:INFO:          scikitplot: 0.3.7
2026-01-30 09:39:04,358:INFO:         yellowbrick: 1.5
2026-01-30 09:39:04,358:INFO:              plotly: 5.24.1
2026-01-30 09:39:04,358:INFO:    plotly-resampler: Not installed
2026-01-30 09:39:04,358:INFO:             kaleido: 1.2.0
2026-01-30 09:39:04,358:INFO:           schemdraw: 0.15
2026-01-30 09:39:04,358:INFO:         statsmodels: 0.14.6
2026-01-30 09:39:04,358:INFO:              sktime: 0.26.0
2026-01-30 09:39:04,358:INFO:               tbats: 1.1.3
2026-01-30 09:39:04,358:INFO:            pmdarima: 2.0.4
2026-01-30 09:39:04,358:INFO:              psutil: 7.2.1
2026-01-30 09:39:04,358:INFO:          markupsafe: 3.0.3
2026-01-30 09:39:04,358:INFO:             pickle5: Not installed
2026-01-30 09:39:04,358:INFO:         cloudpickle: 3.0.0
2026-01-30 09:39:04,358:INFO:         deprecation: 2.1.0
2026-01-30 09:39:04,358:INFO:              xxhash: 3.6.0
2026-01-30 09:39:04,358:INFO:           wurlitzer: Not installed
2026-01-30 09:39:04,358:INFO:PyCaret optional dependencies:
2026-01-30 09:39:04,358:INFO:                shap: 0.44.1
2026-01-30 09:39:04,358:INFO:           interpret: 0.7.3
2026-01-30 09:39:04,358:INFO:                umap: 0.5.7
2026-01-30 09:39:04,358:INFO:     ydata_profiling: 4.18.1
2026-01-30 09:39:04,358:INFO:  explainerdashboard: 0.5.1
2026-01-30 09:39:04,358:INFO:             autoviz: Not installed
2026-01-30 09:39:04,358:INFO:           fairlearn: 0.7.0
2026-01-30 09:39:04,358:INFO:          deepchecks: Not installed
2026-01-30 09:39:04,358:INFO:             xgboost: Not installed
2026-01-30 09:39:04,358:INFO:            catboost: 1.2.8
2026-01-30 09:39:04,358:INFO:              kmodes: 0.12.2
2026-01-30 09:39:04,358:INFO:             mlxtend: 0.23.4
2026-01-30 09:39:04,358:INFO:       statsforecast: 1.5.0
2026-01-30 09:39:04,358:INFO:        tune_sklearn: Not installed
2026-01-30 09:39:04,358:INFO:                 ray: Not installed
2026-01-30 09:39:04,358:INFO:            hyperopt: 0.2.7
2026-01-30 09:39:04,358:INFO:              optuna: 4.6.0
2026-01-30 09:39:04,358:INFO:               skopt: 0.10.2
2026-01-30 09:39:04,358:INFO:              mlflow: 3.8.1
2026-01-30 09:39:04,358:INFO:              gradio: 6.3.0
2026-01-30 09:39:04,358:INFO:             fastapi: 0.128.0
2026-01-30 09:39:04,358:INFO:             uvicorn: 0.40.0
2026-01-30 09:39:04,358:INFO:              m2cgen: 0.10.0
2026-01-30 09:39:04,358:INFO:           evidently: 0.4.40
2026-01-30 09:39:04,358:INFO:               fugue: 0.8.7
2026-01-30 09:39:04,358:INFO:           streamlit: Not installed
2026-01-30 09:39:04,358:INFO:             prophet: Not installed
2026-01-30 09:39:04,358:INFO:None
2026-01-30 09:39:04,358:INFO:Set up data.
2026-01-30 09:39:04,474:INFO:Set up folding strategy.
2026-01-30 09:39:04,474:INFO:Set up train/test split.
2026-01-30 09:39:04,661:INFO:Set up index.
2026-01-30 09:39:04,673:INFO:Assigning column types.
2026-01-30 09:39:04,778:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-30 09:39:04,811:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 09:39:04,811:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:39:04,827:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:39:04,827:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:39:04,839:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 09:39:04,839:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:39:04,861:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:39:04,861:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:39:04,870:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-30 09:39:04,894:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:39:04,911:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:39:04,911:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:39:04,937:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:39:04,954:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:39:04,954:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:39:04,955:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-30 09:39:04,994:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:39:04,994:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:39:05,037:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:39:05,037:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:39:05,039:INFO:Preparing preprocessing pipeline...
2026-01-30 09:39:05,058:INFO:Set up simple imputation.
2026-01-30 09:39:05,059:INFO:Set up feature normalization.
2026-01-30 09:39:05,507:INFO:Finished creating preprocessing pipeline.
2026-01-30 09:39:05,507:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'PAID_AMOUNT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdina...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-30 09:39:05,507:INFO:Creating final display dataframe.
2026-01-30 09:39:06,610:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape      (429278, 22)
4        Transformed data shape      (429278, 22)
5   Transformed train set shape      (300494, 22)
6    Transformed test set shape      (128784, 22)
7              Numeric features                18
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                 3
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              a68c
2026-01-30 09:39:06,638:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:39:06,638:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:39:06,690:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:39:06,690:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:39:06,690:INFO:setup() successfully completed in 2.35s...............
2026-01-30 09:39:06,690:INFO:Initializing compare_models()
2026-01-30 09:39:06,690:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-30 09:39:06,690:INFO:Checking exceptions
2026-01-30 09:39:06,791:INFO:Preparing display monitor
2026-01-30 09:39:06,791:INFO:Initializing Logistic Regression
2026-01-30 09:39:06,791:INFO:Total runtime is 0.0 minutes
2026-01-30 09:39:06,791:INFO:SubProcess create_model() called ==================================
2026-01-30 09:39:06,791:INFO:Initializing create_model()
2026-01-30 09:39:06,791:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C9F29550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:39:06,791:INFO:Checking exceptions
2026-01-30 09:39:06,791:INFO:Importing libraries
2026-01-30 09:39:06,791:INFO:Copying training dataset
2026-01-30 09:39:06,925:INFO:Defining folds
2026-01-30 09:39:06,925:INFO:Declaring metric variables
2026-01-30 09:39:06,925:INFO:Importing untrained model
2026-01-30 09:39:06,925:INFO:Logistic Regression Imported successfully
2026-01-30 09:39:06,925:INFO:Starting cross validation
2026-01-30 09:39:06,925:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:39:14,419:INFO:Calculating mean and std
2026-01-30 09:39:14,420:INFO:Creating metrics dataframe
2026-01-30 09:39:14,421:INFO:Uploading results into container
2026-01-30 09:39:14,421:INFO:Uploading model into container now
2026-01-30 09:39:14,421:INFO:_master_model_container: 1
2026-01-30 09:39:14,421:INFO:_display_container: 2
2026-01-30 09:39:14,425:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-30 09:39:14,425:INFO:create_model() successfully completed......................................
2026-01-30 09:39:14,541:INFO:SubProcess create_model() end ==================================
2026-01-30 09:39:14,541:INFO:Creating metrics dataframe
2026-01-30 09:39:14,541:INFO:Initializing Decision Tree Classifier
2026-01-30 09:39:14,541:INFO:Total runtime is 0.12916266918182373 minutes
2026-01-30 09:39:14,541:INFO:SubProcess create_model() called ==================================
2026-01-30 09:39:14,541:INFO:Initializing create_model()
2026-01-30 09:39:14,541:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C9F29550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:39:14,541:INFO:Checking exceptions
2026-01-30 09:39:14,541:INFO:Importing libraries
2026-01-30 09:39:14,541:INFO:Copying training dataset
2026-01-30 09:39:14,671:INFO:Defining folds
2026-01-30 09:39:14,671:INFO:Declaring metric variables
2026-01-30 09:39:14,671:INFO:Importing untrained model
2026-01-30 09:39:14,671:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:39:14,671:INFO:Starting cross validation
2026-01-30 09:39:14,671:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:39:20,653:INFO:Calculating mean and std
2026-01-30 09:39:20,655:INFO:Creating metrics dataframe
2026-01-30 09:39:20,659:INFO:Uploading results into container
2026-01-30 09:39:20,659:INFO:Uploading model into container now
2026-01-30 09:39:20,661:INFO:_master_model_container: 2
2026-01-30 09:39:20,661:INFO:_display_container: 2
2026-01-30 09:39:20,661:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:39:20,661:INFO:create_model() successfully completed......................................
2026-01-30 09:39:20,771:INFO:SubProcess create_model() end ==================================
2026-01-30 09:39:20,771:INFO:Creating metrics dataframe
2026-01-30 09:39:20,771:INFO:Initializing Random Forest Classifier
2026-01-30 09:39:20,771:INFO:Total runtime is 0.23299130996068318 minutes
2026-01-30 09:39:20,771:INFO:SubProcess create_model() called ==================================
2026-01-30 09:39:20,771:INFO:Initializing create_model()
2026-01-30 09:39:20,771:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C9F29550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:39:20,771:INFO:Checking exceptions
2026-01-30 09:39:20,771:INFO:Importing libraries
2026-01-30 09:39:20,771:INFO:Copying training dataset
2026-01-30 09:39:20,904:INFO:Defining folds
2026-01-30 09:39:20,904:INFO:Declaring metric variables
2026-01-30 09:39:20,904:INFO:Importing untrained model
2026-01-30 09:39:20,904:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:39:20,904:INFO:Starting cross validation
2026-01-30 09:39:20,904:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:39:37,903:INFO:Calculating mean and std
2026-01-30 09:39:37,904:INFO:Creating metrics dataframe
2026-01-30 09:39:37,904:INFO:Uploading results into container
2026-01-30 09:39:37,904:INFO:Uploading model into container now
2026-01-30 09:39:37,904:INFO:_master_model_container: 3
2026-01-30 09:39:37,904:INFO:_display_container: 2
2026-01-30 09:39:37,904:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:39:37,904:INFO:create_model() successfully completed......................................
2026-01-30 09:39:38,021:INFO:SubProcess create_model() end ==================================
2026-01-30 09:39:38,021:INFO:Creating metrics dataframe
2026-01-30 09:39:38,021:INFO:Initializing Light Gradient Boosting Machine
2026-01-30 09:39:38,021:INFO:Total runtime is 0.5204903920491537 minutes
2026-01-30 09:39:38,021:INFO:SubProcess create_model() called ==================================
2026-01-30 09:39:38,021:INFO:Initializing create_model()
2026-01-30 09:39:38,021:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C9F29550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:39:38,021:INFO:Checking exceptions
2026-01-30 09:39:38,021:INFO:Importing libraries
2026-01-30 09:39:38,021:INFO:Copying training dataset
2026-01-30 09:39:38,171:INFO:Defining folds
2026-01-30 09:39:38,171:INFO:Declaring metric variables
2026-01-30 09:39:38,171:INFO:Importing untrained model
2026-01-30 09:39:38,171:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:39:38,171:INFO:Starting cross validation
2026-01-30 09:39:38,171:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:39:45,503:INFO:Calculating mean and std
2026-01-30 09:39:45,504:INFO:Creating metrics dataframe
2026-01-30 09:39:45,504:INFO:Uploading results into container
2026-01-30 09:39:45,504:INFO:Uploading model into container now
2026-01-30 09:39:45,504:INFO:_master_model_container: 4
2026-01-30 09:39:45,504:INFO:_display_container: 2
2026-01-30 09:39:45,504:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:39:45,504:INFO:create_model() successfully completed......................................
2026-01-30 09:39:45,624:INFO:SubProcess create_model() end ==================================
2026-01-30 09:39:45,624:INFO:Creating metrics dataframe
2026-01-30 09:39:45,624:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-30 09:39:45,624:INFO:Initializing create_model()
2026-01-30 09:39:45,624:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:39:45,624:INFO:Checking exceptions
2026-01-30 09:39:45,624:INFO:Importing libraries
2026-01-30 09:39:45,624:INFO:Copying training dataset
2026-01-30 09:39:45,771:INFO:Defining folds
2026-01-30 09:39:45,771:INFO:Declaring metric variables
2026-01-30 09:39:45,771:INFO:Importing untrained model
2026-01-30 09:39:45,771:INFO:Declaring custom model
2026-01-30 09:39:45,771:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:39:45,771:INFO:Cross validation set to False
2026-01-30 09:39:45,771:INFO:Fitting Model
2026-01-30 09:39:52,757:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:39:52,757:INFO:create_model() successfully completed......................................
2026-01-30 09:39:52,871:INFO:Initializing create_model()
2026-01-30 09:39:52,871:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:39:52,871:INFO:Checking exceptions
2026-01-30 09:39:52,871:INFO:Importing libraries
2026-01-30 09:39:52,871:INFO:Copying training dataset
2026-01-30 09:39:53,023:INFO:Defining folds
2026-01-30 09:39:53,023:INFO:Declaring metric variables
2026-01-30 09:39:53,023:INFO:Importing untrained model
2026-01-30 09:39:53,023:INFO:Declaring custom model
2026-01-30 09:39:53,023:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:39:53,023:INFO:Cross validation set to False
2026-01-30 09:39:53,023:INFO:Fitting Model
2026-01-30 09:39:53,651:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 09:39:53,699:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008173 seconds.
2026-01-30 09:39:53,699:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:39:53,699:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:39:53,701:INFO:[LightGBM] [Info] Total Bins 3112
2026-01-30 09:39:53,701:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 21
2026-01-30 09:39:53,704:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 09:39:53,704:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 09:39:54,537:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:39:54,537:INFO:create_model() successfully completed......................................
2026-01-30 09:39:54,704:INFO:Initializing create_model()
2026-01-30 09:39:54,719:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:39:54,720:INFO:Checking exceptions
2026-01-30 09:39:54,720:INFO:Importing libraries
2026-01-30 09:39:54,720:INFO:Copying training dataset
2026-01-30 09:39:54,889:INFO:Defining folds
2026-01-30 09:39:54,889:INFO:Declaring metric variables
2026-01-30 09:39:54,889:INFO:Importing untrained model
2026-01-30 09:39:54,889:INFO:Declaring custom model
2026-01-30 09:39:54,889:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:39:54,889:INFO:Cross validation set to False
2026-01-30 09:39:54,889:INFO:Fitting Model
2026-01-30 09:39:57,713:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:39:57,713:INFO:create_model() successfully completed......................................
2026-01-30 09:39:57,843:INFO:_master_model_container: 4
2026-01-30 09:39:57,844:INFO:_display_container: 2
2026-01-30 09:39:57,844:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')]
2026-01-30 09:39:57,844:INFO:compare_models() successfully completed......................................
2026-01-30 09:39:57,861:INFO:Initializing tune_model()
2026-01-30 09:39:57,861:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:39:57,861:INFO:Checking exceptions
2026-01-30 09:39:57,916:INFO:Copying training dataset
2026-01-30 09:39:58,022:INFO:Checking base model
2026-01-30 09:39:58,023:INFO:Base model : Random Forest Classifier
2026-01-30 09:39:58,023:INFO:Declaring metric variables
2026-01-30 09:39:58,024:INFO:Defining Hyperparameters
2026-01-30 09:39:58,141:INFO:Tuning with n_jobs=-1
2026-01-30 09:39:58,142:INFO:Initializing RandomizedSearchCV
2026-01-30 09:42:15,983:INFO:best_params: {'actual_estimator__n_estimators': 120, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-30 09:42:15,986:INFO:Hyperparameter search completed
2026-01-30 09:42:15,986:INFO:SubProcess create_model() called ==================================
2026-01-30 09:42:15,986:INFO:Initializing create_model()
2026-01-30 09:42:15,986:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A06A301290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 120, 'min_samples_split': 5, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': True})
2026-01-30 09:42:15,986:INFO:Checking exceptions
2026-01-30 09:42:15,986:INFO:Importing libraries
2026-01-30 09:42:15,986:INFO:Copying training dataset
2026-01-30 09:42:16,220:INFO:Defining folds
2026-01-30 09:42:16,220:INFO:Declaring metric variables
2026-01-30 09:42:16,220:INFO:Importing untrained model
2026-01-30 09:42:16,220:INFO:Declaring custom model
2026-01-30 09:42:16,220:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:42:16,220:INFO:Starting cross validation
2026-01-30 09:42:16,220:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:42:30,870:INFO:Calculating mean and std
2026-01-30 09:42:30,870:INFO:Creating metrics dataframe
2026-01-30 09:42:30,874:INFO:Finalizing model
2026-01-30 09:42:37,952:INFO:Uploading results into container
2026-01-30 09:42:37,952:INFO:Uploading model into container now
2026-01-30 09:42:37,952:INFO:_master_model_container: 5
2026-01-30 09:42:37,966:INFO:_display_container: 3
2026-01-30 09:42:37,966:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=120, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:42:37,966:INFO:create_model() successfully completed......................................
2026-01-30 09:42:38,118:INFO:SubProcess create_model() end ==================================
2026-01-30 09:42:38,118:INFO:choose_better activated
2026-01-30 09:42:38,118:INFO:SubProcess create_model() called ==================================
2026-01-30 09:42:38,118:INFO:Initializing create_model()
2026-01-30 09:42:38,118:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:42:38,118:INFO:Checking exceptions
2026-01-30 09:42:38,118:INFO:Importing libraries
2026-01-30 09:42:38,118:INFO:Copying training dataset
2026-01-30 09:42:38,285:INFO:Defining folds
2026-01-30 09:42:38,285:INFO:Declaring metric variables
2026-01-30 09:42:38,285:INFO:Importing untrained model
2026-01-30 09:42:38,285:INFO:Declaring custom model
2026-01-30 09:42:38,285:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:42:38,285:INFO:Starting cross validation
2026-01-30 09:42:38,285:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:42:56,385:INFO:Calculating mean and std
2026-01-30 09:42:56,385:INFO:Creating metrics dataframe
2026-01-30 09:42:56,385:INFO:Finalizing model
2026-01-30 09:43:04,851:INFO:Uploading results into container
2026-01-30 09:43:04,852:INFO:Uploading model into container now
2026-01-30 09:43:04,853:INFO:_master_model_container: 6
2026-01-30 09:43:04,853:INFO:_display_container: 4
2026-01-30 09:43:04,853:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:43:04,853:INFO:create_model() successfully completed......................................
2026-01-30 09:43:04,970:INFO:SubProcess create_model() end ==================================
2026-01-30 09:43:04,970:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.998
2026-01-30 09:43:04,970:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=120, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9879
2026-01-30 09:43:04,970:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-30 09:43:04,970:INFO:choose_better completed
2026-01-30 09:43:04,970:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 09:43:04,985:INFO:_master_model_container: 6
2026-01-30 09:43:04,985:INFO:_display_container: 3
2026-01-30 09:43:04,985:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:43:04,985:INFO:tune_model() successfully completed......................................
2026-01-30 09:43:05,107:INFO:Initializing tune_model()
2026-01-30 09:43:05,107:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:43:05,107:INFO:Checking exceptions
2026-01-30 09:43:05,151:INFO:Copying training dataset
2026-01-30 09:43:05,262:INFO:Checking base model
2026-01-30 09:43:05,262:INFO:Base model : Light Gradient Boosting Machine
2026-01-30 09:43:05,262:INFO:Declaring metric variables
2026-01-30 09:43:05,262:INFO:Defining Hyperparameters
2026-01-30 09:43:05,368:INFO:Tuning with n_jobs=-1
2026-01-30 09:43:05,368:INFO:Initializing RandomizedSearchCV
2026-01-30 09:43:43,827:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2026-01-30 09:43:43,828:INFO:Hyperparameter search completed
2026-01-30 09:43:43,830:INFO:SubProcess create_model() called ==================================
2026-01-30 09:43:43,832:INFO:Initializing create_model()
2026-01-30 09:43:43,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C28A16D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2026-01-30 09:43:43,833:INFO:Checking exceptions
2026-01-30 09:43:43,833:INFO:Importing libraries
2026-01-30 09:43:43,833:INFO:Copying training dataset
2026-01-30 09:43:44,105:INFO:Defining folds
2026-01-30 09:43:44,105:INFO:Declaring metric variables
2026-01-30 09:43:44,105:INFO:Importing untrained model
2026-01-30 09:43:44,105:INFO:Declaring custom model
2026-01-30 09:43:44,107:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:43:44,108:INFO:Starting cross validation
2026-01-30 09:43:44,109:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:43:53,442:INFO:Calculating mean and std
2026-01-30 09:43:53,442:INFO:Creating metrics dataframe
2026-01-30 09:43:53,442:INFO:Finalizing model
2026-01-30 09:43:54,017:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 09:43:54,017:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 09:43:54,017:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 09:43:54,196:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 09:43:54,196:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 09:43:54,196:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 09:43:54,197:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 09:43:54,255:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009683 seconds.
2026-01-30 09:43:54,255:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:43:54,255:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:43:54,256:INFO:[LightGBM] [Info] Total Bins 3112
2026-01-30 09:43:54,257:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 21
2026-01-30 09:43:54,261:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 09:43:54,261:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 09:43:57,221:INFO:Uploading results into container
2026-01-30 09:43:57,223:INFO:Uploading model into container now
2026-01-30 09:43:57,223:INFO:_master_model_container: 7
2026-01-30 09:43:57,223:INFO:_display_container: 4
2026-01-30 09:43:57,225:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:43:57,225:INFO:create_model() successfully completed......................................
2026-01-30 09:43:57,411:INFO:SubProcess create_model() end ==================================
2026-01-30 09:43:57,411:INFO:choose_better activated
2026-01-30 09:43:57,411:INFO:SubProcess create_model() called ==================================
2026-01-30 09:43:57,412:INFO:Initializing create_model()
2026-01-30 09:43:57,412:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:43:57,412:INFO:Checking exceptions
2026-01-30 09:43:57,413:INFO:Importing libraries
2026-01-30 09:43:57,413:INFO:Copying training dataset
2026-01-30 09:43:57,600:INFO:Defining folds
2026-01-30 09:43:57,600:INFO:Declaring metric variables
2026-01-30 09:43:57,600:INFO:Importing untrained model
2026-01-30 09:43:57,600:INFO:Declaring custom model
2026-01-30 09:43:57,600:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:43:57,600:INFO:Starting cross validation
2026-01-30 09:43:57,600:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:44:01,906:INFO:Calculating mean and std
2026-01-30 09:44:01,906:INFO:Creating metrics dataframe
2026-01-30 09:44:01,906:INFO:Finalizing model
2026-01-30 09:44:02,554:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 09:44:02,607:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008181 seconds.
2026-01-30 09:44:02,607:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:44:02,607:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:44:02,607:INFO:[LightGBM] [Info] Total Bins 3112
2026-01-30 09:44:02,609:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 21
2026-01-30 09:44:02,612:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 09:44:02,612:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 09:44:03,503:INFO:Uploading results into container
2026-01-30 09:44:03,504:INFO:Uploading model into container now
2026-01-30 09:44:03,505:INFO:_master_model_container: 8
2026-01-30 09:44:03,505:INFO:_display_container: 5
2026-01-30 09:44:03,506:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:44:03,506:INFO:create_model() successfully completed......................................
2026-01-30 09:44:03,700:INFO:SubProcess create_model() end ==================================
2026-01-30 09:44:03,700:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9936
2026-01-30 09:44:03,700:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9981
2026-01-30 09:44:03,700:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2026-01-30 09:44:03,700:INFO:choose_better completed
2026-01-30 09:44:03,700:INFO:_master_model_container: 8
2026-01-30 09:44:03,700:INFO:_display_container: 4
2026-01-30 09:44:03,700:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:44:03,700:INFO:tune_model() successfully completed......................................
2026-01-30 09:44:03,833:INFO:Initializing tune_model()
2026-01-30 09:44:03,833:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:44:03,833:INFO:Checking exceptions
2026-01-30 09:44:03,907:INFO:Copying training dataset
2026-01-30 09:44:04,017:INFO:Checking base model
2026-01-30 09:44:04,017:INFO:Base model : Decision Tree Classifier
2026-01-30 09:44:04,017:INFO:Declaring metric variables
2026-01-30 09:44:04,017:INFO:Defining Hyperparameters
2026-01-30 09:44:04,134:INFO:Tuning with n_jobs=-1
2026-01-30 09:44:04,134:INFO:Initializing RandomizedSearchCV
2026-01-30 09:44:10,874:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 15, 'actual_estimator__criterion': 'gini'}
2026-01-30 09:44:10,874:INFO:Hyperparameter search completed
2026-01-30 09:44:10,874:INFO:SubProcess create_model() called ==================================
2026-01-30 09:44:10,874:INFO:Initializing create_model()
2026-01-30 09:44:10,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A06E646BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 2, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 15, 'criterion': 'gini'})
2026-01-30 09:44:10,874:INFO:Checking exceptions
2026-01-30 09:44:10,874:INFO:Importing libraries
2026-01-30 09:44:10,874:INFO:Copying training dataset
2026-01-30 09:44:11,083:INFO:Defining folds
2026-01-30 09:44:11,083:INFO:Declaring metric variables
2026-01-30 09:44:11,083:INFO:Importing untrained model
2026-01-30 09:44:11,083:INFO:Declaring custom model
2026-01-30 09:44:11,083:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:44:11,083:INFO:Starting cross validation
2026-01-30 09:44:11,083:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:44:13,487:INFO:Calculating mean and std
2026-01-30 09:44:13,489:INFO:Creating metrics dataframe
2026-01-30 09:44:13,494:INFO:Finalizing model
2026-01-30 09:44:15,064:INFO:Uploading results into container
2026-01-30 09:44:15,065:INFO:Uploading model into container now
2026-01-30 09:44:15,065:INFO:_master_model_container: 9
2026-01-30 09:44:15,065:INFO:_display_container: 5
2026-01-30 09:44:15,065:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:44:15,066:INFO:create_model() successfully completed......................................
2026-01-30 09:44:15,192:INFO:SubProcess create_model() end ==================================
2026-01-30 09:44:15,192:INFO:choose_better activated
2026-01-30 09:44:15,192:INFO:SubProcess create_model() called ==================================
2026-01-30 09:44:15,193:INFO:Initializing create_model()
2026-01-30 09:44:15,193:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:44:15,193:INFO:Checking exceptions
2026-01-30 09:44:15,193:INFO:Importing libraries
2026-01-30 09:44:15,194:INFO:Copying training dataset
2026-01-30 09:44:15,367:INFO:Defining folds
2026-01-30 09:44:15,367:INFO:Declaring metric variables
2026-01-30 09:44:15,367:INFO:Importing untrained model
2026-01-30 09:44:15,367:INFO:Declaring custom model
2026-01-30 09:44:15,367:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:44:15,367:INFO:Starting cross validation
2026-01-30 09:44:15,367:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:44:18,821:INFO:Calculating mean and std
2026-01-30 09:44:18,821:INFO:Creating metrics dataframe
2026-01-30 09:44:18,822:INFO:Finalizing model
2026-01-30 09:44:21,655:INFO:Uploading results into container
2026-01-30 09:44:21,655:INFO:Uploading model into container now
2026-01-30 09:44:21,666:INFO:_master_model_container: 10
2026-01-30 09:44:21,666:INFO:_display_container: 6
2026-01-30 09:44:21,666:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:44:21,666:INFO:create_model() successfully completed......................................
2026-01-30 09:44:21,807:INFO:SubProcess create_model() end ==================================
2026-01-30 09:44:21,807:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9856
2026-01-30 09:44:21,808:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9831
2026-01-30 09:44:21,808:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-30 09:44:21,808:INFO:choose_better completed
2026-01-30 09:44:21,808:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 09:44:21,810:INFO:_master_model_container: 10
2026-01-30 09:44:21,811:INFO:_display_container: 5
2026-01-30 09:44:21,811:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:44:21,811:INFO:tune_model() successfully completed......................................
2026-01-30 09:44:21,967:INFO:Initializing predict_model()
2026-01-30 09:44:21,967:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A03C5465C0>)
2026-01-30 09:44:21,968:INFO:Checking exceptions
2026-01-30 09:44:21,968:INFO:Preloading libraries
2026-01-30 09:44:21,968:INFO:Set up data.
2026-01-30 09:44:22,007:INFO:Set up index.
2026-01-30 09:44:23,289:INFO:Initializing predict_model()
2026-01-30 09:44:23,289:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A0C3C9E700>)
2026-01-30 09:44:23,289:INFO:Checking exceptions
2026-01-30 09:44:23,289:INFO:Preloading libraries
2026-01-30 09:44:23,289:INFO:Set up data.
2026-01-30 09:44:23,333:INFO:Set up index.
2026-01-30 09:44:24,423:INFO:Initializing predict_model()
2026-01-30 09:44:24,423:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A03C5465C0>)
2026-01-30 09:44:24,423:INFO:Checking exceptions
2026-01-30 09:44:24,423:INFO:Preloading libraries
2026-01-30 09:44:24,423:INFO:Set up data.
2026-01-30 09:44:24,460:INFO:Set up index.
2026-01-30 09:44:24,955:INFO:Initializing plot_model()
2026-01-30 09:44:24,961:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 09:44:24,961:INFO:Checking exceptions
2026-01-30 09:44:25,057:INFO:Preloading libraries
2026-01-30 09:44:25,136:INFO:Copying training dataset
2026-01-30 09:44:25,136:INFO:Plot type: feature
2026-01-30 09:44:25,136:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 09:44:25,418:INFO:Visual Rendered Successfully
2026-01-30 09:44:25,538:INFO:plot_model() successfully completed......................................
2026-01-30 09:44:25,549:INFO:Initializing plot_model()
2026-01-30 09:44:25,549:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature_all, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 09:44:25,549:INFO:Checking exceptions
2026-01-30 09:44:25,633:INFO:Preloading libraries
2026-01-30 09:44:25,700:INFO:Copying training dataset
2026-01-30 09:44:25,700:INFO:Plot type: feature_all
2026-01-30 09:44:25,850:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 09:44:26,189:INFO:Visual Rendered Successfully
2026-01-30 09:44:26,307:INFO:plot_model() successfully completed......................................
2026-01-30 09:44:26,323:INFO:Initializing save_model()
2026-01-30 09:44:26,323:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), model_name=..\datos\04. Modelos\modelo_final_explicable, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'PAID_AMOUNT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdina...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-30 09:44:26,323:INFO:Adding model into prep_pipe
2026-01-30 09:44:26,426:INFO:..\datos\04. Modelos\modelo_final_explicable.pkl saved in current working directory
2026-01-30 09:44:26,429:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'PAID_AMOUNT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdinario_def__c',
                                             'CU_precioAplicado_def__c',
                                             'PO...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=42, verbose=0,
                                        warm_start=False))],
         verbose=False)
2026-01-30 09:44:26,429:INFO:save_model() successfully completed......................................
2026-01-30 09:54:19,796:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\3560701889.py:20: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-30 09:54:21,875:INFO:PyCaret ClassificationExperiment
2026-01-30 09:54:21,890:INFO:Logging name: clf-default-name
2026-01-30 09:54:21,890:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-30 09:54:21,890:INFO:version 3.3.2
2026-01-30 09:54:21,891:INFO:Initializing setup()
2026-01-30 09:54:21,891:INFO:self.USI: 0e4f
2026-01-30 09:54:21,891:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'n_jobs_param', 'data', 'X', 'idx', 'y_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'USI', 'target_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'y_train', 'X_test', 'seed', 'gpu_param', 'gpu_n_jobs_param', 'y', 'logging_param', 'pipeline', 'fold_generator', 'exp_id'}
2026-01-30 09:54:21,891:INFO:Checking environment
2026-01-30 09:54:21,892:INFO:python_version: 3.11.11
2026-01-30 09:54:21,892:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-30 09:54:21,892:INFO:machine: AMD64
2026-01-30 09:54:21,893:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-30 09:54:21,893:INFO:Memory: svmem(total=34009374720, available=15314989056, percent=55.0, used=18694385664, free=15314989056)
2026-01-30 09:54:21,893:INFO:Physical Core: 12
2026-01-30 09:54:21,893:INFO:Logical Core: 16
2026-01-30 09:54:21,894:INFO:Checking libraries
2026-01-30 09:54:21,894:INFO:System:
2026-01-30 09:54:21,894:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-30 09:54:21,894:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-30 09:54:21,894:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-30 09:54:21,894:INFO:PyCaret required dependencies:
2026-01-30 09:54:21,894:INFO:                 pip: 25.0
2026-01-30 09:54:21,894:INFO:          setuptools: 75.8.0
2026-01-30 09:54:21,894:INFO:             pycaret: 3.3.2
2026-01-30 09:54:21,894:INFO:             IPython: 9.9.0
2026-01-30 09:54:21,894:INFO:          ipywidgets: 8.1.8
2026-01-30 09:54:21,894:INFO:                tqdm: 4.67.1
2026-01-30 09:54:21,894:INFO:               numpy: 1.26.4
2026-01-30 09:54:21,894:INFO:              pandas: 2.1.4
2026-01-30 09:54:21,894:INFO:              jinja2: 3.1.6
2026-01-30 09:54:21,894:INFO:               scipy: 1.11.4
2026-01-30 09:54:21,894:INFO:              joblib: 1.3.2
2026-01-30 09:54:21,894:INFO:             sklearn: 1.4.2
2026-01-30 09:54:21,894:INFO:                pyod: 2.0.6
2026-01-30 09:54:21,894:INFO:            imblearn: 0.14.1
2026-01-30 09:54:21,894:INFO:   category_encoders: 2.7.0
2026-01-30 09:54:21,894:INFO:            lightgbm: 4.6.0
2026-01-30 09:54:21,894:INFO:               numba: 0.62.1
2026-01-30 09:54:21,894:INFO:            requests: 2.32.3
2026-01-30 09:54:21,894:INFO:          matplotlib: 3.7.5
2026-01-30 09:54:21,894:INFO:          scikitplot: 0.3.7
2026-01-30 09:54:21,894:INFO:         yellowbrick: 1.5
2026-01-30 09:54:21,894:INFO:              plotly: 5.24.1
2026-01-30 09:54:21,894:INFO:    plotly-resampler: Not installed
2026-01-30 09:54:21,894:INFO:             kaleido: 1.2.0
2026-01-30 09:54:21,894:INFO:           schemdraw: 0.15
2026-01-30 09:54:21,894:INFO:         statsmodels: 0.14.6
2026-01-30 09:54:21,894:INFO:              sktime: 0.26.0
2026-01-30 09:54:21,894:INFO:               tbats: 1.1.3
2026-01-30 09:54:21,894:INFO:            pmdarima: 2.0.4
2026-01-30 09:54:21,894:INFO:              psutil: 7.2.1
2026-01-30 09:54:21,894:INFO:          markupsafe: 3.0.3
2026-01-30 09:54:21,894:INFO:             pickle5: Not installed
2026-01-30 09:54:21,894:INFO:         cloudpickle: 3.0.0
2026-01-30 09:54:21,894:INFO:         deprecation: 2.1.0
2026-01-30 09:54:21,894:INFO:              xxhash: 3.6.0
2026-01-30 09:54:21,894:INFO:           wurlitzer: Not installed
2026-01-30 09:54:21,894:INFO:PyCaret optional dependencies:
2026-01-30 09:54:21,894:INFO:                shap: 0.44.1
2026-01-30 09:54:21,894:INFO:           interpret: 0.7.3
2026-01-30 09:54:21,894:INFO:                umap: 0.5.7
2026-01-30 09:54:21,894:INFO:     ydata_profiling: 4.18.1
2026-01-30 09:54:21,894:INFO:  explainerdashboard: 0.5.1
2026-01-30 09:54:21,894:INFO:             autoviz: Not installed
2026-01-30 09:54:21,894:INFO:           fairlearn: 0.7.0
2026-01-30 09:54:21,894:INFO:          deepchecks: Not installed
2026-01-30 09:54:21,894:INFO:             xgboost: Not installed
2026-01-30 09:54:21,894:INFO:            catboost: 1.2.8
2026-01-30 09:54:21,894:INFO:              kmodes: 0.12.2
2026-01-30 09:54:21,894:INFO:             mlxtend: 0.23.4
2026-01-30 09:54:21,894:INFO:       statsforecast: 1.5.0
2026-01-30 09:54:21,894:INFO:        tune_sklearn: Not installed
2026-01-30 09:54:21,894:INFO:                 ray: Not installed
2026-01-30 09:54:21,894:INFO:            hyperopt: 0.2.7
2026-01-30 09:54:21,894:INFO:              optuna: 4.6.0
2026-01-30 09:54:21,894:INFO:               skopt: 0.10.2
2026-01-30 09:54:21,894:INFO:              mlflow: 3.8.1
2026-01-30 09:54:21,894:INFO:              gradio: 6.3.0
2026-01-30 09:54:21,894:INFO:             fastapi: 0.128.0
2026-01-30 09:54:21,894:INFO:             uvicorn: 0.40.0
2026-01-30 09:54:21,894:INFO:              m2cgen: 0.10.0
2026-01-30 09:54:21,894:INFO:           evidently: 0.4.40
2026-01-30 09:54:21,894:INFO:               fugue: 0.8.7
2026-01-30 09:54:21,894:INFO:           streamlit: Not installed
2026-01-30 09:54:21,894:INFO:             prophet: Not installed
2026-01-30 09:54:21,894:INFO:None
2026-01-30 09:54:21,894:INFO:Set up data.
2026-01-30 09:54:22,054:INFO:Set up folding strategy.
2026-01-30 09:54:22,054:INFO:Set up train/test split.
2026-01-30 09:54:22,275:INFO:Set up index.
2026-01-30 09:54:22,291:INFO:Assigning column types.
2026-01-30 09:54:22,456:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-30 09:54:22,486:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 09:54:22,487:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:54:22,506:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:54:22,506:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:54:22,536:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 09:54:22,537:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:54:22,556:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:54:22,557:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:54:22,558:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-30 09:54:22,584:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:54:22,610:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:54:22,610:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:54:22,644:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:54:22,658:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:54:22,658:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:54:22,658:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-30 09:54:22,708:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:54:22,708:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:54:22,758:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:54:22,758:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:54:22,758:INFO:Preparing preprocessing pipeline...
2026-01-30 09:54:22,791:INFO:Set up simple imputation.
2026-01-30 09:54:22,791:INFO:Set up feature normalization.
2026-01-30 09:54:23,696:INFO:Finished creating preprocessing pipeline.
2026-01-30 09:54:23,707:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'PAID_AMOUNT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdina...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-30 09:54:23,708:INFO:Creating final display dataframe.
2026-01-30 09:54:25,695:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape      (482669, 28)
4        Transformed data shape      (482669, 28)
5   Transformed train set shape      (337868, 28)
6    Transformed test set shape      (144801, 28)
7              Numeric features                24
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                 3
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              0e4f
2026-01-30 09:54:25,761:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:54:25,761:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:54:25,828:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:54:25,828:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:54:25,828:INFO:setup() successfully completed in 3.95s...............
2026-01-30 09:54:25,828:INFO:Initializing compare_models()
2026-01-30 09:54:25,828:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-30 09:54:25,828:INFO:Checking exceptions
2026-01-30 09:54:25,975:INFO:Preparing display monitor
2026-01-30 09:54:25,991:INFO:Initializing Logistic Regression
2026-01-30 09:54:25,991:INFO:Total runtime is 0.0 minutes
2026-01-30 09:54:25,991:INFO:SubProcess create_model() called ==================================
2026-01-30 09:54:25,991:INFO:Initializing create_model()
2026-01-30 09:54:25,991:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0D02B07D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:54:25,991:INFO:Checking exceptions
2026-01-30 09:54:25,991:INFO:Importing libraries
2026-01-30 09:54:25,991:INFO:Copying training dataset
2026-01-30 09:54:26,227:INFO:Defining folds
2026-01-30 09:54:26,227:INFO:Declaring metric variables
2026-01-30 09:54:26,227:INFO:Importing untrained model
2026-01-30 09:54:26,227:INFO:Logistic Regression Imported successfully
2026-01-30 09:54:26,227:INFO:Starting cross validation
2026-01-30 09:54:26,227:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:54:36,429:INFO:Calculating mean and std
2026-01-30 09:54:36,429:INFO:Creating metrics dataframe
2026-01-30 09:54:36,429:INFO:Uploading results into container
2026-01-30 09:54:36,429:INFO:Uploading model into container now
2026-01-30 09:54:36,429:INFO:_master_model_container: 1
2026-01-30 09:54:36,429:INFO:_display_container: 2
2026-01-30 09:54:36,429:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-30 09:54:36,429:INFO:create_model() successfully completed......................................
2026-01-30 09:54:36,558:INFO:SubProcess create_model() end ==================================
2026-01-30 09:54:36,573:INFO:Creating metrics dataframe
2026-01-30 09:54:36,575:INFO:Initializing Decision Tree Classifier
2026-01-30 09:54:36,575:INFO:Total runtime is 0.17639289697011312 minutes
2026-01-30 09:54:36,575:INFO:SubProcess create_model() called ==================================
2026-01-30 09:54:36,575:INFO:Initializing create_model()
2026-01-30 09:54:36,575:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0D02B07D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:54:36,575:INFO:Checking exceptions
2026-01-30 09:54:36,575:INFO:Importing libraries
2026-01-30 09:54:36,575:INFO:Copying training dataset
2026-01-30 09:54:36,774:INFO:Defining folds
2026-01-30 09:54:36,774:INFO:Declaring metric variables
2026-01-30 09:54:36,774:INFO:Importing untrained model
2026-01-30 09:54:36,774:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:54:36,774:INFO:Starting cross validation
2026-01-30 09:54:36,774:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:54:45,395:INFO:Calculating mean and std
2026-01-30 09:54:45,395:INFO:Creating metrics dataframe
2026-01-30 09:54:45,395:INFO:Uploading results into container
2026-01-30 09:54:45,395:INFO:Uploading model into container now
2026-01-30 09:54:45,395:INFO:_master_model_container: 2
2026-01-30 09:54:45,395:INFO:_display_container: 2
2026-01-30 09:54:45,395:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:54:45,395:INFO:create_model() successfully completed......................................
2026-01-30 09:54:45,524:INFO:SubProcess create_model() end ==================================
2026-01-30 09:54:45,524:INFO:Creating metrics dataframe
2026-01-30 09:54:45,524:INFO:Initializing Random Forest Classifier
2026-01-30 09:54:45,524:INFO:Total runtime is 0.3255495190620422 minutes
2026-01-30 09:54:45,524:INFO:SubProcess create_model() called ==================================
2026-01-30 09:54:45,524:INFO:Initializing create_model()
2026-01-30 09:54:45,524:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0D02B07D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:54:45,524:INFO:Checking exceptions
2026-01-30 09:54:45,524:INFO:Importing libraries
2026-01-30 09:54:45,524:INFO:Copying training dataset
2026-01-30 09:54:45,724:INFO:Defining folds
2026-01-30 09:54:45,724:INFO:Declaring metric variables
2026-01-30 09:54:45,725:INFO:Importing untrained model
2026-01-30 09:54:45,725:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:54:45,725:INFO:Starting cross validation
2026-01-30 09:54:45,725:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:55:10,669:INFO:Calculating mean and std
2026-01-30 09:55:10,669:INFO:Creating metrics dataframe
2026-01-30 09:55:10,673:INFO:Uploading results into container
2026-01-30 09:55:10,674:INFO:Uploading model into container now
2026-01-30 09:55:10,674:INFO:_master_model_container: 3
2026-01-30 09:55:10,674:INFO:_display_container: 2
2026-01-30 09:55:10,674:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:55:10,674:INFO:create_model() successfully completed......................................
2026-01-30 09:55:10,807:INFO:SubProcess create_model() end ==================================
2026-01-30 09:55:10,807:INFO:Creating metrics dataframe
2026-01-30 09:55:10,807:INFO:Initializing Light Gradient Boosting Machine
2026-01-30 09:55:10,807:INFO:Total runtime is 0.7469383398691813 minutes
2026-01-30 09:55:10,807:INFO:SubProcess create_model() called ==================================
2026-01-30 09:55:10,807:INFO:Initializing create_model()
2026-01-30 09:55:10,807:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0D02B07D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:55:10,807:INFO:Checking exceptions
2026-01-30 09:55:10,807:INFO:Importing libraries
2026-01-30 09:55:10,807:INFO:Copying training dataset
2026-01-30 09:55:11,091:INFO:Defining folds
2026-01-30 09:55:11,091:INFO:Declaring metric variables
2026-01-30 09:55:11,091:INFO:Importing untrained model
2026-01-30 09:55:11,091:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:55:11,091:INFO:Starting cross validation
2026-01-30 09:55:11,091:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:55:20,519:INFO:Calculating mean and std
2026-01-30 09:55:20,523:INFO:Creating metrics dataframe
2026-01-30 09:55:20,524:INFO:Uploading results into container
2026-01-30 09:55:20,524:INFO:Uploading model into container now
2026-01-30 09:55:20,524:INFO:_master_model_container: 4
2026-01-30 09:55:20,524:INFO:_display_container: 2
2026-01-30 09:55:20,524:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:55:20,524:INFO:create_model() successfully completed......................................
2026-01-30 09:55:20,652:INFO:SubProcess create_model() end ==================================
2026-01-30 09:55:20,652:INFO:Creating metrics dataframe
2026-01-30 09:55:20,656:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-30 09:55:20,657:INFO:Initializing create_model()
2026-01-30 09:55:20,657:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:55:20,658:INFO:Checking exceptions
2026-01-30 09:55:20,658:INFO:Importing libraries
2026-01-30 09:55:20,658:INFO:Copying training dataset
2026-01-30 09:55:20,841:INFO:Defining folds
2026-01-30 09:55:20,841:INFO:Declaring metric variables
2026-01-30 09:55:20,841:INFO:Importing untrained model
2026-01-30 09:55:20,841:INFO:Declaring custom model
2026-01-30 09:55:20,841:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:55:20,841:INFO:Cross validation set to False
2026-01-30 09:55:20,841:INFO:Fitting Model
2026-01-30 09:55:30,974:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:55:30,974:INFO:create_model() successfully completed......................................
2026-01-30 09:55:31,112:INFO:Initializing create_model()
2026-01-30 09:55:31,112:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:55:31,112:INFO:Checking exceptions
2026-01-30 09:55:31,112:INFO:Importing libraries
2026-01-30 09:55:31,112:INFO:Copying training dataset
2026-01-30 09:55:31,307:INFO:Defining folds
2026-01-30 09:55:31,307:INFO:Declaring metric variables
2026-01-30 09:55:31,307:INFO:Importing untrained model
2026-01-30 09:55:31,307:INFO:Declaring custom model
2026-01-30 09:55:31,323:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:55:31,323:INFO:Cross validation set to False
2026-01-30 09:55:31,323:INFO:Fitting Model
2026-01-30 09:55:32,242:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 09:55:32,304:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014178 seconds.
2026-01-30 09:55:32,304:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:55:32,304:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:55:32,306:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 09:55:32,307:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 09:55:32,309:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 09:55:32,309:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 09:55:33,474:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:55:33,474:INFO:create_model() successfully completed......................................
2026-01-30 09:55:33,674:INFO:Initializing create_model()
2026-01-30 09:55:33,674:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:55:33,674:INFO:Checking exceptions
2026-01-30 09:55:33,674:INFO:Importing libraries
2026-01-30 09:55:33,674:INFO:Copying training dataset
2026-01-30 09:55:33,974:INFO:Defining folds
2026-01-30 09:55:33,989:INFO:Declaring metric variables
2026-01-30 09:55:33,989:INFO:Importing untrained model
2026-01-30 09:55:33,989:INFO:Declaring custom model
2026-01-30 09:55:33,989:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:55:33,990:INFO:Cross validation set to False
2026-01-30 09:55:33,990:INFO:Fitting Model
2026-01-30 09:55:36,774:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:55:36,774:INFO:create_model() successfully completed......................................
2026-01-30 09:55:36,909:INFO:_master_model_container: 4
2026-01-30 09:55:36,909:INFO:_display_container: 2
2026-01-30 09:55:36,909:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')]
2026-01-30 09:55:36,909:INFO:compare_models() successfully completed......................................
2026-01-30 09:55:36,909:INFO:Initializing tune_model()
2026-01-30 09:55:36,909:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:55:36,909:INFO:Checking exceptions
2026-01-30 09:55:36,990:INFO:Copying training dataset
2026-01-30 09:55:37,109:INFO:Checking base model
2026-01-30 09:55:37,109:INFO:Base model : Random Forest Classifier
2026-01-30 09:55:37,109:INFO:Declaring metric variables
2026-01-30 09:55:37,109:INFO:Defining Hyperparameters
2026-01-30 09:55:37,226:INFO:Tuning with n_jobs=-1
2026-01-30 09:55:37,226:INFO:Initializing RandomizedSearchCV
2026-01-30 09:58:27,555:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-30 09:58:27,558:INFO:Hyperparameter search completed
2026-01-30 09:58:27,558:INFO:SubProcess create_model() called ==================================
2026-01-30 09:58:27,560:INFO:Initializing create_model()
2026-01-30 09:58:27,560:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A06E675E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': True})
2026-01-30 09:58:27,560:INFO:Checking exceptions
2026-01-30 09:58:27,560:INFO:Importing libraries
2026-01-30 09:58:27,561:INFO:Copying training dataset
2026-01-30 09:58:27,988:INFO:Defining folds
2026-01-30 09:58:27,988:INFO:Declaring metric variables
2026-01-30 09:58:27,988:INFO:Importing untrained model
2026-01-30 09:58:27,988:INFO:Declaring custom model
2026-01-30 09:58:27,988:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:58:27,988:INFO:Starting cross validation
2026-01-30 09:58:27,988:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:59:01,021:INFO:Calculating mean and std
2026-01-30 09:59:01,024:INFO:Creating metrics dataframe
2026-01-30 09:59:01,027:INFO:Finalizing model
2026-01-30 09:59:17,913:INFO:Uploading results into container
2026-01-30 09:59:17,914:INFO:Uploading model into container now
2026-01-30 09:59:17,915:INFO:_master_model_container: 5
2026-01-30 09:59:17,916:INFO:_display_container: 3
2026-01-30 09:59:17,917:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:59:17,917:INFO:create_model() successfully completed......................................
2026-01-30 09:59:18,082:INFO:SubProcess create_model() end ==================================
2026-01-30 09:59:18,082:INFO:choose_better activated
2026-01-30 09:59:18,082:INFO:SubProcess create_model() called ==================================
2026-01-30 09:59:18,084:INFO:Initializing create_model()
2026-01-30 09:59:18,084:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:59:18,084:INFO:Checking exceptions
2026-01-30 09:59:18,085:INFO:Importing libraries
2026-01-30 09:59:18,085:INFO:Copying training dataset
2026-01-30 09:59:18,469:INFO:Defining folds
2026-01-30 09:59:18,469:INFO:Declaring metric variables
2026-01-30 09:59:18,469:INFO:Importing untrained model
2026-01-30 09:59:18,469:INFO:Declaring custom model
2026-01-30 09:59:18,470:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:59:18,470:INFO:Starting cross validation
2026-01-30 09:59:18,472:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:59:40,639:INFO:Calculating mean and std
2026-01-30 09:59:40,640:INFO:Creating metrics dataframe
2026-01-30 09:59:40,642:INFO:Finalizing model
2026-01-30 09:59:51,731:INFO:Uploading results into container
2026-01-30 09:59:51,732:INFO:Uploading model into container now
2026-01-30 09:59:51,732:INFO:_master_model_container: 6
2026-01-30 09:59:51,733:INFO:_display_container: 4
2026-01-30 09:59:51,733:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:59:51,733:INFO:create_model() successfully completed......................................
2026-01-30 09:59:51,899:INFO:SubProcess create_model() end ==================================
2026-01-30 09:59:51,900:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9985
2026-01-30 09:59:51,901:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9894
2026-01-30 09:59:51,901:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-30 09:59:51,901:INFO:choose_better completed
2026-01-30 09:59:51,902:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 09:59:51,905:INFO:_master_model_container: 6
2026-01-30 09:59:51,906:INFO:_display_container: 3
2026-01-30 09:59:51,906:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:59:51,907:INFO:tune_model() successfully completed......................................
2026-01-30 09:59:52,068:INFO:Initializing tune_model()
2026-01-30 09:59:52,068:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:59:52,068:INFO:Checking exceptions
2026-01-30 09:59:52,189:INFO:Copying training dataset
2026-01-30 09:59:52,385:INFO:Checking base model
2026-01-30 09:59:52,385:INFO:Base model : Light Gradient Boosting Machine
2026-01-30 09:59:52,386:INFO:Declaring metric variables
2026-01-30 09:59:52,387:INFO:Defining Hyperparameters
2026-01-30 09:59:52,564:INFO:Tuning with n_jobs=-1
2026-01-30 09:59:52,565:INFO:Initializing RandomizedSearchCV
2026-01-30 10:00:39,556:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2026-01-30 10:00:39,558:INFO:Hyperparameter search completed
2026-01-30 10:00:39,558:INFO:SubProcess create_model() called ==================================
2026-01-30 10:00:39,559:INFO:Initializing create_model()
2026-01-30 10:00:39,559:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A074FCD0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2026-01-30 10:00:39,560:INFO:Checking exceptions
2026-01-30 10:00:39,560:INFO:Importing libraries
2026-01-30 10:00:39,560:INFO:Copying training dataset
2026-01-30 10:00:39,882:INFO:Defining folds
2026-01-30 10:00:39,883:INFO:Declaring metric variables
2026-01-30 10:00:39,883:INFO:Importing untrained model
2026-01-30 10:00:39,883:INFO:Declaring custom model
2026-01-30 10:00:39,885:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:00:39,885:INFO:Starting cross validation
2026-01-30 10:00:39,886:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:00:51,413:INFO:Calculating mean and std
2026-01-30 10:00:51,414:INFO:Creating metrics dataframe
2026-01-30 10:00:51,416:INFO:Finalizing model
2026-01-30 10:00:52,223:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 10:00:52,223:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 10:00:52,223:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 10:00:52,437:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 10:00:52,438:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 10:00:52,438:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 10:00:52,438:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 10:00:52,502:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014042 seconds.
2026-01-30 10:00:52,502:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 10:00:52,502:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 10:00:52,502:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 10:00:52,504:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 10:00:52,509:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 10:00:52,510:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 10:00:56,832:INFO:Uploading results into container
2026-01-30 10:00:56,833:INFO:Uploading model into container now
2026-01-30 10:00:56,834:INFO:_master_model_container: 7
2026-01-30 10:00:56,835:INFO:_display_container: 4
2026-01-30 10:00:56,836:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:00:56,836:INFO:create_model() successfully completed......................................
2026-01-30 10:00:57,036:INFO:SubProcess create_model() end ==================================
2026-01-30 10:00:57,036:INFO:choose_better activated
2026-01-30 10:00:57,036:INFO:SubProcess create_model() called ==================================
2026-01-30 10:00:57,038:INFO:Initializing create_model()
2026-01-30 10:00:57,038:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:00:57,038:INFO:Checking exceptions
2026-01-30 10:00:57,039:INFO:Importing libraries
2026-01-30 10:00:57,040:INFO:Copying training dataset
2026-01-30 10:00:57,289:INFO:Defining folds
2026-01-30 10:00:57,289:INFO:Declaring metric variables
2026-01-30 10:00:57,289:INFO:Importing untrained model
2026-01-30 10:00:57,289:INFO:Declaring custom model
2026-01-30 10:00:57,290:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:00:57,290:INFO:Starting cross validation
2026-01-30 10:00:57,291:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:01:02,991:INFO:Calculating mean and std
2026-01-30 10:01:02,991:INFO:Creating metrics dataframe
2026-01-30 10:01:02,992:INFO:Finalizing model
2026-01-30 10:01:03,951:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 10:01:04,011:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016510 seconds.
2026-01-30 10:01:04,011:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 10:01:04,011:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 10:01:04,012:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 10:01:04,012:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 10:01:04,015:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 10:01:04,015:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 10:01:05,325:INFO:Uploading results into container
2026-01-30 10:01:05,326:INFO:Uploading model into container now
2026-01-30 10:01:05,327:INFO:_master_model_container: 8
2026-01-30 10:01:05,327:INFO:_display_container: 5
2026-01-30 10:01:05,328:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:01:05,328:INFO:create_model() successfully completed......................................
2026-01-30 10:01:05,528:INFO:SubProcess create_model() end ==================================
2026-01-30 10:01:05,529:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9945
2026-01-30 10:01:05,530:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9987
2026-01-30 10:01:05,531:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2026-01-30 10:01:05,531:INFO:choose_better completed
2026-01-30 10:01:05,534:INFO:_master_model_container: 8
2026-01-30 10:01:05,534:INFO:_display_container: 4
2026-01-30 10:01:05,535:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:01:05,535:INFO:tune_model() successfully completed......................................
2026-01-30 10:01:05,691:INFO:Initializing tune_model()
2026-01-30 10:01:05,692:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 10:01:05,692:INFO:Checking exceptions
2026-01-30 10:01:05,781:INFO:Copying training dataset
2026-01-30 10:01:05,953:INFO:Checking base model
2026-01-30 10:01:05,953:INFO:Base model : Decision Tree Classifier
2026-01-30 10:01:05,954:INFO:Declaring metric variables
2026-01-30 10:01:05,955:INFO:Defining Hyperparameters
2026-01-30 10:01:06,090:INFO:Tuning with n_jobs=-1
2026-01-30 10:01:06,090:INFO:Initializing RandomizedSearchCV
2026-01-30 10:01:15,556:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 15, 'actual_estimator__criterion': 'gini'}
2026-01-30 10:01:15,557:INFO:Hyperparameter search completed
2026-01-30 10:01:15,558:INFO:SubProcess create_model() called ==================================
2026-01-30 10:01:15,559:INFO:Initializing create_model()
2026-01-30 10:01:15,559:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C295D9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 2, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 15, 'criterion': 'gini'})
2026-01-30 10:01:15,559:INFO:Checking exceptions
2026-01-30 10:01:15,559:INFO:Importing libraries
2026-01-30 10:01:15,560:INFO:Copying training dataset
2026-01-30 10:01:15,784:INFO:Defining folds
2026-01-30 10:01:15,785:INFO:Declaring metric variables
2026-01-30 10:01:15,785:INFO:Importing untrained model
2026-01-30 10:01:15,785:INFO:Declaring custom model
2026-01-30 10:01:15,786:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:01:15,786:INFO:Starting cross validation
2026-01-30 10:01:15,788:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:01:18,941:INFO:Calculating mean and std
2026-01-30 10:01:18,943:INFO:Creating metrics dataframe
2026-01-30 10:01:18,945:INFO:Finalizing model
2026-01-30 10:01:21,310:INFO:Uploading results into container
2026-01-30 10:01:21,312:INFO:Uploading model into container now
2026-01-30 10:01:21,312:INFO:_master_model_container: 9
2026-01-30 10:01:21,312:INFO:_display_container: 5
2026-01-30 10:01:21,313:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:01:21,313:INFO:create_model() successfully completed......................................
2026-01-30 10:01:21,461:INFO:SubProcess create_model() end ==================================
2026-01-30 10:01:21,461:INFO:choose_better activated
2026-01-30 10:01:21,461:INFO:SubProcess create_model() called ==================================
2026-01-30 10:01:21,462:INFO:Initializing create_model()
2026-01-30 10:01:21,462:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:01:21,462:INFO:Checking exceptions
2026-01-30 10:01:21,462:INFO:Importing libraries
2026-01-30 10:01:21,462:INFO:Copying training dataset
2026-01-30 10:01:21,673:INFO:Defining folds
2026-01-30 10:01:21,673:INFO:Declaring metric variables
2026-01-30 10:01:21,673:INFO:Importing untrained model
2026-01-30 10:01:21,674:INFO:Declaring custom model
2026-01-30 10:01:21,674:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:01:21,674:INFO:Starting cross validation
2026-01-30 10:01:21,675:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:01:26,057:INFO:Calculating mean and std
2026-01-30 10:01:26,058:INFO:Creating metrics dataframe
2026-01-30 10:01:26,061:INFO:Finalizing model
2026-01-30 10:01:29,406:INFO:Uploading results into container
2026-01-30 10:01:29,406:INFO:Uploading model into container now
2026-01-30 10:01:29,407:INFO:_master_model_container: 10
2026-01-30 10:01:29,407:INFO:_display_container: 6
2026-01-30 10:01:29,407:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:01:29,407:INFO:create_model() successfully completed......................................
2026-01-30 10:01:29,553:INFO:SubProcess create_model() end ==================================
2026-01-30 10:01:29,553:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.989
2026-01-30 10:01:29,554:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9826
2026-01-30 10:01:29,554:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-30 10:01:29,554:INFO:choose_better completed
2026-01-30 10:01:29,554:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 10:01:29,556:INFO:_master_model_container: 10
2026-01-30 10:01:29,557:INFO:_display_container: 5
2026-01-30 10:01:29,557:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:01:29,557:INFO:tune_model() successfully completed......................................
2026-01-30 10:01:29,709:INFO:Initializing predict_model()
2026-01-30 10:01:29,710:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A069E44EA0>)
2026-01-30 10:01:29,710:INFO:Checking exceptions
2026-01-30 10:01:29,710:INFO:Preloading libraries
2026-01-30 10:01:29,710:INFO:Set up data.
2026-01-30 10:01:29,736:INFO:Set up index.
2026-01-30 10:01:30,158:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\utils\generic.py:585: UserWarning: Traceback (most recent call last):
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\utils\generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\utils\generic.py", line 583, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.


2026-01-30 10:01:30,181:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.

2026-01-30 10:02:49,008:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\1960418326.py:20: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-30 10:02:51,284:INFO:PyCaret ClassificationExperiment
2026-01-30 10:02:51,284:INFO:Logging name: clf-default-name
2026-01-30 10:02:51,284:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-30 10:02:51,284:INFO:version 3.3.2
2026-01-30 10:02:51,284:INFO:Initializing setup()
2026-01-30 10:02:51,284:INFO:self.USI: 60e5
2026-01-30 10:02:51,284:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'n_jobs_param', 'data', 'X', 'idx', 'y_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'USI', 'target_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'y_train', 'X_test', 'seed', 'gpu_param', 'gpu_n_jobs_param', 'y', 'logging_param', 'pipeline', 'fold_generator', 'exp_id'}
2026-01-30 10:02:51,284:INFO:Checking environment
2026-01-30 10:02:51,284:INFO:python_version: 3.11.11
2026-01-30 10:02:51,284:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-30 10:02:51,284:INFO:machine: AMD64
2026-01-30 10:02:51,284:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-30 10:02:51,285:INFO:Memory: svmem(total=34009374720, available=12001648640, percent=64.7, used=22007726080, free=12001648640)
2026-01-30 10:02:51,286:INFO:Physical Core: 12
2026-01-30 10:02:51,286:INFO:Logical Core: 16
2026-01-30 10:02:51,286:INFO:Checking libraries
2026-01-30 10:02:51,286:INFO:System:
2026-01-30 10:02:51,286:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-30 10:02:51,286:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-30 10:02:51,286:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-30 10:02:51,286:INFO:PyCaret required dependencies:
2026-01-30 10:02:51,286:INFO:                 pip: 25.0
2026-01-30 10:02:51,286:INFO:          setuptools: 75.8.0
2026-01-30 10:02:51,286:INFO:             pycaret: 3.3.2
2026-01-30 10:02:51,286:INFO:             IPython: 9.9.0
2026-01-30 10:02:51,286:INFO:          ipywidgets: 8.1.8
2026-01-30 10:02:51,286:INFO:                tqdm: 4.67.1
2026-01-30 10:02:51,286:INFO:               numpy: 1.26.4
2026-01-30 10:02:51,286:INFO:              pandas: 2.1.4
2026-01-30 10:02:51,286:INFO:              jinja2: 3.1.6
2026-01-30 10:02:51,286:INFO:               scipy: 1.11.4
2026-01-30 10:02:51,286:INFO:              joblib: 1.3.2
2026-01-30 10:02:51,286:INFO:             sklearn: 1.4.2
2026-01-30 10:02:51,286:INFO:                pyod: 2.0.6
2026-01-30 10:02:51,286:INFO:            imblearn: 0.14.1
2026-01-30 10:02:51,286:INFO:   category_encoders: 2.7.0
2026-01-30 10:02:51,286:INFO:            lightgbm: 4.6.0
2026-01-30 10:02:51,286:INFO:               numba: 0.62.1
2026-01-30 10:02:51,287:INFO:            requests: 2.32.3
2026-01-30 10:02:51,287:INFO:          matplotlib: 3.7.5
2026-01-30 10:02:51,287:INFO:          scikitplot: 0.3.7
2026-01-30 10:02:51,287:INFO:         yellowbrick: 1.5
2026-01-30 10:02:51,287:INFO:              plotly: 5.24.1
2026-01-30 10:02:51,287:INFO:    plotly-resampler: Not installed
2026-01-30 10:02:51,287:INFO:             kaleido: 1.2.0
2026-01-30 10:02:51,287:INFO:           schemdraw: 0.15
2026-01-30 10:02:51,287:INFO:         statsmodels: 0.14.6
2026-01-30 10:02:51,287:INFO:              sktime: 0.26.0
2026-01-30 10:02:51,287:INFO:               tbats: 1.1.3
2026-01-30 10:02:51,287:INFO:            pmdarima: 2.0.4
2026-01-30 10:02:51,287:INFO:              psutil: 7.2.1
2026-01-30 10:02:51,287:INFO:          markupsafe: 3.0.3
2026-01-30 10:02:51,287:INFO:             pickle5: Not installed
2026-01-30 10:02:51,287:INFO:         cloudpickle: 3.0.0
2026-01-30 10:02:51,287:INFO:         deprecation: 2.1.0
2026-01-30 10:02:51,287:INFO:              xxhash: 3.6.0
2026-01-30 10:02:51,287:INFO:           wurlitzer: Not installed
2026-01-30 10:02:51,287:INFO:PyCaret optional dependencies:
2026-01-30 10:02:51,287:INFO:                shap: 0.44.1
2026-01-30 10:02:51,287:INFO:           interpret: 0.7.3
2026-01-30 10:02:51,287:INFO:                umap: 0.5.7
2026-01-30 10:02:51,289:INFO:     ydata_profiling: 4.18.1
2026-01-30 10:02:51,289:INFO:  explainerdashboard: 0.5.1
2026-01-30 10:02:51,289:INFO:             autoviz: Not installed
2026-01-30 10:02:51,289:INFO:           fairlearn: 0.7.0
2026-01-30 10:02:51,289:INFO:          deepchecks: Not installed
2026-01-30 10:02:51,290:INFO:             xgboost: Not installed
2026-01-30 10:02:51,291:INFO:            catboost: 1.2.8
2026-01-30 10:02:51,291:INFO:              kmodes: 0.12.2
2026-01-30 10:02:51,292:INFO:             mlxtend: 0.23.4
2026-01-30 10:02:51,292:INFO:       statsforecast: 1.5.0
2026-01-30 10:02:51,293:INFO:        tune_sklearn: Not installed
2026-01-30 10:02:51,293:INFO:                 ray: Not installed
2026-01-30 10:02:51,293:INFO:            hyperopt: 0.2.7
2026-01-30 10:02:51,294:INFO:              optuna: 4.6.0
2026-01-30 10:02:51,294:INFO:               skopt: 0.10.2
2026-01-30 10:02:51,294:INFO:              mlflow: 3.8.1
2026-01-30 10:02:51,294:INFO:              gradio: 6.3.0
2026-01-30 10:02:51,294:INFO:             fastapi: 0.128.0
2026-01-30 10:02:51,294:INFO:             uvicorn: 0.40.0
2026-01-30 10:02:51,294:INFO:              m2cgen: 0.10.0
2026-01-30 10:02:51,294:INFO:           evidently: 0.4.40
2026-01-30 10:02:51,294:INFO:               fugue: 0.8.7
2026-01-30 10:02:51,294:INFO:           streamlit: Not installed
2026-01-30 10:02:51,294:INFO:             prophet: Not installed
2026-01-30 10:02:51,294:INFO:None
2026-01-30 10:02:51,294:INFO:Set up data.
2026-01-30 10:02:51,447:INFO:Set up folding strategy.
2026-01-30 10:02:51,447:INFO:Set up train/test split.
2026-01-30 10:02:51,692:INFO:Set up index.
2026-01-30 10:02:51,703:INFO:Assigning column types.
2026-01-30 10:02:51,857:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-30 10:02:51,885:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 10:02:51,885:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:02:51,903:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:02:51,904:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:02:51,934:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 10:02:51,934:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:02:51,954:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:02:51,954:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:02:51,955:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-30 10:02:51,985:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:02:52,002:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:02:52,002:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:02:52,032:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:02:52,050:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:02:52,050:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:02:52,051:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-30 10:02:52,097:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:02:52,098:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:02:52,145:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:02:52,145:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:02:52,147:INFO:Preparing preprocessing pipeline...
2026-01-30 10:02:52,177:INFO:Set up simple imputation.
2026-01-30 10:02:52,177:INFO:Set up feature normalization.
2026-01-30 10:02:52,502:INFO:Finished creating preprocessing pipeline.
2026-01-30 10:02:52,505:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'PAID_AMOUNT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdina...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-30 10:02:52,505:INFO:Creating final display dataframe.
2026-01-30 10:02:53,362:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape      (482669, 28)
4        Transformed data shape      (482669, 28)
5   Transformed train set shape      (337868, 28)
6    Transformed test set shape      (144801, 28)
7              Numeric features                24
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                 3
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              60e5
2026-01-30 10:02:53,434:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:02:53,434:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:02:53,506:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:02:53,508:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:02:53,510:INFO:setup() successfully completed in 2.23s...............
2026-01-30 10:02:53,510:INFO:Initializing compare_models()
2026-01-30 10:02:53,510:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-30 10:02:53,510:INFO:Checking exceptions
2026-01-30 10:02:53,680:INFO:Preparing display monitor
2026-01-30 10:02:53,685:INFO:Initializing Logistic Regression
2026-01-30 10:02:53,685:INFO:Total runtime is 0.0 minutes
2026-01-30 10:02:53,685:INFO:SubProcess create_model() called ==================================
2026-01-30 10:02:53,686:INFO:Initializing create_model()
2026-01-30 10:02:53,686:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03C57F050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:02:53,686:INFO:Checking exceptions
2026-01-30 10:02:53,686:INFO:Importing libraries
2026-01-30 10:02:53,686:INFO:Copying training dataset
2026-01-30 10:02:53,946:INFO:Defining folds
2026-01-30 10:02:53,946:INFO:Declaring metric variables
2026-01-30 10:02:53,946:INFO:Importing untrained model
2026-01-30 10:02:53,947:INFO:Logistic Regression Imported successfully
2026-01-30 10:02:53,947:INFO:Starting cross validation
2026-01-30 10:02:53,947:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:02:58,109:INFO:Calculating mean and std
2026-01-30 10:02:58,114:INFO:Creating metrics dataframe
2026-01-30 10:02:58,118:INFO:Uploading results into container
2026-01-30 10:02:58,120:INFO:Uploading model into container now
2026-01-30 10:02:58,123:INFO:_master_model_container: 1
2026-01-30 10:02:58,124:INFO:_display_container: 2
2026-01-30 10:02:58,126:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-30 10:02:58,127:INFO:create_model() successfully completed......................................
2026-01-30 10:02:58,286:INFO:SubProcess create_model() end ==================================
2026-01-30 10:02:58,286:INFO:Creating metrics dataframe
2026-01-30 10:02:58,289:INFO:Initializing Decision Tree Classifier
2026-01-30 10:02:58,290:INFO:Total runtime is 0.07675575415293376 minutes
2026-01-30 10:02:58,291:INFO:SubProcess create_model() called ==================================
2026-01-30 10:02:58,291:INFO:Initializing create_model()
2026-01-30 10:02:58,292:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03C57F050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:02:58,292:INFO:Checking exceptions
2026-01-30 10:02:58,292:INFO:Importing libraries
2026-01-30 10:02:58,292:INFO:Copying training dataset
2026-01-30 10:02:58,630:INFO:Defining folds
2026-01-30 10:02:58,630:INFO:Declaring metric variables
2026-01-30 10:02:58,631:INFO:Importing untrained model
2026-01-30 10:02:58,631:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:02:58,632:INFO:Starting cross validation
2026-01-30 10:02:58,633:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:03:02,845:INFO:Calculating mean and std
2026-01-30 10:03:02,846:INFO:Creating metrics dataframe
2026-01-30 10:03:02,848:INFO:Uploading results into container
2026-01-30 10:03:02,848:INFO:Uploading model into container now
2026-01-30 10:03:02,849:INFO:_master_model_container: 2
2026-01-30 10:03:02,849:INFO:_display_container: 2
2026-01-30 10:03:02,850:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:03:02,850:INFO:create_model() successfully completed......................................
2026-01-30 10:03:03,004:INFO:SubProcess create_model() end ==================================
2026-01-30 10:03:03,004:INFO:Creating metrics dataframe
2026-01-30 10:03:03,006:INFO:Initializing Random Forest Classifier
2026-01-30 10:03:03,006:INFO:Total runtime is 0.15534850756327312 minutes
2026-01-30 10:03:03,006:INFO:SubProcess create_model() called ==================================
2026-01-30 10:03:03,006:INFO:Initializing create_model()
2026-01-30 10:03:03,007:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03C57F050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:03:03,007:INFO:Checking exceptions
2026-01-30 10:03:03,007:INFO:Importing libraries
2026-01-30 10:03:03,007:INFO:Copying training dataset
2026-01-30 10:03:03,213:INFO:Defining folds
2026-01-30 10:03:03,213:INFO:Declaring metric variables
2026-01-30 10:03:03,213:INFO:Importing untrained model
2026-01-30 10:03:03,215:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:03:03,215:INFO:Starting cross validation
2026-01-30 10:03:03,216:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:03:23,840:INFO:Calculating mean and std
2026-01-30 10:03:23,842:INFO:Creating metrics dataframe
2026-01-30 10:03:23,844:INFO:Uploading results into container
2026-01-30 10:03:23,844:INFO:Uploading model into container now
2026-01-30 10:03:23,845:INFO:_master_model_container: 3
2026-01-30 10:03:23,845:INFO:_display_container: 2
2026-01-30 10:03:23,846:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:03:23,846:INFO:create_model() successfully completed......................................
2026-01-30 10:03:23,990:INFO:SubProcess create_model() end ==================================
2026-01-30 10:03:23,991:INFO:Creating metrics dataframe
2026-01-30 10:03:23,993:INFO:Initializing Light Gradient Boosting Machine
2026-01-30 10:03:23,993:INFO:Total runtime is 0.5051378766695658 minutes
2026-01-30 10:03:23,993:INFO:SubProcess create_model() called ==================================
2026-01-30 10:03:23,993:INFO:Initializing create_model()
2026-01-30 10:03:23,993:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03C57F050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:03:23,993:INFO:Checking exceptions
2026-01-30 10:03:23,993:INFO:Importing libraries
2026-01-30 10:03:23,993:INFO:Copying training dataset
2026-01-30 10:03:24,208:INFO:Defining folds
2026-01-30 10:03:24,209:INFO:Declaring metric variables
2026-01-30 10:03:24,209:INFO:Importing untrained model
2026-01-30 10:03:24,209:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:03:24,210:INFO:Starting cross validation
2026-01-30 10:03:24,210:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:03:29,704:INFO:Calculating mean and std
2026-01-30 10:03:29,705:INFO:Creating metrics dataframe
2026-01-30 10:03:29,707:INFO:Uploading results into container
2026-01-30 10:03:29,707:INFO:Uploading model into container now
2026-01-30 10:03:29,708:INFO:_master_model_container: 4
2026-01-30 10:03:29,708:INFO:_display_container: 2
2026-01-30 10:03:29,708:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:03:29,708:INFO:create_model() successfully completed......................................
2026-01-30 10:03:29,849:INFO:SubProcess create_model() end ==================================
2026-01-30 10:03:29,849:INFO:Creating metrics dataframe
2026-01-30 10:03:29,852:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-30 10:03:29,853:INFO:Initializing create_model()
2026-01-30 10:03:29,853:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:03:29,853:INFO:Checking exceptions
2026-01-30 10:03:29,854:INFO:Importing libraries
2026-01-30 10:03:29,854:INFO:Copying training dataset
2026-01-30 10:03:30,051:INFO:Defining folds
2026-01-30 10:03:30,051:INFO:Declaring metric variables
2026-01-30 10:03:30,051:INFO:Importing untrained model
2026-01-30 10:03:30,051:INFO:Declaring custom model
2026-01-30 10:03:30,052:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:03:30,052:INFO:Cross validation set to False
2026-01-30 10:03:30,052:INFO:Fitting Model
2026-01-30 10:03:40,854:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:03:40,855:INFO:create_model() successfully completed......................................
2026-01-30 10:03:41,013:INFO:Initializing create_model()
2026-01-30 10:03:41,014:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:03:41,014:INFO:Checking exceptions
2026-01-30 10:03:41,014:INFO:Importing libraries
2026-01-30 10:03:41,014:INFO:Copying training dataset
2026-01-30 10:03:41,243:INFO:Defining folds
2026-01-30 10:03:41,243:INFO:Declaring metric variables
2026-01-30 10:03:41,243:INFO:Importing untrained model
2026-01-30 10:03:41,243:INFO:Declaring custom model
2026-01-30 10:03:41,245:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:03:41,246:INFO:Cross validation set to False
2026-01-30 10:03:41,246:INFO:Fitting Model
2026-01-30 10:03:42,175:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 10:03:42,237:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014972 seconds.
2026-01-30 10:03:42,237:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 10:03:42,237:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 10:03:42,238:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 10:03:42,239:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 10:03:42,241:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 10:03:42,242:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 10:03:43,349:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:03:43,350:INFO:create_model() successfully completed......................................
2026-01-30 10:03:43,577:INFO:Initializing create_model()
2026-01-30 10:03:43,578:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:03:43,578:INFO:Checking exceptions
2026-01-30 10:03:43,579:INFO:Importing libraries
2026-01-30 10:03:43,579:INFO:Copying training dataset
2026-01-30 10:03:43,889:INFO:Defining folds
2026-01-30 10:03:43,889:INFO:Declaring metric variables
2026-01-30 10:03:43,890:INFO:Importing untrained model
2026-01-30 10:03:43,890:INFO:Declaring custom model
2026-01-30 10:03:43,890:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:03:43,891:INFO:Cross validation set to False
2026-01-30 10:03:43,891:INFO:Fitting Model
2026-01-30 10:03:46,873:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:03:46,874:INFO:create_model() successfully completed......................................
2026-01-30 10:03:47,018:INFO:_master_model_container: 4
2026-01-30 10:03:47,019:INFO:_display_container: 2
2026-01-30 10:03:47,020:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')]
2026-01-30 10:03:47,020:INFO:compare_models() successfully completed......................................
2026-01-30 10:03:47,026:INFO:Initializing tune_model()
2026-01-30 10:03:47,026:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 10:03:47,026:INFO:Checking exceptions
2026-01-30 10:03:47,105:INFO:Copying training dataset
2026-01-30 10:03:47,268:INFO:Checking base model
2026-01-30 10:03:47,269:INFO:Base model : Random Forest Classifier
2026-01-30 10:03:47,269:INFO:Declaring metric variables
2026-01-30 10:03:47,269:INFO:Defining Hyperparameters
2026-01-30 10:03:47,414:INFO:Tuning with n_jobs=-1
2026-01-30 10:03:47,414:INFO:Initializing RandomizedSearchCV
2026-01-30 10:06:42,417:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-30 10:06:42,418:INFO:Hyperparameter search completed
2026-01-30 10:06:42,419:INFO:SubProcess create_model() called ==================================
2026-01-30 10:06:42,420:INFO:Initializing create_model()
2026-01-30 10:06:42,420:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0CCB75350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': True})
2026-01-30 10:06:42,420:INFO:Checking exceptions
2026-01-30 10:06:42,420:INFO:Importing libraries
2026-01-30 10:06:42,420:INFO:Copying training dataset
2026-01-30 10:06:42,684:INFO:Defining folds
2026-01-30 10:06:42,685:INFO:Declaring metric variables
2026-01-30 10:06:42,685:INFO:Importing untrained model
2026-01-30 10:06:42,685:INFO:Declaring custom model
2026-01-30 10:06:42,686:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:06:42,686:INFO:Starting cross validation
2026-01-30 10:06:42,687:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:07:16,513:INFO:Calculating mean and std
2026-01-30 10:07:16,515:INFO:Creating metrics dataframe
2026-01-30 10:07:16,516:INFO:Finalizing model
2026-01-30 10:07:34,329:INFO:Uploading results into container
2026-01-30 10:07:34,330:INFO:Uploading model into container now
2026-01-30 10:07:34,332:INFO:_master_model_container: 5
2026-01-30 10:07:34,332:INFO:_display_container: 3
2026-01-30 10:07:34,332:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:07:34,332:INFO:create_model() successfully completed......................................
2026-01-30 10:07:34,497:INFO:SubProcess create_model() end ==================================
2026-01-30 10:07:34,497:INFO:choose_better activated
2026-01-30 10:07:34,498:INFO:SubProcess create_model() called ==================================
2026-01-30 10:07:34,498:INFO:Initializing create_model()
2026-01-30 10:07:34,498:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:07:34,498:INFO:Checking exceptions
2026-01-30 10:07:34,499:INFO:Importing libraries
2026-01-30 10:07:34,499:INFO:Copying training dataset
2026-01-30 10:07:34,748:INFO:Defining folds
2026-01-30 10:07:34,749:INFO:Declaring metric variables
2026-01-30 10:07:34,749:INFO:Importing untrained model
2026-01-30 10:07:34,749:INFO:Declaring custom model
2026-01-30 10:07:34,749:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:07:34,750:INFO:Starting cross validation
2026-01-30 10:07:34,750:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:07:59,024:INFO:Calculating mean and std
2026-01-30 10:07:59,025:INFO:Creating metrics dataframe
2026-01-30 10:07:59,027:INFO:Finalizing model
2026-01-30 10:08:10,681:INFO:Uploading results into container
2026-01-30 10:08:10,683:INFO:Uploading model into container now
2026-01-30 10:08:10,684:INFO:_master_model_container: 6
2026-01-30 10:08:10,684:INFO:_display_container: 4
2026-01-30 10:08:10,685:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:08:10,685:INFO:create_model() successfully completed......................................
2026-01-30 10:08:10,888:INFO:SubProcess create_model() end ==================================
2026-01-30 10:08:10,889:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9985
2026-01-30 10:08:10,890:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9894
2026-01-30 10:08:10,890:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-30 10:08:10,890:INFO:choose_better completed
2026-01-30 10:08:10,891:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 10:08:10,893:INFO:_master_model_container: 6
2026-01-30 10:08:10,893:INFO:_display_container: 3
2026-01-30 10:08:10,894:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:08:10,894:INFO:tune_model() successfully completed......................................
2026-01-30 10:08:11,076:INFO:Initializing tune_model()
2026-01-30 10:08:11,076:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 10:08:11,076:INFO:Checking exceptions
2026-01-30 10:08:11,199:INFO:Copying training dataset
2026-01-30 10:08:11,358:INFO:Checking base model
2026-01-30 10:08:11,359:INFO:Base model : Light Gradient Boosting Machine
2026-01-30 10:08:11,359:INFO:Declaring metric variables
2026-01-30 10:08:11,360:INFO:Defining Hyperparameters
2026-01-30 10:08:11,531:INFO:Tuning with n_jobs=-1
2026-01-30 10:08:11,531:INFO:Initializing RandomizedSearchCV
2026-01-30 10:09:01,031:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2026-01-30 10:09:01,033:INFO:Hyperparameter search completed
2026-01-30 10:09:01,033:INFO:SubProcess create_model() called ==================================
2026-01-30 10:09:01,035:INFO:Initializing create_model()
2026-01-30 10:09:01,035:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03CF7E090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2026-01-30 10:09:01,035:INFO:Checking exceptions
2026-01-30 10:09:01,035:INFO:Importing libraries
2026-01-30 10:09:01,036:INFO:Copying training dataset
2026-01-30 10:09:01,345:INFO:Defining folds
2026-01-30 10:09:01,345:INFO:Declaring metric variables
2026-01-30 10:09:01,346:INFO:Importing untrained model
2026-01-30 10:09:01,346:INFO:Declaring custom model
2026-01-30 10:09:01,347:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:09:01,348:INFO:Starting cross validation
2026-01-30 10:09:01,349:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:09:13,730:INFO:Calculating mean and std
2026-01-30 10:09:13,733:INFO:Creating metrics dataframe
2026-01-30 10:09:13,740:INFO:Finalizing model
2026-01-30 10:09:14,645:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 10:09:14,645:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 10:09:14,645:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 10:09:14,877:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 10:09:14,877:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 10:09:14,877:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 10:09:14,878:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 10:09:14,940:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014003 seconds.
2026-01-30 10:09:14,940:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 10:09:14,940:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 10:09:14,941:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 10:09:14,942:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 10:09:14,948:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 10:09:14,948:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 10:09:19,410:INFO:Uploading results into container
2026-01-30 10:09:19,413:INFO:Uploading model into container now
2026-01-30 10:09:19,414:INFO:_master_model_container: 7
2026-01-30 10:09:19,414:INFO:_display_container: 4
2026-01-30 10:09:19,415:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:09:19,415:INFO:create_model() successfully completed......................................
2026-01-30 10:09:19,632:INFO:SubProcess create_model() end ==================================
2026-01-30 10:09:19,633:INFO:choose_better activated
2026-01-30 10:09:19,634:INFO:SubProcess create_model() called ==================================
2026-01-30 10:09:19,635:INFO:Initializing create_model()
2026-01-30 10:09:19,636:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:09:19,636:INFO:Checking exceptions
2026-01-30 10:09:19,637:INFO:Importing libraries
2026-01-30 10:09:19,637:INFO:Copying training dataset
2026-01-30 10:09:19,909:INFO:Defining folds
2026-01-30 10:09:19,910:INFO:Declaring metric variables
2026-01-30 10:09:19,910:INFO:Importing untrained model
2026-01-30 10:09:19,910:INFO:Declaring custom model
2026-01-30 10:09:19,911:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:09:19,911:INFO:Starting cross validation
2026-01-30 10:09:19,912:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:09:26,041:INFO:Calculating mean and std
2026-01-30 10:09:26,043:INFO:Creating metrics dataframe
2026-01-30 10:09:26,046:INFO:Finalizing model
2026-01-30 10:09:27,142:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 10:09:27,225:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016146 seconds.
2026-01-30 10:09:27,225:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 10:09:27,225:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 10:09:27,226:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 10:09:27,227:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 10:09:27,230:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 10:09:27,230:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 10:09:28,396:INFO:Uploading results into container
2026-01-30 10:09:28,398:INFO:Uploading model into container now
2026-01-30 10:09:28,399:INFO:_master_model_container: 8
2026-01-30 10:09:28,399:INFO:_display_container: 5
2026-01-30 10:09:28,400:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:09:28,401:INFO:create_model() successfully completed......................................
2026-01-30 10:09:28,617:INFO:SubProcess create_model() end ==================================
2026-01-30 10:09:28,619:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9945
2026-01-30 10:09:28,620:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9987
2026-01-30 10:09:28,621:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2026-01-30 10:09:28,621:INFO:choose_better completed
2026-01-30 10:09:28,623:INFO:_master_model_container: 8
2026-01-30 10:09:28,624:INFO:_display_container: 4
2026-01-30 10:09:28,624:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:09:28,624:INFO:tune_model() successfully completed......................................
2026-01-30 10:09:28,801:INFO:Initializing tune_model()
2026-01-30 10:09:28,801:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 10:09:28,801:INFO:Checking exceptions
2026-01-30 10:09:28,898:INFO:Copying training dataset
2026-01-30 10:09:29,164:INFO:Checking base model
2026-01-30 10:09:29,164:INFO:Base model : Decision Tree Classifier
2026-01-30 10:09:29,165:INFO:Declaring metric variables
2026-01-30 10:09:29,165:INFO:Defining Hyperparameters
2026-01-30 10:09:29,365:INFO:Tuning with n_jobs=-1
2026-01-30 10:09:29,365:INFO:Initializing RandomizedSearchCV
2026-01-30 10:09:39,406:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 15, 'actual_estimator__criterion': 'gini'}
2026-01-30 10:09:39,408:INFO:Hyperparameter search completed
2026-01-30 10:09:39,409:INFO:SubProcess create_model() called ==================================
2026-01-30 10:09:39,411:INFO:Initializing create_model()
2026-01-30 10:09:39,412:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03C3AF350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 2, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 15, 'criterion': 'gini'})
2026-01-30 10:09:39,412:INFO:Checking exceptions
2026-01-30 10:09:39,412:INFO:Importing libraries
2026-01-30 10:09:39,412:INFO:Copying training dataset
2026-01-30 10:09:39,656:INFO:Defining folds
2026-01-30 10:09:39,657:INFO:Declaring metric variables
2026-01-30 10:09:39,657:INFO:Importing untrained model
2026-01-30 10:09:39,657:INFO:Declaring custom model
2026-01-30 10:09:39,658:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:09:39,658:INFO:Starting cross validation
2026-01-30 10:09:39,659:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:09:42,904:INFO:Calculating mean and std
2026-01-30 10:09:42,905:INFO:Creating metrics dataframe
2026-01-30 10:09:42,906:INFO:Finalizing model
2026-01-30 10:09:45,241:INFO:Uploading results into container
2026-01-30 10:09:45,242:INFO:Uploading model into container now
2026-01-30 10:09:45,243:INFO:_master_model_container: 9
2026-01-30 10:09:45,243:INFO:_display_container: 5
2026-01-30 10:09:45,243:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:09:45,244:INFO:create_model() successfully completed......................................
2026-01-30 10:09:45,454:INFO:SubProcess create_model() end ==================================
2026-01-30 10:09:45,455:INFO:choose_better activated
2026-01-30 10:09:45,455:INFO:SubProcess create_model() called ==================================
2026-01-30 10:09:45,455:INFO:Initializing create_model()
2026-01-30 10:09:45,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:09:45,455:INFO:Checking exceptions
2026-01-30 10:09:45,456:INFO:Importing libraries
2026-01-30 10:09:45,456:INFO:Copying training dataset
2026-01-30 10:09:45,705:INFO:Defining folds
2026-01-30 10:09:45,706:INFO:Declaring metric variables
2026-01-30 10:09:45,706:INFO:Importing untrained model
2026-01-30 10:09:45,706:INFO:Declaring custom model
2026-01-30 10:09:45,706:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:09:45,706:INFO:Starting cross validation
2026-01-30 10:09:45,707:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:09:50,230:INFO:Calculating mean and std
2026-01-30 10:09:50,231:INFO:Creating metrics dataframe
2026-01-30 10:09:50,234:INFO:Finalizing model
2026-01-30 10:09:53,817:INFO:Uploading results into container
2026-01-30 10:09:53,818:INFO:Uploading model into container now
2026-01-30 10:09:53,818:INFO:_master_model_container: 10
2026-01-30 10:09:53,818:INFO:_display_container: 6
2026-01-30 10:09:53,819:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:09:53,819:INFO:create_model() successfully completed......................................
2026-01-30 10:09:53,984:INFO:SubProcess create_model() end ==================================
2026-01-30 10:09:53,985:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.989
2026-01-30 10:09:53,985:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9826
2026-01-30 10:09:53,985:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-30 10:09:53,985:INFO:choose_better completed
2026-01-30 10:09:53,986:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 10:09:53,988:INFO:_master_model_container: 10
2026-01-30 10:09:53,988:INFO:_display_container: 5
2026-01-30 10:09:53,988:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:09:53,988:INFO:tune_model() successfully completed......................................
2026-01-30 10:09:54,185:INFO:Initializing predict_model()
2026-01-30 10:09:54,185:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A0C9F74040>)
2026-01-30 10:09:54,185:INFO:Checking exceptions
2026-01-30 10:09:54,185:INFO:Preloading libraries
2026-01-30 10:09:54,186:INFO:Set up data.
2026-01-30 10:09:54,221:INFO:Set up index.
2026-01-30 10:09:54,433:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\utils\generic.py:585: UserWarning: Traceback (most recent call last):
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\utils\generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\utils\generic.py", line 583, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.


2026-01-30 10:09:54,448:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.

2026-01-30 10:09:54,720:INFO:Initializing predict_model()
2026-01-30 10:09:54,720:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A0C9F747C0>)
2026-01-30 10:09:54,720:INFO:Checking exceptions
2026-01-30 10:09:54,721:INFO:Preloading libraries
2026-01-30 10:09:54,721:INFO:Set up data.
2026-01-30 10:09:54,747:INFO:Set up index.
2026-01-30 10:09:54,968:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\utils\generic.py:585: UserWarning: Traceback (most recent call last):
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\utils\generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\utils\generic.py", line 583, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.


2026-01-30 10:09:54,994:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.

2026-01-30 10:09:55,330:INFO:Initializing predict_model()
2026-01-30 10:09:55,331:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A0C9F74860>)
2026-01-30 10:09:55,331:INFO:Checking exceptions
2026-01-30 10:09:55,331:INFO:Preloading libraries
2026-01-30 10:09:55,331:INFO:Set up data.
2026-01-30 10:09:55,375:INFO:Set up index.
2026-01-30 10:09:55,458:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\utils\generic.py:585: UserWarning: Traceback (most recent call last):
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\utils\generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\utils\generic.py", line 583, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.


2026-01-30 10:09:55,491:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.

2026-01-30 10:11:37,314:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\3053220979.py:20: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-30 10:13:01,137:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\3424666871.py:20: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-30 10:13:03,486:INFO:PyCaret ClassificationExperiment
2026-01-30 10:13:03,486:INFO:Logging name: clf-default-name
2026-01-30 10:13:03,486:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-30 10:13:03,486:INFO:version 3.3.2
2026-01-30 10:13:03,486:INFO:Initializing setup()
2026-01-30 10:13:03,486:INFO:self.USI: e91e
2026-01-30 10:13:03,486:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'n_jobs_param', 'data', 'X', 'idx', 'y_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'USI', 'target_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'y_train', 'X_test', 'seed', 'gpu_param', 'gpu_n_jobs_param', 'y', 'logging_param', 'pipeline', 'fold_generator', 'exp_id'}
2026-01-30 10:13:03,487:INFO:Checking environment
2026-01-30 10:13:03,487:INFO:python_version: 3.11.11
2026-01-30 10:13:03,487:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-30 10:13:03,487:INFO:machine: AMD64
2026-01-30 10:13:03,487:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-30 10:13:03,487:INFO:Memory: svmem(total=34009374720, available=11281739776, percent=66.8, used=22727634944, free=11281739776)
2026-01-30 10:13:03,487:INFO:Physical Core: 12
2026-01-30 10:13:03,487:INFO:Logical Core: 16
2026-01-30 10:13:03,487:INFO:Checking libraries
2026-01-30 10:13:03,487:INFO:System:
2026-01-30 10:13:03,487:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-30 10:13:03,487:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-30 10:13:03,487:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-30 10:13:03,487:INFO:PyCaret required dependencies:
2026-01-30 10:13:03,487:INFO:                 pip: 25.0
2026-01-30 10:13:03,487:INFO:          setuptools: 75.8.0
2026-01-30 10:13:03,488:INFO:             pycaret: 3.3.2
2026-01-30 10:13:03,488:INFO:             IPython: 9.9.0
2026-01-30 10:13:03,489:INFO:          ipywidgets: 8.1.8
2026-01-30 10:13:03,489:INFO:                tqdm: 4.67.1
2026-01-30 10:13:03,489:INFO:               numpy: 1.26.4
2026-01-30 10:13:03,489:INFO:              pandas: 2.1.4
2026-01-30 10:13:03,489:INFO:              jinja2: 3.1.6
2026-01-30 10:13:03,489:INFO:               scipy: 1.11.4
2026-01-30 10:13:03,489:INFO:              joblib: 1.3.2
2026-01-30 10:13:03,489:INFO:             sklearn: 1.4.2
2026-01-30 10:13:03,489:INFO:                pyod: 2.0.6
2026-01-30 10:13:03,489:INFO:            imblearn: 0.14.1
2026-01-30 10:13:03,490:INFO:   category_encoders: 2.7.0
2026-01-30 10:13:03,490:INFO:            lightgbm: 4.6.0
2026-01-30 10:13:03,490:INFO:               numba: 0.62.1
2026-01-30 10:13:03,490:INFO:            requests: 2.32.3
2026-01-30 10:13:03,490:INFO:          matplotlib: 3.7.5
2026-01-30 10:13:03,490:INFO:          scikitplot: 0.3.7
2026-01-30 10:13:03,490:INFO:         yellowbrick: 1.5
2026-01-30 10:13:03,490:INFO:              plotly: 5.24.1
2026-01-30 10:13:03,490:INFO:    plotly-resampler: Not installed
2026-01-30 10:13:03,490:INFO:             kaleido: 1.2.0
2026-01-30 10:13:03,490:INFO:           schemdraw: 0.15
2026-01-30 10:13:03,490:INFO:         statsmodels: 0.14.6
2026-01-30 10:13:03,491:INFO:              sktime: 0.26.0
2026-01-30 10:13:03,491:INFO:               tbats: 1.1.3
2026-01-30 10:13:03,491:INFO:            pmdarima: 2.0.4
2026-01-30 10:13:03,491:INFO:              psutil: 7.2.1
2026-01-30 10:13:03,491:INFO:          markupsafe: 3.0.3
2026-01-30 10:13:03,491:INFO:             pickle5: Not installed
2026-01-30 10:13:03,491:INFO:         cloudpickle: 3.0.0
2026-01-30 10:13:03,491:INFO:         deprecation: 2.1.0
2026-01-30 10:13:03,491:INFO:              xxhash: 3.6.0
2026-01-30 10:13:03,491:INFO:           wurlitzer: Not installed
2026-01-30 10:13:03,492:INFO:PyCaret optional dependencies:
2026-01-30 10:13:03,492:INFO:                shap: 0.44.1
2026-01-30 10:13:03,492:INFO:           interpret: 0.7.3
2026-01-30 10:13:03,492:INFO:                umap: 0.5.7
2026-01-30 10:13:03,492:INFO:     ydata_profiling: 4.18.1
2026-01-30 10:13:03,492:INFO:  explainerdashboard: 0.5.1
2026-01-30 10:13:03,492:INFO:             autoviz: Not installed
2026-01-30 10:13:03,492:INFO:           fairlearn: 0.7.0
2026-01-30 10:13:03,493:INFO:          deepchecks: Not installed
2026-01-30 10:13:03,493:INFO:             xgboost: Not installed
2026-01-30 10:13:03,493:INFO:            catboost: 1.2.8
2026-01-30 10:13:03,493:INFO:              kmodes: 0.12.2
2026-01-30 10:13:03,493:INFO:             mlxtend: 0.23.4
2026-01-30 10:13:03,493:INFO:       statsforecast: 1.5.0
2026-01-30 10:13:03,493:INFO:        tune_sklearn: Not installed
2026-01-30 10:13:03,493:INFO:                 ray: Not installed
2026-01-30 10:13:03,493:INFO:            hyperopt: 0.2.7
2026-01-30 10:13:03,493:INFO:              optuna: 4.6.0
2026-01-30 10:13:03,493:INFO:               skopt: 0.10.2
2026-01-30 10:13:03,495:INFO:              mlflow: 3.8.1
2026-01-30 10:13:03,495:INFO:              gradio: 6.3.0
2026-01-30 10:13:03,495:INFO:             fastapi: 0.128.0
2026-01-30 10:13:03,495:INFO:             uvicorn: 0.40.0
2026-01-30 10:13:03,495:INFO:              m2cgen: 0.10.0
2026-01-30 10:13:03,495:INFO:           evidently: 0.4.40
2026-01-30 10:13:03,495:INFO:               fugue: 0.8.7
2026-01-30 10:13:03,496:INFO:           streamlit: Not installed
2026-01-30 10:13:03,496:INFO:             prophet: Not installed
2026-01-30 10:13:03,496:INFO:None
2026-01-30 10:13:03,496:INFO:Set up data.
2026-01-30 10:13:03,641:INFO:Set up folding strategy.
2026-01-30 10:13:03,641:INFO:Set up train/test split.
2026-01-30 10:13:03,878:INFO:Set up index.
2026-01-30 10:13:03,889:INFO:Assigning column types.
2026-01-30 10:13:04,052:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-30 10:13:04,083:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 10:13:04,084:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:13:04,104:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:13:04,104:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:13:04,137:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 10:13:04,137:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:13:04,158:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:13:04,159:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:13:04,160:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-30 10:13:04,192:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:13:04,211:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:13:04,212:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:13:04,245:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:13:04,265:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:13:04,267:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:13:04,267:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-30 10:13:04,317:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:13:04,318:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:13:04,370:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:13:04,370:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:13:04,372:INFO:Preparing preprocessing pipeline...
2026-01-30 10:13:04,402:INFO:Set up simple imputation.
2026-01-30 10:13:04,403:INFO:Set up feature normalization.
2026-01-30 10:13:04,721:INFO:Finished creating preprocessing pipeline.
2026-01-30 10:13:04,724:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'PAID_AMOUNT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdina...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-30 10:13:04,725:INFO:Creating final display dataframe.
2026-01-30 10:13:05,444:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape      (482669, 28)
4        Transformed data shape      (482669, 28)
5   Transformed train set shape      (337868, 28)
6    Transformed test set shape      (144801, 28)
7              Numeric features                24
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                 3
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              e91e
2026-01-30 10:13:05,496:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:13:05,496:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:13:05,551:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:13:05,551:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:13:05,552:INFO:setup() successfully completed in 2.08s...............
2026-01-30 10:13:05,552:INFO:Initializing compare_models()
2026-01-30 10:13:05,553:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-30 10:13:05,553:INFO:Checking exceptions
2026-01-30 10:13:05,678:INFO:Preparing display monitor
2026-01-30 10:13:05,681:INFO:Initializing Logistic Regression
2026-01-30 10:13:05,682:INFO:Total runtime is 1.659393310546875e-05 minutes
2026-01-30 10:13:05,682:INFO:SubProcess create_model() called ==================================
2026-01-30 10:13:05,682:INFO:Initializing create_model()
2026-01-30 10:13:05,682:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04EFD5490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:13:05,682:INFO:Checking exceptions
2026-01-30 10:13:05,682:INFO:Importing libraries
2026-01-30 10:13:05,682:INFO:Copying training dataset
2026-01-30 10:13:05,889:INFO:Defining folds
2026-01-30 10:13:05,889:INFO:Declaring metric variables
2026-01-30 10:13:05,889:INFO:Importing untrained model
2026-01-30 10:13:05,889:INFO:Logistic Regression Imported successfully
2026-01-30 10:13:05,889:INFO:Starting cross validation
2026-01-30 10:13:05,890:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:13:09,628:INFO:Calculating mean and std
2026-01-30 10:13:09,630:INFO:Creating metrics dataframe
2026-01-30 10:13:09,633:INFO:Uploading results into container
2026-01-30 10:13:09,634:INFO:Uploading model into container now
2026-01-30 10:13:09,635:INFO:_master_model_container: 1
2026-01-30 10:13:09,635:INFO:_display_container: 2
2026-01-30 10:13:09,636:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-30 10:13:09,636:INFO:create_model() successfully completed......................................
2026-01-30 10:13:09,814:INFO:SubProcess create_model() end ==================================
2026-01-30 10:13:09,814:INFO:Creating metrics dataframe
2026-01-30 10:13:09,816:INFO:Initializing Decision Tree Classifier
2026-01-30 10:13:09,816:INFO:Total runtime is 0.06890580654144286 minutes
2026-01-30 10:13:09,817:INFO:SubProcess create_model() called ==================================
2026-01-30 10:13:09,817:INFO:Initializing create_model()
2026-01-30 10:13:09,817:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04EFD5490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:13:09,817:INFO:Checking exceptions
2026-01-30 10:13:09,817:INFO:Importing libraries
2026-01-30 10:13:09,817:INFO:Copying training dataset
2026-01-30 10:13:10,037:INFO:Defining folds
2026-01-30 10:13:10,037:INFO:Declaring metric variables
2026-01-30 10:13:10,038:INFO:Importing untrained model
2026-01-30 10:13:10,038:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:13:10,039:INFO:Starting cross validation
2026-01-30 10:13:10,039:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:13:14,147:INFO:Calculating mean and std
2026-01-30 10:13:14,148:INFO:Creating metrics dataframe
2026-01-30 10:13:14,150:INFO:Uploading results into container
2026-01-30 10:13:14,150:INFO:Uploading model into container now
2026-01-30 10:13:14,150:INFO:_master_model_container: 2
2026-01-30 10:13:14,150:INFO:_display_container: 2
2026-01-30 10:13:14,151:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:13:14,151:INFO:create_model() successfully completed......................................
2026-01-30 10:13:14,327:INFO:SubProcess create_model() end ==================================
2026-01-30 10:13:14,327:INFO:Creating metrics dataframe
2026-01-30 10:13:14,330:INFO:Initializing Random Forest Classifier
2026-01-30 10:13:14,331:INFO:Total runtime is 0.1441625396410624 minutes
2026-01-30 10:13:14,331:INFO:SubProcess create_model() called ==================================
2026-01-30 10:13:14,331:INFO:Initializing create_model()
2026-01-30 10:13:14,331:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04EFD5490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:13:14,331:INFO:Checking exceptions
2026-01-30 10:13:14,331:INFO:Importing libraries
2026-01-30 10:13:14,331:INFO:Copying training dataset
2026-01-30 10:13:14,538:INFO:Defining folds
2026-01-30 10:13:14,538:INFO:Declaring metric variables
2026-01-30 10:13:14,539:INFO:Importing untrained model
2026-01-30 10:13:14,539:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:13:14,539:INFO:Starting cross validation
2026-01-30 10:13:14,540:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:13:36,189:INFO:Calculating mean and std
2026-01-30 10:13:36,192:INFO:Creating metrics dataframe
2026-01-30 10:13:36,193:INFO:Uploading results into container
2026-01-30 10:13:36,193:INFO:Uploading model into container now
2026-01-30 10:13:36,193:INFO:_master_model_container: 3
2026-01-30 10:13:36,193:INFO:_display_container: 2
2026-01-30 10:13:36,198:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:13:36,198:INFO:create_model() successfully completed......................................
2026-01-30 10:13:36,437:INFO:SubProcess create_model() end ==================================
2026-01-30 10:13:36,437:INFO:Creating metrics dataframe
2026-01-30 10:13:36,440:INFO:Initializing Light Gradient Boosting Machine
2026-01-30 10:13:36,440:INFO:Total runtime is 0.5126409689585367 minutes
2026-01-30 10:13:36,440:INFO:SubProcess create_model() called ==================================
2026-01-30 10:13:36,440:INFO:Initializing create_model()
2026-01-30 10:13:36,441:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04EFD5490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:13:36,441:INFO:Checking exceptions
2026-01-30 10:13:36,441:INFO:Importing libraries
2026-01-30 10:13:36,441:INFO:Copying training dataset
2026-01-30 10:13:36,705:INFO:Defining folds
2026-01-30 10:13:36,706:INFO:Declaring metric variables
2026-01-30 10:13:36,706:INFO:Importing untrained model
2026-01-30 10:13:36,707:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:13:36,707:INFO:Starting cross validation
2026-01-30 10:13:36,708:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:13:42,306:INFO:Calculating mean and std
2026-01-30 10:13:42,309:INFO:Creating metrics dataframe
2026-01-30 10:13:42,312:INFO:Uploading results into container
2026-01-30 10:13:42,313:INFO:Uploading model into container now
2026-01-30 10:13:42,314:INFO:_master_model_container: 4
2026-01-30 10:13:42,314:INFO:_display_container: 2
2026-01-30 10:13:42,315:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:13:42,315:INFO:create_model() successfully completed......................................
2026-01-30 10:13:42,578:INFO:SubProcess create_model() end ==================================
2026-01-30 10:13:42,578:INFO:Creating metrics dataframe
2026-01-30 10:13:42,582:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-30 10:13:42,584:INFO:Initializing create_model()
2026-01-30 10:13:42,584:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:13:42,584:INFO:Checking exceptions
2026-01-30 10:13:42,585:INFO:Importing libraries
2026-01-30 10:13:42,585:INFO:Copying training dataset
2026-01-30 10:13:42,890:INFO:Defining folds
2026-01-30 10:13:42,890:INFO:Declaring metric variables
2026-01-30 10:13:42,890:INFO:Importing untrained model
2026-01-30 10:13:42,890:INFO:Declaring custom model
2026-01-30 10:13:42,891:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:13:42,892:INFO:Cross validation set to False
2026-01-30 10:13:42,893:INFO:Fitting Model
2026-01-30 10:13:53,868:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:13:53,869:INFO:create_model() successfully completed......................................
2026-01-30 10:13:54,076:INFO:Initializing create_model()
2026-01-30 10:13:54,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:13:54,076:INFO:Checking exceptions
2026-01-30 10:13:54,078:INFO:Importing libraries
2026-01-30 10:13:54,078:INFO:Copying training dataset
2026-01-30 10:13:54,308:INFO:Defining folds
2026-01-30 10:13:54,308:INFO:Declaring metric variables
2026-01-30 10:13:54,309:INFO:Importing untrained model
2026-01-30 10:13:54,309:INFO:Declaring custom model
2026-01-30 10:13:54,311:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:13:54,311:INFO:Cross validation set to False
2026-01-30 10:13:54,311:INFO:Fitting Model
2026-01-30 10:13:55,388:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 10:13:55,454:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015382 seconds.
2026-01-30 10:13:55,454:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 10:13:55,455:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 10:13:55,455:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 10:13:55,456:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 10:13:55,460:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 10:13:55,460:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 10:13:56,695:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:13:56,696:INFO:create_model() successfully completed......................................
2026-01-30 10:13:56,955:INFO:Initializing create_model()
2026-01-30 10:13:56,955:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:13:56,955:INFO:Checking exceptions
2026-01-30 10:13:56,957:INFO:Importing libraries
2026-01-30 10:13:56,957:INFO:Copying training dataset
2026-01-30 10:13:57,220:INFO:Defining folds
2026-01-30 10:13:57,220:INFO:Declaring metric variables
2026-01-30 10:13:57,220:INFO:Importing untrained model
2026-01-30 10:13:57,220:INFO:Declaring custom model
2026-01-30 10:13:57,221:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:13:57,221:INFO:Cross validation set to False
2026-01-30 10:13:57,222:INFO:Fitting Model
2026-01-30 10:14:00,450:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:14:00,450:INFO:create_model() successfully completed......................................
2026-01-30 10:14:00,609:INFO:_master_model_container: 4
2026-01-30 10:14:00,609:INFO:_display_container: 2
2026-01-30 10:14:00,611:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')]
2026-01-30 10:14:00,611:INFO:compare_models() successfully completed......................................
2026-01-30 10:14:00,628:INFO:Initializing tune_model()
2026-01-30 10:14:00,628:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 10:14:00,628:INFO:Checking exceptions
2026-01-30 10:14:00,717:INFO:Copying training dataset
2026-01-30 10:14:00,887:INFO:Checking base model
2026-01-30 10:14:00,888:INFO:Base model : Random Forest Classifier
2026-01-30 10:14:00,888:INFO:Declaring metric variables
2026-01-30 10:14:00,889:INFO:Defining Hyperparameters
2026-01-30 10:14:01,045:INFO:Tuning with n_jobs=-1
2026-01-30 10:14:01,045:INFO:Initializing RandomizedSearchCV
2026-01-30 10:16:54,746:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-30 10:16:54,746:INFO:Hyperparameter search completed
2026-01-30 10:16:54,746:INFO:SubProcess create_model() called ==================================
2026-01-30 10:16:54,746:INFO:Initializing create_model()
2026-01-30 10:16:54,746:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04C86B010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': True})
2026-01-30 10:16:54,746:INFO:Checking exceptions
2026-01-30 10:16:54,746:INFO:Importing libraries
2026-01-30 10:16:54,746:INFO:Copying training dataset
2026-01-30 10:16:55,039:INFO:Defining folds
2026-01-30 10:16:55,039:INFO:Declaring metric variables
2026-01-30 10:16:55,039:INFO:Importing untrained model
2026-01-30 10:16:55,039:INFO:Declaring custom model
2026-01-30 10:16:55,039:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:16:55,039:INFO:Starting cross validation
2026-01-30 10:16:55,039:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:17:27,418:INFO:Calculating mean and std
2026-01-30 10:17:27,420:INFO:Creating metrics dataframe
2026-01-30 10:17:27,422:INFO:Finalizing model
2026-01-30 10:17:43,154:INFO:Uploading results into container
2026-01-30 10:17:43,155:INFO:Uploading model into container now
2026-01-30 10:17:43,156:INFO:_master_model_container: 5
2026-01-30 10:17:43,156:INFO:_display_container: 3
2026-01-30 10:17:43,158:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:17:43,158:INFO:create_model() successfully completed......................................
2026-01-30 10:17:43,328:INFO:SubProcess create_model() end ==================================
2026-01-30 10:17:43,328:INFO:choose_better activated
2026-01-30 10:17:43,328:INFO:SubProcess create_model() called ==================================
2026-01-30 10:17:43,329:INFO:Initializing create_model()
2026-01-30 10:17:43,329:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:17:43,329:INFO:Checking exceptions
2026-01-30 10:17:43,329:INFO:Importing libraries
2026-01-30 10:17:43,330:INFO:Copying training dataset
2026-01-30 10:17:43,543:INFO:Defining folds
2026-01-30 10:17:43,544:INFO:Declaring metric variables
2026-01-30 10:17:43,544:INFO:Importing untrained model
2026-01-30 10:17:43,544:INFO:Declaring custom model
2026-01-30 10:17:43,544:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:17:43,545:INFO:Starting cross validation
2026-01-30 10:17:43,545:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:18:06,409:INFO:Calculating mean and std
2026-01-30 10:18:06,410:INFO:Creating metrics dataframe
2026-01-30 10:18:06,411:INFO:Finalizing model
2026-01-30 10:18:17,025:INFO:Uploading results into container
2026-01-30 10:18:17,027:INFO:Uploading model into container now
2026-01-30 10:18:17,027:INFO:_master_model_container: 6
2026-01-30 10:18:17,028:INFO:_display_container: 4
2026-01-30 10:18:17,029:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:18:17,029:INFO:create_model() successfully completed......................................
2026-01-30 10:18:17,231:INFO:SubProcess create_model() end ==================================
2026-01-30 10:18:17,232:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9985
2026-01-30 10:18:17,232:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9894
2026-01-30 10:18:17,232:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-30 10:18:17,233:INFO:choose_better completed
2026-01-30 10:18:17,233:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 10:18:17,236:INFO:_master_model_container: 6
2026-01-30 10:18:17,236:INFO:_display_container: 3
2026-01-30 10:18:17,237:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:18:17,237:INFO:tune_model() successfully completed......................................
2026-01-30 10:18:17,407:INFO:Initializing tune_model()
2026-01-30 10:18:17,407:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 10:18:17,408:INFO:Checking exceptions
2026-01-30 10:18:17,487:INFO:Copying training dataset
2026-01-30 10:18:17,645:INFO:Checking base model
2026-01-30 10:18:17,646:INFO:Base model : Light Gradient Boosting Machine
2026-01-30 10:18:17,647:INFO:Declaring metric variables
2026-01-30 10:18:17,647:INFO:Defining Hyperparameters
2026-01-30 10:18:17,823:INFO:Tuning with n_jobs=-1
2026-01-30 10:18:17,823:INFO:Initializing RandomizedSearchCV
2026-01-30 10:19:02,500:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2026-01-30 10:19:02,501:INFO:Hyperparameter search completed
2026-01-30 10:19:02,502:INFO:SubProcess create_model() called ==================================
2026-01-30 10:19:02,505:INFO:Initializing create_model()
2026-01-30 10:19:02,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0D02B0E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2026-01-30 10:19:02,506:INFO:Checking exceptions
2026-01-30 10:19:02,506:INFO:Importing libraries
2026-01-30 10:19:02,506:INFO:Copying training dataset
2026-01-30 10:19:02,908:INFO:Defining folds
2026-01-30 10:19:02,908:INFO:Declaring metric variables
2026-01-30 10:19:02,908:INFO:Importing untrained model
2026-01-30 10:19:02,909:INFO:Declaring custom model
2026-01-30 10:19:02,911:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:19:02,911:INFO:Starting cross validation
2026-01-30 10:19:02,912:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:19:14,173:INFO:Calculating mean and std
2026-01-30 10:19:14,174:INFO:Creating metrics dataframe
2026-01-30 10:19:14,174:INFO:Finalizing model
2026-01-30 10:19:14,938:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 10:19:14,938:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 10:19:14,938:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 10:19:15,152:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 10:19:15,154:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 10:19:15,154:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 10:19:15,154:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 10:19:15,207:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013022 seconds.
2026-01-30 10:19:15,207:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 10:19:15,207:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 10:19:15,209:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 10:19:15,210:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 10:19:15,215:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 10:19:15,215:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 10:19:18,895:INFO:Uploading results into container
2026-01-30 10:19:18,897:INFO:Uploading model into container now
2026-01-30 10:19:18,897:INFO:_master_model_container: 7
2026-01-30 10:19:18,899:INFO:_display_container: 4
2026-01-30 10:19:18,899:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:19:18,901:INFO:create_model() successfully completed......................................
2026-01-30 10:19:19,104:INFO:SubProcess create_model() end ==================================
2026-01-30 10:19:19,104:INFO:choose_better activated
2026-01-30 10:19:19,104:INFO:SubProcess create_model() called ==================================
2026-01-30 10:19:19,104:INFO:Initializing create_model()
2026-01-30 10:19:19,104:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:19:19,104:INFO:Checking exceptions
2026-01-30 10:19:19,104:INFO:Importing libraries
2026-01-30 10:19:19,104:INFO:Copying training dataset
2026-01-30 10:19:19,336:INFO:Defining folds
2026-01-30 10:19:19,336:INFO:Declaring metric variables
2026-01-30 10:19:19,336:INFO:Importing untrained model
2026-01-30 10:19:19,336:INFO:Declaring custom model
2026-01-30 10:19:19,336:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:19:19,336:INFO:Starting cross validation
2026-01-30 10:19:19,336:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:19:24,241:INFO:Calculating mean and std
2026-01-30 10:19:24,241:INFO:Creating metrics dataframe
2026-01-30 10:19:24,241:INFO:Finalizing model
2026-01-30 10:19:25,128:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 10:19:25,194:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012585 seconds.
2026-01-30 10:19:25,194:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 10:19:25,194:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 10:19:25,194:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 10:19:25,194:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 10:19:25,198:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 10:19:25,198:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 10:19:26,108:INFO:Uploading results into container
2026-01-30 10:19:26,108:INFO:Uploading model into container now
2026-01-30 10:19:26,110:INFO:_master_model_container: 8
2026-01-30 10:19:26,110:INFO:_display_container: 5
2026-01-30 10:19:26,110:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:19:26,110:INFO:create_model() successfully completed......................................
2026-01-30 10:19:26,330:INFO:SubProcess create_model() end ==================================
2026-01-30 10:19:26,330:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9945
2026-01-30 10:19:26,330:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9987
2026-01-30 10:19:26,330:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2026-01-30 10:19:26,330:INFO:choose_better completed
2026-01-30 10:19:26,330:INFO:_master_model_container: 8
2026-01-30 10:19:26,330:INFO:_display_container: 4
2026-01-30 10:19:26,330:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:19:26,330:INFO:tune_model() successfully completed......................................
2026-01-30 10:19:26,486:INFO:Initializing tune_model()
2026-01-30 10:19:26,486:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 10:19:26,486:INFO:Checking exceptions
2026-01-30 10:19:26,574:INFO:Copying training dataset
2026-01-30 10:19:26,721:INFO:Checking base model
2026-01-30 10:19:26,721:INFO:Base model : Decision Tree Classifier
2026-01-30 10:19:26,721:INFO:Declaring metric variables
2026-01-30 10:19:26,721:INFO:Defining Hyperparameters
2026-01-30 10:19:26,871:INFO:Tuning with n_jobs=-1
2026-01-30 10:19:26,871:INFO:Initializing RandomizedSearchCV
2026-01-30 10:19:35,453:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 15, 'actual_estimator__criterion': 'gini'}
2026-01-30 10:19:35,454:INFO:Hyperparameter search completed
2026-01-30 10:19:35,454:INFO:SubProcess create_model() called ==================================
2026-01-30 10:19:35,456:INFO:Initializing create_model()
2026-01-30 10:19:35,456:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C71DB810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 2, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 15, 'criterion': 'gini'})
2026-01-30 10:19:35,456:INFO:Checking exceptions
2026-01-30 10:19:35,456:INFO:Importing libraries
2026-01-30 10:19:35,456:INFO:Copying training dataset
2026-01-30 10:19:35,687:INFO:Defining folds
2026-01-30 10:19:35,687:INFO:Declaring metric variables
2026-01-30 10:19:35,687:INFO:Importing untrained model
2026-01-30 10:19:35,687:INFO:Declaring custom model
2026-01-30 10:19:35,687:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:19:35,687:INFO:Starting cross validation
2026-01-30 10:19:35,687:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:19:38,688:INFO:Calculating mean and std
2026-01-30 10:19:38,691:INFO:Creating metrics dataframe
2026-01-30 10:19:38,693:INFO:Finalizing model
2026-01-30 10:19:40,703:INFO:Uploading results into container
2026-01-30 10:19:40,703:INFO:Uploading model into container now
2026-01-30 10:19:40,703:INFO:_master_model_container: 9
2026-01-30 10:19:40,703:INFO:_display_container: 5
2026-01-30 10:19:40,703:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:19:40,703:INFO:create_model() successfully completed......................................
2026-01-30 10:19:40,853:INFO:SubProcess create_model() end ==================================
2026-01-30 10:19:40,853:INFO:choose_better activated
2026-01-30 10:19:40,853:INFO:SubProcess create_model() called ==================================
2026-01-30 10:19:40,853:INFO:Initializing create_model()
2026-01-30 10:19:40,853:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:19:40,853:INFO:Checking exceptions
2026-01-30 10:19:40,853:INFO:Importing libraries
2026-01-30 10:19:40,853:INFO:Copying training dataset
2026-01-30 10:19:41,053:INFO:Defining folds
2026-01-30 10:19:41,053:INFO:Declaring metric variables
2026-01-30 10:19:41,053:INFO:Importing untrained model
2026-01-30 10:19:41,053:INFO:Declaring custom model
2026-01-30 10:19:41,053:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:19:41,053:INFO:Starting cross validation
2026-01-30 10:19:41,053:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:19:44,805:INFO:Calculating mean and std
2026-01-30 10:19:44,808:INFO:Creating metrics dataframe
2026-01-30 10:19:44,810:INFO:Finalizing model
2026-01-30 10:19:47,703:INFO:Uploading results into container
2026-01-30 10:19:47,703:INFO:Uploading model into container now
2026-01-30 10:19:47,703:INFO:_master_model_container: 10
2026-01-30 10:19:47,703:INFO:_display_container: 6
2026-01-30 10:19:47,703:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:19:47,703:INFO:create_model() successfully completed......................................
2026-01-30 10:19:47,853:INFO:SubProcess create_model() end ==================================
2026-01-30 10:19:47,853:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.989
2026-01-30 10:19:47,853:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9826
2026-01-30 10:19:47,853:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-30 10:19:47,853:INFO:choose_better completed
2026-01-30 10:19:47,853:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 10:19:47,853:INFO:_master_model_container: 10
2026-01-30 10:19:47,853:INFO:_display_container: 5
2026-01-30 10:19:47,853:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:19:47,853:INFO:tune_model() successfully completed......................................
2026-01-30 10:19:48,047:INFO:Initializing predict_model()
2026-01-30 10:19:48,047:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A06E850F40>)
2026-01-30 10:19:48,047:INFO:Checking exceptions
2026-01-30 10:19:48,047:INFO:Preloading libraries
2026-01-30 10:19:48,047:INFO:Set up data.
2026-01-30 10:21:10,305:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\3860568932.py:20: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-30 10:21:12,595:INFO:PyCaret ClassificationExperiment
2026-01-30 10:21:12,596:INFO:Logging name: clf-default-name
2026-01-30 10:21:12,596:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-30 10:21:12,596:INFO:version 3.3.2
2026-01-30 10:21:12,596:INFO:Initializing setup()
2026-01-30 10:21:12,596:INFO:self.USI: 145c
2026-01-30 10:21:12,598:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'n_jobs_param', 'data', 'X', 'idx', 'y_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'USI', 'target_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'y_train', 'X_test', 'seed', 'gpu_param', 'gpu_n_jobs_param', 'y', 'logging_param', 'pipeline', 'fold_generator', 'exp_id'}
2026-01-30 10:21:12,598:INFO:Checking environment
2026-01-30 10:21:12,598:INFO:python_version: 3.11.11
2026-01-30 10:21:12,599:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-30 10:21:12,599:INFO:machine: AMD64
2026-01-30 10:21:12,599:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-30 10:21:12,599:INFO:Memory: svmem(total=34009374720, available=10333499392, percent=69.6, used=23675875328, free=10333499392)
2026-01-30 10:21:12,600:INFO:Physical Core: 12
2026-01-30 10:21:12,600:INFO:Logical Core: 16
2026-01-30 10:21:12,600:INFO:Checking libraries
2026-01-30 10:21:12,600:INFO:System:
2026-01-30 10:21:12,600:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-30 10:21:12,600:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-30 10:21:12,601:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-30 10:21:12,602:INFO:PyCaret required dependencies:
2026-01-30 10:21:12,602:INFO:                 pip: 25.0
2026-01-30 10:21:12,602:INFO:          setuptools: 75.8.0
2026-01-30 10:21:12,602:INFO:             pycaret: 3.3.2
2026-01-30 10:21:12,602:INFO:             IPython: 9.9.0
2026-01-30 10:21:12,602:INFO:          ipywidgets: 8.1.8
2026-01-30 10:21:12,603:INFO:                tqdm: 4.67.1
2026-01-30 10:21:12,603:INFO:               numpy: 1.26.4
2026-01-30 10:21:12,603:INFO:              pandas: 2.1.4
2026-01-30 10:21:12,603:INFO:              jinja2: 3.1.6
2026-01-30 10:21:12,603:INFO:               scipy: 1.11.4
2026-01-30 10:21:12,603:INFO:              joblib: 1.3.2
2026-01-30 10:21:12,603:INFO:             sklearn: 1.4.2
2026-01-30 10:21:12,604:INFO:                pyod: 2.0.6
2026-01-30 10:21:12,604:INFO:            imblearn: 0.14.1
2026-01-30 10:21:12,604:INFO:   category_encoders: 2.7.0
2026-01-30 10:21:12,605:INFO:            lightgbm: 4.6.0
2026-01-30 10:21:12,606:INFO:               numba: 0.62.1
2026-01-30 10:21:12,606:INFO:            requests: 2.32.3
2026-01-30 10:21:12,606:INFO:          matplotlib: 3.7.5
2026-01-30 10:21:12,606:INFO:          scikitplot: 0.3.7
2026-01-30 10:21:12,606:INFO:         yellowbrick: 1.5
2026-01-30 10:21:12,606:INFO:              plotly: 5.24.1
2026-01-30 10:21:12,607:INFO:    plotly-resampler: Not installed
2026-01-30 10:21:12,607:INFO:             kaleido: 1.2.0
2026-01-30 10:21:12,607:INFO:           schemdraw: 0.15
2026-01-30 10:21:12,607:INFO:         statsmodels: 0.14.6
2026-01-30 10:21:12,607:INFO:              sktime: 0.26.0
2026-01-30 10:21:12,607:INFO:               tbats: 1.1.3
2026-01-30 10:21:12,607:INFO:            pmdarima: 2.0.4
2026-01-30 10:21:12,608:INFO:              psutil: 7.2.1
2026-01-30 10:21:12,608:INFO:          markupsafe: 3.0.3
2026-01-30 10:21:12,608:INFO:             pickle5: Not installed
2026-01-30 10:21:12,608:INFO:         cloudpickle: 3.0.0
2026-01-30 10:21:12,609:INFO:         deprecation: 2.1.0
2026-01-30 10:21:12,609:INFO:              xxhash: 3.6.0
2026-01-30 10:21:12,609:INFO:           wurlitzer: Not installed
2026-01-30 10:21:12,609:INFO:PyCaret optional dependencies:
2026-01-30 10:21:12,609:INFO:                shap: 0.44.1
2026-01-30 10:21:12,610:INFO:           interpret: 0.7.3
2026-01-30 10:21:12,610:INFO:                umap: 0.5.7
2026-01-30 10:21:12,610:INFO:     ydata_profiling: 4.18.1
2026-01-30 10:21:12,610:INFO:  explainerdashboard: 0.5.1
2026-01-30 10:21:12,610:INFO:             autoviz: Not installed
2026-01-30 10:21:12,610:INFO:           fairlearn: 0.7.0
2026-01-30 10:21:12,611:INFO:          deepchecks: Not installed
2026-01-30 10:21:12,611:INFO:             xgboost: Not installed
2026-01-30 10:21:12,611:INFO:            catboost: 1.2.8
2026-01-30 10:21:12,611:INFO:              kmodes: 0.12.2
2026-01-30 10:21:12,611:INFO:             mlxtend: 0.23.4
2026-01-30 10:21:12,611:INFO:       statsforecast: 1.5.0
2026-01-30 10:21:12,611:INFO:        tune_sklearn: Not installed
2026-01-30 10:21:12,611:INFO:                 ray: Not installed
2026-01-30 10:21:12,612:INFO:            hyperopt: 0.2.7
2026-01-30 10:21:12,612:INFO:              optuna: 4.6.0
2026-01-30 10:21:12,613:INFO:               skopt: 0.10.2
2026-01-30 10:21:12,613:INFO:              mlflow: 3.8.1
2026-01-30 10:21:12,613:INFO:              gradio: 6.3.0
2026-01-30 10:21:12,613:INFO:             fastapi: 0.128.0
2026-01-30 10:21:12,613:INFO:             uvicorn: 0.40.0
2026-01-30 10:21:12,613:INFO:              m2cgen: 0.10.0
2026-01-30 10:21:12,614:INFO:           evidently: 0.4.40
2026-01-30 10:21:12,614:INFO:               fugue: 0.8.7
2026-01-30 10:21:12,614:INFO:           streamlit: Not installed
2026-01-30 10:21:12,614:INFO:             prophet: Not installed
2026-01-30 10:21:12,615:INFO:None
2026-01-30 10:21:12,615:INFO:Set up data.
2026-01-30 10:21:12,766:INFO:Set up folding strategy.
2026-01-30 10:21:12,766:INFO:Set up train/test split.
2026-01-30 10:21:13,022:INFO:Set up index.
2026-01-30 10:21:13,033:INFO:Assigning column types.
2026-01-30 10:21:13,185:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-30 10:21:13,202:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 10:21:13,202:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:21:13,219:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:21:13,219:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:21:13,252:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 10:21:13,252:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:21:13,272:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:21:13,285:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:21:13,285:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-30 10:21:13,302:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:21:13,335:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:21:13,335:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:21:13,352:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:21:13,385:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:21:13,385:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:21:13,386:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-30 10:21:13,435:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:21:13,435:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:21:13,468:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:21:13,484:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:21:13,486:INFO:Preparing preprocessing pipeline...
2026-01-30 10:21:13,502:INFO:Set up simple imputation.
2026-01-30 10:21:13,502:INFO:Set up feature normalization.
2026-01-30 10:21:13,801:INFO:Finished creating preprocessing pipeline.
2026-01-30 10:21:13,806:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'PAID_AMOUNT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdina...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-30 10:21:13,806:INFO:Creating final display dataframe.
2026-01-30 10:21:14,469:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape      (482669, 28)
4        Transformed data shape      (482669, 28)
5   Transformed train set shape      (337868, 28)
6    Transformed test set shape      (144801, 28)
7              Numeric features                24
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                 3
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              145c
2026-01-30 10:21:14,519:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:21:14,519:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:21:14,575:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:21:14,576:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:21:14,577:INFO:setup() successfully completed in 1.99s...............
2026-01-30 10:21:14,577:INFO:Initializing compare_models()
2026-01-30 10:21:14,577:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-30 10:21:14,577:INFO:Checking exceptions
2026-01-30 10:21:14,752:INFO:Preparing display monitor
2026-01-30 10:21:14,756:INFO:Initializing Logistic Regression
2026-01-30 10:21:14,758:INFO:Total runtime is 3.84370485941569e-05 minutes
2026-01-30 10:21:14,758:INFO:SubProcess create_model() called ==================================
2026-01-30 10:21:14,758:INFO:Initializing create_model()
2026-01-30 10:21:14,759:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04D4BB5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:21:14,759:INFO:Checking exceptions
2026-01-30 10:21:14,759:INFO:Importing libraries
2026-01-30 10:21:14,759:INFO:Copying training dataset
2026-01-30 10:21:15,018:INFO:Defining folds
2026-01-30 10:21:15,035:INFO:Declaring metric variables
2026-01-30 10:21:15,035:INFO:Importing untrained model
2026-01-30 10:21:15,035:INFO:Logistic Regression Imported successfully
2026-01-30 10:21:15,035:INFO:Starting cross validation
2026-01-30 10:21:15,035:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:21:18,459:INFO:Calculating mean and std
2026-01-30 10:21:18,459:INFO:Creating metrics dataframe
2026-01-30 10:21:18,459:INFO:Uploading results into container
2026-01-30 10:21:18,459:INFO:Uploading model into container now
2026-01-30 10:21:18,459:INFO:_master_model_container: 1
2026-01-30 10:21:18,459:INFO:_display_container: 2
2026-01-30 10:21:18,459:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-30 10:21:18,459:INFO:create_model() successfully completed......................................
2026-01-30 10:21:18,684:INFO:SubProcess create_model() end ==================================
2026-01-30 10:21:18,689:INFO:Creating metrics dataframe
2026-01-30 10:21:18,693:INFO:Initializing Decision Tree Classifier
2026-01-30 10:21:18,693:INFO:Total runtime is 0.06562891801198324 minutes
2026-01-30 10:21:18,693:INFO:SubProcess create_model() called ==================================
2026-01-30 10:21:18,694:INFO:Initializing create_model()
2026-01-30 10:21:18,694:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04D4BB5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:21:18,694:INFO:Checking exceptions
2026-01-30 10:21:18,694:INFO:Importing libraries
2026-01-30 10:21:18,694:INFO:Copying training dataset
2026-01-30 10:21:18,918:INFO:Defining folds
2026-01-30 10:21:18,918:INFO:Declaring metric variables
2026-01-30 10:21:18,918:INFO:Importing untrained model
2026-01-30 10:21:18,918:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:21:18,918:INFO:Starting cross validation
2026-01-30 10:21:18,918:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:21:22,798:INFO:Calculating mean and std
2026-01-30 10:21:22,802:INFO:Creating metrics dataframe
2026-01-30 10:21:22,802:INFO:Uploading results into container
2026-01-30 10:21:22,802:INFO:Uploading model into container now
2026-01-30 10:21:22,802:INFO:_master_model_container: 2
2026-01-30 10:21:22,802:INFO:_display_container: 2
2026-01-30 10:21:22,802:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:21:22,802:INFO:create_model() successfully completed......................................
2026-01-30 10:21:22,968:INFO:SubProcess create_model() end ==================================
2026-01-30 10:21:22,968:INFO:Creating metrics dataframe
2026-01-30 10:21:22,984:INFO:Initializing Random Forest Classifier
2026-01-30 10:21:22,985:INFO:Total runtime is 0.13715004920959473 minutes
2026-01-30 10:21:22,985:INFO:SubProcess create_model() called ==================================
2026-01-30 10:21:22,985:INFO:Initializing create_model()
2026-01-30 10:21:22,985:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04D4BB5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:21:22,985:INFO:Checking exceptions
2026-01-30 10:21:22,985:INFO:Importing libraries
2026-01-30 10:21:22,985:INFO:Copying training dataset
2026-01-30 10:21:23,168:INFO:Defining folds
2026-01-30 10:21:23,184:INFO:Declaring metric variables
2026-01-30 10:21:23,184:INFO:Importing untrained model
2026-01-30 10:21:23,185:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:21:23,185:INFO:Starting cross validation
2026-01-30 10:21:23,185:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:21:42,090:INFO:Calculating mean and std
2026-01-30 10:21:42,093:INFO:Creating metrics dataframe
2026-01-30 10:21:42,096:INFO:Uploading results into container
2026-01-30 10:21:42,097:INFO:Uploading model into container now
2026-01-30 10:21:42,098:INFO:_master_model_container: 3
2026-01-30 10:21:42,098:INFO:_display_container: 2
2026-01-30 10:21:42,099:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:21:42,099:INFO:create_model() successfully completed......................................
2026-01-30 10:21:42,299:INFO:SubProcess create_model() end ==================================
2026-01-30 10:21:42,299:INFO:Creating metrics dataframe
2026-01-30 10:21:42,302:INFO:Initializing Light Gradient Boosting Machine
2026-01-30 10:21:42,302:INFO:Total runtime is 0.4591042995452881 minutes
2026-01-30 10:21:42,302:INFO:SubProcess create_model() called ==================================
2026-01-30 10:21:42,302:INFO:Initializing create_model()
2026-01-30 10:21:42,302:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04D4BB5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:21:42,302:INFO:Checking exceptions
2026-01-30 10:21:42,302:INFO:Importing libraries
2026-01-30 10:21:42,302:INFO:Copying training dataset
2026-01-30 10:21:42,659:INFO:Defining folds
2026-01-30 10:21:42,659:INFO:Declaring metric variables
2026-01-30 10:21:42,660:INFO:Importing untrained model
2026-01-30 10:21:42,660:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:21:42,661:INFO:Starting cross validation
2026-01-30 10:21:42,662:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:21:47,834:INFO:Calculating mean and std
2026-01-30 10:21:47,834:INFO:Creating metrics dataframe
2026-01-30 10:21:47,834:INFO:Uploading results into container
2026-01-30 10:21:47,834:INFO:Uploading model into container now
2026-01-30 10:21:47,834:INFO:_master_model_container: 4
2026-01-30 10:21:47,834:INFO:_display_container: 2
2026-01-30 10:21:47,834:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:21:47,834:INFO:create_model() successfully completed......................................
2026-01-30 10:21:48,002:INFO:SubProcess create_model() end ==================================
2026-01-30 10:21:48,002:INFO:Creating metrics dataframe
2026-01-30 10:21:48,002:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-30 10:21:48,002:INFO:Initializing create_model()
2026-01-30 10:21:48,002:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:21:48,002:INFO:Checking exceptions
2026-01-30 10:21:48,002:INFO:Importing libraries
2026-01-30 10:21:48,002:INFO:Copying training dataset
2026-01-30 10:21:48,204:INFO:Defining folds
2026-01-30 10:21:48,204:INFO:Declaring metric variables
2026-01-30 10:21:48,204:INFO:Importing untrained model
2026-01-30 10:21:48,204:INFO:Declaring custom model
2026-01-30 10:21:48,204:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:21:48,204:INFO:Cross validation set to False
2026-01-30 10:21:48,204:INFO:Fitting Model
2026-01-30 10:21:57,854:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:21:57,854:INFO:create_model() successfully completed......................................
2026-01-30 10:21:58,035:INFO:Initializing create_model()
2026-01-30 10:21:58,037:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:21:58,037:INFO:Checking exceptions
2026-01-30 10:21:58,037:INFO:Importing libraries
2026-01-30 10:21:58,037:INFO:Copying training dataset
2026-01-30 10:21:58,220:INFO:Defining folds
2026-01-30 10:21:58,220:INFO:Declaring metric variables
2026-01-30 10:21:58,220:INFO:Importing untrained model
2026-01-30 10:21:58,220:INFO:Declaring custom model
2026-01-30 10:21:58,220:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:21:58,220:INFO:Cross validation set to False
2026-01-30 10:21:58,220:INFO:Fitting Model
2026-01-30 10:21:59,128:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 10:21:59,195:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012663 seconds.
2026-01-30 10:21:59,197:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 10:21:59,197:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 10:21:59,197:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 10:21:59,197:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 10:21:59,199:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 10:21:59,199:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 10:22:00,091:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:22:00,093:INFO:create_model() successfully completed......................................
2026-01-30 10:22:00,323:INFO:Initializing create_model()
2026-01-30 10:22:00,323:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:22:00,323:INFO:Checking exceptions
2026-01-30 10:22:00,323:INFO:Importing libraries
2026-01-30 10:22:00,323:INFO:Copying training dataset
2026-01-30 10:22:00,541:INFO:Defining folds
2026-01-30 10:22:00,541:INFO:Declaring metric variables
2026-01-30 10:22:00,541:INFO:Importing untrained model
2026-01-30 10:22:00,541:INFO:Declaring custom model
2026-01-30 10:22:00,541:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:22:00,541:INFO:Cross validation set to False
2026-01-30 10:22:00,541:INFO:Fitting Model
2026-01-30 10:22:03,792:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:22:03,792:INFO:create_model() successfully completed......................................
2026-01-30 10:22:03,961:INFO:_master_model_container: 4
2026-01-30 10:22:03,961:INFO:_display_container: 2
2026-01-30 10:22:03,962:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')]
2026-01-30 10:22:03,962:INFO:compare_models() successfully completed......................................
2026-01-30 10:22:03,981:INFO:Initializing tune_model()
2026-01-30 10:22:03,981:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 10:22:03,981:INFO:Checking exceptions
2026-01-30 10:22:04,054:INFO:Copying training dataset
2026-01-30 10:22:04,216:INFO:Checking base model
2026-01-30 10:22:04,216:INFO:Base model : Random Forest Classifier
2026-01-30 10:22:04,217:INFO:Declaring metric variables
2026-01-30 10:22:04,218:INFO:Defining Hyperparameters
2026-01-30 10:22:04,367:INFO:Tuning with n_jobs=-1
2026-01-30 10:22:04,367:INFO:Initializing RandomizedSearchCV
2026-01-30 10:24:50,387:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-30 10:24:50,387:INFO:Hyperparameter search completed
2026-01-30 10:24:50,387:INFO:SubProcess create_model() called ==================================
2026-01-30 10:24:50,387:INFO:Initializing create_model()
2026-01-30 10:24:50,387:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03CE1AC90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': True})
2026-01-30 10:24:50,387:INFO:Checking exceptions
2026-01-30 10:24:50,387:INFO:Importing libraries
2026-01-30 10:24:50,387:INFO:Copying training dataset
2026-01-30 10:24:50,615:INFO:Defining folds
2026-01-30 10:24:50,615:INFO:Declaring metric variables
2026-01-30 10:24:50,615:INFO:Importing untrained model
2026-01-30 10:24:50,615:INFO:Declaring custom model
2026-01-30 10:24:50,615:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:24:50,615:INFO:Starting cross validation
2026-01-30 10:24:50,615:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:25:23,142:INFO:Calculating mean and std
2026-01-30 10:25:23,143:INFO:Creating metrics dataframe
2026-01-30 10:25:23,145:INFO:Finalizing model
2026-01-30 10:25:39,015:INFO:Uploading results into container
2026-01-30 10:25:39,015:INFO:Uploading model into container now
2026-01-30 10:25:39,015:INFO:_master_model_container: 5
2026-01-30 10:25:39,025:INFO:_display_container: 3
2026-01-30 10:25:39,025:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:25:39,025:INFO:create_model() successfully completed......................................
2026-01-30 10:25:39,198:INFO:SubProcess create_model() end ==================================
2026-01-30 10:25:39,198:INFO:choose_better activated
2026-01-30 10:25:39,198:INFO:SubProcess create_model() called ==================================
2026-01-30 10:25:39,198:INFO:Initializing create_model()
2026-01-30 10:25:39,198:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:25:39,198:INFO:Checking exceptions
2026-01-30 10:25:39,214:INFO:Importing libraries
2026-01-30 10:25:39,214:INFO:Copying training dataset
2026-01-30 10:25:39,465:INFO:Defining folds
2026-01-30 10:25:39,465:INFO:Declaring metric variables
2026-01-30 10:25:39,465:INFO:Importing untrained model
2026-01-30 10:25:39,465:INFO:Declaring custom model
2026-01-30 10:25:39,465:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:25:39,465:INFO:Starting cross validation
2026-01-30 10:25:39,465:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:26:00,508:INFO:Calculating mean and std
2026-01-30 10:26:00,508:INFO:Creating metrics dataframe
2026-01-30 10:26:00,508:INFO:Finalizing model
2026-01-30 10:26:10,631:INFO:Uploading results into container
2026-01-30 10:26:10,631:INFO:Uploading model into container now
2026-01-30 10:26:10,631:INFO:_master_model_container: 6
2026-01-30 10:26:10,631:INFO:_display_container: 4
2026-01-30 10:26:10,631:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:26:10,631:INFO:create_model() successfully completed......................................
2026-01-30 10:26:10,814:INFO:SubProcess create_model() end ==================================
2026-01-30 10:26:10,814:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9985
2026-01-30 10:26:10,814:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9894
2026-01-30 10:26:10,814:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-30 10:26:10,814:INFO:choose_better completed
2026-01-30 10:26:10,814:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 10:26:10,814:INFO:_master_model_container: 6
2026-01-30 10:26:10,814:INFO:_display_container: 3
2026-01-30 10:26:10,814:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:26:10,814:INFO:tune_model() successfully completed......................................
2026-01-30 10:26:10,981:INFO:Initializing tune_model()
2026-01-30 10:26:10,981:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 10:26:10,981:INFO:Checking exceptions
2026-01-30 10:26:11,074:INFO:Copying training dataset
2026-01-30 10:26:11,198:INFO:Checking base model
2026-01-30 10:26:11,198:INFO:Base model : Light Gradient Boosting Machine
2026-01-30 10:26:11,213:INFO:Declaring metric variables
2026-01-30 10:26:11,213:INFO:Defining Hyperparameters
2026-01-30 10:26:11,364:INFO:Tuning with n_jobs=-1
2026-01-30 10:26:11,364:INFO:Initializing RandomizedSearchCV
2026-01-30 10:26:56,428:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2026-01-30 10:26:56,428:INFO:Hyperparameter search completed
2026-01-30 10:26:56,428:INFO:SubProcess create_model() called ==================================
2026-01-30 10:26:56,428:INFO:Initializing create_model()
2026-01-30 10:26:56,428:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04825E010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2026-01-30 10:26:56,428:INFO:Checking exceptions
2026-01-30 10:26:56,428:INFO:Importing libraries
2026-01-30 10:26:56,428:INFO:Copying training dataset
2026-01-30 10:26:56,682:INFO:Defining folds
2026-01-30 10:26:56,682:INFO:Declaring metric variables
2026-01-30 10:26:56,682:INFO:Importing untrained model
2026-01-30 10:26:56,682:INFO:Declaring custom model
2026-01-30 10:26:56,686:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:26:56,686:INFO:Starting cross validation
2026-01-30 10:26:56,686:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:27:07,423:INFO:Calculating mean and std
2026-01-30 10:27:07,423:INFO:Creating metrics dataframe
2026-01-30 10:27:07,431:INFO:Finalizing model
2026-01-30 10:27:08,197:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 10:27:08,197:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 10:27:08,197:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 10:27:08,445:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 10:27:08,445:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 10:27:08,445:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 10:27:08,447:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 10:27:08,513:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016019 seconds.
2026-01-30 10:27:08,513:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 10:27:08,513:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 10:27:08,515:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 10:27:08,516:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 10:27:08,520:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 10:27:08,522:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 10:27:12,001:INFO:Uploading results into container
2026-01-30 10:27:12,003:INFO:Uploading model into container now
2026-01-30 10:27:12,003:INFO:_master_model_container: 7
2026-01-30 10:27:12,005:INFO:_display_container: 4
2026-01-30 10:27:12,005:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:27:12,007:INFO:create_model() successfully completed......................................
2026-01-30 10:27:12,236:INFO:SubProcess create_model() end ==================================
2026-01-30 10:27:12,238:INFO:choose_better activated
2026-01-30 10:27:12,238:INFO:SubProcess create_model() called ==================================
2026-01-30 10:27:12,238:INFO:Initializing create_model()
2026-01-30 10:27:12,238:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:27:12,240:INFO:Checking exceptions
2026-01-30 10:27:12,240:INFO:Importing libraries
2026-01-30 10:27:12,240:INFO:Copying training dataset
2026-01-30 10:27:12,447:INFO:Defining folds
2026-01-30 10:27:12,447:INFO:Declaring metric variables
2026-01-30 10:27:12,447:INFO:Importing untrained model
2026-01-30 10:27:12,447:INFO:Declaring custom model
2026-01-30 10:27:12,447:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:27:12,447:INFO:Starting cross validation
2026-01-30 10:27:12,447:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:27:17,530:INFO:Calculating mean and std
2026-01-30 10:27:17,530:INFO:Creating metrics dataframe
2026-01-30 10:27:17,530:INFO:Finalizing model
2026-01-30 10:27:18,457:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 10:27:18,505:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014214 seconds.
2026-01-30 10:27:18,505:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 10:27:18,505:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 10:27:18,505:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 10:27:18,505:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 10:27:18,509:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 10:27:18,509:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 10:27:19,411:INFO:Uploading results into container
2026-01-30 10:27:19,411:INFO:Uploading model into container now
2026-01-30 10:27:19,413:INFO:_master_model_container: 8
2026-01-30 10:27:19,413:INFO:_display_container: 5
2026-01-30 10:27:19,414:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:27:19,414:INFO:create_model() successfully completed......................................
2026-01-30 10:27:19,630:INFO:SubProcess create_model() end ==================================
2026-01-30 10:27:19,630:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9945
2026-01-30 10:27:19,630:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9987
2026-01-30 10:27:19,630:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2026-01-30 10:27:19,630:INFO:choose_better completed
2026-01-30 10:27:19,646:INFO:_master_model_container: 8
2026-01-30 10:27:19,646:INFO:_display_container: 4
2026-01-30 10:27:19,646:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:27:19,646:INFO:tune_model() successfully completed......................................
2026-01-30 10:27:19,815:INFO:Initializing tune_model()
2026-01-30 10:27:19,815:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 10:27:19,815:INFO:Checking exceptions
2026-01-30 10:27:19,904:INFO:Copying training dataset
2026-01-30 10:27:20,064:INFO:Checking base model
2026-01-30 10:27:20,064:INFO:Base model : Decision Tree Classifier
2026-01-30 10:27:20,064:INFO:Declaring metric variables
2026-01-30 10:27:20,064:INFO:Defining Hyperparameters
2026-01-30 10:27:20,234:INFO:Tuning with n_jobs=-1
2026-01-30 10:27:20,234:INFO:Initializing RandomizedSearchCV
2026-01-30 10:27:29,011:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 15, 'actual_estimator__criterion': 'gini'}
2026-01-30 10:27:29,011:INFO:Hyperparameter search completed
2026-01-30 10:27:29,011:INFO:SubProcess create_model() called ==================================
2026-01-30 10:27:29,011:INFO:Initializing create_model()
2026-01-30 10:27:29,011:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03C4F3150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 2, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 15, 'criterion': 'gini'})
2026-01-30 10:27:29,011:INFO:Checking exceptions
2026-01-30 10:27:29,011:INFO:Importing libraries
2026-01-30 10:27:29,011:INFO:Copying training dataset
2026-01-30 10:27:29,231:INFO:Defining folds
2026-01-30 10:27:29,231:INFO:Declaring metric variables
2026-01-30 10:27:29,231:INFO:Importing untrained model
2026-01-30 10:27:29,231:INFO:Declaring custom model
2026-01-30 10:27:29,233:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:27:29,233:INFO:Starting cross validation
2026-01-30 10:27:29,233:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:27:32,303:INFO:Calculating mean and std
2026-01-30 10:27:32,303:INFO:Creating metrics dataframe
2026-01-30 10:27:32,309:INFO:Finalizing model
2026-01-30 10:27:34,346:INFO:Uploading results into container
2026-01-30 10:27:34,346:INFO:Uploading model into container now
2026-01-30 10:27:34,346:INFO:_master_model_container: 9
2026-01-30 10:27:34,346:INFO:_display_container: 5
2026-01-30 10:27:34,346:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:27:34,346:INFO:create_model() successfully completed......................................
2026-01-30 10:27:34,498:INFO:SubProcess create_model() end ==================================
2026-01-30 10:27:34,498:INFO:choose_better activated
2026-01-30 10:27:34,498:INFO:SubProcess create_model() called ==================================
2026-01-30 10:27:34,498:INFO:Initializing create_model()
2026-01-30 10:27:34,498:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:27:34,498:INFO:Checking exceptions
2026-01-30 10:27:34,498:INFO:Importing libraries
2026-01-30 10:27:34,498:INFO:Copying training dataset
2026-01-30 10:27:34,732:INFO:Defining folds
2026-01-30 10:27:34,732:INFO:Declaring metric variables
2026-01-30 10:27:34,732:INFO:Importing untrained model
2026-01-30 10:27:34,732:INFO:Declaring custom model
2026-01-30 10:27:34,733:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:27:34,733:INFO:Starting cross validation
2026-01-30 10:27:34,734:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:27:38,519:INFO:Calculating mean and std
2026-01-30 10:27:38,520:INFO:Creating metrics dataframe
2026-01-30 10:27:38,520:INFO:Finalizing model
2026-01-30 10:27:41,735:INFO:Uploading results into container
2026-01-30 10:27:41,736:INFO:Uploading model into container now
2026-01-30 10:27:41,736:INFO:_master_model_container: 10
2026-01-30 10:27:41,736:INFO:_display_container: 6
2026-01-30 10:27:41,736:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:27:41,736:INFO:create_model() successfully completed......................................
2026-01-30 10:27:41,897:INFO:SubProcess create_model() end ==================================
2026-01-30 10:27:41,898:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.989
2026-01-30 10:27:41,898:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9826
2026-01-30 10:27:41,898:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-30 10:27:41,898:INFO:choose_better completed
2026-01-30 10:27:41,898:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 10:27:41,900:INFO:_master_model_container: 10
2026-01-30 10:27:41,901:INFO:_display_container: 5
2026-01-30 10:27:41,901:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:27:41,901:INFO:tune_model() successfully completed......................................
2026-01-30 10:27:42,069:INFO:Initializing predict_model()
2026-01-30 10:27:42,069:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A0C9F760C0>)
2026-01-30 10:27:42,069:INFO:Checking exceptions
2026-01-30 10:27:42,069:INFO:Preloading libraries
2026-01-30 10:27:42,069:INFO:Set up data.
2026-01-30 10:27:42,079:INFO:Set up index.
2026-01-30 10:27:42,613:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\utils\_array_api.py:290: RuntimeWarning: invalid value encountered in cast

2026-01-30 10:29:40,062:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\503664258.py:20: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-30 10:29:42,260:INFO:PyCaret ClassificationExperiment
2026-01-30 10:29:42,260:INFO:Logging name: clf-default-name
2026-01-30 10:29:42,260:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-30 10:29:42,260:INFO:version 3.3.2
2026-01-30 10:29:42,260:INFO:Initializing setup()
2026-01-30 10:29:42,260:INFO:self.USI: 16e5
2026-01-30 10:29:42,260:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'n_jobs_param', 'data', 'X', 'idx', 'y_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'USI', 'target_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'y_train', 'X_test', 'seed', 'gpu_param', 'gpu_n_jobs_param', 'y', 'logging_param', 'pipeline', 'fold_generator', 'exp_id'}
2026-01-30 10:29:42,260:INFO:Checking environment
2026-01-30 10:29:42,260:INFO:python_version: 3.11.11
2026-01-30 10:29:42,260:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-30 10:29:42,260:INFO:machine: AMD64
2026-01-30 10:29:42,260:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-30 10:29:42,261:INFO:Memory: svmem(total=34009374720, available=9681879040, percent=71.5, used=24327495680, free=9681879040)
2026-01-30 10:29:42,261:INFO:Physical Core: 12
2026-01-30 10:29:42,261:INFO:Logical Core: 16
2026-01-30 10:29:42,261:INFO:Checking libraries
2026-01-30 10:29:42,261:INFO:System:
2026-01-30 10:29:42,261:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-30 10:29:42,261:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-30 10:29:42,261:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-30 10:29:42,261:INFO:PyCaret required dependencies:
2026-01-30 10:29:42,261:INFO:                 pip: 25.0
2026-01-30 10:29:42,261:INFO:          setuptools: 75.8.0
2026-01-30 10:29:42,261:INFO:             pycaret: 3.3.2
2026-01-30 10:29:42,261:INFO:             IPython: 9.9.0
2026-01-30 10:29:42,261:INFO:          ipywidgets: 8.1.8
2026-01-30 10:29:42,261:INFO:                tqdm: 4.67.1
2026-01-30 10:29:42,261:INFO:               numpy: 1.26.4
2026-01-30 10:29:42,261:INFO:              pandas: 2.1.4
2026-01-30 10:29:42,261:INFO:              jinja2: 3.1.6
2026-01-30 10:29:42,261:INFO:               scipy: 1.11.4
2026-01-30 10:29:42,261:INFO:              joblib: 1.3.2
2026-01-30 10:29:42,261:INFO:             sklearn: 1.4.2
2026-01-30 10:29:42,262:INFO:                pyod: 2.0.6
2026-01-30 10:29:42,262:INFO:            imblearn: 0.14.1
2026-01-30 10:29:42,262:INFO:   category_encoders: 2.7.0
2026-01-30 10:29:42,262:INFO:            lightgbm: 4.6.0
2026-01-30 10:29:42,262:INFO:               numba: 0.62.1
2026-01-30 10:29:42,262:INFO:            requests: 2.32.3
2026-01-30 10:29:42,262:INFO:          matplotlib: 3.7.5
2026-01-30 10:29:42,263:INFO:          scikitplot: 0.3.7
2026-01-30 10:29:42,263:INFO:         yellowbrick: 1.5
2026-01-30 10:29:42,264:INFO:              plotly: 5.24.1
2026-01-30 10:29:42,264:INFO:    plotly-resampler: Not installed
2026-01-30 10:29:42,264:INFO:             kaleido: 1.2.0
2026-01-30 10:29:42,264:INFO:           schemdraw: 0.15
2026-01-30 10:29:42,264:INFO:         statsmodels: 0.14.6
2026-01-30 10:29:42,264:INFO:              sktime: 0.26.0
2026-01-30 10:29:42,264:INFO:               tbats: 1.1.3
2026-01-30 10:29:42,264:INFO:            pmdarima: 2.0.4
2026-01-30 10:29:42,264:INFO:              psutil: 7.2.1
2026-01-30 10:29:42,264:INFO:          markupsafe: 3.0.3
2026-01-30 10:29:42,264:INFO:             pickle5: Not installed
2026-01-30 10:29:42,264:INFO:         cloudpickle: 3.0.0
2026-01-30 10:29:42,264:INFO:         deprecation: 2.1.0
2026-01-30 10:29:42,264:INFO:              xxhash: 3.6.0
2026-01-30 10:29:42,264:INFO:           wurlitzer: Not installed
2026-01-30 10:29:42,264:INFO:PyCaret optional dependencies:
2026-01-30 10:29:42,264:INFO:                shap: 0.44.1
2026-01-30 10:29:42,264:INFO:           interpret: 0.7.3
2026-01-30 10:29:42,264:INFO:                umap: 0.5.7
2026-01-30 10:29:42,264:INFO:     ydata_profiling: 4.18.1
2026-01-30 10:29:42,265:INFO:  explainerdashboard: 0.5.1
2026-01-30 10:29:42,265:INFO:             autoviz: Not installed
2026-01-30 10:29:42,265:INFO:           fairlearn: 0.7.0
2026-01-30 10:29:42,265:INFO:          deepchecks: Not installed
2026-01-30 10:29:42,265:INFO:             xgboost: Not installed
2026-01-30 10:29:42,265:INFO:            catboost: 1.2.8
2026-01-30 10:29:42,265:INFO:              kmodes: 0.12.2
2026-01-30 10:29:42,265:INFO:             mlxtend: 0.23.4
2026-01-30 10:29:42,265:INFO:       statsforecast: 1.5.0
2026-01-30 10:29:42,265:INFO:        tune_sklearn: Not installed
2026-01-30 10:29:42,265:INFO:                 ray: Not installed
2026-01-30 10:29:42,265:INFO:            hyperopt: 0.2.7
2026-01-30 10:29:42,265:INFO:              optuna: 4.6.0
2026-01-30 10:29:42,265:INFO:               skopt: 0.10.2
2026-01-30 10:29:42,265:INFO:              mlflow: 3.8.1
2026-01-30 10:29:42,266:INFO:              gradio: 6.3.0
2026-01-30 10:29:42,266:INFO:             fastapi: 0.128.0
2026-01-30 10:29:42,266:INFO:             uvicorn: 0.40.0
2026-01-30 10:29:42,266:INFO:              m2cgen: 0.10.0
2026-01-30 10:29:42,266:INFO:           evidently: 0.4.40
2026-01-30 10:29:42,266:INFO:               fugue: 0.8.7
2026-01-30 10:29:42,266:INFO:           streamlit: Not installed
2026-01-30 10:29:42,266:INFO:             prophet: Not installed
2026-01-30 10:29:42,266:INFO:None
2026-01-30 10:29:42,266:INFO:Set up data.
2026-01-30 10:29:42,413:INFO:Set up folding strategy.
2026-01-30 10:29:42,413:INFO:Set up train/test split.
2026-01-30 10:29:42,631:INFO:Set up index.
2026-01-30 10:29:42,645:INFO:Assigning column types.
2026-01-30 10:29:42,800:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-30 10:29:42,830:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 10:29:42,830:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:29:42,849:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:29:42,849:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:29:42,882:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 10:29:42,882:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:29:42,906:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:29:42,906:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:29:42,906:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-30 10:29:42,944:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:29:42,961:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:29:42,961:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:29:43,000:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:29:43,022:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:29:43,022:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:29:43,024:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-30 10:29:43,078:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:29:43,078:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:29:43,144:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:29:43,144:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:29:43,145:INFO:Preparing preprocessing pipeline...
2026-01-30 10:29:43,177:INFO:Set up simple imputation.
2026-01-30 10:29:43,177:INFO:Set up feature normalization.
2026-01-30 10:29:43,473:INFO:Finished creating preprocessing pipeline.
2026-01-30 10:29:43,476:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'PAID_AMOUNT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdina...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-30 10:29:43,477:INFO:Creating final display dataframe.
2026-01-30 10:29:44,132:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape      (482669, 28)
4        Transformed data shape      (482669, 28)
5   Transformed train set shape      (337868, 28)
6    Transformed test set shape      (144801, 28)
7              Numeric features                24
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                 3
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              16e5
2026-01-30 10:29:44,178:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:29:44,178:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:29:44,232:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:29:44,232:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:29:44,232:INFO:setup() successfully completed in 1.99s...............
2026-01-30 10:29:44,232:INFO:Initializing compare_models()
2026-01-30 10:29:44,232:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-30 10:29:44,232:INFO:Checking exceptions
2026-01-30 10:29:44,365:INFO:Preparing display monitor
2026-01-30 10:29:44,378:INFO:Initializing Logistic Regression
2026-01-30 10:29:44,378:INFO:Total runtime is 0.0 minutes
2026-01-30 10:29:44,378:INFO:SubProcess create_model() called ==================================
2026-01-30 10:29:44,378:INFO:Initializing create_model()
2026-01-30 10:29:44,378:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A053B26C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:29:44,378:INFO:Checking exceptions
2026-01-30 10:29:44,378:INFO:Importing libraries
2026-01-30 10:29:44,378:INFO:Copying training dataset
2026-01-30 10:29:44,595:INFO:Defining folds
2026-01-30 10:29:44,607:INFO:Declaring metric variables
2026-01-30 10:29:44,607:INFO:Importing untrained model
2026-01-30 10:29:44,610:INFO:Logistic Regression Imported successfully
2026-01-30 10:29:44,610:INFO:Starting cross validation
2026-01-30 10:29:44,611:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:29:48,600:INFO:Calculating mean and std
2026-01-30 10:29:48,602:INFO:Creating metrics dataframe
2026-01-30 10:29:48,606:INFO:Uploading results into container
2026-01-30 10:29:48,607:INFO:Uploading model into container now
2026-01-30 10:29:48,608:INFO:_master_model_container: 1
2026-01-30 10:29:48,608:INFO:_display_container: 2
2026-01-30 10:29:48,609:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-30 10:29:48,610:INFO:create_model() successfully completed......................................
2026-01-30 10:29:48,839:INFO:SubProcess create_model() end ==================================
2026-01-30 10:29:48,839:INFO:Creating metrics dataframe
2026-01-30 10:29:48,841:INFO:Initializing Decision Tree Classifier
2026-01-30 10:29:48,841:INFO:Total runtime is 0.07438475290934245 minutes
2026-01-30 10:29:48,841:INFO:SubProcess create_model() called ==================================
2026-01-30 10:29:48,841:INFO:Initializing create_model()
2026-01-30 10:29:48,843:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A053B26C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:29:48,843:INFO:Checking exceptions
2026-01-30 10:29:48,843:INFO:Importing libraries
2026-01-30 10:29:48,843:INFO:Copying training dataset
2026-01-30 10:29:49,049:INFO:Defining folds
2026-01-30 10:29:49,050:INFO:Declaring metric variables
2026-01-30 10:29:49,050:INFO:Importing untrained model
2026-01-30 10:29:49,051:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:29:49,051:INFO:Starting cross validation
2026-01-30 10:29:49,052:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:29:53,220:INFO:Calculating mean and std
2026-01-30 10:29:53,220:INFO:Creating metrics dataframe
2026-01-30 10:29:53,220:INFO:Uploading results into container
2026-01-30 10:29:53,230:INFO:Uploading model into container now
2026-01-30 10:29:53,230:INFO:_master_model_container: 2
2026-01-30 10:29:53,230:INFO:_display_container: 2
2026-01-30 10:29:53,230:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:29:53,230:INFO:create_model() successfully completed......................................
2026-01-30 10:29:53,397:INFO:SubProcess create_model() end ==================================
2026-01-30 10:29:53,397:INFO:Creating metrics dataframe
2026-01-30 10:29:53,397:INFO:Initializing Random Forest Classifier
2026-01-30 10:29:53,397:INFO:Total runtime is 0.15030624866485595 minutes
2026-01-30 10:29:53,397:INFO:SubProcess create_model() called ==================================
2026-01-30 10:29:53,412:INFO:Initializing create_model()
2026-01-30 10:29:53,412:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A053B26C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:29:53,412:INFO:Checking exceptions
2026-01-30 10:29:53,412:INFO:Importing libraries
2026-01-30 10:29:53,412:INFO:Copying training dataset
2026-01-30 10:29:53,640:INFO:Defining folds
2026-01-30 10:29:53,641:INFO:Declaring metric variables
2026-01-30 10:29:53,641:INFO:Importing untrained model
2026-01-30 10:29:53,642:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:29:53,642:INFO:Starting cross validation
2026-01-30 10:29:53,643:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:30:15,330:INFO:Calculating mean and std
2026-01-30 10:30:15,332:INFO:Creating metrics dataframe
2026-01-30 10:30:15,333:INFO:Uploading results into container
2026-01-30 10:30:15,334:INFO:Uploading model into container now
2026-01-30 10:30:15,334:INFO:_master_model_container: 3
2026-01-30 10:30:15,334:INFO:_display_container: 2
2026-01-30 10:30:15,335:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:30:15,335:INFO:create_model() successfully completed......................................
2026-01-30 10:30:15,528:INFO:SubProcess create_model() end ==================================
2026-01-30 10:30:15,528:INFO:Creating metrics dataframe
2026-01-30 10:30:15,530:INFO:Initializing Light Gradient Boosting Machine
2026-01-30 10:30:15,531:INFO:Total runtime is 0.5191914717356364 minutes
2026-01-30 10:30:15,531:INFO:SubProcess create_model() called ==================================
2026-01-30 10:30:15,531:INFO:Initializing create_model()
2026-01-30 10:30:15,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A053B26C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:30:15,531:INFO:Checking exceptions
2026-01-30 10:30:15,531:INFO:Importing libraries
2026-01-30 10:30:15,531:INFO:Copying training dataset
2026-01-30 10:30:15,731:INFO:Defining folds
2026-01-30 10:30:15,731:INFO:Declaring metric variables
2026-01-30 10:30:15,731:INFO:Importing untrained model
2026-01-30 10:30:15,731:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:30:15,731:INFO:Starting cross validation
2026-01-30 10:30:15,731:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:30:20,756:INFO:Calculating mean and std
2026-01-30 10:30:20,760:INFO:Creating metrics dataframe
2026-01-30 10:30:20,762:INFO:Uploading results into container
2026-01-30 10:30:20,762:INFO:Uploading model into container now
2026-01-30 10:30:20,764:INFO:_master_model_container: 4
2026-01-30 10:30:20,764:INFO:_display_container: 2
2026-01-30 10:30:20,764:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:30:20,764:INFO:create_model() successfully completed......................................
2026-01-30 10:30:20,931:INFO:SubProcess create_model() end ==================================
2026-01-30 10:30:20,931:INFO:Creating metrics dataframe
2026-01-30 10:30:20,931:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-30 10:30:20,931:INFO:Initializing create_model()
2026-01-30 10:30:20,931:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:30:20,931:INFO:Checking exceptions
2026-01-30 10:30:20,931:INFO:Importing libraries
2026-01-30 10:30:20,931:INFO:Copying training dataset
2026-01-30 10:30:21,158:INFO:Defining folds
2026-01-30 10:30:21,158:INFO:Declaring metric variables
2026-01-30 10:30:21,158:INFO:Importing untrained model
2026-01-30 10:30:21,159:INFO:Declaring custom model
2026-01-30 10:30:21,159:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:30:21,160:INFO:Cross validation set to False
2026-01-30 10:30:21,160:INFO:Fitting Model
2026-01-30 10:30:31,944:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:30:31,944:INFO:create_model() successfully completed......................................
2026-01-30 10:30:32,131:INFO:Initializing create_model()
2026-01-30 10:30:32,131:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:30:32,131:INFO:Checking exceptions
2026-01-30 10:30:32,131:INFO:Importing libraries
2026-01-30 10:30:32,131:INFO:Copying training dataset
2026-01-30 10:30:32,327:INFO:Defining folds
2026-01-30 10:30:32,327:INFO:Declaring metric variables
2026-01-30 10:30:32,327:INFO:Importing untrained model
2026-01-30 10:30:32,327:INFO:Declaring custom model
2026-01-30 10:30:32,327:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:30:32,327:INFO:Cross validation set to False
2026-01-30 10:30:32,327:INFO:Fitting Model
2026-01-30 10:30:33,228:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 10:30:33,294:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016880 seconds.
2026-01-30 10:30:33,294:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 10:30:33,294:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 10:30:33,295:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 10:30:33,296:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 10:30:33,298:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 10:30:33,299:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 10:30:34,233:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:30:34,233:INFO:create_model() successfully completed......................................
2026-01-30 10:30:34,476:INFO:Initializing create_model()
2026-01-30 10:30:34,476:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:30:34,476:INFO:Checking exceptions
2026-01-30 10:30:34,477:INFO:Importing libraries
2026-01-30 10:30:34,477:INFO:Copying training dataset
2026-01-30 10:30:34,677:INFO:Defining folds
2026-01-30 10:30:34,677:INFO:Declaring metric variables
2026-01-30 10:30:34,677:INFO:Importing untrained model
2026-01-30 10:30:34,677:INFO:Declaring custom model
2026-01-30 10:30:34,693:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:30:34,693:INFO:Cross validation set to False
2026-01-30 10:30:34,693:INFO:Fitting Model
2026-01-30 10:30:37,611:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:30:37,611:INFO:create_model() successfully completed......................................
2026-01-30 10:30:37,814:INFO:_master_model_container: 4
2026-01-30 10:30:37,814:INFO:_display_container: 2
2026-01-30 10:30:37,815:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')]
2026-01-30 10:30:37,815:INFO:compare_models() successfully completed......................................
2026-01-30 10:30:37,836:INFO:Initializing tune_model()
2026-01-30 10:30:37,836:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 10:30:37,836:INFO:Checking exceptions
2026-01-30 10:30:37,932:INFO:Copying training dataset
2026-01-30 10:30:38,088:INFO:Checking base model
2026-01-30 10:30:38,088:INFO:Base model : Random Forest Classifier
2026-01-30 10:30:38,089:INFO:Declaring metric variables
2026-01-30 10:30:38,089:INFO:Defining Hyperparameters
2026-01-30 10:30:38,295:INFO:Tuning with n_jobs=-1
2026-01-30 10:30:38,295:INFO:Initializing RandomizedSearchCV
2026-01-30 10:33:26,929:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-30 10:33:26,930:INFO:Hyperparameter search completed
2026-01-30 10:33:26,931:INFO:SubProcess create_model() called ==================================
2026-01-30 10:33:26,932:INFO:Initializing create_model()
2026-01-30 10:33:26,932:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04D500ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': True})
2026-01-30 10:33:26,932:INFO:Checking exceptions
2026-01-30 10:33:26,932:INFO:Importing libraries
2026-01-30 10:33:26,932:INFO:Copying training dataset
2026-01-30 10:33:27,310:INFO:Defining folds
2026-01-30 10:33:27,311:INFO:Declaring metric variables
2026-01-30 10:33:27,311:INFO:Importing untrained model
2026-01-30 10:33:27,311:INFO:Declaring custom model
2026-01-30 10:33:27,313:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:33:27,313:INFO:Starting cross validation
2026-01-30 10:33:27,314:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:33:59,581:INFO:Calculating mean and std
2026-01-30 10:33:59,582:INFO:Creating metrics dataframe
2026-01-30 10:33:59,585:INFO:Finalizing model
2026-01-30 10:34:16,224:INFO:Uploading results into container
2026-01-30 10:34:16,225:INFO:Uploading model into container now
2026-01-30 10:34:16,225:INFO:_master_model_container: 5
2026-01-30 10:34:16,226:INFO:_display_container: 3
2026-01-30 10:34:16,227:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:34:16,227:INFO:create_model() successfully completed......................................
2026-01-30 10:34:16,435:INFO:SubProcess create_model() end ==================================
2026-01-30 10:34:16,435:INFO:choose_better activated
2026-01-30 10:34:16,436:INFO:SubProcess create_model() called ==================================
2026-01-30 10:34:16,436:INFO:Initializing create_model()
2026-01-30 10:34:16,436:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:34:16,436:INFO:Checking exceptions
2026-01-30 10:34:16,437:INFO:Importing libraries
2026-01-30 10:34:16,437:INFO:Copying training dataset
2026-01-30 10:34:16,707:INFO:Defining folds
2026-01-30 10:34:16,707:INFO:Declaring metric variables
2026-01-30 10:34:16,707:INFO:Importing untrained model
2026-01-30 10:34:16,707:INFO:Declaring custom model
2026-01-30 10:34:16,708:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:34:16,708:INFO:Starting cross validation
2026-01-30 10:34:16,709:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:34:37,749:INFO:Calculating mean and std
2026-01-30 10:34:37,750:INFO:Creating metrics dataframe
2026-01-30 10:34:37,752:INFO:Finalizing model
2026-01-30 10:34:47,818:INFO:Uploading results into container
2026-01-30 10:34:47,819:INFO:Uploading model into container now
2026-01-30 10:34:47,819:INFO:_master_model_container: 6
2026-01-30 10:34:47,819:INFO:_display_container: 4
2026-01-30 10:34:47,820:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:34:47,820:INFO:create_model() successfully completed......................................
2026-01-30 10:34:48,011:INFO:SubProcess create_model() end ==================================
2026-01-30 10:34:48,012:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9985
2026-01-30 10:34:48,012:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9894
2026-01-30 10:34:48,013:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-30 10:34:48,013:INFO:choose_better completed
2026-01-30 10:34:48,013:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 10:34:48,015:INFO:_master_model_container: 6
2026-01-30 10:34:48,015:INFO:_display_container: 3
2026-01-30 10:34:48,016:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:34:48,016:INFO:tune_model() successfully completed......................................
2026-01-30 10:34:48,194:INFO:Initializing tune_model()
2026-01-30 10:34:48,194:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 10:34:48,194:INFO:Checking exceptions
2026-01-30 10:34:48,280:INFO:Copying training dataset
2026-01-30 10:34:48,422:INFO:Checking base model
2026-01-30 10:34:48,423:INFO:Base model : Light Gradient Boosting Machine
2026-01-30 10:34:48,424:INFO:Declaring metric variables
2026-01-30 10:34:48,424:INFO:Defining Hyperparameters
2026-01-30 10:34:48,595:INFO:Tuning with n_jobs=-1
2026-01-30 10:34:48,595:INFO:Initializing RandomizedSearchCV
2026-01-30 10:35:31,506:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2026-01-30 10:35:31,508:INFO:Hyperparameter search completed
2026-01-30 10:35:31,509:INFO:SubProcess create_model() called ==================================
2026-01-30 10:35:31,511:INFO:Initializing create_model()
2026-01-30 10:35:31,511:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03D5BDD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2026-01-30 10:35:31,511:INFO:Checking exceptions
2026-01-30 10:35:31,512:INFO:Importing libraries
2026-01-30 10:35:31,512:INFO:Copying training dataset
2026-01-30 10:35:31,895:INFO:Defining folds
2026-01-30 10:35:31,895:INFO:Declaring metric variables
2026-01-30 10:35:31,896:INFO:Importing untrained model
2026-01-30 10:35:31,897:INFO:Declaring custom model
2026-01-30 10:35:31,898:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:35:31,898:INFO:Starting cross validation
2026-01-30 10:35:31,899:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:35:42,866:INFO:Calculating mean and std
2026-01-30 10:35:42,867:INFO:Creating metrics dataframe
2026-01-30 10:35:42,869:INFO:Finalizing model
2026-01-30 10:35:43,596:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 10:35:43,596:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 10:35:43,596:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 10:35:43,809:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 10:35:43,809:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 10:35:43,809:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 10:35:43,810:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 10:35:43,858:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012089 seconds.
2026-01-30 10:35:43,859:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 10:35:43,859:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 10:35:43,859:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 10:35:43,860:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 10:35:43,865:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 10:35:43,865:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 10:35:47,739:INFO:Uploading results into container
2026-01-30 10:35:47,741:INFO:Uploading model into container now
2026-01-30 10:35:47,742:INFO:_master_model_container: 7
2026-01-30 10:35:47,742:INFO:_display_container: 4
2026-01-30 10:35:47,744:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:35:47,744:INFO:create_model() successfully completed......................................
2026-01-30 10:35:47,984:INFO:SubProcess create_model() end ==================================
2026-01-30 10:35:47,984:INFO:choose_better activated
2026-01-30 10:35:47,985:INFO:SubProcess create_model() called ==================================
2026-01-30 10:35:47,987:INFO:Initializing create_model()
2026-01-30 10:35:47,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:35:47,987:INFO:Checking exceptions
2026-01-30 10:35:47,988:INFO:Importing libraries
2026-01-30 10:35:47,988:INFO:Copying training dataset
2026-01-30 10:35:48,217:INFO:Defining folds
2026-01-30 10:35:48,217:INFO:Declaring metric variables
2026-01-30 10:35:48,218:INFO:Importing untrained model
2026-01-30 10:35:48,218:INFO:Declaring custom model
2026-01-30 10:35:48,218:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:35:48,219:INFO:Starting cross validation
2026-01-30 10:35:48,219:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:35:53,108:INFO:Calculating mean and std
2026-01-30 10:35:53,109:INFO:Creating metrics dataframe
2026-01-30 10:35:53,113:INFO:Finalizing model
2026-01-30 10:35:54,065:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 10:35:54,127:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011123 seconds.
2026-01-30 10:35:54,128:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 10:35:54,128:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 10:35:54,128:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 10:35:54,129:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 10:35:54,131:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 10:35:54,131:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 10:35:55,217:INFO:Uploading results into container
2026-01-30 10:35:55,218:INFO:Uploading model into container now
2026-01-30 10:35:55,218:INFO:_master_model_container: 8
2026-01-30 10:35:55,218:INFO:_display_container: 5
2026-01-30 10:35:55,220:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:35:55,220:INFO:create_model() successfully completed......................................
2026-01-30 10:35:55,461:INFO:SubProcess create_model() end ==================================
2026-01-30 10:35:55,462:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9945
2026-01-30 10:35:55,462:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9987
2026-01-30 10:35:55,463:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2026-01-30 10:35:55,463:INFO:choose_better completed
2026-01-30 10:35:55,465:INFO:_master_model_container: 8
2026-01-30 10:35:55,466:INFO:_display_container: 4
2026-01-30 10:35:55,467:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:35:55,467:INFO:tune_model() successfully completed......................................
2026-01-30 10:35:55,648:INFO:Initializing tune_model()
2026-01-30 10:35:55,649:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 10:35:55,649:INFO:Checking exceptions
2026-01-30 10:35:55,731:INFO:Copying training dataset
2026-01-30 10:35:55,861:INFO:Checking base model
2026-01-30 10:35:55,861:INFO:Base model : Decision Tree Classifier
2026-01-30 10:35:55,861:INFO:Declaring metric variables
2026-01-30 10:35:55,861:INFO:Defining Hyperparameters
2026-01-30 10:35:56,031:INFO:Tuning with n_jobs=-1
2026-01-30 10:35:56,032:INFO:Initializing RandomizedSearchCV
2026-01-30 10:36:04,537:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 15, 'actual_estimator__criterion': 'gini'}
2026-01-30 10:36:04,538:INFO:Hyperparameter search completed
2026-01-30 10:36:04,539:INFO:SubProcess create_model() called ==================================
2026-01-30 10:36:04,540:INFO:Initializing create_model()
2026-01-30 10:36:04,541:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03CFFBBD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 2, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 15, 'criterion': 'gini'})
2026-01-30 10:36:04,541:INFO:Checking exceptions
2026-01-30 10:36:04,541:INFO:Importing libraries
2026-01-30 10:36:04,541:INFO:Copying training dataset
2026-01-30 10:36:04,768:INFO:Defining folds
2026-01-30 10:36:04,768:INFO:Declaring metric variables
2026-01-30 10:36:04,768:INFO:Importing untrained model
2026-01-30 10:36:04,769:INFO:Declaring custom model
2026-01-30 10:36:04,769:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:36:04,769:INFO:Starting cross validation
2026-01-30 10:36:04,770:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:36:07,925:INFO:Calculating mean and std
2026-01-30 10:36:07,926:INFO:Creating metrics dataframe
2026-01-30 10:36:07,927:INFO:Finalizing model
2026-01-30 10:36:09,906:INFO:Uploading results into container
2026-01-30 10:36:09,907:INFO:Uploading model into container now
2026-01-30 10:36:09,908:INFO:_master_model_container: 9
2026-01-30 10:36:09,908:INFO:_display_container: 5
2026-01-30 10:36:09,909:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:36:09,909:INFO:create_model() successfully completed......................................
2026-01-30 10:36:10,078:INFO:SubProcess create_model() end ==================================
2026-01-30 10:36:10,079:INFO:choose_better activated
2026-01-30 10:36:10,079:INFO:SubProcess create_model() called ==================================
2026-01-30 10:36:10,079:INFO:Initializing create_model()
2026-01-30 10:36:10,079:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:36:10,079:INFO:Checking exceptions
2026-01-30 10:36:10,080:INFO:Importing libraries
2026-01-30 10:36:10,080:INFO:Copying training dataset
2026-01-30 10:36:10,320:INFO:Defining folds
2026-01-30 10:36:10,320:INFO:Declaring metric variables
2026-01-30 10:36:10,320:INFO:Importing untrained model
2026-01-30 10:36:10,320:INFO:Declaring custom model
2026-01-30 10:36:10,321:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:36:10,321:INFO:Starting cross validation
2026-01-30 10:36:10,322:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:36:14,511:INFO:Calculating mean and std
2026-01-30 10:36:14,513:INFO:Creating metrics dataframe
2026-01-30 10:36:14,515:INFO:Finalizing model
2026-01-30 10:36:17,699:INFO:Uploading results into container
2026-01-30 10:36:17,699:INFO:Uploading model into container now
2026-01-30 10:36:17,700:INFO:_master_model_container: 10
2026-01-30 10:36:17,700:INFO:_display_container: 6
2026-01-30 10:36:17,700:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:36:17,700:INFO:create_model() successfully completed......................................
2026-01-30 10:36:17,869:INFO:SubProcess create_model() end ==================================
2026-01-30 10:36:17,869:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.989
2026-01-30 10:36:17,870:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9826
2026-01-30 10:36:17,870:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-30 10:36:17,870:INFO:choose_better completed
2026-01-30 10:36:17,870:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 10:36:17,873:INFO:_master_model_container: 10
2026-01-30 10:36:17,873:INFO:_display_container: 5
2026-01-30 10:36:17,873:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:36:17,873:INFO:tune_model() successfully completed......................................
2026-01-30 10:36:18,059:INFO:Initializing predict_model()
2026-01-30 10:36:18,060:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A03C59F240>)
2026-01-30 10:36:18,060:INFO:Checking exceptions
2026-01-30 10:36:18,060:INFO:Preloading libraries
2026-01-30 10:36:18,060:INFO:Set up data.
2026-01-30 10:36:18,072:INFO:Set up index.
2026-01-30 10:36:18,475:INFO:Initializing predict_model()
2026-01-30 10:36:18,475:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A06E850F40>)
2026-01-30 10:36:18,475:INFO:Checking exceptions
2026-01-30 10:36:18,476:INFO:Preloading libraries
2026-01-30 10:36:18,476:INFO:Set up data.
2026-01-30 10:36:18,489:INFO:Set up index.
2026-01-30 10:36:18,913:INFO:Initializing predict_model()
2026-01-30 10:36:18,915:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A03D1FF1A0>)
2026-01-30 10:36:18,915:INFO:Checking exceptions
2026-01-30 10:36:18,915:INFO:Preloading libraries
2026-01-30 10:36:18,915:INFO:Set up data.
2026-01-30 10:36:18,925:INFO:Set up index.
2026-01-30 10:36:19,330:INFO:Initializing plot_model()
2026-01-30 10:36:19,330:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 10:36:19,330:INFO:Checking exceptions
2026-01-30 10:36:19,448:INFO:Preloading libraries
2026-01-30 10:36:19,528:INFO:Copying training dataset
2026-01-30 10:36:19,528:INFO:Plot type: feature
2026-01-30 10:36:19,529:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 10:36:19,907:INFO:Visual Rendered Successfully
2026-01-30 10:36:20,081:INFO:plot_model() successfully completed......................................
2026-01-30 10:36:20,092:INFO:Initializing plot_model()
2026-01-30 10:36:20,093:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature_all, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 10:36:20,093:INFO:Checking exceptions
2026-01-30 10:36:20,220:INFO:Preloading libraries
2026-01-30 10:36:20,282:INFO:Copying training dataset
2026-01-30 10:36:20,282:INFO:Plot type: feature_all
2026-01-30 10:36:20,502:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 10:36:20,982:INFO:Visual Rendered Successfully
2026-01-30 10:36:21,156:INFO:plot_model() successfully completed......................................
2026-01-30 10:36:21,171:INFO:Initializing save_model()
2026-01-30 10:36:21,171:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), model_name=..\datos\04. Modelos\modelo_final_explicable, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'PAID_AMOUNT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdina...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-30 10:36:21,171:INFO:Adding model into prep_pipe
2026-01-30 10:36:21,288:INFO:..\datos\04. Modelos\modelo_final_explicable.pkl saved in current working directory
2026-01-30 10:36:21,295:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'PAID_AMOUNT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdinario_def__c',
                                             'CU_precioAplicado_def__c',
                                             'PO...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=42, verbose=0,
                                        warm_start=False))],
         verbose=False)
2026-01-30 10:36:21,296:INFO:save_model() successfully completed......................................
2026-01-30 11:55:06,857:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-30 11:55:06,857:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-30 11:55:06,857:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-30 11:55:06,857:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-30 11:55:10,035:INFO:Initializing load_model()
2026-01-30 11:55:10,035:INFO:load_model(model_name=..\datos\04. Modelos\modelo_final_explicable, platform=None, authentication=None, verbose=True)
2026-01-30 11:57:07,233:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\503664258.py:20: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-30 11:57:09,574:INFO:PyCaret ClassificationExperiment
2026-01-30 11:57:09,574:INFO:Logging name: clf-default-name
2026-01-30 11:57:09,574:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-30 11:57:09,574:INFO:version 3.3.2
2026-01-30 11:57:09,574:INFO:Initializing setup()
2026-01-30 11:57:09,574:INFO:self.USI: b17d
2026-01-30 11:57:09,574:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'n_jobs_param', 'data', 'X', 'idx', 'y_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'USI', 'target_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'y_train', 'X_test', 'seed', 'gpu_param', 'gpu_n_jobs_param', 'y', 'logging_param', 'pipeline', 'fold_generator', 'exp_id'}
2026-01-30 11:57:09,574:INFO:Checking environment
2026-01-30 11:57:09,574:INFO:python_version: 3.11.11
2026-01-30 11:57:09,574:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-30 11:57:09,574:INFO:machine: AMD64
2026-01-30 11:57:09,574:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-30 11:57:09,574:INFO:Memory: svmem(total=34009374720, available=14170279936, percent=58.3, used=19839094784, free=14170279936)
2026-01-30 11:57:09,574:INFO:Physical Core: 12
2026-01-30 11:57:09,574:INFO:Logical Core: 16
2026-01-30 11:57:09,574:INFO:Checking libraries
2026-01-30 11:57:09,574:INFO:System:
2026-01-30 11:57:09,574:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-30 11:57:09,574:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-30 11:57:09,574:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-30 11:57:09,574:INFO:PyCaret required dependencies:
2026-01-30 11:57:09,574:INFO:                 pip: 25.0
2026-01-30 11:57:09,574:INFO:          setuptools: 75.8.0
2026-01-30 11:57:09,574:INFO:             pycaret: 3.3.2
2026-01-30 11:57:09,574:INFO:             IPython: 9.9.0
2026-01-30 11:57:09,574:INFO:          ipywidgets: 8.1.8
2026-01-30 11:57:09,574:INFO:                tqdm: 4.67.1
2026-01-30 11:57:09,574:INFO:               numpy: 1.26.4
2026-01-30 11:57:09,574:INFO:              pandas: 2.1.4
2026-01-30 11:57:09,574:INFO:              jinja2: 3.1.6
2026-01-30 11:57:09,574:INFO:               scipy: 1.11.4
2026-01-30 11:57:09,574:INFO:              joblib: 1.3.2
2026-01-30 11:57:09,574:INFO:             sklearn: 1.4.2
2026-01-30 11:57:09,574:INFO:                pyod: 2.0.6
2026-01-30 11:57:09,574:INFO:            imblearn: 0.14.1
2026-01-30 11:57:09,574:INFO:   category_encoders: 2.7.0
2026-01-30 11:57:09,574:INFO:            lightgbm: 4.6.0
2026-01-30 11:57:09,574:INFO:               numba: 0.62.1
2026-01-30 11:57:09,574:INFO:            requests: 2.32.3
2026-01-30 11:57:09,574:INFO:          matplotlib: 3.7.5
2026-01-30 11:57:09,574:INFO:          scikitplot: 0.3.7
2026-01-30 11:57:09,574:INFO:         yellowbrick: 1.5
2026-01-30 11:57:09,574:INFO:              plotly: 5.24.1
2026-01-30 11:57:09,574:INFO:    plotly-resampler: Not installed
2026-01-30 11:57:09,574:INFO:             kaleido: 1.2.0
2026-01-30 11:57:09,574:INFO:           schemdraw: 0.15
2026-01-30 11:57:09,574:INFO:         statsmodels: 0.14.6
2026-01-30 11:57:09,574:INFO:              sktime: 0.26.0
2026-01-30 11:57:09,574:INFO:               tbats: 1.1.3
2026-01-30 11:57:09,574:INFO:            pmdarima: 2.0.4
2026-01-30 11:57:09,574:INFO:              psutil: 7.2.1
2026-01-30 11:57:09,574:INFO:          markupsafe: 3.0.3
2026-01-30 11:57:09,574:INFO:             pickle5: Not installed
2026-01-30 11:57:09,574:INFO:         cloudpickle: 3.0.0
2026-01-30 11:57:09,574:INFO:         deprecation: 2.1.0
2026-01-30 11:57:09,574:INFO:              xxhash: 3.6.0
2026-01-30 11:57:09,574:INFO:           wurlitzer: Not installed
2026-01-30 11:57:09,574:INFO:PyCaret optional dependencies:
2026-01-30 11:57:09,574:INFO:                shap: 0.44.1
2026-01-30 11:57:09,574:INFO:           interpret: 0.7.3
2026-01-30 11:57:09,574:INFO:                umap: 0.5.7
2026-01-30 11:57:09,574:INFO:     ydata_profiling: 4.18.1
2026-01-30 11:57:09,574:INFO:  explainerdashboard: 0.5.1
2026-01-30 11:57:09,574:INFO:             autoviz: Not installed
2026-01-30 11:57:09,574:INFO:           fairlearn: 0.7.0
2026-01-30 11:57:09,574:INFO:          deepchecks: Not installed
2026-01-30 11:57:09,574:INFO:             xgboost: Not installed
2026-01-30 11:57:09,574:INFO:            catboost: 1.2.8
2026-01-30 11:57:09,574:INFO:              kmodes: 0.12.2
2026-01-30 11:57:09,574:INFO:             mlxtend: 0.23.4
2026-01-30 11:57:09,574:INFO:       statsforecast: 1.5.0
2026-01-30 11:57:09,574:INFO:        tune_sklearn: Not installed
2026-01-30 11:57:09,574:INFO:                 ray: Not installed
2026-01-30 11:57:09,574:INFO:            hyperopt: 0.2.7
2026-01-30 11:57:09,574:INFO:              optuna: 4.6.0
2026-01-30 11:57:09,574:INFO:               skopt: 0.10.2
2026-01-30 11:57:09,574:INFO:              mlflow: 3.8.1
2026-01-30 11:57:09,574:INFO:              gradio: 6.3.0
2026-01-30 11:57:09,574:INFO:             fastapi: 0.128.0
2026-01-30 11:57:09,574:INFO:             uvicorn: 0.40.0
2026-01-30 11:57:09,574:INFO:              m2cgen: 0.10.0
2026-01-30 11:57:09,574:INFO:           evidently: 0.4.40
2026-01-30 11:57:09,574:INFO:               fugue: 0.8.7
2026-01-30 11:57:09,574:INFO:           streamlit: Not installed
2026-01-30 11:57:09,574:INFO:             prophet: Not installed
2026-01-30 11:57:09,574:INFO:None
2026-01-30 11:57:09,574:INFO:Set up data.
2026-01-30 11:57:09,755:INFO:Set up folding strategy.
2026-01-30 11:57:09,755:INFO:Set up train/test split.
2026-01-30 11:57:10,230:INFO:Set up index.
2026-01-30 11:57:10,250:INFO:Assigning column types.
2026-01-30 11:57:10,494:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-30 11:57:10,536:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 11:57:10,536:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 11:57:10,553:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 11:57:10,566:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 11:57:10,606:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 11:57:10,606:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 11:57:10,633:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 11:57:10,634:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 11:57:10,635:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-30 11:57:10,670:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 11:57:10,703:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 11:57:10,703:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 11:57:10,738:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 11:57:10,772:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 11:57:10,773:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 11:57:10,773:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-30 11:57:10,836:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 11:57:10,836:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 11:57:10,903:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 11:57:10,903:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 11:57:10,903:INFO:Preparing preprocessing pipeline...
2026-01-30 11:57:10,953:INFO:Set up simple imputation.
2026-01-30 11:57:10,953:INFO:Set up feature normalization.
2026-01-30 11:57:11,333:INFO:Finished creating preprocessing pipeline.
2026-01-30 11:57:11,333:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'PAID_AMOUNT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdina...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-30 11:57:11,333:INFO:Creating final display dataframe.
2026-01-30 11:57:12,198:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape      (482669, 28)
4        Transformed data shape      (482669, 28)
5   Transformed train set shape      (337868, 28)
6    Transformed test set shape      (144801, 28)
7              Numeric features                24
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                 3
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              b17d
2026-01-30 11:57:12,250:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 11:57:12,250:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 11:57:12,316:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 11:57:12,316:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 11:57:12,316:INFO:setup() successfully completed in 2.76s...............
2026-01-30 11:57:12,316:INFO:Initializing compare_models()
2026-01-30 11:57:12,316:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-30 11:57:12,316:INFO:Checking exceptions
2026-01-30 11:57:12,466:INFO:Preparing display monitor
2026-01-30 11:57:12,466:INFO:Initializing Logistic Regression
2026-01-30 11:57:12,466:INFO:Total runtime is 0.0 minutes
2026-01-30 11:57:12,466:INFO:SubProcess create_model() called ==================================
2026-01-30 11:57:12,466:INFO:Initializing create_model()
2026-01-30 11:57:12,466:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0536012D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 11:57:12,466:INFO:Checking exceptions
2026-01-30 11:57:12,466:INFO:Importing libraries
2026-01-30 11:57:12,466:INFO:Copying training dataset
2026-01-30 11:57:12,729:INFO:Defining folds
2026-01-30 11:57:12,729:INFO:Declaring metric variables
2026-01-30 11:57:12,730:INFO:Importing untrained model
2026-01-30 11:57:12,730:INFO:Logistic Regression Imported successfully
2026-01-30 11:57:12,730:INFO:Starting cross validation
2026-01-30 11:57:12,731:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 11:57:25,659:INFO:Calculating mean and std
2026-01-30 11:57:25,660:INFO:Creating metrics dataframe
2026-01-30 11:57:25,664:INFO:Uploading results into container
2026-01-30 11:57:25,664:INFO:Uploading model into container now
2026-01-30 11:57:25,665:INFO:_master_model_container: 1
2026-01-30 11:57:25,665:INFO:_display_container: 2
2026-01-30 11:57:25,666:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-30 11:57:25,666:INFO:create_model() successfully completed......................................
2026-01-30 11:57:25,849:INFO:SubProcess create_model() end ==================================
2026-01-30 11:57:25,850:INFO:Creating metrics dataframe
2026-01-30 11:57:25,850:INFO:Initializing Decision Tree Classifier
2026-01-30 11:57:25,850:INFO:Total runtime is 0.22305553754170734 minutes
2026-01-30 11:57:25,850:INFO:SubProcess create_model() called ==================================
2026-01-30 11:57:25,850:INFO:Initializing create_model()
2026-01-30 11:57:25,850:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0536012D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 11:57:25,850:INFO:Checking exceptions
2026-01-30 11:57:25,850:INFO:Importing libraries
2026-01-30 11:57:25,850:INFO:Copying training dataset
2026-01-30 11:57:26,018:INFO:Defining folds
2026-01-30 11:57:26,018:INFO:Declaring metric variables
2026-01-30 11:57:26,019:INFO:Importing untrained model
2026-01-30 11:57:26,019:INFO:Decision Tree Classifier Imported successfully
2026-01-30 11:57:26,019:INFO:Starting cross validation
2026-01-30 11:57:26,020:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 11:57:33,554:INFO:Calculating mean and std
2026-01-30 11:57:33,554:INFO:Creating metrics dataframe
2026-01-30 11:57:33,554:INFO:Uploading results into container
2026-01-30 11:57:33,554:INFO:Uploading model into container now
2026-01-30 11:57:33,554:INFO:_master_model_container: 2
2026-01-30 11:57:33,554:INFO:_display_container: 2
2026-01-30 11:57:33,554:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 11:57:33,554:INFO:create_model() successfully completed......................................
2026-01-30 11:57:33,716:INFO:SubProcess create_model() end ==================================
2026-01-30 11:57:33,716:INFO:Creating metrics dataframe
2026-01-30 11:57:33,716:INFO:Initializing Random Forest Classifier
2026-01-30 11:57:33,716:INFO:Total runtime is 0.35416378180185953 minutes
2026-01-30 11:57:33,716:INFO:SubProcess create_model() called ==================================
2026-01-30 11:57:33,716:INFO:Initializing create_model()
2026-01-30 11:57:33,716:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0536012D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 11:57:33,716:INFO:Checking exceptions
2026-01-30 11:57:33,716:INFO:Importing libraries
2026-01-30 11:57:33,716:INFO:Copying training dataset
2026-01-30 11:57:33,925:INFO:Defining folds
2026-01-30 11:57:33,926:INFO:Declaring metric variables
2026-01-30 11:57:33,926:INFO:Importing untrained model
2026-01-30 11:57:33,926:INFO:Random Forest Classifier Imported successfully
2026-01-30 11:57:33,926:INFO:Starting cross validation
2026-01-30 11:57:33,927:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 11:57:58,036:INFO:Calculating mean and std
2026-01-30 11:57:58,038:INFO:Creating metrics dataframe
2026-01-30 11:57:58,038:INFO:Uploading results into container
2026-01-30 11:57:58,038:INFO:Uploading model into container now
2026-01-30 11:57:58,038:INFO:_master_model_container: 3
2026-01-30 11:57:58,038:INFO:_display_container: 2
2026-01-30 11:57:58,038:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 11:57:58,038:INFO:create_model() successfully completed......................................
2026-01-30 11:57:58,290:INFO:SubProcess create_model() end ==================================
2026-01-30 11:57:58,290:INFO:Creating metrics dataframe
2026-01-30 11:57:58,293:INFO:Initializing Light Gradient Boosting Machine
2026-01-30 11:57:58,293:INFO:Total runtime is 0.7637775659561157 minutes
2026-01-30 11:57:58,293:INFO:SubProcess create_model() called ==================================
2026-01-30 11:57:58,293:INFO:Initializing create_model()
2026-01-30 11:57:58,293:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0536012D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 11:57:58,293:INFO:Checking exceptions
2026-01-30 11:57:58,293:INFO:Importing libraries
2026-01-30 11:57:58,293:INFO:Copying training dataset
2026-01-30 11:57:58,575:INFO:Defining folds
2026-01-30 11:57:58,575:INFO:Declaring metric variables
2026-01-30 11:57:58,576:INFO:Importing untrained model
2026-01-30 11:57:58,576:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 11:57:58,577:INFO:Starting cross validation
2026-01-30 11:57:58,578:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 11:58:08,826:INFO:Calculating mean and std
2026-01-30 11:58:08,827:INFO:Creating metrics dataframe
2026-01-30 11:58:08,828:INFO:Uploading results into container
2026-01-30 11:58:08,829:INFO:Uploading model into container now
2026-01-30 11:58:08,829:INFO:_master_model_container: 4
2026-01-30 11:58:08,829:INFO:_display_container: 2
2026-01-30 11:58:08,830:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 11:58:08,830:INFO:create_model() successfully completed......................................
2026-01-30 11:58:08,999:INFO:SubProcess create_model() end ==================================
2026-01-30 11:58:08,999:INFO:Creating metrics dataframe
2026-01-30 11:58:08,999:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-30 11:58:08,999:INFO:Initializing create_model()
2026-01-30 11:58:08,999:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 11:58:08,999:INFO:Checking exceptions
2026-01-30 11:58:08,999:INFO:Importing libraries
2026-01-30 11:58:08,999:INFO:Copying training dataset
2026-01-30 11:58:09,199:INFO:Defining folds
2026-01-30 11:58:09,199:INFO:Declaring metric variables
2026-01-30 11:58:09,199:INFO:Importing untrained model
2026-01-30 11:58:09,199:INFO:Declaring custom model
2026-01-30 11:58:09,199:INFO:Random Forest Classifier Imported successfully
2026-01-30 11:58:09,201:INFO:Cross validation set to False
2026-01-30 11:58:09,201:INFO:Fitting Model
2026-01-30 11:58:18,771:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 11:58:18,771:INFO:create_model() successfully completed......................................
2026-01-30 11:58:18,949:INFO:Initializing create_model()
2026-01-30 11:58:18,949:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 11:58:18,949:INFO:Checking exceptions
2026-01-30 11:58:18,949:INFO:Importing libraries
2026-01-30 11:58:18,949:INFO:Copying training dataset
2026-01-30 11:58:19,132:INFO:Defining folds
2026-01-30 11:58:19,148:INFO:Declaring metric variables
2026-01-30 11:58:19,148:INFO:Importing untrained model
2026-01-30 11:58:19,148:INFO:Declaring custom model
2026-01-30 11:58:19,148:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 11:58:19,149:INFO:Cross validation set to False
2026-01-30 11:58:19,149:INFO:Fitting Model
2026-01-30 11:58:20,005:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 11:58:20,081:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016610 seconds.
2026-01-30 11:58:20,081:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 11:58:20,081:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 11:58:20,082:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 11:58:20,082:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 11:58:20,085:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 11:58:20,085:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 11:58:21,009:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 11:58:21,009:INFO:create_model() successfully completed......................................
2026-01-30 11:58:21,247:INFO:Initializing create_model()
2026-01-30 11:58:21,247:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 11:58:21,249:INFO:Checking exceptions
2026-01-30 11:58:21,249:INFO:Importing libraries
2026-01-30 11:58:21,249:INFO:Copying training dataset
2026-01-30 11:58:21,449:INFO:Defining folds
2026-01-30 11:58:21,449:INFO:Declaring metric variables
2026-01-30 11:58:21,449:INFO:Importing untrained model
2026-01-30 11:58:21,449:INFO:Declaring custom model
2026-01-30 11:58:21,449:INFO:Decision Tree Classifier Imported successfully
2026-01-30 11:58:21,464:INFO:Cross validation set to False
2026-01-30 11:58:21,464:INFO:Fitting Model
2026-01-30 11:58:24,432:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 11:58:24,432:INFO:create_model() successfully completed......................................
2026-01-30 11:58:24,632:INFO:_master_model_container: 4
2026-01-30 11:58:24,632:INFO:_display_container: 2
2026-01-30 11:58:24,632:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')]
2026-01-30 11:58:24,632:INFO:compare_models() successfully completed......................................
2026-01-30 11:58:24,632:INFO:Initializing tune_model()
2026-01-30 11:58:24,632:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 11:58:24,632:INFO:Checking exceptions
2026-01-30 11:58:24,719:INFO:Copying training dataset
2026-01-30 11:58:24,865:INFO:Checking base model
2026-01-30 11:58:24,865:INFO:Base model : Random Forest Classifier
2026-01-30 11:58:24,865:INFO:Declaring metric variables
2026-01-30 11:58:24,866:INFO:Defining Hyperparameters
2026-01-30 11:58:25,032:INFO:Tuning with n_jobs=-1
2026-01-30 11:58:25,032:INFO:Initializing RandomizedSearchCV
2026-01-30 12:01:15,391:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-30 12:01:15,393:INFO:Hyperparameter search completed
2026-01-30 12:01:15,393:INFO:SubProcess create_model() called ==================================
2026-01-30 12:01:15,395:INFO:Initializing create_model()
2026-01-30 12:01:15,396:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A048BAE990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': True})
2026-01-30 12:01:15,396:INFO:Checking exceptions
2026-01-30 12:01:15,396:INFO:Importing libraries
2026-01-30 12:01:15,397:INFO:Copying training dataset
2026-01-30 12:01:15,713:INFO:Defining folds
2026-01-30 12:01:15,713:INFO:Declaring metric variables
2026-01-30 12:01:15,713:INFO:Importing untrained model
2026-01-30 12:01:15,713:INFO:Declaring custom model
2026-01-30 12:01:15,713:INFO:Random Forest Classifier Imported successfully
2026-01-30 12:01:15,713:INFO:Starting cross validation
2026-01-30 12:01:15,713:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:01:49,729:INFO:Calculating mean and std
2026-01-30 12:01:49,730:INFO:Creating metrics dataframe
2026-01-30 12:01:49,730:INFO:Finalizing model
2026-01-30 12:02:06,077:INFO:Uploading results into container
2026-01-30 12:02:06,079:INFO:Uploading model into container now
2026-01-30 12:02:06,080:INFO:_master_model_container: 5
2026-01-30 12:02:06,080:INFO:_display_container: 3
2026-01-30 12:02:06,081:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 12:02:06,081:INFO:create_model() successfully completed......................................
2026-01-30 12:02:06,298:INFO:SubProcess create_model() end ==================================
2026-01-30 12:02:06,298:INFO:choose_better activated
2026-01-30 12:02:06,299:INFO:SubProcess create_model() called ==================================
2026-01-30 12:02:06,300:INFO:Initializing create_model()
2026-01-30 12:02:06,300:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:02:06,300:INFO:Checking exceptions
2026-01-30 12:02:06,300:INFO:Importing libraries
2026-01-30 12:02:06,300:INFO:Copying training dataset
2026-01-30 12:02:06,513:INFO:Defining folds
2026-01-30 12:02:06,513:INFO:Declaring metric variables
2026-01-30 12:02:06,513:INFO:Importing untrained model
2026-01-30 12:02:06,513:INFO:Declaring custom model
2026-01-30 12:02:06,514:INFO:Random Forest Classifier Imported successfully
2026-01-30 12:02:06,514:INFO:Starting cross validation
2026-01-30 12:02:06,515:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:02:28,045:INFO:Calculating mean and std
2026-01-30 12:02:28,045:INFO:Creating metrics dataframe
2026-01-30 12:02:28,045:INFO:Finalizing model
2026-01-30 12:02:38,145:INFO:Uploading results into container
2026-01-30 12:02:38,145:INFO:Uploading model into container now
2026-01-30 12:02:38,145:INFO:_master_model_container: 6
2026-01-30 12:02:38,145:INFO:_display_container: 4
2026-01-30 12:02:38,145:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 12:02:38,145:INFO:create_model() successfully completed......................................
2026-01-30 12:02:38,331:INFO:SubProcess create_model() end ==================================
2026-01-30 12:02:38,331:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9985
2026-01-30 12:02:38,331:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9894
2026-01-30 12:02:38,331:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-30 12:02:38,331:INFO:choose_better completed
2026-01-30 12:02:38,331:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 12:02:38,345:INFO:_master_model_container: 6
2026-01-30 12:02:38,345:INFO:_display_container: 3
2026-01-30 12:02:38,345:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 12:02:38,345:INFO:tune_model() successfully completed......................................
2026-01-30 12:02:38,512:INFO:Initializing tune_model()
2026-01-30 12:02:38,512:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 12:02:38,512:INFO:Checking exceptions
2026-01-30 12:02:38,598:INFO:Copying training dataset
2026-01-30 12:02:38,731:INFO:Checking base model
2026-01-30 12:02:38,731:INFO:Base model : Light Gradient Boosting Machine
2026-01-30 12:02:38,731:INFO:Declaring metric variables
2026-01-30 12:02:38,731:INFO:Defining Hyperparameters
2026-01-30 12:02:38,895:INFO:Tuning with n_jobs=-1
2026-01-30 12:02:38,895:INFO:Initializing RandomizedSearchCV
2026-01-30 12:03:24,744:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2026-01-30 12:03:24,745:INFO:Hyperparameter search completed
2026-01-30 12:03:24,745:INFO:SubProcess create_model() called ==================================
2026-01-30 12:03:24,745:INFO:Initializing create_model()
2026-01-30 12:03:24,745:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03CE100D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2026-01-30 12:03:24,745:INFO:Checking exceptions
2026-01-30 12:03:24,745:INFO:Importing libraries
2026-01-30 12:03:24,745:INFO:Copying training dataset
2026-01-30 12:03:25,011:INFO:Defining folds
2026-01-30 12:03:25,011:INFO:Declaring metric variables
2026-01-30 12:03:25,011:INFO:Importing untrained model
2026-01-30 12:03:25,011:INFO:Declaring custom model
2026-01-30 12:03:25,011:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 12:03:25,011:INFO:Starting cross validation
2026-01-30 12:03:25,025:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:03:35,832:INFO:Calculating mean and std
2026-01-30 12:03:35,835:INFO:Creating metrics dataframe
2026-01-30 12:03:35,837:INFO:Finalizing model
2026-01-30 12:03:36,658:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 12:03:36,659:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 12:03:36,659:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 12:03:36,882:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 12:03:36,882:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 12:03:36,882:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 12:03:36,883:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 12:03:36,944:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014886 seconds.
2026-01-30 12:03:36,944:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 12:03:36,944:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 12:03:36,945:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 12:03:36,946:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 12:03:36,951:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 12:03:36,951:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 12:03:40,600:INFO:Uploading results into container
2026-01-30 12:03:40,601:INFO:Uploading model into container now
2026-01-30 12:03:40,602:INFO:_master_model_container: 7
2026-01-30 12:03:40,602:INFO:_display_container: 4
2026-01-30 12:03:40,603:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 12:03:40,604:INFO:create_model() successfully completed......................................
2026-01-30 12:03:40,844:INFO:SubProcess create_model() end ==================================
2026-01-30 12:03:40,845:INFO:choose_better activated
2026-01-30 12:03:40,846:INFO:SubProcess create_model() called ==================================
2026-01-30 12:03:40,847:INFO:Initializing create_model()
2026-01-30 12:03:40,847:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:03:40,847:INFO:Checking exceptions
2026-01-30 12:03:40,848:INFO:Importing libraries
2026-01-30 12:03:40,848:INFO:Copying training dataset
2026-01-30 12:03:41,077:INFO:Defining folds
2026-01-30 12:03:41,077:INFO:Declaring metric variables
2026-01-30 12:03:41,078:INFO:Importing untrained model
2026-01-30 12:03:41,078:INFO:Declaring custom model
2026-01-30 12:03:41,078:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 12:03:41,078:INFO:Starting cross validation
2026-01-30 12:03:41,078:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:03:46,051:INFO:Calculating mean and std
2026-01-30 12:03:46,052:INFO:Creating metrics dataframe
2026-01-30 12:03:46,054:INFO:Finalizing model
2026-01-30 12:03:46,960:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 12:03:47,016:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016709 seconds.
2026-01-30 12:03:47,016:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 12:03:47,016:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 12:03:47,016:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 12:03:47,016:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 12:03:47,020:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 12:03:47,020:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 12:03:47,953:INFO:Uploading results into container
2026-01-30 12:03:47,953:INFO:Uploading model into container now
2026-01-30 12:03:47,955:INFO:_master_model_container: 8
2026-01-30 12:03:47,955:INFO:_display_container: 5
2026-01-30 12:03:47,955:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 12:03:47,955:INFO:create_model() successfully completed......................................
2026-01-30 12:03:48,233:INFO:SubProcess create_model() end ==================================
2026-01-30 12:03:48,233:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9945
2026-01-30 12:03:48,233:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9987
2026-01-30 12:03:48,233:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2026-01-30 12:03:48,233:INFO:choose_better completed
2026-01-30 12:03:48,233:INFO:_master_model_container: 8
2026-01-30 12:03:48,233:INFO:_display_container: 4
2026-01-30 12:03:48,233:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 12:03:48,233:INFO:tune_model() successfully completed......................................
2026-01-30 12:03:48,411:INFO:Initializing tune_model()
2026-01-30 12:03:48,411:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 12:03:48,411:INFO:Checking exceptions
2026-01-30 12:03:48,503:INFO:Copying training dataset
2026-01-30 12:03:48,628:INFO:Checking base model
2026-01-30 12:03:48,628:INFO:Base model : Decision Tree Classifier
2026-01-30 12:03:48,628:INFO:Declaring metric variables
2026-01-30 12:03:48,628:INFO:Defining Hyperparameters
2026-01-30 12:03:48,811:INFO:Tuning with n_jobs=-1
2026-01-30 12:03:48,811:INFO:Initializing RandomizedSearchCV
2026-01-30 12:03:58,461:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 15, 'actual_estimator__criterion': 'gini'}
2026-01-30 12:03:58,462:INFO:Hyperparameter search completed
2026-01-30 12:03:58,462:INFO:SubProcess create_model() called ==================================
2026-01-30 12:03:58,463:INFO:Initializing create_model()
2026-01-30 12:03:58,463:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03D06B890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 2, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 15, 'criterion': 'gini'})
2026-01-30 12:03:58,464:INFO:Checking exceptions
2026-01-30 12:03:58,464:INFO:Importing libraries
2026-01-30 12:03:58,464:INFO:Copying training dataset
2026-01-30 12:03:58,733:INFO:Defining folds
2026-01-30 12:03:58,733:INFO:Declaring metric variables
2026-01-30 12:03:58,733:INFO:Importing untrained model
2026-01-30 12:03:58,734:INFO:Declaring custom model
2026-01-30 12:03:58,735:INFO:Decision Tree Classifier Imported successfully
2026-01-30 12:03:58,735:INFO:Starting cross validation
2026-01-30 12:03:58,736:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:04:02,006:INFO:Calculating mean and std
2026-01-30 12:04:02,009:INFO:Creating metrics dataframe
2026-01-30 12:04:02,013:INFO:Finalizing model
2026-01-30 12:04:04,688:INFO:Uploading results into container
2026-01-30 12:04:04,688:INFO:Uploading model into container now
2026-01-30 12:04:04,694:INFO:_master_model_container: 9
2026-01-30 12:04:04,694:INFO:_display_container: 5
2026-01-30 12:04:04,694:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 12:04:04,694:INFO:create_model() successfully completed......................................
2026-01-30 12:04:04,948:INFO:SubProcess create_model() end ==================================
2026-01-30 12:04:04,948:INFO:choose_better activated
2026-01-30 12:04:04,949:INFO:SubProcess create_model() called ==================================
2026-01-30 12:04:04,949:INFO:Initializing create_model()
2026-01-30 12:04:04,950:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:04:04,950:INFO:Checking exceptions
2026-01-30 12:04:04,951:INFO:Importing libraries
2026-01-30 12:04:04,951:INFO:Copying training dataset
2026-01-30 12:04:05,262:INFO:Defining folds
2026-01-30 12:04:05,262:INFO:Declaring metric variables
2026-01-30 12:04:05,262:INFO:Importing untrained model
2026-01-30 12:04:05,262:INFO:Declaring custom model
2026-01-30 12:04:05,263:INFO:Decision Tree Classifier Imported successfully
2026-01-30 12:04:05,264:INFO:Starting cross validation
2026-01-30 12:04:05,266:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:04:10,352:INFO:Calculating mean and std
2026-01-30 12:04:10,352:INFO:Creating metrics dataframe
2026-01-30 12:04:10,354:INFO:Finalizing model
2026-01-30 12:04:13,846:INFO:Uploading results into container
2026-01-30 12:04:13,846:INFO:Uploading model into container now
2026-01-30 12:04:13,847:INFO:_master_model_container: 10
2026-01-30 12:04:13,847:INFO:_display_container: 6
2026-01-30 12:04:13,847:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 12:04:13,847:INFO:create_model() successfully completed......................................
2026-01-30 12:04:14,027:INFO:SubProcess create_model() end ==================================
2026-01-30 12:04:14,027:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.989
2026-01-30 12:04:14,027:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9826
2026-01-30 12:04:14,027:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-30 12:04:14,027:INFO:choose_better completed
2026-01-30 12:04:14,027:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 12:04:14,027:INFO:_master_model_container: 10
2026-01-30 12:04:14,027:INFO:_display_container: 5
2026-01-30 12:04:14,027:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 12:04:14,027:INFO:tune_model() successfully completed......................................
2026-01-30 12:04:14,226:INFO:Initializing predict_model()
2026-01-30 12:04:14,226:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A06E731760>)
2026-01-30 12:04:14,226:INFO:Checking exceptions
2026-01-30 12:04:14,226:INFO:Preloading libraries
2026-01-30 12:04:14,226:INFO:Set up data.
2026-01-30 12:04:14,232:INFO:Set up index.
2026-01-30 12:04:14,697:INFO:Initializing predict_model()
2026-01-30 12:04:14,698:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A03D1FF1A0>)
2026-01-30 12:04:14,698:INFO:Checking exceptions
2026-01-30 12:04:14,698:INFO:Preloading libraries
2026-01-30 12:04:14,698:INFO:Set up data.
2026-01-30 12:04:14,711:INFO:Set up index.
2026-01-30 12:04:15,228:INFO:Initializing predict_model()
2026-01-30 12:04:15,228:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A03D1FE700>)
2026-01-30 12:04:15,228:INFO:Checking exceptions
2026-01-30 12:04:15,229:INFO:Preloading libraries
2026-01-30 12:04:15,229:INFO:Set up data.
2026-01-30 12:04:15,243:INFO:Set up index.
2026-01-30 12:04:15,655:INFO:Initializing plot_model()
2026-01-30 12:04:15,655:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 12:04:15,655:INFO:Checking exceptions
2026-01-30 12:04:15,793:INFO:Preloading libraries
2026-01-30 12:04:15,924:INFO:Copying training dataset
2026-01-30 12:04:15,924:INFO:Plot type: feature
2026-01-30 12:04:15,925:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 12:04:16,360:INFO:Visual Rendered Successfully
2026-01-30 12:04:16,570:INFO:plot_model() successfully completed......................................
2026-01-30 12:04:16,586:INFO:Initializing plot_model()
2026-01-30 12:04:16,586:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature_all, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 12:04:16,586:INFO:Checking exceptions
2026-01-30 12:04:16,714:INFO:Preloading libraries
2026-01-30 12:04:16,794:INFO:Copying training dataset
2026-01-30 12:04:16,794:INFO:Plot type: feature_all
2026-01-30 12:04:17,010:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 12:04:17,477:INFO:Visual Rendered Successfully
2026-01-30 12:04:17,664:INFO:plot_model() successfully completed......................................
2026-01-30 12:04:17,689:INFO:Initializing save_model()
2026-01-30 12:04:17,689:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), model_name=..\datos\04. Modelos\modelo_final_explicable, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'PAID_AMOUNT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdina...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-30 12:04:17,689:INFO:Adding model into prep_pipe
2026-01-30 12:04:17,831:INFO:..\datos\04. Modelos\modelo_final_explicable.pkl saved in current working directory
2026-01-30 12:04:17,831:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'PAID_AMOUNT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdinario_def__c',
                                             'CU_precioAplicado_def__c',
                                             'PO...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=42, verbose=0,
                                        warm_start=False))],
         verbose=False)
2026-01-30 12:04:17,831:INFO:save_model() successfully completed......................................
2026-01-30 12:08:02,808:INFO:Initializing load_model()
2026-01-30 12:08:02,809:INFO:load_model(model_name=..\datos\04. Modelos\modelo_final_explicable, platform=None, authentication=None, verbose=True)
2026-01-30 12:08:05,357:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\770966573.py:26: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-30 12:09:13,859:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\2705027463.py:20: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-30 12:09:16,837:INFO:PyCaret ClassificationExperiment
2026-01-30 12:09:16,838:INFO:Logging name: clf-default-name
2026-01-30 12:09:16,839:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-30 12:09:16,839:INFO:version 3.3.2
2026-01-30 12:09:16,839:INFO:Initializing setup()
2026-01-30 12:09:16,839:INFO:self.USI: 662d
2026-01-30 12:09:16,839:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'n_jobs_param', 'data', 'X', 'idx', 'y_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'USI', 'target_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'y_train', 'X_test', 'seed', 'gpu_param', 'gpu_n_jobs_param', 'y', 'logging_param', 'pipeline', 'fold_generator', 'exp_id'}
2026-01-30 12:09:16,839:INFO:Checking environment
2026-01-30 12:09:16,839:INFO:python_version: 3.11.11
2026-01-30 12:09:16,839:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-30 12:09:16,839:INFO:machine: AMD64
2026-01-30 12:09:16,839:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-30 12:09:16,839:INFO:Memory: svmem(total=34009374720, available=14299074560, percent=58.0, used=19710300160, free=14299074560)
2026-01-30 12:09:16,839:INFO:Physical Core: 12
2026-01-30 12:09:16,841:INFO:Logical Core: 16
2026-01-30 12:09:16,841:INFO:Checking libraries
2026-01-30 12:09:16,841:INFO:System:
2026-01-30 12:09:16,841:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-30 12:09:16,842:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-30 12:09:16,842:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-30 12:09:16,842:INFO:PyCaret required dependencies:
2026-01-30 12:09:16,842:INFO:                 pip: 25.0
2026-01-30 12:09:16,842:INFO:          setuptools: 75.8.0
2026-01-30 12:09:16,842:INFO:             pycaret: 3.3.2
2026-01-30 12:09:16,842:INFO:             IPython: 9.9.0
2026-01-30 12:09:16,843:INFO:          ipywidgets: 8.1.8
2026-01-30 12:09:16,843:INFO:                tqdm: 4.67.1
2026-01-30 12:09:16,843:INFO:               numpy: 1.26.4
2026-01-30 12:09:16,844:INFO:              pandas: 2.1.4
2026-01-30 12:09:16,844:INFO:              jinja2: 3.1.6
2026-01-30 12:09:16,845:INFO:               scipy: 1.11.4
2026-01-30 12:09:16,845:INFO:              joblib: 1.3.2
2026-01-30 12:09:16,845:INFO:             sklearn: 1.4.2
2026-01-30 12:09:16,845:INFO:                pyod: 2.0.6
2026-01-30 12:09:16,845:INFO:            imblearn: 0.14.1
2026-01-30 12:09:16,845:INFO:   category_encoders: 2.7.0
2026-01-30 12:09:16,846:INFO:            lightgbm: 4.6.0
2026-01-30 12:09:16,846:INFO:               numba: 0.62.1
2026-01-30 12:09:16,846:INFO:            requests: 2.32.3
2026-01-30 12:09:16,846:INFO:          matplotlib: 3.7.5
2026-01-30 12:09:16,846:INFO:          scikitplot: 0.3.7
2026-01-30 12:09:16,846:INFO:         yellowbrick: 1.5
2026-01-30 12:09:16,846:INFO:              plotly: 5.24.1
2026-01-30 12:09:16,847:INFO:    plotly-resampler: Not installed
2026-01-30 12:09:16,847:INFO:             kaleido: 1.2.0
2026-01-30 12:09:16,847:INFO:           schemdraw: 0.15
2026-01-30 12:09:16,847:INFO:         statsmodels: 0.14.6
2026-01-30 12:09:16,847:INFO:              sktime: 0.26.0
2026-01-30 12:09:16,847:INFO:               tbats: 1.1.3
2026-01-30 12:09:16,847:INFO:            pmdarima: 2.0.4
2026-01-30 12:09:16,847:INFO:              psutil: 7.2.1
2026-01-30 12:09:16,847:INFO:          markupsafe: 3.0.3
2026-01-30 12:09:16,847:INFO:             pickle5: Not installed
2026-01-30 12:09:16,847:INFO:         cloudpickle: 3.0.0
2026-01-30 12:09:16,848:INFO:         deprecation: 2.1.0
2026-01-30 12:09:16,848:INFO:              xxhash: 3.6.0
2026-01-30 12:09:16,848:INFO:           wurlitzer: Not installed
2026-01-30 12:09:16,848:INFO:PyCaret optional dependencies:
2026-01-30 12:09:16,848:INFO:                shap: 0.44.1
2026-01-30 12:09:16,848:INFO:           interpret: 0.7.3
2026-01-30 12:09:16,848:INFO:                umap: 0.5.7
2026-01-30 12:09:16,848:INFO:     ydata_profiling: 4.18.1
2026-01-30 12:09:16,848:INFO:  explainerdashboard: 0.5.1
2026-01-30 12:09:16,849:INFO:             autoviz: Not installed
2026-01-30 12:09:16,849:INFO:           fairlearn: 0.7.0
2026-01-30 12:09:16,849:INFO:          deepchecks: Not installed
2026-01-30 12:09:16,849:INFO:             xgboost: Not installed
2026-01-30 12:09:16,849:INFO:            catboost: 1.2.8
2026-01-30 12:09:16,849:INFO:              kmodes: 0.12.2
2026-01-30 12:09:16,850:INFO:             mlxtend: 0.23.4
2026-01-30 12:09:16,850:INFO:       statsforecast: 1.5.0
2026-01-30 12:09:16,850:INFO:        tune_sklearn: Not installed
2026-01-30 12:09:16,850:INFO:                 ray: Not installed
2026-01-30 12:09:16,850:INFO:            hyperopt: 0.2.7
2026-01-30 12:09:16,850:INFO:              optuna: 4.6.0
2026-01-30 12:09:16,850:INFO:               skopt: 0.10.2
2026-01-30 12:09:16,850:INFO:              mlflow: 3.8.1
2026-01-30 12:09:16,851:INFO:              gradio: 6.3.0
2026-01-30 12:09:16,851:INFO:             fastapi: 0.128.0
2026-01-30 12:09:16,851:INFO:             uvicorn: 0.40.0
2026-01-30 12:09:16,851:INFO:              m2cgen: 0.10.0
2026-01-30 12:09:16,851:INFO:           evidently: 0.4.40
2026-01-30 12:09:16,851:INFO:               fugue: 0.8.7
2026-01-30 12:09:16,851:INFO:           streamlit: Not installed
2026-01-30 12:09:16,851:INFO:             prophet: Not installed
2026-01-30 12:09:16,851:INFO:None
2026-01-30 12:09:16,851:INFO:Set up data.
2026-01-30 12:09:17,004:INFO:Set up folding strategy.
2026-01-30 12:09:17,005:INFO:Set up train/test split.
2026-01-30 12:09:17,257:INFO:Set up index.
2026-01-30 12:09:17,276:INFO:Assigning column types.
2026-01-30 12:09:17,455:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-30 12:09:17,492:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 12:09:17,493:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 12:09:17,517:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:09:17,517:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:09:17,557:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 12:09:17,558:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 12:09:17,582:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:09:17,583:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:09:17,584:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-30 12:09:17,624:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 12:09:17,649:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:09:17,649:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:09:17,690:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 12:09:17,715:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:09:17,715:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:09:17,715:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-30 12:09:17,780:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:09:17,780:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:09:17,842:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:09:17,843:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:09:17,844:INFO:Preparing preprocessing pipeline...
2026-01-30 12:09:17,881:INFO:Set up simple imputation.
2026-01-30 12:09:17,881:INFO:Set up feature normalization.
2026-01-30 12:09:18,935:INFO:Finished creating preprocessing pipeline.
2026-01-30 12:09:18,941:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdinario_def__c',
                                             'C...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-30 12:09:18,941:INFO:Creating final display dataframe.
2026-01-30 12:09:21,931:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape      (482669, 27)
4        Transformed data shape      (482669, 27)
5   Transformed train set shape      (337868, 27)
6    Transformed test set shape      (144801, 27)
7              Numeric features                23
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                 3
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              662d
2026-01-30 12:09:22,017:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:09:22,017:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:09:22,098:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:09:22,098:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:09:22,101:INFO:setup() successfully completed in 5.27s...............
2026-01-30 12:09:22,101:INFO:Initializing compare_models()
2026-01-30 12:09:22,101:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C27B3A10>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C27B3A10>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-30 12:09:22,101:INFO:Checking exceptions
2026-01-30 12:09:22,278:INFO:Preparing display monitor
2026-01-30 12:09:22,280:INFO:Initializing Logistic Regression
2026-01-30 12:09:22,280:INFO:Total runtime is 0.0 minutes
2026-01-30 12:09:22,280:INFO:SubProcess create_model() called ==================================
2026-01-30 12:09:22,280:INFO:Initializing create_model()
2026-01-30 12:09:22,280:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C27B3A10>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03F649690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:09:22,280:INFO:Checking exceptions
2026-01-30 12:09:22,280:INFO:Importing libraries
2026-01-30 12:09:22,280:INFO:Copying training dataset
2026-01-30 12:09:22,473:INFO:Defining folds
2026-01-30 12:09:22,473:INFO:Declaring metric variables
2026-01-30 12:09:22,473:INFO:Importing untrained model
2026-01-30 12:09:22,474:INFO:Logistic Regression Imported successfully
2026-01-30 12:09:22,474:INFO:Starting cross validation
2026-01-30 12:09:22,474:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:09:31,244:INFO:Calculating mean and std
2026-01-30 12:09:31,245:INFO:Creating metrics dataframe
2026-01-30 12:09:31,247:INFO:Uploading results into container
2026-01-30 12:09:31,248:INFO:Uploading model into container now
2026-01-30 12:09:31,248:INFO:_master_model_container: 1
2026-01-30 12:09:31,248:INFO:_display_container: 2
2026-01-30 12:09:31,249:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-30 12:09:31,249:INFO:create_model() successfully completed......................................
2026-01-30 12:09:31,406:INFO:SubProcess create_model() end ==================================
2026-01-30 12:09:31,406:INFO:Creating metrics dataframe
2026-01-30 12:09:31,406:INFO:Initializing Decision Tree Classifier
2026-01-30 12:09:31,406:INFO:Total runtime is 0.15210139751434326 minutes
2026-01-30 12:09:31,406:INFO:SubProcess create_model() called ==================================
2026-01-30 12:09:31,406:INFO:Initializing create_model()
2026-01-30 12:09:31,406:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C27B3A10>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03F649690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:09:31,406:INFO:Checking exceptions
2026-01-30 12:09:31,406:INFO:Importing libraries
2026-01-30 12:09:31,406:INFO:Copying training dataset
2026-01-30 12:09:31,584:INFO:Defining folds
2026-01-30 12:09:31,585:INFO:Declaring metric variables
2026-01-30 12:09:31,585:INFO:Importing untrained model
2026-01-30 12:09:31,585:INFO:Decision Tree Classifier Imported successfully
2026-01-30 12:09:31,586:INFO:Starting cross validation
2026-01-30 12:09:31,586:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:09:40,700:INFO:Calculating mean and std
2026-01-30 12:09:40,702:INFO:Creating metrics dataframe
2026-01-30 12:09:40,705:INFO:Uploading results into container
2026-01-30 12:09:40,706:INFO:Uploading model into container now
2026-01-30 12:09:40,706:INFO:_master_model_container: 2
2026-01-30 12:09:40,706:INFO:_display_container: 2
2026-01-30 12:09:40,706:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 12:09:40,707:INFO:create_model() successfully completed......................................
2026-01-30 12:09:40,855:INFO:SubProcess create_model() end ==================================
2026-01-30 12:09:40,855:INFO:Creating metrics dataframe
2026-01-30 12:09:40,855:INFO:Initializing Random Forest Classifier
2026-01-30 12:09:40,855:INFO:Total runtime is 0.3095914800961812 minutes
2026-01-30 12:09:40,855:INFO:SubProcess create_model() called ==================================
2026-01-30 12:09:40,855:INFO:Initializing create_model()
2026-01-30 12:09:40,855:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C27B3A10>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03F649690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:09:40,855:INFO:Checking exceptions
2026-01-30 12:09:40,855:INFO:Importing libraries
2026-01-30 12:09:40,855:INFO:Copying training dataset
2026-01-30 12:09:41,034:INFO:Defining folds
2026-01-30 12:09:41,034:INFO:Declaring metric variables
2026-01-30 12:09:41,035:INFO:Importing untrained model
2026-01-30 12:09:41,035:INFO:Random Forest Classifier Imported successfully
2026-01-30 12:09:41,036:INFO:Starting cross validation
2026-01-30 12:09:41,036:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:10:04,178:INFO:Calculating mean and std
2026-01-30 12:10:04,182:INFO:Creating metrics dataframe
2026-01-30 12:10:04,183:INFO:Uploading results into container
2026-01-30 12:10:04,183:INFO:Uploading model into container now
2026-01-30 12:10:04,185:INFO:_master_model_container: 3
2026-01-30 12:10:04,185:INFO:_display_container: 2
2026-01-30 12:10:04,185:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 12:10:04,185:INFO:create_model() successfully completed......................................
2026-01-30 12:10:04,381:INFO:SubProcess create_model() end ==================================
2026-01-30 12:10:04,381:INFO:Creating metrics dataframe
2026-01-30 12:10:04,383:INFO:Initializing Light Gradient Boosting Machine
2026-01-30 12:10:04,383:INFO:Total runtime is 0.7017121752103169 minutes
2026-01-30 12:10:04,383:INFO:SubProcess create_model() called ==================================
2026-01-30 12:10:04,384:INFO:Initializing create_model()
2026-01-30 12:10:04,384:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C27B3A10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03F649690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:10:04,384:INFO:Checking exceptions
2026-01-30 12:10:04,384:INFO:Importing libraries
2026-01-30 12:10:04,384:INFO:Copying training dataset
2026-01-30 12:10:04,649:INFO:Defining folds
2026-01-30 12:10:04,649:INFO:Declaring metric variables
2026-01-30 12:10:04,649:INFO:Importing untrained model
2026-01-30 12:10:04,650:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 12:10:04,650:INFO:Starting cross validation
2026-01-30 12:10:04,651:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:10:13,362:INFO:Calculating mean and std
2026-01-30 12:10:13,362:INFO:Creating metrics dataframe
2026-01-30 12:10:13,362:INFO:Uploading results into container
2026-01-30 12:10:13,362:INFO:Uploading model into container now
2026-01-30 12:10:13,362:INFO:_master_model_container: 4
2026-01-30 12:10:13,362:INFO:_display_container: 2
2026-01-30 12:10:13,362:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 12:10:13,362:INFO:create_model() successfully completed......................................
2026-01-30 12:10:13,541:INFO:SubProcess create_model() end ==================================
2026-01-30 12:10:13,541:INFO:Creating metrics dataframe
2026-01-30 12:10:13,543:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-30 12:10:13,544:INFO:Initializing create_model()
2026-01-30 12:10:13,544:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C27B3A10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:10:13,545:INFO:Checking exceptions
2026-01-30 12:10:13,545:INFO:Importing libraries
2026-01-30 12:10:13,545:INFO:Copying training dataset
2026-01-30 12:10:13,730:INFO:Defining folds
2026-01-30 12:10:13,730:INFO:Declaring metric variables
2026-01-30 12:10:13,731:INFO:Importing untrained model
2026-01-30 12:10:13,731:INFO:Declaring custom model
2026-01-30 12:10:13,731:INFO:Random Forest Classifier Imported successfully
2026-01-30 12:10:13,732:INFO:Cross validation set to False
2026-01-30 12:10:13,732:INFO:Fitting Model
2026-01-30 12:10:23,491:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 12:10:23,491:INFO:create_model() successfully completed......................................
2026-01-30 12:10:23,660:INFO:Initializing create_model()
2026-01-30 12:10:23,661:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C27B3A10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:10:23,661:INFO:Checking exceptions
2026-01-30 12:10:23,662:INFO:Importing libraries
2026-01-30 12:10:23,662:INFO:Copying training dataset
2026-01-30 12:10:23,864:INFO:Defining folds
2026-01-30 12:10:23,864:INFO:Declaring metric variables
2026-01-30 12:10:23,864:INFO:Importing untrained model
2026-01-30 12:10:23,864:INFO:Declaring custom model
2026-01-30 12:10:23,865:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 12:10:23,865:INFO:Cross validation set to False
2026-01-30 12:10:23,865:INFO:Fitting Model
2026-01-30 12:10:24,917:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 12:10:24,979:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015172 seconds.
2026-01-30 12:10:24,980:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 12:10:24,980:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 12:10:24,980:INFO:[LightGBM] [Info] Total Bins 2868
2026-01-30 12:10:24,981:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 26
2026-01-30 12:10:24,984:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 12:10:24,984:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 12:10:25,919:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 12:10:25,919:INFO:create_model() successfully completed......................................
2026-01-30 12:10:26,183:INFO:Initializing create_model()
2026-01-30 12:10:26,183:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C27B3A10>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:10:26,184:INFO:Checking exceptions
2026-01-30 12:10:26,185:INFO:Importing libraries
2026-01-30 12:10:26,185:INFO:Copying training dataset
2026-01-30 12:10:26,517:INFO:Defining folds
2026-01-30 12:10:26,518:INFO:Declaring metric variables
2026-01-30 12:10:26,518:INFO:Importing untrained model
2026-01-30 12:10:26,518:INFO:Declaring custom model
2026-01-30 12:10:26,518:INFO:Decision Tree Classifier Imported successfully
2026-01-30 12:10:26,519:INFO:Cross validation set to False
2026-01-30 12:10:26,519:INFO:Fitting Model
2026-01-30 12:10:29,755:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 12:10:29,756:INFO:create_model() successfully completed......................................
2026-01-30 12:10:30,023:INFO:_master_model_container: 4
2026-01-30 12:10:30,024:INFO:_display_container: 2
2026-01-30 12:10:30,025:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')]
2026-01-30 12:10:30,025:INFO:compare_models() successfully completed......................................
2026-01-30 12:10:30,034:INFO:Initializing tune_model()
2026-01-30 12:10:30,034:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C27B3A10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 12:10:30,034:INFO:Checking exceptions
2026-01-30 12:10:30,135:INFO:Copying training dataset
2026-01-30 12:10:30,271:INFO:Checking base model
2026-01-30 12:10:30,273:INFO:Base model : Random Forest Classifier
2026-01-30 12:10:30,274:INFO:Declaring metric variables
2026-01-30 12:10:30,274:INFO:Defining Hyperparameters
2026-01-30 12:10:30,441:INFO:Tuning with n_jobs=-1
2026-01-30 12:10:30,442:INFO:Initializing RandomizedSearchCV
2026-01-30 12:13:13,943:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-30 12:13:13,943:INFO:Hyperparameter search completed
2026-01-30 12:13:13,943:INFO:SubProcess create_model() called ==================================
2026-01-30 12:13:13,943:INFO:Initializing create_model()
2026-01-30 12:13:13,943:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C27B3A10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04C7D9690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': True})
2026-01-30 12:13:13,943:INFO:Checking exceptions
2026-01-30 12:13:13,943:INFO:Importing libraries
2026-01-30 12:13:13,943:INFO:Copying training dataset
2026-01-30 12:13:14,186:INFO:Defining folds
2026-01-30 12:13:14,186:INFO:Declaring metric variables
2026-01-30 12:13:14,186:INFO:Importing untrained model
2026-01-30 12:13:14,186:INFO:Declaring custom model
2026-01-30 12:13:14,186:INFO:Random Forest Classifier Imported successfully
2026-01-30 12:13:14,186:INFO:Starting cross validation
2026-01-30 12:13:14,186:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:13:46,239:INFO:Calculating mean and std
2026-01-30 12:13:46,239:INFO:Creating metrics dataframe
2026-01-30 12:13:46,239:INFO:Finalizing model
2026-01-30 12:14:02,009:INFO:Uploading results into container
2026-01-30 12:14:02,009:INFO:Uploading model into container now
2026-01-30 12:14:02,009:INFO:_master_model_container: 5
2026-01-30 12:14:02,009:INFO:_display_container: 3
2026-01-30 12:14:02,009:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 12:14:02,009:INFO:create_model() successfully completed......................................
2026-01-30 12:14:02,202:INFO:SubProcess create_model() end ==================================
2026-01-30 12:14:02,202:INFO:choose_better activated
2026-01-30 12:14:02,202:INFO:SubProcess create_model() called ==================================
2026-01-30 12:14:02,202:INFO:Initializing create_model()
2026-01-30 12:14:02,202:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C27B3A10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:14:02,202:INFO:Checking exceptions
2026-01-30 12:14:02,202:INFO:Importing libraries
2026-01-30 12:14:02,202:INFO:Copying training dataset
2026-01-30 12:14:02,386:INFO:Defining folds
2026-01-30 12:14:02,386:INFO:Declaring metric variables
2026-01-30 12:14:02,386:INFO:Importing untrained model
2026-01-30 12:14:02,386:INFO:Declaring custom model
2026-01-30 12:14:02,386:INFO:Random Forest Classifier Imported successfully
2026-01-30 12:14:02,386:INFO:Starting cross validation
2026-01-30 12:14:02,386:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:14:25,135:INFO:Calculating mean and std
2026-01-30 12:14:25,135:INFO:Creating metrics dataframe
2026-01-30 12:14:25,135:INFO:Finalizing model
2026-01-30 12:14:35,792:INFO:Uploading results into container
2026-01-30 12:14:35,800:INFO:Uploading model into container now
2026-01-30 12:14:35,800:INFO:_master_model_container: 6
2026-01-30 12:14:35,800:INFO:_display_container: 4
2026-01-30 12:14:35,801:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 12:14:35,801:INFO:create_model() successfully completed......................................
2026-01-30 12:14:35,985:INFO:SubProcess create_model() end ==================================
2026-01-30 12:14:35,985:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9962
2026-01-30 12:14:35,985:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9658
2026-01-30 12:14:35,985:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-30 12:14:35,985:INFO:choose_better completed
2026-01-30 12:14:35,985:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 12:14:35,985:INFO:_master_model_container: 6
2026-01-30 12:14:35,985:INFO:_display_container: 3
2026-01-30 12:14:35,985:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 12:14:35,985:INFO:tune_model() successfully completed......................................
2026-01-30 12:14:36,170:INFO:Initializing tune_model()
2026-01-30 12:14:36,170:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C27B3A10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 12:14:36,170:INFO:Checking exceptions
2026-01-30 12:14:36,240:INFO:Copying training dataset
2026-01-30 12:14:36,362:INFO:Checking base model
2026-01-30 12:14:36,362:INFO:Base model : Light Gradient Boosting Machine
2026-01-30 12:14:36,366:INFO:Declaring metric variables
2026-01-30 12:14:36,366:INFO:Defining Hyperparameters
2026-01-30 12:14:36,519:INFO:Tuning with n_jobs=-1
2026-01-30 12:14:36,519:INFO:Initializing RandomizedSearchCV
2026-01-30 12:15:19,258:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2026-01-30 12:15:19,258:INFO:Hyperparameter search completed
2026-01-30 12:15:19,258:INFO:SubProcess create_model() called ==================================
2026-01-30 12:15:19,258:INFO:Initializing create_model()
2026-01-30 12:15:19,258:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C27B3A10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04CA73550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2026-01-30 12:15:19,258:INFO:Checking exceptions
2026-01-30 12:15:19,258:INFO:Importing libraries
2026-01-30 12:15:19,258:INFO:Copying training dataset
2026-01-30 12:15:19,523:INFO:Defining folds
2026-01-30 12:15:19,523:INFO:Declaring metric variables
2026-01-30 12:15:19,524:INFO:Importing untrained model
2026-01-30 12:15:19,524:INFO:Declaring custom model
2026-01-30 12:15:19,526:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 12:15:19,526:INFO:Starting cross validation
2026-01-30 12:15:19,527:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:15:30,660:INFO:Calculating mean and std
2026-01-30 12:15:30,662:INFO:Creating metrics dataframe
2026-01-30 12:15:30,664:INFO:Finalizing model
2026-01-30 12:15:31,568:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 12:15:31,569:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 12:15:31,569:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 12:15:31,786:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 12:15:31,786:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 12:15:31,786:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 12:15:31,788:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 12:15:31,853:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013389 seconds.
2026-01-30 12:15:31,853:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 12:15:31,853:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 12:15:31,853:INFO:[LightGBM] [Info] Total Bins 2868
2026-01-30 12:15:31,855:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 26
2026-01-30 12:15:31,859:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 12:15:31,861:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 12:15:36,027:INFO:Uploading results into container
2026-01-30 12:15:36,028:INFO:Uploading model into container now
2026-01-30 12:15:36,030:INFO:_master_model_container: 7
2026-01-30 12:15:36,030:INFO:_display_container: 4
2026-01-30 12:15:36,032:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 12:15:36,032:INFO:create_model() successfully completed......................................
2026-01-30 12:15:36,288:INFO:SubProcess create_model() end ==================================
2026-01-30 12:15:36,289:INFO:choose_better activated
2026-01-30 12:15:36,289:INFO:SubProcess create_model() called ==================================
2026-01-30 12:15:36,290:INFO:Initializing create_model()
2026-01-30 12:15:36,290:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C27B3A10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:15:36,290:INFO:Checking exceptions
2026-01-30 12:15:36,292:INFO:Importing libraries
2026-01-30 12:15:36,292:INFO:Copying training dataset
2026-01-30 12:15:36,606:INFO:Defining folds
2026-01-30 12:15:36,606:INFO:Declaring metric variables
2026-01-30 12:15:36,607:INFO:Importing untrained model
2026-01-30 12:15:36,607:INFO:Declaring custom model
2026-01-30 12:15:36,608:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 12:15:36,608:INFO:Starting cross validation
2026-01-30 12:15:36,609:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:15:42,054:INFO:Calculating mean and std
2026-01-30 12:15:42,055:INFO:Creating metrics dataframe
2026-01-30 12:15:42,056:INFO:Finalizing model
2026-01-30 12:15:43,075:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 12:15:43,135:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013812 seconds.
2026-01-30 12:15:43,136:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 12:15:43,136:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 12:15:43,136:INFO:[LightGBM] [Info] Total Bins 2868
2026-01-30 12:15:43,137:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 26
2026-01-30 12:15:43,140:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 12:15:43,140:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 12:15:44,105:INFO:Uploading results into container
2026-01-30 12:15:44,107:INFO:Uploading model into container now
2026-01-30 12:15:44,107:INFO:_master_model_container: 8
2026-01-30 12:15:44,107:INFO:_display_container: 5
2026-01-30 12:15:44,107:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 12:15:44,109:INFO:create_model() successfully completed......................................
2026-01-30 12:15:44,387:INFO:SubProcess create_model() end ==================================
2026-01-30 12:15:44,389:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9766
2026-01-30 12:15:44,390:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9936
2026-01-30 12:15:44,391:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2026-01-30 12:15:44,391:INFO:choose_better completed
2026-01-30 12:15:44,393:INFO:_master_model_container: 8
2026-01-30 12:15:44,393:INFO:_display_container: 4
2026-01-30 12:15:44,395:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 12:15:44,395:INFO:tune_model() successfully completed......................................
2026-01-30 12:15:44,604:INFO:Initializing tune_model()
2026-01-30 12:15:44,604:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C27B3A10>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 12:15:44,605:INFO:Checking exceptions
2026-01-30 12:15:44,708:INFO:Copying training dataset
2026-01-30 12:15:44,838:INFO:Checking base model
2026-01-30 12:15:44,838:INFO:Base model : Decision Tree Classifier
2026-01-30 12:15:44,838:INFO:Declaring metric variables
2026-01-30 12:15:44,839:INFO:Defining Hyperparameters
2026-01-30 12:15:45,030:INFO:Tuning with n_jobs=-1
2026-01-30 12:15:45,030:INFO:Initializing RandomizedSearchCV
2026-01-30 12:15:53,301:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 15, 'actual_estimator__criterion': 'gini'}
2026-01-30 12:15:53,301:INFO:Hyperparameter search completed
2026-01-30 12:15:53,301:INFO:SubProcess create_model() called ==================================
2026-01-30 12:15:53,301:INFO:Initializing create_model()
2026-01-30 12:15:53,301:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C27B3A10>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03C38F990>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 2, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 15, 'criterion': 'gini'})
2026-01-30 12:15:53,301:INFO:Checking exceptions
2026-01-30 12:15:53,301:INFO:Importing libraries
2026-01-30 12:15:53,301:INFO:Copying training dataset
2026-01-30 12:15:53,535:INFO:Defining folds
2026-01-30 12:15:53,535:INFO:Declaring metric variables
2026-01-30 12:15:53,535:INFO:Importing untrained model
2026-01-30 12:15:53,535:INFO:Declaring custom model
2026-01-30 12:15:53,536:INFO:Decision Tree Classifier Imported successfully
2026-01-30 12:15:53,536:INFO:Starting cross validation
2026-01-30 12:15:53,537:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:15:56,442:INFO:Calculating mean and std
2026-01-30 12:15:56,442:INFO:Creating metrics dataframe
2026-01-30 12:15:56,451:INFO:Finalizing model
2026-01-30 12:15:58,200:INFO:Uploading results into container
2026-01-30 12:15:58,200:INFO:Uploading model into container now
2026-01-30 12:15:58,200:INFO:_master_model_container: 9
2026-01-30 12:15:58,200:INFO:_display_container: 5
2026-01-30 12:15:58,200:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 12:15:58,200:INFO:create_model() successfully completed......................................
2026-01-30 12:15:58,367:INFO:SubProcess create_model() end ==================================
2026-01-30 12:15:58,367:INFO:choose_better activated
2026-01-30 12:15:58,367:INFO:SubProcess create_model() called ==================================
2026-01-30 12:15:58,367:INFO:Initializing create_model()
2026-01-30 12:15:58,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C27B3A10>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:15:58,367:INFO:Checking exceptions
2026-01-30 12:15:58,367:INFO:Importing libraries
2026-01-30 12:15:58,367:INFO:Copying training dataset
2026-01-30 12:15:58,567:INFO:Defining folds
2026-01-30 12:15:58,567:INFO:Declaring metric variables
2026-01-30 12:15:58,567:INFO:Importing untrained model
2026-01-30 12:15:58,567:INFO:Declaring custom model
2026-01-30 12:15:58,567:INFO:Decision Tree Classifier Imported successfully
2026-01-30 12:15:58,567:INFO:Starting cross validation
2026-01-30 12:15:58,567:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:16:02,453:INFO:Calculating mean and std
2026-01-30 12:16:02,455:INFO:Creating metrics dataframe
2026-01-30 12:16:02,456:INFO:Finalizing model
2026-01-30 12:16:05,534:INFO:Uploading results into container
2026-01-30 12:16:05,534:INFO:Uploading model into container now
2026-01-30 12:16:05,534:INFO:_master_model_container: 10
2026-01-30 12:16:05,534:INFO:_display_container: 6
2026-01-30 12:16:05,534:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 12:16:05,534:INFO:create_model() successfully completed......................................
2026-01-30 12:16:05,700:INFO:SubProcess create_model() end ==================================
2026-01-30 12:16:05,700:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9701
2026-01-30 12:16:05,700:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9544
2026-01-30 12:16:05,700:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-30 12:16:05,700:INFO:choose_better completed
2026-01-30 12:16:05,700:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 12:16:05,700:INFO:_master_model_container: 10
2026-01-30 12:16:05,700:INFO:_display_container: 5
2026-01-30 12:16:05,700:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 12:16:05,700:INFO:tune_model() successfully completed......................................
2026-01-30 12:16:05,884:INFO:Initializing predict_model()
2026-01-30 12:16:05,884:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C27B3A10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A0C9E37600>)
2026-01-30 12:16:05,884:INFO:Checking exceptions
2026-01-30 12:16:05,884:INFO:Preloading libraries
2026-01-30 12:16:05,884:INFO:Set up data.
2026-01-30 12:16:05,884:INFO:Set up index.
2026-01-30 12:16:06,400:INFO:Initializing predict_model()
2026-01-30 12:16:06,400:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C27B3A10>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A0C9E365C0>)
2026-01-30 12:16:06,400:INFO:Checking exceptions
2026-01-30 12:16:06,400:INFO:Preloading libraries
2026-01-30 12:16:06,400:INFO:Set up data.
2026-01-30 12:16:06,417:INFO:Set up index.
2026-01-30 12:16:06,810:INFO:Initializing predict_model()
2026-01-30 12:16:06,810:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C27B3A10>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A0C9E349A0>)
2026-01-30 12:16:06,810:INFO:Checking exceptions
2026-01-30 12:16:06,810:INFO:Preloading libraries
2026-01-30 12:16:06,810:INFO:Set up data.
2026-01-30 12:16:06,817:INFO:Set up index.
2026-01-30 12:16:07,151:INFO:Initializing plot_model()
2026-01-30 12:16:07,151:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C27B3A10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 12:16:07,151:INFO:Checking exceptions
2026-01-30 12:16:07,250:INFO:Preloading libraries
2026-01-30 12:16:07,369:INFO:Copying training dataset
2026-01-30 12:16:07,369:INFO:Plot type: feature
2026-01-30 12:16:07,369:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 12:16:07,700:INFO:Visual Rendered Successfully
2026-01-30 12:16:07,877:INFO:plot_model() successfully completed......................................
2026-01-30 12:16:07,884:INFO:Initializing plot_model()
2026-01-30 12:16:07,884:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C27B3A10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature_all, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 12:16:07,884:INFO:Checking exceptions
2026-01-30 12:16:07,983:INFO:Preloading libraries
2026-01-30 12:16:08,083:INFO:Copying training dataset
2026-01-30 12:16:08,083:INFO:Plot type: feature_all
2026-01-30 12:16:08,284:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 12:16:08,684:INFO:Visual Rendered Successfully
2026-01-30 12:16:08,850:INFO:plot_model() successfully completed......................................
2026-01-30 12:16:08,873:INFO:Initializing save_model()
2026-01-30 12:16:08,873:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), model_name=..\datos\04. Modelos\modelo_final_explicable, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdinario_def__c',
                                             'C...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-30 12:16:08,873:INFO:Adding model into prep_pipe
2026-01-30 12:16:09,017:INFO:..\datos\04. Modelos\modelo_final_explicable.pkl saved in current working directory
2026-01-30 12:16:09,017:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdinario_def__c',
                                             'CU_precioAplicado_def__c',
                                             'PORCENTAJE_PAGAD...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=42, verbose=0,
                                        warm_start=False))],
         verbose=False)
2026-01-30 12:16:09,017:INFO:save_model() successfully completed......................................
2026-01-30 12:16:43,042:INFO:Initializing load_model()
2026-01-30 12:16:43,042:INFO:load_model(model_name=..\datos\04. Modelos\modelo_final_explicable, platform=None, authentication=None, verbose=True)
2026-01-30 12:16:45,200:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\3530218875.py:26: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-30 12:16:45,700:INFO:Initializing predict_model()
2026-01-30 12:16:45,700:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029C4C357590>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdinario_def__c',
                                             'CU_precioAplicado_def__c',
                                             'PORCENTAJE_PAGADO_FINAL',
                                             'tie...
                                             'flag_CU_IMPORTE_TOTAL_na',
                                             'flag_CU_precioOrdinario_def__c_na',
                                             'flag_CU_precioAplicado_def__c_na'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 RandomForestClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000029C524F4AE0>)
2026-01-30 12:16:45,700:INFO:Checking exceptions
2026-01-30 12:16:45,700:INFO:Preloading libraries
2026-01-30 12:16:45,700:INFO:Set up data.
2026-01-30 12:16:45,800:INFO:Set up index.
2026-01-30 12:19:38,795:INFO:Initializing load_model()
2026-01-30 12:19:38,795:INFO:load_model(model_name=..\datos\04. Modelos\modelo_final_explicable, platform=None, authentication=None, verbose=True)
2026-01-30 12:19:40,892:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\1468113168.py:26: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-30 12:21:14,101:INFO:Initializing load_model()
2026-01-30 12:21:14,101:INFO:load_model(model_name=..\datos\04. Modelos\modelo_final_explicable, platform=None, authentication=None, verbose=True)
2026-01-30 12:21:16,330:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\3896292828.py:26: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-30 12:22:11,901:INFO:Initializing load_model()
2026-01-30 12:22:11,901:INFO:load_model(model_name=..\datos\04. Modelos\modelo_final_explicable, platform=None, authentication=None, verbose=True)
2026-01-30 12:22:14,179:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\3420052680.py:26: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-30 12:23:35,373:INFO:Initializing load_model()
2026-01-30 12:23:35,374:INFO:load_model(model_name=..\datos\04. Modelos\modelo_final_explicable, platform=None, authentication=None, verbose=True)
2026-01-30 12:23:37,477:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\2096248682.py:26: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-30 12:24:36,048:INFO:Initializing load_model()
2026-01-30 12:24:36,048:INFO:load_model(model_name=..\datos\04. Modelos\modelo_final_explicable, platform=None, authentication=None, verbose=True)
2026-01-30 12:24:38,299:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\2914251258.py:26: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-30 12:25:49,909:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\3289443975.py:20: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-30 12:25:52,059:INFO:PyCaret ClassificationExperiment
2026-01-30 12:25:52,059:INFO:Logging name: clf-default-name
2026-01-30 12:25:52,059:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-30 12:25:52,059:INFO:version 3.3.2
2026-01-30 12:25:52,059:INFO:Initializing setup()
2026-01-30 12:25:52,059:INFO:self.USI: 85dd
2026-01-30 12:25:52,059:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'n_jobs_param', 'data', 'X', 'idx', 'y_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'USI', 'target_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'y_train', 'X_test', 'seed', 'gpu_param', 'gpu_n_jobs_param', 'y', 'logging_param', 'pipeline', 'fold_generator', 'exp_id'}
2026-01-30 12:25:52,059:INFO:Checking environment
2026-01-30 12:25:52,059:INFO:python_version: 3.11.11
2026-01-30 12:25:52,059:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-30 12:25:52,059:INFO:machine: AMD64
2026-01-30 12:25:52,059:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-30 12:25:52,062:INFO:Memory: svmem(total=34009374720, available=12823748608, percent=62.3, used=21185626112, free=12823748608)
2026-01-30 12:25:52,062:INFO:Physical Core: 12
2026-01-30 12:25:52,062:INFO:Logical Core: 16
2026-01-30 12:25:52,062:INFO:Checking libraries
2026-01-30 12:25:52,062:INFO:System:
2026-01-30 12:25:52,062:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-30 12:25:52,062:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-30 12:25:52,062:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-30 12:25:52,062:INFO:PyCaret required dependencies:
2026-01-30 12:25:52,062:INFO:                 pip: 25.0
2026-01-30 12:25:52,062:INFO:          setuptools: 75.8.0
2026-01-30 12:25:52,062:INFO:             pycaret: 3.3.2
2026-01-30 12:25:52,062:INFO:             IPython: 9.9.0
2026-01-30 12:25:52,064:INFO:          ipywidgets: 8.1.8
2026-01-30 12:25:52,064:INFO:                tqdm: 4.67.1
2026-01-30 12:25:52,064:INFO:               numpy: 1.26.4
2026-01-30 12:25:52,064:INFO:              pandas: 2.1.4
2026-01-30 12:25:52,064:INFO:              jinja2: 3.1.6
2026-01-30 12:25:52,064:INFO:               scipy: 1.11.4
2026-01-30 12:25:52,064:INFO:              joblib: 1.3.2
2026-01-30 12:25:52,064:INFO:             sklearn: 1.4.2
2026-01-30 12:25:52,064:INFO:                pyod: 2.0.6
2026-01-30 12:25:52,064:INFO:            imblearn: 0.14.1
2026-01-30 12:25:52,064:INFO:   category_encoders: 2.7.0
2026-01-30 12:25:52,064:INFO:            lightgbm: 4.6.0
2026-01-30 12:25:52,064:INFO:               numba: 0.62.1
2026-01-30 12:25:52,064:INFO:            requests: 2.32.3
2026-01-30 12:25:52,064:INFO:          matplotlib: 3.7.5
2026-01-30 12:25:52,064:INFO:          scikitplot: 0.3.7
2026-01-30 12:25:52,064:INFO:         yellowbrick: 1.5
2026-01-30 12:25:52,064:INFO:              plotly: 5.24.1
2026-01-30 12:25:52,064:INFO:    plotly-resampler: Not installed
2026-01-30 12:25:52,064:INFO:             kaleido: 1.2.0
2026-01-30 12:25:52,064:INFO:           schemdraw: 0.15
2026-01-30 12:25:52,064:INFO:         statsmodels: 0.14.6
2026-01-30 12:25:52,064:INFO:              sktime: 0.26.0
2026-01-30 12:25:52,064:INFO:               tbats: 1.1.3
2026-01-30 12:25:52,064:INFO:            pmdarima: 2.0.4
2026-01-30 12:25:52,064:INFO:              psutil: 7.2.1
2026-01-30 12:25:52,064:INFO:          markupsafe: 3.0.3
2026-01-30 12:25:52,064:INFO:             pickle5: Not installed
2026-01-30 12:25:52,064:INFO:         cloudpickle: 3.0.0
2026-01-30 12:25:52,064:INFO:         deprecation: 2.1.0
2026-01-30 12:25:52,064:INFO:              xxhash: 3.6.0
2026-01-30 12:25:52,064:INFO:           wurlitzer: Not installed
2026-01-30 12:25:52,064:INFO:PyCaret optional dependencies:
2026-01-30 12:25:52,064:INFO:                shap: 0.44.1
2026-01-30 12:25:52,064:INFO:           interpret: 0.7.3
2026-01-30 12:25:52,064:INFO:                umap: 0.5.7
2026-01-30 12:25:52,064:INFO:     ydata_profiling: 4.18.1
2026-01-30 12:25:52,064:INFO:  explainerdashboard: 0.5.1
2026-01-30 12:25:52,064:INFO:             autoviz: Not installed
2026-01-30 12:25:52,064:INFO:           fairlearn: 0.7.0
2026-01-30 12:25:52,064:INFO:          deepchecks: Not installed
2026-01-30 12:25:52,064:INFO:             xgboost: Not installed
2026-01-30 12:25:52,064:INFO:            catboost: 1.2.8
2026-01-30 12:25:52,064:INFO:              kmodes: 0.12.2
2026-01-30 12:25:52,064:INFO:             mlxtend: 0.23.4
2026-01-30 12:25:52,064:INFO:       statsforecast: 1.5.0
2026-01-30 12:25:52,064:INFO:        tune_sklearn: Not installed
2026-01-30 12:25:52,064:INFO:                 ray: Not installed
2026-01-30 12:25:52,064:INFO:            hyperopt: 0.2.7
2026-01-30 12:25:52,064:INFO:              optuna: 4.6.0
2026-01-30 12:25:52,064:INFO:               skopt: 0.10.2
2026-01-30 12:25:52,064:INFO:              mlflow: 3.8.1
2026-01-30 12:25:52,064:INFO:              gradio: 6.3.0
2026-01-30 12:25:52,064:INFO:             fastapi: 0.128.0
2026-01-30 12:25:52,064:INFO:             uvicorn: 0.40.0
2026-01-30 12:25:52,064:INFO:              m2cgen: 0.10.0
2026-01-30 12:25:52,064:INFO:           evidently: 0.4.40
2026-01-30 12:25:52,064:INFO:               fugue: 0.8.7
2026-01-30 12:25:52,064:INFO:           streamlit: Not installed
2026-01-30 12:25:52,064:INFO:             prophet: Not installed
2026-01-30 12:25:52,064:INFO:None
2026-01-30 12:25:52,064:INFO:Set up data.
2026-01-30 12:25:52,192:INFO:Set up folding strategy.
2026-01-30 12:25:52,192:INFO:Set up train/test split.
2026-01-30 12:25:52,392:INFO:Set up index.
2026-01-30 12:25:52,412:INFO:Assigning column types.
2026-01-30 12:25:52,559:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-30 12:25:52,587:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 12:25:52,587:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 12:25:52,592:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:25:52,592:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:25:52,626:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 12:25:52,626:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 12:25:52,645:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:25:52,645:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:25:52,645:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-30 12:25:52,675:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 12:25:52,692:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:25:52,692:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:25:52,725:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 12:25:52,742:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:25:52,742:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:25:52,742:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-30 12:25:52,799:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:25:52,799:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:25:52,842:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:25:52,842:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:25:52,842:INFO:Preparing preprocessing pipeline...
2026-01-30 12:25:52,875:INFO:Set up simple imputation.
2026-01-30 12:25:52,875:INFO:Set up feature normalization.
2026-01-30 12:25:53,179:INFO:Finished creating preprocessing pipeline.
2026-01-30 12:25:53,179:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdinario_def__c',
                                             'C...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-30 12:25:53,179:INFO:Creating final display dataframe.
2026-01-30 12:25:53,795:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape      (482669, 27)
4        Transformed data shape      (482669, 27)
5   Transformed train set shape      (337868, 27)
6    Transformed test set shape      (144801, 27)
7              Numeric features                23
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                 3
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              85dd
2026-01-30 12:25:53,841:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:25:53,841:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:25:53,876:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:25:53,876:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:25:53,876:INFO:setup() successfully completed in 1.83s...............
2026-01-30 12:25:53,876:INFO:Initializing compare_models()
2026-01-30 12:25:53,890:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04D030E90>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A04D030E90>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-30 12:25:53,890:INFO:Checking exceptions
2026-01-30 12:25:53,992:INFO:Preparing display monitor
2026-01-30 12:25:53,992:INFO:Initializing Logistic Regression
2026-01-30 12:25:53,992:INFO:Total runtime is 0.0 minutes
2026-01-30 12:25:53,992:INFO:SubProcess create_model() called ==================================
2026-01-30 12:25:53,992:INFO:Initializing create_model()
2026-01-30 12:25:53,992:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04D030E90>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04C76F610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:25:53,992:INFO:Checking exceptions
2026-01-30 12:25:53,992:INFO:Importing libraries
2026-01-30 12:25:53,992:INFO:Copying training dataset
2026-01-30 12:25:54,159:INFO:Defining folds
2026-01-30 12:25:54,159:INFO:Declaring metric variables
2026-01-30 12:25:54,159:INFO:Importing untrained model
2026-01-30 12:25:54,159:INFO:Logistic Regression Imported successfully
2026-01-30 12:25:54,159:INFO:Starting cross validation
2026-01-30 12:25:54,159:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:26:02,949:INFO:Calculating mean and std
2026-01-30 12:26:02,951:INFO:Creating metrics dataframe
2026-01-30 12:26:02,954:INFO:Uploading results into container
2026-01-30 12:26:02,954:INFO:Uploading model into container now
2026-01-30 12:26:02,956:INFO:_master_model_container: 1
2026-01-30 12:26:02,956:INFO:_display_container: 2
2026-01-30 12:26:02,956:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-30 12:26:02,956:INFO:create_model() successfully completed......................................
2026-01-30 12:26:03,125:INFO:SubProcess create_model() end ==================================
2026-01-30 12:26:03,125:INFO:Creating metrics dataframe
2026-01-30 12:26:03,125:INFO:Initializing Decision Tree Classifier
2026-01-30 12:26:03,125:INFO:Total runtime is 0.1522191842397054 minutes
2026-01-30 12:26:03,125:INFO:SubProcess create_model() called ==================================
2026-01-30 12:26:03,125:INFO:Initializing create_model()
2026-01-30 12:26:03,125:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04D030E90>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04C76F610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:26:03,125:INFO:Checking exceptions
2026-01-30 12:26:03,125:INFO:Importing libraries
2026-01-30 12:26:03,125:INFO:Copying training dataset
2026-01-30 12:26:03,308:INFO:Defining folds
2026-01-30 12:26:03,308:INFO:Declaring metric variables
2026-01-30 12:26:03,308:INFO:Importing untrained model
2026-01-30 12:26:03,308:INFO:Decision Tree Classifier Imported successfully
2026-01-30 12:26:03,308:INFO:Starting cross validation
2026-01-30 12:26:03,308:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:26:12,309:INFO:Calculating mean and std
2026-01-30 12:26:12,309:INFO:Creating metrics dataframe
2026-01-30 12:26:12,309:INFO:Uploading results into container
2026-01-30 12:26:12,309:INFO:Uploading model into container now
2026-01-30 12:26:12,309:INFO:_master_model_container: 2
2026-01-30 12:26:12,309:INFO:_display_container: 2
2026-01-30 12:26:12,309:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 12:26:12,309:INFO:create_model() successfully completed......................................
2026-01-30 12:26:12,476:INFO:SubProcess create_model() end ==================================
2026-01-30 12:26:12,476:INFO:Creating metrics dataframe
2026-01-30 12:26:12,476:INFO:Initializing Random Forest Classifier
2026-01-30 12:26:12,476:INFO:Total runtime is 0.3080564459164937 minutes
2026-01-30 12:26:12,476:INFO:SubProcess create_model() called ==================================
2026-01-30 12:26:12,476:INFO:Initializing create_model()
2026-01-30 12:26:12,476:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04D030E90>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04C76F610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:26:12,476:INFO:Checking exceptions
2026-01-30 12:26:12,476:INFO:Importing libraries
2026-01-30 12:26:12,476:INFO:Copying training dataset
2026-01-30 12:26:12,662:INFO:Defining folds
2026-01-30 12:26:12,662:INFO:Declaring metric variables
2026-01-30 12:26:12,662:INFO:Importing untrained model
2026-01-30 12:26:12,662:INFO:Random Forest Classifier Imported successfully
2026-01-30 12:26:12,662:INFO:Starting cross validation
2026-01-30 12:26:12,662:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:26:39,226:INFO:Calculating mean and std
2026-01-30 12:26:39,228:INFO:Creating metrics dataframe
2026-01-30 12:26:39,231:INFO:Uploading results into container
2026-01-30 12:26:39,231:INFO:Uploading model into container now
2026-01-30 12:26:39,231:INFO:_master_model_container: 3
2026-01-30 12:26:39,231:INFO:_display_container: 2
2026-01-30 12:26:39,231:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 12:26:39,231:INFO:create_model() successfully completed......................................
2026-01-30 12:26:39,425:INFO:SubProcess create_model() end ==================================
2026-01-30 12:26:39,425:INFO:Creating metrics dataframe
2026-01-30 12:26:39,425:INFO:Initializing Light Gradient Boosting Machine
2026-01-30 12:26:39,425:INFO:Total runtime is 0.7572128812472025 minutes
2026-01-30 12:26:39,425:INFO:SubProcess create_model() called ==================================
2026-01-30 12:26:39,425:INFO:Initializing create_model()
2026-01-30 12:26:39,425:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04D030E90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04C76F610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:26:39,425:INFO:Checking exceptions
2026-01-30 12:26:39,425:INFO:Importing libraries
2026-01-30 12:26:39,425:INFO:Copying training dataset
2026-01-30 12:26:39,642:INFO:Defining folds
2026-01-30 12:26:39,642:INFO:Declaring metric variables
2026-01-30 12:26:39,642:INFO:Importing untrained model
2026-01-30 12:26:39,642:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 12:26:39,642:INFO:Starting cross validation
2026-01-30 12:26:39,642:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:26:50,092:INFO:Calculating mean and std
2026-01-30 12:26:50,094:INFO:Creating metrics dataframe
2026-01-30 12:26:50,099:INFO:Uploading results into container
2026-01-30 12:26:50,099:INFO:Uploading model into container now
2026-01-30 12:26:50,100:INFO:_master_model_container: 4
2026-01-30 12:26:50,100:INFO:_display_container: 2
2026-01-30 12:26:50,101:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 12:26:50,101:INFO:create_model() successfully completed......................................
2026-01-30 12:26:50,273:INFO:SubProcess create_model() end ==================================
2026-01-30 12:26:50,273:INFO:Creating metrics dataframe
2026-01-30 12:26:50,273:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-30 12:26:50,288:INFO:Initializing create_model()
2026-01-30 12:26:50,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04D030E90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:26:50,289:INFO:Checking exceptions
2026-01-30 12:26:50,289:INFO:Importing libraries
2026-01-30 12:26:50,289:INFO:Copying training dataset
2026-01-30 12:26:50,457:INFO:Defining folds
2026-01-30 12:26:50,457:INFO:Declaring metric variables
2026-01-30 12:26:50,457:INFO:Importing untrained model
2026-01-30 12:26:50,457:INFO:Declaring custom model
2026-01-30 12:26:50,457:INFO:Random Forest Classifier Imported successfully
2026-01-30 12:26:50,457:INFO:Cross validation set to False
2026-01-30 12:26:50,457:INFO:Fitting Model
2026-01-30 12:27:01,198:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 12:27:01,198:INFO:create_model() successfully completed......................................
2026-01-30 12:27:01,379:INFO:Initializing create_model()
2026-01-30 12:27:01,379:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04D030E90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:27:01,379:INFO:Checking exceptions
2026-01-30 12:27:01,379:INFO:Importing libraries
2026-01-30 12:27:01,379:INFO:Copying training dataset
2026-01-30 12:27:01,560:INFO:Defining folds
2026-01-30 12:27:01,560:INFO:Declaring metric variables
2026-01-30 12:27:01,560:INFO:Importing untrained model
2026-01-30 12:27:01,560:INFO:Declaring custom model
2026-01-30 12:27:01,560:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 12:27:01,560:INFO:Cross validation set to False
2026-01-30 12:27:01,560:INFO:Fitting Model
2026-01-30 12:27:02,383:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 12:27:02,446:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015792 seconds.
2026-01-30 12:27:02,446:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 12:27:02,446:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 12:27:02,446:INFO:[LightGBM] [Info] Total Bins 2868
2026-01-30 12:27:02,448:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 26
2026-01-30 12:27:02,450:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 12:27:02,450:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 12:27:03,268:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 12:27:03,270:INFO:create_model() successfully completed......................................
2026-01-30 12:27:03,510:INFO:Initializing create_model()
2026-01-30 12:27:03,510:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04D030E90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:27:03,511:INFO:Checking exceptions
2026-01-30 12:27:03,511:INFO:Importing libraries
2026-01-30 12:27:03,511:INFO:Copying training dataset
2026-01-30 12:27:03,796:INFO:Defining folds
2026-01-30 12:27:03,796:INFO:Declaring metric variables
2026-01-30 12:27:03,796:INFO:Importing untrained model
2026-01-30 12:27:03,796:INFO:Declaring custom model
2026-01-30 12:27:03,796:INFO:Decision Tree Classifier Imported successfully
2026-01-30 12:27:03,798:INFO:Cross validation set to False
2026-01-30 12:27:03,798:INFO:Fitting Model
2026-01-30 12:27:06,623:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 12:27:06,623:INFO:create_model() successfully completed......................................
2026-01-30 12:27:06,799:INFO:_master_model_container: 4
2026-01-30 12:27:06,799:INFO:_display_container: 2
2026-01-30 12:27:06,801:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')]
2026-01-30 12:27:06,801:INFO:compare_models() successfully completed......................................
2026-01-30 12:27:06,812:INFO:Initializing tune_model()
2026-01-30 12:27:06,812:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04D030E90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 12:27:06,813:INFO:Checking exceptions
2026-01-30 12:27:06,877:INFO:Copying training dataset
2026-01-30 12:27:06,989:INFO:Checking base model
2026-01-30 12:27:06,989:INFO:Base model : Random Forest Classifier
2026-01-30 12:27:06,989:INFO:Declaring metric variables
2026-01-30 12:27:06,989:INFO:Defining Hyperparameters
2026-01-30 12:27:07,141:INFO:Tuning with n_jobs=-1
2026-01-30 12:27:07,141:INFO:Initializing RandomizedSearchCV
2026-01-30 12:30:01,424:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-30 12:30:01,425:INFO:Hyperparameter search completed
2026-01-30 12:30:01,426:INFO:SubProcess create_model() called ==================================
2026-01-30 12:30:01,427:INFO:Initializing create_model()
2026-01-30 12:30:01,428:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04D030E90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03CFFB5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': True})
2026-01-30 12:30:01,428:INFO:Checking exceptions
2026-01-30 12:30:01,428:INFO:Importing libraries
2026-01-30 12:30:01,428:INFO:Copying training dataset
2026-01-30 12:30:01,717:INFO:Defining folds
2026-01-30 12:30:01,718:INFO:Declaring metric variables
2026-01-30 12:30:01,718:INFO:Importing untrained model
2026-01-30 12:30:01,718:INFO:Declaring custom model
2026-01-30 12:30:01,719:INFO:Random Forest Classifier Imported successfully
2026-01-30 12:30:01,719:INFO:Starting cross validation
2026-01-30 12:30:01,720:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:30:34,356:INFO:Calculating mean and std
2026-01-30 12:30:34,356:INFO:Creating metrics dataframe
2026-01-30 12:30:34,356:INFO:Finalizing model
2026-01-30 12:30:50,379:INFO:Uploading results into container
2026-01-30 12:30:50,380:INFO:Uploading model into container now
2026-01-30 12:30:50,381:INFO:_master_model_container: 5
2026-01-30 12:30:50,381:INFO:_display_container: 3
2026-01-30 12:30:50,381:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 12:30:50,381:INFO:create_model() successfully completed......................................
2026-01-30 12:30:50,571:INFO:SubProcess create_model() end ==================================
2026-01-30 12:30:50,571:INFO:choose_better activated
2026-01-30 12:30:50,571:INFO:SubProcess create_model() called ==================================
2026-01-30 12:30:50,572:INFO:Initializing create_model()
2026-01-30 12:30:50,572:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04D030E90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:30:50,572:INFO:Checking exceptions
2026-01-30 12:30:50,573:INFO:Importing libraries
2026-01-30 12:30:50,573:INFO:Copying training dataset
2026-01-30 12:30:50,821:INFO:Defining folds
2026-01-30 12:30:50,821:INFO:Declaring metric variables
2026-01-30 12:30:50,821:INFO:Importing untrained model
2026-01-30 12:30:50,821:INFO:Declaring custom model
2026-01-30 12:30:50,821:INFO:Random Forest Classifier Imported successfully
2026-01-30 12:30:50,821:INFO:Starting cross validation
2026-01-30 12:30:50,821:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:31:14,374:INFO:Calculating mean and std
2026-01-30 12:31:14,374:INFO:Creating metrics dataframe
2026-01-30 12:31:14,374:INFO:Finalizing model
2026-01-30 12:31:26,214:INFO:Uploading results into container
2026-01-30 12:31:26,215:INFO:Uploading model into container now
2026-01-30 12:31:26,215:INFO:_master_model_container: 6
2026-01-30 12:31:26,216:INFO:_display_container: 4
2026-01-30 12:31:26,216:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 12:31:26,216:INFO:create_model() successfully completed......................................
2026-01-30 12:31:26,410:INFO:SubProcess create_model() end ==================================
2026-01-30 12:31:26,410:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9962
2026-01-30 12:31:26,411:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9658
2026-01-30 12:31:26,411:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-30 12:31:26,411:INFO:choose_better completed
2026-01-30 12:31:26,411:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 12:31:26,413:INFO:_master_model_container: 6
2026-01-30 12:31:26,414:INFO:_display_container: 3
2026-01-30 12:31:26,414:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 12:31:26,414:INFO:tune_model() successfully completed......................................
2026-01-30 12:31:26,590:INFO:Initializing tune_model()
2026-01-30 12:31:26,590:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04D030E90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 12:31:26,590:INFO:Checking exceptions
2026-01-30 12:31:26,664:INFO:Copying training dataset
2026-01-30 12:31:26,800:INFO:Checking base model
2026-01-30 12:31:26,800:INFO:Base model : Light Gradient Boosting Machine
2026-01-30 12:31:26,801:INFO:Declaring metric variables
2026-01-30 12:31:26,801:INFO:Defining Hyperparameters
2026-01-30 12:31:26,977:INFO:Tuning with n_jobs=-1
2026-01-30 12:31:26,977:INFO:Initializing RandomizedSearchCV
2026-01-30 12:32:09,587:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2026-01-30 12:32:09,589:INFO:Hyperparameter search completed
2026-01-30 12:32:09,589:INFO:SubProcess create_model() called ==================================
2026-01-30 12:32:09,591:INFO:Initializing create_model()
2026-01-30 12:32:09,591:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04D030E90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0482018D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2026-01-30 12:32:09,591:INFO:Checking exceptions
2026-01-30 12:32:09,591:INFO:Importing libraries
2026-01-30 12:32:09,591:INFO:Copying training dataset
2026-01-30 12:32:09,853:INFO:Defining folds
2026-01-30 12:32:09,853:INFO:Declaring metric variables
2026-01-30 12:32:09,853:INFO:Importing untrained model
2026-01-30 12:32:09,853:INFO:Declaring custom model
2026-01-30 12:32:09,853:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 12:32:09,853:INFO:Starting cross validation
2026-01-30 12:32:09,853:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:32:19,890:INFO:Calculating mean and std
2026-01-30 12:32:19,890:INFO:Creating metrics dataframe
2026-01-30 12:32:19,890:INFO:Finalizing model
2026-01-30 12:32:20,637:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 12:32:20,637:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 12:32:20,637:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 12:32:20,834:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 12:32:20,834:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 12:32:20,834:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 12:32:20,835:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 12:32:20,893:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013462 seconds.
2026-01-30 12:32:20,894:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 12:32:20,894:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 12:32:20,894:INFO:[LightGBM] [Info] Total Bins 2868
2026-01-30 12:32:20,895:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 26
2026-01-30 12:32:20,901:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 12:32:20,901:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 12:32:24,666:INFO:Uploading results into container
2026-01-30 12:32:24,668:INFO:Uploading model into container now
2026-01-30 12:32:24,668:INFO:_master_model_container: 7
2026-01-30 12:32:24,669:INFO:_display_container: 4
2026-01-30 12:32:24,670:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 12:32:24,671:INFO:create_model() successfully completed......................................
2026-01-30 12:32:24,919:INFO:SubProcess create_model() end ==================================
2026-01-30 12:32:24,921:INFO:choose_better activated
2026-01-30 12:32:24,921:INFO:SubProcess create_model() called ==================================
2026-01-30 12:32:24,922:INFO:Initializing create_model()
2026-01-30 12:32:24,922:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04D030E90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:32:24,923:INFO:Checking exceptions
2026-01-30 12:32:24,924:INFO:Importing libraries
2026-01-30 12:32:24,924:INFO:Copying training dataset
2026-01-30 12:32:25,203:INFO:Defining folds
2026-01-30 12:32:25,203:INFO:Declaring metric variables
2026-01-30 12:32:25,203:INFO:Importing untrained model
2026-01-30 12:32:25,203:INFO:Declaring custom model
2026-01-30 12:32:25,203:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 12:32:25,203:INFO:Starting cross validation
2026-01-30 12:32:25,203:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:32:30,797:INFO:Calculating mean and std
2026-01-30 12:32:30,798:INFO:Creating metrics dataframe
2026-01-30 12:32:30,801:INFO:Finalizing model
2026-01-30 12:32:31,883:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 12:32:31,943:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017205 seconds.
2026-01-30 12:32:31,943:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 12:32:31,945:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 12:32:31,945:INFO:[LightGBM] [Info] Total Bins 2868
2026-01-30 12:32:31,945:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 26
2026-01-30 12:32:31,950:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 12:32:31,950:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 12:32:33,287:INFO:Uploading results into container
2026-01-30 12:32:33,288:INFO:Uploading model into container now
2026-01-30 12:32:33,289:INFO:_master_model_container: 8
2026-01-30 12:32:33,289:INFO:_display_container: 5
2026-01-30 12:32:33,290:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 12:32:33,291:INFO:create_model() successfully completed......................................
2026-01-30 12:32:33,538:INFO:SubProcess create_model() end ==================================
2026-01-30 12:32:33,538:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9766
2026-01-30 12:32:33,554:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9936
2026-01-30 12:32:33,555:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2026-01-30 12:32:33,555:INFO:choose_better completed
2026-01-30 12:32:33,555:INFO:_master_model_container: 8
2026-01-30 12:32:33,555:INFO:_display_container: 4
2026-01-30 12:32:33,555:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 12:32:33,555:INFO:tune_model() successfully completed......................................
2026-01-30 12:32:33,802:INFO:Initializing tune_model()
2026-01-30 12:32:33,802:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04D030E90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 12:32:33,802:INFO:Checking exceptions
2026-01-30 12:32:33,956:INFO:Copying training dataset
2026-01-30 12:32:34,103:INFO:Checking base model
2026-01-30 12:32:34,103:INFO:Base model : Decision Tree Classifier
2026-01-30 12:32:34,103:INFO:Declaring metric variables
2026-01-30 12:32:34,103:INFO:Defining Hyperparameters
2026-01-30 12:32:34,290:INFO:Tuning with n_jobs=-1
2026-01-30 12:32:34,290:INFO:Initializing RandomizedSearchCV
2026-01-30 12:32:43,006:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 15, 'actual_estimator__criterion': 'gini'}
2026-01-30 12:32:43,008:INFO:Hyperparameter search completed
2026-01-30 12:32:43,008:INFO:SubProcess create_model() called ==================================
2026-01-30 12:32:43,009:INFO:Initializing create_model()
2026-01-30 12:32:43,009:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04D030E90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C9FF2490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 2, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 15, 'criterion': 'gini'})
2026-01-30 12:32:43,009:INFO:Checking exceptions
2026-01-30 12:32:43,009:INFO:Importing libraries
2026-01-30 12:32:43,009:INFO:Copying training dataset
2026-01-30 12:32:43,237:INFO:Defining folds
2026-01-30 12:32:43,238:INFO:Declaring metric variables
2026-01-30 12:32:43,238:INFO:Importing untrained model
2026-01-30 12:32:43,238:INFO:Declaring custom model
2026-01-30 12:32:43,239:INFO:Decision Tree Classifier Imported successfully
2026-01-30 12:32:43,239:INFO:Starting cross validation
2026-01-30 12:32:43,240:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:32:46,062:INFO:Calculating mean and std
2026-01-30 12:32:46,062:INFO:Creating metrics dataframe
2026-01-30 12:32:46,070:INFO:Finalizing model
2026-01-30 12:32:47,919:INFO:Uploading results into container
2026-01-30 12:32:47,919:INFO:Uploading model into container now
2026-01-30 12:32:47,919:INFO:_master_model_container: 9
2026-01-30 12:32:47,919:INFO:_display_container: 5
2026-01-30 12:32:47,919:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 12:32:47,919:INFO:create_model() successfully completed......................................
2026-01-30 12:32:48,103:INFO:SubProcess create_model() end ==================================
2026-01-30 12:32:48,103:INFO:choose_better activated
2026-01-30 12:32:48,103:INFO:SubProcess create_model() called ==================================
2026-01-30 12:32:48,103:INFO:Initializing create_model()
2026-01-30 12:32:48,103:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04D030E90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:32:48,103:INFO:Checking exceptions
2026-01-30 12:32:48,103:INFO:Importing libraries
2026-01-30 12:32:48,103:INFO:Copying training dataset
2026-01-30 12:32:48,303:INFO:Defining folds
2026-01-30 12:32:48,303:INFO:Declaring metric variables
2026-01-30 12:32:48,303:INFO:Importing untrained model
2026-01-30 12:32:48,303:INFO:Declaring custom model
2026-01-30 12:32:48,303:INFO:Decision Tree Classifier Imported successfully
2026-01-30 12:32:48,303:INFO:Starting cross validation
2026-01-30 12:32:48,303:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:32:52,440:INFO:Calculating mean and std
2026-01-30 12:32:52,441:INFO:Creating metrics dataframe
2026-01-30 12:32:52,442:INFO:Finalizing model
2026-01-30 12:32:55,552:INFO:Uploading results into container
2026-01-30 12:32:55,552:INFO:Uploading model into container now
2026-01-30 12:32:55,552:INFO:_master_model_container: 10
2026-01-30 12:32:55,552:INFO:_display_container: 6
2026-01-30 12:32:55,552:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 12:32:55,552:INFO:create_model() successfully completed......................................
2026-01-30 12:32:55,719:INFO:SubProcess create_model() end ==================================
2026-01-30 12:32:55,719:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9701
2026-01-30 12:32:55,719:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9544
2026-01-30 12:32:55,719:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-30 12:32:55,719:INFO:choose_better completed
2026-01-30 12:32:55,719:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 12:32:55,719:INFO:_master_model_container: 10
2026-01-30 12:32:55,719:INFO:_display_container: 5
2026-01-30 12:32:55,719:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 12:32:55,719:INFO:tune_model() successfully completed......................................
2026-01-30 12:32:55,902:INFO:Initializing predict_model()
2026-01-30 12:32:55,902:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04D030E90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A07498FC40>)
2026-01-30 12:32:55,902:INFO:Checking exceptions
2026-01-30 12:32:55,902:INFO:Preloading libraries
2026-01-30 12:32:55,903:INFO:Set up data.
2026-01-30 12:32:55,903:INFO:Set up index.
2026-01-30 12:32:56,291:INFO:Initializing predict_model()
2026-01-30 12:32:56,291:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04D030E90>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A0530D3BA0>)
2026-01-30 12:32:56,291:INFO:Checking exceptions
2026-01-30 12:32:56,291:INFO:Preloading libraries
2026-01-30 12:32:56,291:INFO:Set up data.
2026-01-30 12:32:56,301:INFO:Set up index.
2026-01-30 12:32:56,685:INFO:Initializing predict_model()
2026-01-30 12:32:56,685:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04D030E90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A0530D3920>)
2026-01-30 12:32:56,685:INFO:Checking exceptions
2026-01-30 12:32:56,685:INFO:Preloading libraries
2026-01-30 12:32:56,685:INFO:Set up data.
2026-01-30 12:32:56,706:INFO:Set up index.
2026-01-30 12:36:25,958:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\1851865221.py:20: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-30 12:36:28,250:INFO:PyCaret ClassificationExperiment
2026-01-30 12:36:28,250:INFO:Logging name: clf-default-name
2026-01-30 12:36:28,250:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-30 12:36:28,250:INFO:version 3.3.2
2026-01-30 12:36:28,250:INFO:Initializing setup()
2026-01-30 12:36:28,250:INFO:self.USI: 0c31
2026-01-30 12:36:28,250:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'n_jobs_param', 'data', 'X', 'idx', 'y_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'USI', 'target_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'y_train', 'X_test', 'seed', 'gpu_param', 'gpu_n_jobs_param', 'y', 'logging_param', 'pipeline', 'fold_generator', 'exp_id'}
2026-01-30 12:36:28,250:INFO:Checking environment
2026-01-30 12:36:28,250:INFO:python_version: 3.11.11
2026-01-30 12:36:28,250:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-30 12:36:28,250:INFO:machine: AMD64
2026-01-30 12:36:28,250:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-30 12:36:28,250:INFO:Memory: svmem(total=34009374720, available=9214246912, percent=72.9, used=24795127808, free=9214246912)
2026-01-30 12:36:28,250:INFO:Physical Core: 12
2026-01-30 12:36:28,250:INFO:Logical Core: 16
2026-01-30 12:36:28,250:INFO:Checking libraries
2026-01-30 12:36:28,250:INFO:System:
2026-01-30 12:36:28,250:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-30 12:36:28,250:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-30 12:36:28,250:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-30 12:36:28,250:INFO:PyCaret required dependencies:
2026-01-30 12:36:28,250:INFO:                 pip: 25.0
2026-01-30 12:36:28,250:INFO:          setuptools: 75.8.0
2026-01-30 12:36:28,250:INFO:             pycaret: 3.3.2
2026-01-30 12:36:28,250:INFO:             IPython: 9.9.0
2026-01-30 12:36:28,250:INFO:          ipywidgets: 8.1.8
2026-01-30 12:36:28,250:INFO:                tqdm: 4.67.1
2026-01-30 12:36:28,250:INFO:               numpy: 1.26.4
2026-01-30 12:36:28,250:INFO:              pandas: 2.1.4
2026-01-30 12:36:28,250:INFO:              jinja2: 3.1.6
2026-01-30 12:36:28,250:INFO:               scipy: 1.11.4
2026-01-30 12:36:28,250:INFO:              joblib: 1.3.2
2026-01-30 12:36:28,250:INFO:             sklearn: 1.4.2
2026-01-30 12:36:28,250:INFO:                pyod: 2.0.6
2026-01-30 12:36:28,250:INFO:            imblearn: 0.14.1
2026-01-30 12:36:28,250:INFO:   category_encoders: 2.7.0
2026-01-30 12:36:28,250:INFO:            lightgbm: 4.6.0
2026-01-30 12:36:28,250:INFO:               numba: 0.62.1
2026-01-30 12:36:28,250:INFO:            requests: 2.32.3
2026-01-30 12:36:28,250:INFO:          matplotlib: 3.7.5
2026-01-30 12:36:28,250:INFO:          scikitplot: 0.3.7
2026-01-30 12:36:28,250:INFO:         yellowbrick: 1.5
2026-01-30 12:36:28,250:INFO:              plotly: 5.24.1
2026-01-30 12:36:28,250:INFO:    plotly-resampler: Not installed
2026-01-30 12:36:28,250:INFO:             kaleido: 1.2.0
2026-01-30 12:36:28,250:INFO:           schemdraw: 0.15
2026-01-30 12:36:28,250:INFO:         statsmodels: 0.14.6
2026-01-30 12:36:28,250:INFO:              sktime: 0.26.0
2026-01-30 12:36:28,250:INFO:               tbats: 1.1.3
2026-01-30 12:36:28,250:INFO:            pmdarima: 2.0.4
2026-01-30 12:36:28,250:INFO:              psutil: 7.2.1
2026-01-30 12:36:28,250:INFO:          markupsafe: 3.0.3
2026-01-30 12:36:28,250:INFO:             pickle5: Not installed
2026-01-30 12:36:28,250:INFO:         cloudpickle: 3.0.0
2026-01-30 12:36:28,250:INFO:         deprecation: 2.1.0
2026-01-30 12:36:28,250:INFO:              xxhash: 3.6.0
2026-01-30 12:36:28,250:INFO:           wurlitzer: Not installed
2026-01-30 12:36:28,250:INFO:PyCaret optional dependencies:
2026-01-30 12:36:28,250:INFO:                shap: 0.44.1
2026-01-30 12:36:28,250:INFO:           interpret: 0.7.3
2026-01-30 12:36:28,250:INFO:                umap: 0.5.7
2026-01-30 12:36:28,250:INFO:     ydata_profiling: 4.18.1
2026-01-30 12:36:28,250:INFO:  explainerdashboard: 0.5.1
2026-01-30 12:36:28,250:INFO:             autoviz: Not installed
2026-01-30 12:36:28,250:INFO:           fairlearn: 0.7.0
2026-01-30 12:36:28,250:INFO:          deepchecks: Not installed
2026-01-30 12:36:28,250:INFO:             xgboost: Not installed
2026-01-30 12:36:28,250:INFO:            catboost: 1.2.8
2026-01-30 12:36:28,250:INFO:              kmodes: 0.12.2
2026-01-30 12:36:28,250:INFO:             mlxtend: 0.23.4
2026-01-30 12:36:28,250:INFO:       statsforecast: 1.5.0
2026-01-30 12:36:28,250:INFO:        tune_sklearn: Not installed
2026-01-30 12:36:28,250:INFO:                 ray: Not installed
2026-01-30 12:36:28,250:INFO:            hyperopt: 0.2.7
2026-01-30 12:36:28,250:INFO:              optuna: 4.6.0
2026-01-30 12:36:28,250:INFO:               skopt: 0.10.2
2026-01-30 12:36:28,250:INFO:              mlflow: 3.8.1
2026-01-30 12:36:28,250:INFO:              gradio: 6.3.0
2026-01-30 12:36:28,250:INFO:             fastapi: 0.128.0
2026-01-30 12:36:28,250:INFO:             uvicorn: 0.40.0
2026-01-30 12:36:28,250:INFO:              m2cgen: 0.10.0
2026-01-30 12:36:28,250:INFO:           evidently: 0.4.40
2026-01-30 12:36:28,250:INFO:               fugue: 0.8.7
2026-01-30 12:36:28,250:INFO:           streamlit: Not installed
2026-01-30 12:36:28,250:INFO:             prophet: Not installed
2026-01-30 12:36:28,250:INFO:None
2026-01-30 12:36:28,250:INFO:Set up data.
2026-01-30 12:36:28,381:INFO:Set up folding strategy.
2026-01-30 12:36:28,381:INFO:Set up train/test split.
2026-01-30 12:36:28,606:INFO:Set up index.
2026-01-30 12:36:28,615:INFO:Assigning column types.
2026-01-30 12:36:28,833:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-30 12:36:28,873:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 12:36:28,874:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 12:36:28,896:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:36:28,896:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:36:28,928:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 12:36:28,929:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 12:36:28,952:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:36:28,952:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:36:28,953:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-30 12:36:28,985:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 12:36:29,003:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:36:29,004:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:36:29,036:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 12:36:29,055:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:36:29,056:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:36:29,056:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-30 12:36:29,104:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:36:29,104:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:36:29,154:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:36:29,154:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:36:29,155:INFO:Preparing preprocessing pipeline...
2026-01-30 12:36:29,185:INFO:Set up simple imputation.
2026-01-30 12:36:29,185:INFO:Set up feature normalization.
2026-01-30 12:36:29,473:INFO:Finished creating preprocessing pipeline.
2026-01-30 12:36:29,476:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdinario_def__c',
                                             'C...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-30 12:36:29,476:INFO:Creating final display dataframe.
2026-01-30 12:36:30,161:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape      (482669, 27)
4        Transformed data shape      (482669, 27)
5   Transformed train set shape      (337868, 27)
6    Transformed test set shape      (144801, 27)
7              Numeric features                23
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                 3
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              0c31
2026-01-30 12:36:30,242:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:36:30,243:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:36:30,315:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:36:30,316:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:36:30,318:INFO:setup() successfully completed in 2.1s...............
2026-01-30 12:36:30,318:INFO:Initializing compare_models()
2026-01-30 12:36:30,319:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04C237610>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A04C237610>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-30 12:36:30,319:INFO:Checking exceptions
2026-01-30 12:36:30,517:INFO:Preparing display monitor
2026-01-30 12:36:30,521:INFO:Initializing Logistic Regression
2026-01-30 12:36:30,521:INFO:Total runtime is 0.0 minutes
2026-01-30 12:36:30,522:INFO:SubProcess create_model() called ==================================
2026-01-30 12:36:30,522:INFO:Initializing create_model()
2026-01-30 12:36:30,522:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04C237610>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0482EB790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:36:30,522:INFO:Checking exceptions
2026-01-30 12:36:30,522:INFO:Importing libraries
2026-01-30 12:36:30,522:INFO:Copying training dataset
2026-01-30 12:36:30,851:INFO:Defining folds
2026-01-30 12:36:30,851:INFO:Declaring metric variables
2026-01-30 12:36:30,852:INFO:Importing untrained model
2026-01-30 12:36:30,852:INFO:Logistic Regression Imported successfully
2026-01-30 12:36:30,853:INFO:Starting cross validation
2026-01-30 12:36:30,854:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:36:34,589:INFO:Calculating mean and std
2026-01-30 12:36:34,589:INFO:Creating metrics dataframe
2026-01-30 12:36:34,594:INFO:Uploading results into container
2026-01-30 12:36:34,594:INFO:Uploading model into container now
2026-01-30 12:36:34,594:INFO:_master_model_container: 1
2026-01-30 12:36:34,594:INFO:_display_container: 2
2026-01-30 12:36:34,594:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-30 12:36:34,594:INFO:create_model() successfully completed......................................
2026-01-30 12:36:34,822:INFO:SubProcess create_model() end ==================================
2026-01-30 12:36:34,823:INFO:Creating metrics dataframe
2026-01-30 12:36:34,825:INFO:Initializing Decision Tree Classifier
2026-01-30 12:36:34,825:INFO:Total runtime is 0.07174501021703085 minutes
2026-01-30 12:36:34,825:INFO:SubProcess create_model() called ==================================
2026-01-30 12:36:34,825:INFO:Initializing create_model()
2026-01-30 12:36:34,825:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04C237610>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0482EB790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:36:34,825:INFO:Checking exceptions
2026-01-30 12:36:34,825:INFO:Importing libraries
2026-01-30 12:36:34,825:INFO:Copying training dataset
2026-01-30 12:36:35,034:INFO:Defining folds
2026-01-30 12:36:35,035:INFO:Declaring metric variables
2026-01-30 12:36:35,035:INFO:Importing untrained model
2026-01-30 12:36:35,035:INFO:Decision Tree Classifier Imported successfully
2026-01-30 12:36:35,036:INFO:Starting cross validation
2026-01-30 12:36:35,036:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:36:38,300:INFO:Calculating mean and std
2026-01-30 12:36:38,305:INFO:Creating metrics dataframe
2026-01-30 12:36:38,306:INFO:Uploading results into container
2026-01-30 12:36:38,307:INFO:Uploading model into container now
2026-01-30 12:36:38,307:INFO:_master_model_container: 2
2026-01-30 12:36:38,307:INFO:_display_container: 2
2026-01-30 12:36:38,308:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 12:36:38,308:INFO:create_model() successfully completed......................................
2026-01-30 12:36:38,464:INFO:SubProcess create_model() end ==================================
2026-01-30 12:36:38,464:INFO:Creating metrics dataframe
2026-01-30 12:36:38,464:INFO:Initializing Random Forest Classifier
2026-01-30 12:36:38,464:INFO:Total runtime is 0.13239903052647908 minutes
2026-01-30 12:36:38,464:INFO:SubProcess create_model() called ==================================
2026-01-30 12:36:38,464:INFO:Initializing create_model()
2026-01-30 12:36:38,464:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04C237610>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0482EB790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:36:38,464:INFO:Checking exceptions
2026-01-30 12:36:38,464:INFO:Importing libraries
2026-01-30 12:36:38,464:INFO:Copying training dataset
2026-01-30 12:36:38,640:INFO:Defining folds
2026-01-30 12:36:38,641:INFO:Declaring metric variables
2026-01-30 12:36:38,641:INFO:Importing untrained model
2026-01-30 12:36:38,642:INFO:Random Forest Classifier Imported successfully
2026-01-30 12:36:38,642:INFO:Starting cross validation
2026-01-30 12:36:38,643:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:36:58,226:INFO:Calculating mean and std
2026-01-30 12:36:58,226:INFO:Creating metrics dataframe
2026-01-30 12:36:58,226:INFO:Uploading results into container
2026-01-30 12:36:58,226:INFO:Uploading model into container now
2026-01-30 12:36:58,232:INFO:_master_model_container: 3
2026-01-30 12:36:58,232:INFO:_display_container: 2
2026-01-30 12:36:58,233:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 12:36:58,233:INFO:create_model() successfully completed......................................
2026-01-30 12:36:58,434:INFO:SubProcess create_model() end ==================================
2026-01-30 12:36:58,434:INFO:Creating metrics dataframe
2026-01-30 12:36:58,437:INFO:Initializing Light Gradient Boosting Machine
2026-01-30 12:36:58,437:INFO:Total runtime is 0.46527887980143234 minutes
2026-01-30 12:36:58,437:INFO:SubProcess create_model() called ==================================
2026-01-30 12:36:58,438:INFO:Initializing create_model()
2026-01-30 12:36:58,438:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04C237610>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0482EB790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:36:58,438:INFO:Checking exceptions
2026-01-30 12:36:58,438:INFO:Importing libraries
2026-01-30 12:36:58,438:INFO:Copying training dataset
2026-01-30 12:36:58,631:INFO:Defining folds
2026-01-30 12:36:58,632:INFO:Declaring metric variables
2026-01-30 12:36:58,632:INFO:Importing untrained model
2026-01-30 12:36:58,633:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 12:36:58,633:INFO:Starting cross validation
2026-01-30 12:36:58,634:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:37:03,379:INFO:Calculating mean and std
2026-01-30 12:37:03,381:INFO:Creating metrics dataframe
2026-01-30 12:37:03,383:INFO:Uploading results into container
2026-01-30 12:37:03,383:INFO:Uploading model into container now
2026-01-30 12:37:03,385:INFO:_master_model_container: 4
2026-01-30 12:37:03,385:INFO:_display_container: 2
2026-01-30 12:37:03,385:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 12:37:03,386:INFO:create_model() successfully completed......................................
2026-01-30 12:37:03,549:INFO:SubProcess create_model() end ==================================
2026-01-30 12:37:03,549:INFO:Creating metrics dataframe
2026-01-30 12:37:03,552:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-30 12:37:03,553:INFO:Initializing create_model()
2026-01-30 12:37:03,554:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04C237610>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:37:03,554:INFO:Checking exceptions
2026-01-30 12:37:03,554:INFO:Importing libraries
2026-01-30 12:37:03,554:INFO:Copying training dataset
2026-01-30 12:37:03,687:INFO:Initializing load_model()
2026-01-30 12:37:03,687:INFO:load_model(model_name=..\datos\04. Modelos\modelo_final_explicable, platform=None, authentication=None, verbose=True)
2026-01-30 12:37:03,749:INFO:Defining folds
2026-01-30 12:37:03,750:INFO:Declaring metric variables
2026-01-30 12:37:03,750:INFO:Importing untrained model
2026-01-30 12:37:03,750:INFO:Declaring custom model
2026-01-30 12:37:03,750:INFO:Random Forest Classifier Imported successfully
2026-01-30 12:37:03,750:INFO:Cross validation set to False
2026-01-30 12:37:03,751:INFO:Fitting Model
2026-01-30 12:37:11,801:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\2096248682.py:26: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-30 12:37:15,476:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 12:37:15,477:INFO:create_model() successfully completed......................................
2026-01-30 12:37:15,665:INFO:Initializing create_model()
2026-01-30 12:37:15,665:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04C237610>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:37:15,665:INFO:Checking exceptions
2026-01-30 12:37:15,665:INFO:Importing libraries
2026-01-30 12:37:15,665:INFO:Copying training dataset
2026-01-30 12:37:15,899:INFO:Defining folds
2026-01-30 12:37:15,899:INFO:Declaring metric variables
2026-01-30 12:37:15,899:INFO:Importing untrained model
2026-01-30 12:37:15,899:INFO:Declaring custom model
2026-01-30 12:37:15,899:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 12:37:15,899:INFO:Cross validation set to False
2026-01-30 12:37:15,899:INFO:Fitting Model
2026-01-30 12:37:16,774:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 12:37:16,826:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014579 seconds.
2026-01-30 12:37:16,826:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 12:37:16,826:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 12:37:16,826:INFO:[LightGBM] [Info] Total Bins 2868
2026-01-30 12:37:16,826:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 26
2026-01-30 12:37:16,829:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 12:37:16,829:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 12:37:17,718:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 12:37:17,718:INFO:create_model() successfully completed......................................
2026-01-30 12:37:17,952:INFO:Initializing create_model()
2026-01-30 12:37:17,952:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04C237610>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:37:17,952:INFO:Checking exceptions
2026-01-30 12:37:17,953:INFO:Importing libraries
2026-01-30 12:37:17,953:INFO:Copying training dataset
2026-01-30 12:37:18,146:INFO:Defining folds
2026-01-30 12:37:18,146:INFO:Declaring metric variables
2026-01-30 12:37:18,146:INFO:Importing untrained model
2026-01-30 12:37:18,146:INFO:Declaring custom model
2026-01-30 12:37:18,147:INFO:Decision Tree Classifier Imported successfully
2026-01-30 12:37:18,148:INFO:Cross validation set to False
2026-01-30 12:37:18,148:INFO:Fitting Model
2026-01-30 12:37:21,144:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 12:37:21,144:INFO:create_model() successfully completed......................................
2026-01-30 12:37:21,313:INFO:_master_model_container: 4
2026-01-30 12:37:21,314:INFO:_display_container: 2
2026-01-30 12:37:21,315:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')]
2026-01-30 12:37:21,315:INFO:compare_models() successfully completed......................................
2026-01-30 12:37:21,316:INFO:Initializing tune_model()
2026-01-30 12:37:21,316:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04C237610>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 12:37:21,316:INFO:Checking exceptions
2026-01-30 12:37:21,396:INFO:Copying training dataset
2026-01-30 12:37:21,511:INFO:Checking base model
2026-01-30 12:37:21,511:INFO:Base model : Random Forest Classifier
2026-01-30 12:37:21,511:INFO:Declaring metric variables
2026-01-30 12:37:21,511:INFO:Defining Hyperparameters
2026-01-30 12:37:21,666:INFO:Tuning with n_jobs=-1
2026-01-30 12:37:21,666:INFO:Initializing RandomizedSearchCV
2026-01-30 12:40:12,955:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-30 12:40:12,955:INFO:Hyperparameter search completed
2026-01-30 12:40:12,955:INFO:SubProcess create_model() called ==================================
2026-01-30 12:40:12,955:INFO:Initializing create_model()
2026-01-30 12:40:12,955:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04C237610>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C8C9A1D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': True})
2026-01-30 12:40:12,955:INFO:Checking exceptions
2026-01-30 12:40:12,955:INFO:Importing libraries
2026-01-30 12:40:12,955:INFO:Copying training dataset
2026-01-30 12:40:13,441:INFO:Defining folds
2026-01-30 12:40:13,441:INFO:Declaring metric variables
2026-01-30 12:40:13,442:INFO:Importing untrained model
2026-01-30 12:40:13,442:INFO:Declaring custom model
2026-01-30 12:40:13,444:INFO:Random Forest Classifier Imported successfully
2026-01-30 12:40:13,444:INFO:Starting cross validation
2026-01-30 12:40:13,446:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:40:48,663:INFO:Calculating mean and std
2026-01-30 12:40:48,663:INFO:Creating metrics dataframe
2026-01-30 12:40:48,663:INFO:Finalizing model
2026-01-30 12:41:04,648:INFO:Uploading results into container
2026-01-30 12:41:04,648:INFO:Uploading model into container now
2026-01-30 12:41:04,648:INFO:_master_model_container: 5
2026-01-30 12:41:04,648:INFO:_display_container: 3
2026-01-30 12:41:04,648:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 12:41:04,648:INFO:create_model() successfully completed......................................
2026-01-30 12:41:04,879:INFO:SubProcess create_model() end ==================================
2026-01-30 12:41:04,880:INFO:choose_better activated
2026-01-30 12:41:04,880:INFO:SubProcess create_model() called ==================================
2026-01-30 12:41:04,881:INFO:Initializing create_model()
2026-01-30 12:41:04,881:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04C237610>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:41:04,881:INFO:Checking exceptions
2026-01-30 12:41:04,882:INFO:Importing libraries
2026-01-30 12:41:04,882:INFO:Copying training dataset
2026-01-30 12:41:05,083:INFO:Defining folds
2026-01-30 12:41:05,083:INFO:Declaring metric variables
2026-01-30 12:41:05,083:INFO:Importing untrained model
2026-01-30 12:41:05,083:INFO:Declaring custom model
2026-01-30 12:41:05,083:INFO:Random Forest Classifier Imported successfully
2026-01-30 12:41:05,083:INFO:Starting cross validation
2026-01-30 12:41:05,083:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:41:28,258:INFO:Calculating mean and std
2026-01-30 12:41:28,258:INFO:Creating metrics dataframe
2026-01-30 12:41:28,261:INFO:Finalizing model
2026-01-30 12:41:39,145:INFO:Uploading results into container
2026-01-30 12:41:39,145:INFO:Uploading model into container now
2026-01-30 12:41:39,145:INFO:_master_model_container: 6
2026-01-30 12:41:39,145:INFO:_display_container: 4
2026-01-30 12:41:39,145:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 12:41:39,145:INFO:create_model() successfully completed......................................
2026-01-30 12:41:39,332:INFO:SubProcess create_model() end ==================================
2026-01-30 12:41:39,332:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9962
2026-01-30 12:41:39,332:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9658
2026-01-30 12:41:39,332:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-30 12:41:39,332:INFO:choose_better completed
2026-01-30 12:41:39,332:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 12:41:39,332:INFO:_master_model_container: 6
2026-01-30 12:41:39,332:INFO:_display_container: 3
2026-01-30 12:41:39,332:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 12:41:39,332:INFO:tune_model() successfully completed......................................
2026-01-30 12:41:39,500:INFO:Initializing tune_model()
2026-01-30 12:41:39,500:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04C237610>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 12:41:39,500:INFO:Checking exceptions
2026-01-30 12:41:39,579:INFO:Copying training dataset
2026-01-30 12:41:39,715:INFO:Checking base model
2026-01-30 12:41:39,715:INFO:Base model : Light Gradient Boosting Machine
2026-01-30 12:41:39,715:INFO:Declaring metric variables
2026-01-30 12:41:39,715:INFO:Defining Hyperparameters
2026-01-30 12:41:39,879:INFO:Tuning with n_jobs=-1
2026-01-30 12:41:39,879:INFO:Initializing RandomizedSearchCV
2026-01-30 12:42:22,265:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2026-01-30 12:42:22,266:INFO:Hyperparameter search completed
2026-01-30 12:42:22,267:INFO:SubProcess create_model() called ==================================
2026-01-30 12:42:22,268:INFO:Initializing create_model()
2026-01-30 12:42:22,268:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04C237610>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0D02B1690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2026-01-30 12:42:22,268:INFO:Checking exceptions
2026-01-30 12:42:22,268:INFO:Importing libraries
2026-01-30 12:42:22,268:INFO:Copying training dataset
2026-01-30 12:42:22,557:INFO:Defining folds
2026-01-30 12:42:22,557:INFO:Declaring metric variables
2026-01-30 12:42:22,558:INFO:Importing untrained model
2026-01-30 12:42:22,558:INFO:Declaring custom model
2026-01-30 12:42:22,559:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 12:42:22,559:INFO:Starting cross validation
2026-01-30 12:42:22,560:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:42:33,355:INFO:Calculating mean and std
2026-01-30 12:42:33,357:INFO:Creating metrics dataframe
2026-01-30 12:42:33,361:INFO:Finalizing model
2026-01-30 12:42:34,136:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 12:42:34,136:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 12:42:34,137:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 12:42:34,341:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 12:42:34,341:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 12:42:34,341:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 12:42:34,342:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 12:42:34,400:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013876 seconds.
2026-01-30 12:42:34,400:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 12:42:34,400:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 12:42:34,401:INFO:[LightGBM] [Info] Total Bins 2868
2026-01-30 12:42:34,402:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 26
2026-01-30 12:42:34,407:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 12:42:34,407:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 12:42:38,068:INFO:Uploading results into container
2026-01-30 12:42:38,071:INFO:Uploading model into container now
2026-01-30 12:42:38,071:INFO:_master_model_container: 7
2026-01-30 12:42:38,073:INFO:_display_container: 4
2026-01-30 12:42:38,073:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 12:42:38,073:INFO:create_model() successfully completed......................................
2026-01-30 12:42:38,316:INFO:SubProcess create_model() end ==================================
2026-01-30 12:42:38,324:INFO:choose_better activated
2026-01-30 12:42:38,324:INFO:SubProcess create_model() called ==================================
2026-01-30 12:42:38,324:INFO:Initializing create_model()
2026-01-30 12:42:38,324:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04C237610>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:42:38,324:INFO:Checking exceptions
2026-01-30 12:42:38,324:INFO:Importing libraries
2026-01-30 12:42:38,324:INFO:Copying training dataset
2026-01-30 12:42:38,561:INFO:Defining folds
2026-01-30 12:42:38,561:INFO:Declaring metric variables
2026-01-30 12:42:38,561:INFO:Importing untrained model
2026-01-30 12:42:38,561:INFO:Declaring custom model
2026-01-30 12:42:38,561:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 12:42:38,561:INFO:Starting cross validation
2026-01-30 12:42:38,561:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:42:43,524:INFO:Calculating mean and std
2026-01-30 12:42:43,524:INFO:Creating metrics dataframe
2026-01-30 12:42:43,530:INFO:Finalizing model
2026-01-30 12:42:44,414:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 12:42:44,472:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012333 seconds.
2026-01-30 12:42:44,472:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 12:42:44,472:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 12:42:44,474:INFO:[LightGBM] [Info] Total Bins 2868
2026-01-30 12:42:44,474:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 26
2026-01-30 12:42:44,476:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 12:42:44,476:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 12:42:45,389:INFO:Uploading results into container
2026-01-30 12:42:45,389:INFO:Uploading model into container now
2026-01-30 12:42:45,391:INFO:_master_model_container: 8
2026-01-30 12:42:45,391:INFO:_display_container: 5
2026-01-30 12:42:45,391:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 12:42:45,391:INFO:create_model() successfully completed......................................
2026-01-30 12:42:45,629:INFO:SubProcess create_model() end ==================================
2026-01-30 12:42:45,629:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9766
2026-01-30 12:42:45,629:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9936
2026-01-30 12:42:45,629:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2026-01-30 12:42:45,629:INFO:choose_better completed
2026-01-30 12:42:45,629:INFO:_master_model_container: 8
2026-01-30 12:42:45,629:INFO:_display_container: 4
2026-01-30 12:42:45,629:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 12:42:45,629:INFO:tune_model() successfully completed......................................
2026-01-30 12:42:45,814:INFO:Initializing tune_model()
2026-01-30 12:42:45,814:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04C237610>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 12:42:45,814:INFO:Checking exceptions
2026-01-30 12:42:45,896:INFO:Copying training dataset
2026-01-30 12:42:46,047:INFO:Checking base model
2026-01-30 12:42:46,047:INFO:Base model : Decision Tree Classifier
2026-01-30 12:42:46,047:INFO:Declaring metric variables
2026-01-30 12:42:46,047:INFO:Defining Hyperparameters
2026-01-30 12:42:46,231:INFO:Tuning with n_jobs=-1
2026-01-30 12:42:46,231:INFO:Initializing RandomizedSearchCV
2026-01-30 12:42:54,514:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 15, 'actual_estimator__criterion': 'gini'}
2026-01-30 12:42:54,516:INFO:Hyperparameter search completed
2026-01-30 12:42:54,516:INFO:SubProcess create_model() called ==================================
2026-01-30 12:42:54,516:INFO:Initializing create_model()
2026-01-30 12:42:54,516:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04C237610>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A074FB5810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 2, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 15, 'criterion': 'gini'})
2026-01-30 12:42:54,516:INFO:Checking exceptions
2026-01-30 12:42:54,516:INFO:Importing libraries
2026-01-30 12:42:54,516:INFO:Copying training dataset
2026-01-30 12:42:54,706:INFO:Defining folds
2026-01-30 12:42:54,707:INFO:Declaring metric variables
2026-01-30 12:42:54,707:INFO:Importing untrained model
2026-01-30 12:42:54,707:INFO:Declaring custom model
2026-01-30 12:42:54,707:INFO:Decision Tree Classifier Imported successfully
2026-01-30 12:42:54,707:INFO:Starting cross validation
2026-01-30 12:42:54,707:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:42:57,457:INFO:Calculating mean and std
2026-01-30 12:42:57,460:INFO:Creating metrics dataframe
2026-01-30 12:42:57,461:INFO:Finalizing model
2026-01-30 12:42:59,305:INFO:Uploading results into container
2026-01-30 12:42:59,306:INFO:Uploading model into container now
2026-01-30 12:42:59,306:INFO:_master_model_container: 9
2026-01-30 12:42:59,306:INFO:_display_container: 5
2026-01-30 12:42:59,306:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 12:42:59,306:INFO:create_model() successfully completed......................................
2026-01-30 12:42:59,477:INFO:SubProcess create_model() end ==================================
2026-01-30 12:42:59,477:INFO:choose_better activated
2026-01-30 12:42:59,477:INFO:SubProcess create_model() called ==================================
2026-01-30 12:42:59,478:INFO:Initializing create_model()
2026-01-30 12:42:59,478:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04C237610>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:42:59,478:INFO:Checking exceptions
2026-01-30 12:42:59,479:INFO:Importing libraries
2026-01-30 12:42:59,479:INFO:Copying training dataset
2026-01-30 12:42:59,659:INFO:Defining folds
2026-01-30 12:42:59,659:INFO:Declaring metric variables
2026-01-30 12:42:59,659:INFO:Importing untrained model
2026-01-30 12:42:59,659:INFO:Declaring custom model
2026-01-30 12:42:59,659:INFO:Decision Tree Classifier Imported successfully
2026-01-30 12:42:59,659:INFO:Starting cross validation
2026-01-30 12:42:59,659:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:43:03,619:INFO:Calculating mean and std
2026-01-30 12:43:03,621:INFO:Creating metrics dataframe
2026-01-30 12:43:03,624:INFO:Finalizing model
2026-01-30 12:43:07,682:INFO:Uploading results into container
2026-01-30 12:43:07,684:INFO:Uploading model into container now
2026-01-30 12:43:07,684:INFO:_master_model_container: 10
2026-01-30 12:43:07,684:INFO:_display_container: 6
2026-01-30 12:43:07,685:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 12:43:07,685:INFO:create_model() successfully completed......................................
2026-01-30 12:43:08,010:INFO:SubProcess create_model() end ==================================
2026-01-30 12:43:08,010:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9701
2026-01-30 12:43:08,010:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9544
2026-01-30 12:43:08,010:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-30 12:43:08,010:INFO:choose_better completed
2026-01-30 12:43:08,010:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 12:43:08,010:INFO:_master_model_container: 10
2026-01-30 12:43:08,010:INFO:_display_container: 5
2026-01-30 12:43:08,010:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 12:43:08,010:INFO:tune_model() successfully completed......................................
2026-01-30 12:43:08,205:INFO:Initializing predict_model()
2026-01-30 12:43:08,205:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04C237610>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A0CCB9BCE0>)
2026-01-30 12:43:08,205:INFO:Checking exceptions
2026-01-30 12:43:08,205:INFO:Preloading libraries
2026-01-30 12:43:08,205:INFO:Set up data.
2026-01-30 12:43:08,219:INFO:Set up index.
2026-01-30 12:43:08,662:INFO:Initializing predict_model()
2026-01-30 12:43:08,662:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04C237610>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A051942B60>)
2026-01-30 12:43:08,662:INFO:Checking exceptions
2026-01-30 12:43:08,662:INFO:Preloading libraries
2026-01-30 12:43:08,662:INFO:Set up data.
2026-01-30 12:43:08,673:INFO:Set up index.
2026-01-30 12:43:09,185:INFO:Initializing predict_model()
2026-01-30 12:43:09,186:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04C237610>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A051942B60>)
2026-01-30 12:43:09,186:INFO:Checking exceptions
2026-01-30 12:43:09,186:INFO:Preloading libraries
2026-01-30 12:43:09,186:INFO:Set up data.
2026-01-30 12:43:09,201:INFO:Set up index.
2026-01-30 12:43:09,818:INFO:Initializing plot_model()
2026-01-30 12:43:09,818:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04C237610>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 12:43:09,818:INFO:Checking exceptions
2026-01-30 12:43:10,016:INFO:Preloading libraries
2026-01-30 12:43:10,199:INFO:Copying training dataset
2026-01-30 12:43:10,199:INFO:Plot type: feature
2026-01-30 12:43:10,200:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 12:43:10,706:INFO:Visual Rendered Successfully
2026-01-30 12:43:10,902:INFO:plot_model() successfully completed......................................
2026-01-30 12:43:10,913:INFO:Initializing plot_model()
2026-01-30 12:43:10,914:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04C237610>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature_all, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 12:43:10,914:INFO:Checking exceptions
2026-01-30 12:43:11,031:INFO:Preloading libraries
2026-01-30 12:43:11,172:INFO:Copying training dataset
2026-01-30 12:43:11,172:INFO:Plot type: feature_all
2026-01-30 12:43:11,473:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 12:43:11,981:INFO:Visual Rendered Successfully
2026-01-30 12:43:12,220:INFO:plot_model() successfully completed......................................
2026-01-30 12:43:12,243:INFO:Initializing save_model()
2026-01-30 12:43:12,244:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), model_name=..\datos\04. Modelos\modelo_final_explicable, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdinario_def__c',
                                             'C...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-30 12:43:12,244:INFO:Adding model into prep_pipe
2026-01-30 12:43:12,536:INFO:..\datos\04. Modelos\modelo_final_explicable.pkl saved in current working directory
2026-01-30 12:43:12,545:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdinario_def__c',
                                             'CU_precioAplicado_def__c',
                                             'PORCENTAJE_PAGAD...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=42, verbose=0,
                                        warm_start=False))],
         verbose=False)
2026-01-30 12:43:12,545:INFO:save_model() successfully completed......................................
2026-01-30 12:45:51,310:INFO:Initializing load_model()
2026-01-30 12:45:51,310:INFO:load_model(model_name=..\datos\04. Modelos\modelo_final_explicable, platform=None, authentication=None, verbose=True)
2026-01-30 12:45:53,375:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\2096248682.py:26: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-30 12:47:26,019:INFO:Initializing load_model()
2026-01-30 12:47:26,020:INFO:load_model(model_name=..\datos\04. Modelos\modelo_final_explicable, platform=None, authentication=None, verbose=True)
2026-01-30 12:47:28,290:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\785099566.py:26: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-30 12:47:28,878:INFO:Initializing predict_model()
2026-01-30 12:47:28,878:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029C38048450>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdinario_def__c',
                                             'CU_precioAplicado_def__c',
                                             'PORCENTAJE_PAGADO_FINAL',
                                             'tie...
                                             'flag_CU_IMPORTE_TOTAL_na',
                                             'flag_CU_precioOrdinario_def__c_na',
                                             'flag_CU_precioAplicado_def__c_na'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 RandomForestClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000029C5A86D080>)
2026-01-30 12:47:28,878:INFO:Checking exceptions
2026-01-30 12:47:28,878:INFO:Preloading libraries
2026-01-30 12:47:28,878:INFO:Set up data.
2026-01-30 12:47:28,890:INFO:Set up index.
2026-01-30 12:48:34,343:INFO:Initializing load_model()
2026-01-30 12:48:34,344:INFO:load_model(model_name=..\datos\04. Modelos\modelo_final_explicable, platform=None, authentication=None, verbose=True)
2026-01-30 12:48:36,575:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\1243188443.py:26: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-30 12:48:37,190:INFO:Initializing predict_model()
2026-01-30 12:48:37,190:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029C4AFCAF10>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdinario_def__c',
                                             'CU_precioAplicado_def__c',
                                             'PORCENTAJE_PAGADO_FINAL',
                                             'tie...
                                             'flag_CU_IMPORTE_TOTAL_na',
                                             'flag_CU_precioOrdinario_def__c_na',
                                             'flag_CU_precioAplicado_def__c_na'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 RandomForestClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000029C65678CC0>)
2026-01-30 12:48:37,190:INFO:Checking exceptions
2026-01-30 12:48:37,190:INFO:Preloading libraries
2026-01-30 12:48:37,190:INFO:Set up data.
2026-01-30 12:48:37,206:INFO:Set up index.
2026-01-30 12:50:17,219:INFO:Initializing load_model()
2026-01-30 12:50:17,219:INFO:load_model(model_name=..\datos\04. Modelos\modelo_final_explicable, platform=None, authentication=None, verbose=True)
2026-01-30 12:50:19,386:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\84628162.py:25: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-30 12:51:20,249:INFO:Initializing load_model()
2026-01-30 12:51:20,249:INFO:load_model(model_name=..\datos\04. Modelos\modelo_final_explicable, platform=None, authentication=None, verbose=True)
2026-01-30 12:51:22,491:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\1593748511.py:26: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-30 12:51:57,562:INFO:Initializing load_model()
2026-01-30 12:51:57,562:INFO:load_model(model_name=..\datos\04. Modelos\modelo_final_explicable, platform=None, authentication=None, verbose=True)
2026-01-30 12:51:59,753:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\1815458068.py:26: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-30 12:52:00,870:INFO:Initializing predict_model()
2026-01-30 12:52:00,870:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029C38002250>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdinario_def__c',
                                             'CU_precioAplicado_def__c',
                                             'PORCENTAJE_PAGADO_FINAL',
                                             'tie...
                                             'flag_CU_IMPORTE_TOTAL_na',
                                             'flag_CU_precioOrdinario_def__c_na',
                                             'flag_CU_precioAplicado_def__c_na'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 RandomForestClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000029C4C3823E0>)
2026-01-30 12:52:00,870:INFO:Checking exceptions
2026-01-30 12:52:00,870:INFO:Preloading libraries
2026-01-30 12:52:00,870:INFO:Set up data.
2026-01-30 12:52:01,870:INFO:Set up index.
2026-01-30 12:52:39,467:INFO:Initializing load_model()
2026-01-30 12:52:39,467:INFO:load_model(model_name=..\datos\04. Modelos\modelo_final_explicable, platform=None, authentication=None, verbose=True)
2026-01-30 12:52:41,620:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\951826523.py:23: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-30 12:52:42,786:INFO:Initializing predict_model()
2026-01-30 12:52:42,786:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029C650AB290>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdinario_def__c',
                                             'CU_precioAplicado_def__c',
                                             'PORCENTAJE_PAGADO_FINAL',
                                             'tie...
                                             'flag_CU_IMPORTE_TOTAL_na',
                                             'flag_CU_precioOrdinario_def__c_na',
                                             'flag_CU_precioAplicado_def__c_na'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 RandomForestClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000029C5B1AA160>)
2026-01-30 12:52:42,786:INFO:Checking exceptions
2026-01-30 12:52:42,786:INFO:Preloading libraries
2026-01-30 12:52:42,786:INFO:Set up data.
2026-01-30 12:52:43,706:INFO:Set up index.
2026-01-30 12:53:31,306:INFO:Initializing load_model()
2026-01-30 12:53:31,306:INFO:load_model(model_name=..\datos\04. Modelos\modelo_final_explicable, platform=None, authentication=None, verbose=True)
2026-01-30 12:53:33,525:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\1700848726.py:23: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-30 12:54:37,169:INFO:Initializing load_model()
2026-01-30 12:54:37,170:INFO:load_model(model_name=..\datos\04. Modelos\modelo_final_explicable, platform=None, authentication=None, verbose=True)
2026-01-30 12:54:39,450:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\1700848726.py:23: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-30 12:57:04,918:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\2175477632.py:20: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-30 12:57:07,097:INFO:PyCaret ClassificationExperiment
2026-01-30 12:57:07,098:INFO:Logging name: clf-default-name
2026-01-30 12:57:07,099:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-30 12:57:07,099:INFO:version 3.3.2
2026-01-30 12:57:07,099:INFO:Initializing setup()
2026-01-30 12:57:07,099:INFO:self.USI: d9aa
2026-01-30 12:57:07,099:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'n_jobs_param', 'data', 'X', 'idx', 'y_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'USI', 'target_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'y_train', 'X_test', 'seed', 'gpu_param', 'gpu_n_jobs_param', 'y', 'logging_param', 'pipeline', 'fold_generator', 'exp_id'}
2026-01-30 12:57:07,099:INFO:Checking environment
2026-01-30 12:57:07,099:INFO:python_version: 3.11.11
2026-01-30 12:57:07,099:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-30 12:57:07,099:INFO:machine: AMD64
2026-01-30 12:57:07,099:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-30 12:57:07,099:INFO:Memory: svmem(total=34009374720, available=12575571968, percent=63.0, used=21433802752, free=12575571968)
2026-01-30 12:57:07,099:INFO:Physical Core: 12
2026-01-30 12:57:07,099:INFO:Logical Core: 16
2026-01-30 12:57:07,099:INFO:Checking libraries
2026-01-30 12:57:07,099:INFO:System:
2026-01-30 12:57:07,099:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-30 12:57:07,099:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-30 12:57:07,099:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-30 12:57:07,099:INFO:PyCaret required dependencies:
2026-01-30 12:57:07,099:INFO:                 pip: 25.0
2026-01-30 12:57:07,099:INFO:          setuptools: 75.8.0
2026-01-30 12:57:07,099:INFO:             pycaret: 3.3.2
2026-01-30 12:57:07,099:INFO:             IPython: 9.9.0
2026-01-30 12:57:07,099:INFO:          ipywidgets: 8.1.8
2026-01-30 12:57:07,099:INFO:                tqdm: 4.67.1
2026-01-30 12:57:07,099:INFO:               numpy: 1.26.4
2026-01-30 12:57:07,099:INFO:              pandas: 2.1.4
2026-01-30 12:57:07,099:INFO:              jinja2: 3.1.6
2026-01-30 12:57:07,099:INFO:               scipy: 1.11.4
2026-01-30 12:57:07,099:INFO:              joblib: 1.3.2
2026-01-30 12:57:07,099:INFO:             sklearn: 1.4.2
2026-01-30 12:57:07,099:INFO:                pyod: 2.0.6
2026-01-30 12:57:07,099:INFO:            imblearn: 0.14.1
2026-01-30 12:57:07,099:INFO:   category_encoders: 2.7.0
2026-01-30 12:57:07,099:INFO:            lightgbm: 4.6.0
2026-01-30 12:57:07,099:INFO:               numba: 0.62.1
2026-01-30 12:57:07,099:INFO:            requests: 2.32.3
2026-01-30 12:57:07,099:INFO:          matplotlib: 3.7.5
2026-01-30 12:57:07,099:INFO:          scikitplot: 0.3.7
2026-01-30 12:57:07,099:INFO:         yellowbrick: 1.5
2026-01-30 12:57:07,099:INFO:              plotly: 5.24.1
2026-01-30 12:57:07,099:INFO:    plotly-resampler: Not installed
2026-01-30 12:57:07,099:INFO:             kaleido: 1.2.0
2026-01-30 12:57:07,099:INFO:           schemdraw: 0.15
2026-01-30 12:57:07,099:INFO:         statsmodels: 0.14.6
2026-01-30 12:57:07,099:INFO:              sktime: 0.26.0
2026-01-30 12:57:07,099:INFO:               tbats: 1.1.3
2026-01-30 12:57:07,099:INFO:            pmdarima: 2.0.4
2026-01-30 12:57:07,099:INFO:              psutil: 7.2.1
2026-01-30 12:57:07,099:INFO:          markupsafe: 3.0.3
2026-01-30 12:57:07,099:INFO:             pickle5: Not installed
2026-01-30 12:57:07,099:INFO:         cloudpickle: 3.0.0
2026-01-30 12:57:07,099:INFO:         deprecation: 2.1.0
2026-01-30 12:57:07,099:INFO:              xxhash: 3.6.0
2026-01-30 12:57:07,099:INFO:           wurlitzer: Not installed
2026-01-30 12:57:07,099:INFO:PyCaret optional dependencies:
2026-01-30 12:57:07,099:INFO:                shap: 0.44.1
2026-01-30 12:57:07,099:INFO:           interpret: 0.7.3
2026-01-30 12:57:07,099:INFO:                umap: 0.5.7
2026-01-30 12:57:07,099:INFO:     ydata_profiling: 4.18.1
2026-01-30 12:57:07,099:INFO:  explainerdashboard: 0.5.1
2026-01-30 12:57:07,099:INFO:             autoviz: Not installed
2026-01-30 12:57:07,099:INFO:           fairlearn: 0.7.0
2026-01-30 12:57:07,099:INFO:          deepchecks: Not installed
2026-01-30 12:57:07,099:INFO:             xgboost: Not installed
2026-01-30 12:57:07,099:INFO:            catboost: 1.2.8
2026-01-30 12:57:07,099:INFO:              kmodes: 0.12.2
2026-01-30 12:57:07,099:INFO:             mlxtend: 0.23.4
2026-01-30 12:57:07,099:INFO:       statsforecast: 1.5.0
2026-01-30 12:57:07,099:INFO:        tune_sklearn: Not installed
2026-01-30 12:57:07,099:INFO:                 ray: Not installed
2026-01-30 12:57:07,099:INFO:            hyperopt: 0.2.7
2026-01-30 12:57:07,099:INFO:              optuna: 4.6.0
2026-01-30 12:57:07,099:INFO:               skopt: 0.10.2
2026-01-30 12:57:07,099:INFO:              mlflow: 3.8.1
2026-01-30 12:57:07,099:INFO:              gradio: 6.3.0
2026-01-30 12:57:07,099:INFO:             fastapi: 0.128.0
2026-01-30 12:57:07,099:INFO:             uvicorn: 0.40.0
2026-01-30 12:57:07,099:INFO:              m2cgen: 0.10.0
2026-01-30 12:57:07,099:INFO:           evidently: 0.4.40
2026-01-30 12:57:07,099:INFO:               fugue: 0.8.7
2026-01-30 12:57:07,099:INFO:           streamlit: Not installed
2026-01-30 12:57:07,099:INFO:             prophet: Not installed
2026-01-30 12:57:07,099:INFO:None
2026-01-30 12:57:07,099:INFO:Set up data.
2026-01-30 12:57:07,283:INFO:Set up folding strategy.
2026-01-30 12:57:07,283:INFO:Set up train/test split.
2026-01-30 12:57:07,599:INFO:Set up index.
2026-01-30 12:57:07,615:INFO:Assigning column types.
2026-01-30 12:57:07,869:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-30 12:57:07,920:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 12:57:07,921:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 12:57:07,949:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:57:07,949:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:57:07,999:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 12:57:07,999:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 12:57:08,033:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:57:08,033:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:57:08,033:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-30 12:57:08,083:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 12:57:08,116:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:57:08,116:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:57:08,171:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 12:57:08,203:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:57:08,203:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:57:08,203:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-30 12:57:08,282:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:57:08,282:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:57:08,366:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:57:08,366:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:57:08,366:INFO:Preparing preprocessing pipeline...
2026-01-30 12:57:08,416:INFO:Set up simple imputation.
2026-01-30 12:57:08,416:INFO:Set up feature normalization.
2026-01-30 12:57:09,300:INFO:Finished creating preprocessing pipeline.
2026-01-30 12:57:09,315:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdinario_def__c',
                                             'C...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-30 12:57:09,316:INFO:Creating final display dataframe.
2026-01-30 12:57:10,452:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape      (482669, 27)
4        Transformed data shape      (482669, 27)
5   Transformed train set shape      (337868, 27)
6    Transformed test set shape      (144801, 27)
7              Numeric features                23
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                 3
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              d9aa
2026-01-30 12:57:10,516:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:57:10,516:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:57:10,566:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 12:57:10,566:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 12:57:10,581:INFO:setup() successfully completed in 3.52s...............
2026-01-30 12:57:10,581:INFO:Initializing compare_models()
2026-01-30 12:57:10,581:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C9F04850>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C9F04850>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-30 12:57:10,581:INFO:Checking exceptions
2026-01-30 12:57:10,716:INFO:Preparing display monitor
2026-01-30 12:57:10,719:INFO:Initializing Logistic Regression
2026-01-30 12:57:10,719:INFO:Total runtime is 0.0 minutes
2026-01-30 12:57:10,720:INFO:SubProcess create_model() called ==================================
2026-01-30 12:57:10,720:INFO:Initializing create_model()
2026-01-30 12:57:10,720:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C9F04850>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04EEBD690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:57:10,720:INFO:Checking exceptions
2026-01-30 12:57:10,720:INFO:Importing libraries
2026-01-30 12:57:10,720:INFO:Copying training dataset
2026-01-30 12:57:10,949:INFO:Defining folds
2026-01-30 12:57:10,949:INFO:Declaring metric variables
2026-01-30 12:57:10,949:INFO:Importing untrained model
2026-01-30 12:57:10,950:INFO:Logistic Regression Imported successfully
2026-01-30 12:57:10,950:INFO:Starting cross validation
2026-01-30 12:57:10,951:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:57:21,259:INFO:Calculating mean and std
2026-01-30 12:57:21,261:INFO:Creating metrics dataframe
2026-01-30 12:57:21,262:INFO:Uploading results into container
2026-01-30 12:57:21,263:INFO:Uploading model into container now
2026-01-30 12:57:21,263:INFO:_master_model_container: 1
2026-01-30 12:57:21,263:INFO:_display_container: 2
2026-01-30 12:57:21,264:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-30 12:57:21,264:INFO:create_model() successfully completed......................................
2026-01-30 12:57:21,433:INFO:SubProcess create_model() end ==================================
2026-01-30 12:57:21,433:INFO:Creating metrics dataframe
2026-01-30 12:57:21,433:INFO:Initializing Decision Tree Classifier
2026-01-30 12:57:21,433:INFO:Total runtime is 0.17856082518895466 minutes
2026-01-30 12:57:21,433:INFO:SubProcess create_model() called ==================================
2026-01-30 12:57:21,433:INFO:Initializing create_model()
2026-01-30 12:57:21,433:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C9F04850>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04EEBD690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:57:21,433:INFO:Checking exceptions
2026-01-30 12:57:21,433:INFO:Importing libraries
2026-01-30 12:57:21,433:INFO:Copying training dataset
2026-01-30 12:57:21,642:INFO:Defining folds
2026-01-30 12:57:21,642:INFO:Declaring metric variables
2026-01-30 12:57:21,642:INFO:Importing untrained model
2026-01-30 12:57:21,642:INFO:Decision Tree Classifier Imported successfully
2026-01-30 12:57:21,642:INFO:Starting cross validation
2026-01-30 12:57:21,643:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:57:30,242:INFO:Calculating mean and std
2026-01-30 12:57:30,245:INFO:Creating metrics dataframe
2026-01-30 12:57:30,248:INFO:Uploading results into container
2026-01-30 12:57:30,250:INFO:Uploading model into container now
2026-01-30 12:57:30,250:INFO:_master_model_container: 2
2026-01-30 12:57:30,251:INFO:_display_container: 2
2026-01-30 12:57:30,252:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 12:57:30,252:INFO:create_model() successfully completed......................................
2026-01-30 12:57:30,456:INFO:SubProcess create_model() end ==================================
2026-01-30 12:57:30,457:INFO:Creating metrics dataframe
2026-01-30 12:57:30,458:INFO:Initializing Random Forest Classifier
2026-01-30 12:57:30,458:INFO:Total runtime is 0.3289838433265686 minutes
2026-01-30 12:57:30,458:INFO:SubProcess create_model() called ==================================
2026-01-30 12:57:30,459:INFO:Initializing create_model()
2026-01-30 12:57:30,459:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C9F04850>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04EEBD690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:57:30,459:INFO:Checking exceptions
2026-01-30 12:57:30,459:INFO:Importing libraries
2026-01-30 12:57:30,459:INFO:Copying training dataset
2026-01-30 12:57:30,649:INFO:Defining folds
2026-01-30 12:57:30,665:INFO:Declaring metric variables
2026-01-30 12:57:30,665:INFO:Importing untrained model
2026-01-30 12:57:30,665:INFO:Random Forest Classifier Imported successfully
2026-01-30 12:57:30,666:INFO:Starting cross validation
2026-01-30 12:57:30,666:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:57:52,579:INFO:Calculating mean and std
2026-01-30 12:57:52,580:INFO:Creating metrics dataframe
2026-01-30 12:57:52,582:INFO:Uploading results into container
2026-01-30 12:57:52,582:INFO:Uploading model into container now
2026-01-30 12:57:52,583:INFO:_master_model_container: 3
2026-01-30 12:57:52,583:INFO:_display_container: 2
2026-01-30 12:57:52,583:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 12:57:52,583:INFO:create_model() successfully completed......................................
2026-01-30 12:57:52,800:INFO:SubProcess create_model() end ==================================
2026-01-30 12:57:52,800:INFO:Creating metrics dataframe
2026-01-30 12:57:52,815:INFO:Initializing Light Gradient Boosting Machine
2026-01-30 12:57:52,816:INFO:Total runtime is 0.7016204833984375 minutes
2026-01-30 12:57:52,816:INFO:SubProcess create_model() called ==================================
2026-01-30 12:57:52,816:INFO:Initializing create_model()
2026-01-30 12:57:52,816:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C9F04850>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04EEBD690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:57:52,816:INFO:Checking exceptions
2026-01-30 12:57:52,816:INFO:Importing libraries
2026-01-30 12:57:52,817:INFO:Copying training dataset
2026-01-30 12:57:53,237:INFO:Defining folds
2026-01-30 12:57:53,238:INFO:Declaring metric variables
2026-01-30 12:57:53,238:INFO:Importing untrained model
2026-01-30 12:57:53,239:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 12:57:53,240:INFO:Starting cross validation
2026-01-30 12:57:53,241:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 12:58:03,843:INFO:Calculating mean and std
2026-01-30 12:58:03,844:INFO:Creating metrics dataframe
2026-01-30 12:58:03,846:INFO:Uploading results into container
2026-01-30 12:58:03,847:INFO:Uploading model into container now
2026-01-30 12:58:03,847:INFO:_master_model_container: 4
2026-01-30 12:58:03,847:INFO:_display_container: 2
2026-01-30 12:58:03,848:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 12:58:03,848:INFO:create_model() successfully completed......................................
2026-01-30 12:58:04,048:INFO:SubProcess create_model() end ==================================
2026-01-30 12:58:04,048:INFO:Creating metrics dataframe
2026-01-30 12:58:04,051:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-30 12:58:04,053:INFO:Initializing create_model()
2026-01-30 12:58:04,053:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C9F04850>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:58:04,053:INFO:Checking exceptions
2026-01-30 12:58:04,054:INFO:Importing libraries
2026-01-30 12:58:04,054:INFO:Copying training dataset
2026-01-30 12:58:04,344:INFO:Defining folds
2026-01-30 12:58:04,344:INFO:Declaring metric variables
2026-01-30 12:58:04,344:INFO:Importing untrained model
2026-01-30 12:58:04,344:INFO:Declaring custom model
2026-01-30 12:58:04,345:INFO:Random Forest Classifier Imported successfully
2026-01-30 12:58:04,346:INFO:Cross validation set to False
2026-01-30 12:58:04,346:INFO:Fitting Model
2026-01-30 12:58:13,814:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 12:58:13,814:INFO:create_model() successfully completed......................................
2026-01-30 12:58:14,032:INFO:Initializing create_model()
2026-01-30 12:58:14,032:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C9F04850>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:58:14,032:INFO:Checking exceptions
2026-01-30 12:58:14,033:INFO:Importing libraries
2026-01-30 12:58:14,033:INFO:Copying training dataset
2026-01-30 12:58:14,255:INFO:Defining folds
2026-01-30 12:58:14,255:INFO:Declaring metric variables
2026-01-30 12:58:14,255:INFO:Importing untrained model
2026-01-30 12:58:14,255:INFO:Declaring custom model
2026-01-30 12:58:14,256:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 12:58:14,257:INFO:Cross validation set to False
2026-01-30 12:58:14,257:INFO:Fitting Model
2026-01-30 12:58:15,285:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 12:58:15,336:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014229 seconds.
2026-01-30 12:58:15,337:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 12:58:15,337:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 12:58:15,337:INFO:[LightGBM] [Info] Total Bins 2868
2026-01-30 12:58:15,338:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 26
2026-01-30 12:58:15,340:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 12:58:15,340:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 12:58:16,047:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 12:58:16,048:INFO:create_model() successfully completed......................................
2026-01-30 12:58:16,268:INFO:Initializing create_model()
2026-01-30 12:58:16,268:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C9F04850>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 12:58:16,268:INFO:Checking exceptions
2026-01-30 12:58:16,269:INFO:Importing libraries
2026-01-30 12:58:16,269:INFO:Copying training dataset
2026-01-30 12:58:16,502:INFO:Defining folds
2026-01-30 12:58:16,502:INFO:Declaring metric variables
2026-01-30 12:58:16,502:INFO:Importing untrained model
2026-01-30 12:58:16,502:INFO:Declaring custom model
2026-01-30 12:58:16,503:INFO:Decision Tree Classifier Imported successfully
2026-01-30 12:58:16,503:INFO:Cross validation set to False
2026-01-30 12:58:16,503:INFO:Fitting Model
2026-01-30 12:58:20,179:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 12:58:20,179:INFO:create_model() successfully completed......................................
2026-01-30 12:58:20,371:INFO:_master_model_container: 4
2026-01-30 12:58:20,372:INFO:_display_container: 2
2026-01-30 12:58:20,373:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')]
2026-01-30 12:58:20,373:INFO:compare_models() successfully completed......................................
2026-01-30 12:58:20,385:INFO:Initializing tune_model()
2026-01-30 12:58:20,386:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C9F04850>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 12:58:20,386:INFO:Checking exceptions
2026-01-30 12:58:20,465:INFO:Copying training dataset
2026-01-30 12:58:20,625:INFO:Checking base model
2026-01-30 12:58:20,625:INFO:Base model : Random Forest Classifier
2026-01-30 12:58:20,626:INFO:Declaring metric variables
2026-01-30 12:58:20,626:INFO:Defining Hyperparameters
2026-01-30 12:58:20,811:INFO:Tuning with n_jobs=-1
2026-01-30 12:58:20,811:INFO:Initializing RandomizedSearchCV
2026-01-30 12:59:29,552:INFO:Initializing load_model()
2026-01-30 12:59:29,552:INFO:load_model(model_name=..\datos\04. Modelos\modelo_final_explicable, platform=None, authentication=None, verbose=True)
2026-01-30 13:00:31,813:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\322740615.py:23: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-30 13:00:44,568:INFO:Initializing predict_model()
2026-01-30 13:00:44,568:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029C50E6DA50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdinario_def__c',
                                             'CU_precioAplicado_def__c',
                                             'PORCENTAJE_PAGADO_FINAL',
                                             'tie...
                                             'flag_CU_IMPORTE_TOTAL_na',
                                             'flag_CU_precioOrdinario_def__c_na',
                                             'flag_CU_precioAplicado_def__c_na'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 RandomForestClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000029C50C0E8E0>)
2026-01-30 13:00:44,568:INFO:Checking exceptions
2026-01-30 13:00:44,568:INFO:Preloading libraries
2026-01-30 13:00:44,570:INFO:Set up data.
2026-01-30 13:00:48,976:INFO:Set up index.
2026-01-30 13:00:49,252:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-30 13:00:49,255:INFO:Hyperparameter search completed
2026-01-30 13:00:49,256:INFO:SubProcess create_model() called ==================================
2026-01-30 13:00:49,257:INFO:Initializing create_model()
2026-01-30 13:00:49,258:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C9F04850>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C3052B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': True})
2026-01-30 13:00:49,258:INFO:Checking exceptions
2026-01-30 13:00:49,259:INFO:Importing libraries
2026-01-30 13:00:49,259:INFO:Copying training dataset
2026-01-30 13:00:49,937:INFO:Defining folds
2026-01-30 13:00:49,937:INFO:Declaring metric variables
2026-01-30 13:00:49,937:INFO:Importing untrained model
2026-01-30 13:00:49,938:INFO:Declaring custom model
2026-01-30 13:00:49,939:INFO:Random Forest Classifier Imported successfully
2026-01-30 13:00:49,939:INFO:Starting cross validation
2026-01-30 13:00:49,941:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:01:23,384:INFO:Calculating mean and std
2026-01-30 13:01:23,384:INFO:Creating metrics dataframe
2026-01-30 13:01:23,384:INFO:Finalizing model
2026-01-30 13:01:39,331:INFO:Uploading results into container
2026-01-30 13:01:39,331:INFO:Uploading model into container now
2026-01-30 13:01:39,331:INFO:_master_model_container: 5
2026-01-30 13:01:39,331:INFO:_display_container: 3
2026-01-30 13:01:39,331:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 13:01:39,331:INFO:create_model() successfully completed......................................
2026-01-30 13:01:39,523:INFO:SubProcess create_model() end ==================================
2026-01-30 13:01:39,523:INFO:choose_better activated
2026-01-30 13:01:39,523:INFO:SubProcess create_model() called ==================================
2026-01-30 13:01:39,524:INFO:Initializing create_model()
2026-01-30 13:01:39,524:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C9F04850>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:01:39,524:INFO:Checking exceptions
2026-01-30 13:01:39,524:INFO:Importing libraries
2026-01-30 13:01:39,524:INFO:Copying training dataset
2026-01-30 13:01:39,731:INFO:Defining folds
2026-01-30 13:01:39,731:INFO:Declaring metric variables
2026-01-30 13:01:39,732:INFO:Importing untrained model
2026-01-30 13:01:39,732:INFO:Declaring custom model
2026-01-30 13:01:39,732:INFO:Random Forest Classifier Imported successfully
2026-01-30 13:01:39,732:INFO:Starting cross validation
2026-01-30 13:01:39,733:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:02:02,710:INFO:Calculating mean and std
2026-01-30 13:02:02,710:INFO:Creating metrics dataframe
2026-01-30 13:02:02,710:INFO:Finalizing model
2026-01-30 13:02:13,713:INFO:Uploading results into container
2026-01-30 13:02:13,714:INFO:Uploading model into container now
2026-01-30 13:02:13,715:INFO:_master_model_container: 6
2026-01-30 13:02:13,715:INFO:_display_container: 4
2026-01-30 13:02:13,715:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 13:02:13,716:INFO:create_model() successfully completed......................................
2026-01-30 13:02:13,893:INFO:SubProcess create_model() end ==================================
2026-01-30 13:02:13,893:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9962
2026-01-30 13:02:13,893:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9658
2026-01-30 13:02:13,905:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-30 13:02:13,905:INFO:choose_better completed
2026-01-30 13:02:13,905:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 13:02:13,907:INFO:_master_model_container: 6
2026-01-30 13:02:13,907:INFO:_display_container: 3
2026-01-30 13:02:13,907:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 13:02:13,907:INFO:tune_model() successfully completed......................................
2026-01-30 13:02:14,079:INFO:Initializing tune_model()
2026-01-30 13:02:14,079:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C9F04850>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 13:02:14,079:INFO:Checking exceptions
2026-01-30 13:02:14,149:INFO:Copying training dataset
2026-01-30 13:02:14,267:INFO:Checking base model
2026-01-30 13:02:14,267:INFO:Base model : Light Gradient Boosting Machine
2026-01-30 13:02:14,267:INFO:Declaring metric variables
2026-01-30 13:02:14,267:INFO:Defining Hyperparameters
2026-01-30 13:02:14,440:INFO:Tuning with n_jobs=-1
2026-01-30 13:02:14,440:INFO:Initializing RandomizedSearchCV
2026-01-30 13:03:02,640:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2026-01-30 13:03:02,642:INFO:Hyperparameter search completed
2026-01-30 13:03:02,643:INFO:SubProcess create_model() called ==================================
2026-01-30 13:03:02,645:INFO:Initializing create_model()
2026-01-30 13:03:02,645:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C9F04850>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03C5A75D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2026-01-30 13:03:02,646:INFO:Checking exceptions
2026-01-30 13:03:02,647:INFO:Importing libraries
2026-01-30 13:03:02,647:INFO:Copying training dataset
2026-01-30 13:03:03,196:INFO:Defining folds
2026-01-30 13:03:03,198:INFO:Declaring metric variables
2026-01-30 13:03:03,198:INFO:Importing untrained model
2026-01-30 13:03:03,198:INFO:Declaring custom model
2026-01-30 13:03:03,200:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 13:03:03,202:INFO:Starting cross validation
2026-01-30 13:03:03,202:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:03:15,883:INFO:Calculating mean and std
2026-01-30 13:03:15,885:INFO:Creating metrics dataframe
2026-01-30 13:03:15,889:INFO:Finalizing model
2026-01-30 13:03:16,998:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 13:03:16,998:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 13:03:16,998:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 13:03:17,257:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 13:03:17,257:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 13:03:17,257:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 13:03:17,258:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 13:03:17,330:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016354 seconds.
2026-01-30 13:03:17,330:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 13:03:17,330:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 13:03:17,331:INFO:[LightGBM] [Info] Total Bins 2868
2026-01-30 13:03:17,332:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 26
2026-01-30 13:03:17,337:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 13:03:17,338:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 13:03:21,295:INFO:Uploading results into container
2026-01-30 13:03:21,295:INFO:Uploading model into container now
2026-01-30 13:03:21,297:INFO:_master_model_container: 7
2026-01-30 13:03:21,297:INFO:_display_container: 4
2026-01-30 13:03:21,299:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 13:03:21,299:INFO:create_model() successfully completed......................................
2026-01-30 13:03:21,544:INFO:SubProcess create_model() end ==================================
2026-01-30 13:03:21,545:INFO:choose_better activated
2026-01-30 13:03:21,546:INFO:SubProcess create_model() called ==================================
2026-01-30 13:03:21,546:INFO:Initializing create_model()
2026-01-30 13:03:21,546:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C9F04850>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:03:21,546:INFO:Checking exceptions
2026-01-30 13:03:21,547:INFO:Importing libraries
2026-01-30 13:03:21,547:INFO:Copying training dataset
2026-01-30 13:03:21,752:INFO:Defining folds
2026-01-30 13:03:21,752:INFO:Declaring metric variables
2026-01-30 13:03:21,752:INFO:Importing untrained model
2026-01-30 13:03:21,752:INFO:Declaring custom model
2026-01-30 13:03:21,752:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 13:03:21,752:INFO:Starting cross validation
2026-01-30 13:03:21,755:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:03:26,582:INFO:Calculating mean and std
2026-01-30 13:03:26,584:INFO:Creating metrics dataframe
2026-01-30 13:03:26,587:INFO:Finalizing model
2026-01-30 13:03:27,513:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 13:03:27,563:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013262 seconds.
2026-01-30 13:03:27,565:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 13:03:27,565:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 13:03:27,565:INFO:[LightGBM] [Info] Total Bins 2868
2026-01-30 13:03:27,565:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 26
2026-01-30 13:03:27,568:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 13:03:27,568:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 13:03:28,477:INFO:Uploading results into container
2026-01-30 13:03:28,479:INFO:Uploading model into container now
2026-01-30 13:03:28,479:INFO:_master_model_container: 8
2026-01-30 13:03:28,479:INFO:_display_container: 5
2026-01-30 13:03:28,479:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 13:03:28,481:INFO:create_model() successfully completed......................................
2026-01-30 13:03:28,740:INFO:SubProcess create_model() end ==================================
2026-01-30 13:03:28,740:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9766
2026-01-30 13:03:28,741:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9936
2026-01-30 13:03:28,742:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2026-01-30 13:03:28,742:INFO:choose_better completed
2026-01-30 13:03:28,744:INFO:_master_model_container: 8
2026-01-30 13:03:28,744:INFO:_display_container: 4
2026-01-30 13:03:28,745:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 13:03:28,745:INFO:tune_model() successfully completed......................................
2026-01-30 13:03:28,921:INFO:Initializing tune_model()
2026-01-30 13:03:28,921:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C9F04850>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 13:03:28,921:INFO:Checking exceptions
2026-01-30 13:03:28,995:INFO:Copying training dataset
2026-01-30 13:03:29,120:INFO:Checking base model
2026-01-30 13:03:29,120:INFO:Base model : Decision Tree Classifier
2026-01-30 13:03:29,120:INFO:Declaring metric variables
2026-01-30 13:03:29,120:INFO:Defining Hyperparameters
2026-01-30 13:03:29,337:INFO:Tuning with n_jobs=-1
2026-01-30 13:03:29,337:INFO:Initializing RandomizedSearchCV
2026-01-30 13:03:38,666:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 15, 'actual_estimator__criterion': 'gini'}
2026-01-30 13:03:38,667:INFO:Hyperparameter search completed
2026-01-30 13:03:38,668:INFO:SubProcess create_model() called ==================================
2026-01-30 13:03:38,668:INFO:Initializing create_model()
2026-01-30 13:03:38,668:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C9F04850>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0CA0B3250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 2, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 15, 'criterion': 'gini'})
2026-01-30 13:03:38,670:INFO:Checking exceptions
2026-01-30 13:03:38,670:INFO:Importing libraries
2026-01-30 13:03:38,670:INFO:Copying training dataset
2026-01-30 13:03:39,033:INFO:Defining folds
2026-01-30 13:03:39,034:INFO:Declaring metric variables
2026-01-30 13:03:39,034:INFO:Importing untrained model
2026-01-30 13:03:39,034:INFO:Declaring custom model
2026-01-30 13:03:39,035:INFO:Decision Tree Classifier Imported successfully
2026-01-30 13:03:39,036:INFO:Starting cross validation
2026-01-30 13:03:39,037:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:03:42,597:INFO:Calculating mean and std
2026-01-30 13:03:42,597:INFO:Creating metrics dataframe
2026-01-30 13:03:42,597:INFO:Finalizing model
2026-01-30 13:03:44,661:INFO:Uploading results into container
2026-01-30 13:03:44,662:INFO:Uploading model into container now
2026-01-30 13:03:44,663:INFO:_master_model_container: 9
2026-01-30 13:03:44,663:INFO:_display_container: 5
2026-01-30 13:03:44,663:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 13:03:44,663:INFO:create_model() successfully completed......................................
2026-01-30 13:03:44,832:INFO:SubProcess create_model() end ==================================
2026-01-30 13:03:44,833:INFO:choose_better activated
2026-01-30 13:03:44,833:INFO:SubProcess create_model() called ==================================
2026-01-30 13:03:44,833:INFO:Initializing create_model()
2026-01-30 13:03:44,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C9F04850>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:03:44,833:INFO:Checking exceptions
2026-01-30 13:03:44,834:INFO:Importing libraries
2026-01-30 13:03:44,834:INFO:Copying training dataset
2026-01-30 13:03:45,037:INFO:Defining folds
2026-01-30 13:03:45,037:INFO:Declaring metric variables
2026-01-30 13:03:45,037:INFO:Importing untrained model
2026-01-30 13:03:45,039:INFO:Declaring custom model
2026-01-30 13:03:45,039:INFO:Decision Tree Classifier Imported successfully
2026-01-30 13:03:45,040:INFO:Starting cross validation
2026-01-30 13:03:45,040:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:03:49,771:INFO:Calculating mean and std
2026-01-30 13:03:49,772:INFO:Creating metrics dataframe
2026-01-30 13:03:49,775:INFO:Finalizing model
2026-01-30 13:03:53,894:INFO:Uploading results into container
2026-01-30 13:03:53,895:INFO:Uploading model into container now
2026-01-30 13:03:53,895:INFO:_master_model_container: 10
2026-01-30 13:03:53,895:INFO:_display_container: 6
2026-01-30 13:03:53,895:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 13:03:53,895:INFO:create_model() successfully completed......................................
2026-01-30 13:03:54,077:INFO:SubProcess create_model() end ==================================
2026-01-30 13:03:54,078:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9701
2026-01-30 13:03:54,078:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9544
2026-01-30 13:03:54,078:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-30 13:03:54,079:INFO:choose_better completed
2026-01-30 13:03:54,079:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 13:03:54,081:INFO:_master_model_container: 10
2026-01-30 13:03:54,081:INFO:_display_container: 5
2026-01-30 13:03:54,081:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 13:03:54,082:INFO:tune_model() successfully completed......................................
2026-01-30 13:03:54,283:INFO:Initializing predict_model()
2026-01-30 13:03:54,283:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C9F04850>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A06E731760>)
2026-01-30 13:03:54,283:INFO:Checking exceptions
2026-01-30 13:03:54,283:INFO:Preloading libraries
2026-01-30 13:03:54,283:INFO:Set up data.
2026-01-30 13:03:54,294:INFO:Set up index.
2026-01-30 13:03:54,741:INFO:Initializing predict_model()
2026-01-30 13:03:54,742:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C9F04850>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A01562A5C0>)
2026-01-30 13:03:54,742:INFO:Checking exceptions
2026-01-30 13:03:54,742:INFO:Preloading libraries
2026-01-30 13:03:54,742:INFO:Set up data.
2026-01-30 13:03:54,754:INFO:Set up index.
2026-01-30 13:03:55,266:INFO:Initializing predict_model()
2026-01-30 13:03:55,266:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C9F04850>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A06E731760>)
2026-01-30 13:03:55,266:INFO:Checking exceptions
2026-01-30 13:03:55,266:INFO:Preloading libraries
2026-01-30 13:03:55,267:INFO:Set up data.
2026-01-30 13:03:55,279:INFO:Set up index.
2026-01-30 13:03:55,902:INFO:Initializing plot_model()
2026-01-30 13:03:55,902:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C9F04850>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 13:03:55,903:INFO:Checking exceptions
2026-01-30 13:03:56,082:INFO:Preloading libraries
2026-01-30 13:03:56,215:INFO:Copying training dataset
2026-01-30 13:03:56,215:INFO:Plot type: feature
2026-01-30 13:03:56,216:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 13:03:56,615:INFO:Visual Rendered Successfully
2026-01-30 13:03:56,802:INFO:plot_model() successfully completed......................................
2026-01-30 13:03:56,811:INFO:Initializing plot_model()
2026-01-30 13:03:56,811:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C9F04850>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature_all, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 13:03:56,811:INFO:Checking exceptions
2026-01-30 13:03:56,918:INFO:Preloading libraries
2026-01-30 13:03:57,069:INFO:Copying training dataset
2026-01-30 13:03:57,069:INFO:Plot type: feature_all
2026-01-30 13:03:57,308:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 13:03:57,841:INFO:Visual Rendered Successfully
2026-01-30 13:03:58,071:INFO:plot_model() successfully completed......................................
2026-01-30 13:03:58,090:INFO:Initializing save_model()
2026-01-30 13:03:58,091:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), model_name=..\datos\04. Modelos\modelo_final_explicable, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdinario_def__c',
                                             'C...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-30 13:03:58,091:INFO:Adding model into prep_pipe
2026-01-30 13:03:58,297:INFO:..\datos\04. Modelos\modelo_final_explicable.pkl saved in current working directory
2026-01-30 13:03:58,302:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdinario_def__c',
                                             'CU_precioAplicado_def__c',
                                             'PORCENTAJE_PAGAD...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=42, verbose=0,
                                        warm_start=False))],
         verbose=False)
2026-01-30 13:03:58,302:INFO:save_model() successfully completed......................................
2026-01-30 13:04:34,410:INFO:Initializing load_model()
2026-01-30 13:04:34,410:INFO:load_model(model_name=..\datos\04. Modelos\modelo_final_explicable, platform=None, authentication=None, verbose=True)
2026-01-30 13:04:36,686:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\2381771573.py:23: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-30 13:04:38,408:INFO:Initializing predict_model()
2026-01-30 13:04:38,408:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029C59DB9D90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdinario_def__c',
                                             'CU_precioAplicado_def__c',
                                             'PORCENTAJE_PAGADO_FINAL',
                                             'tie...
                                             'flag_CU_IMPORTE_TOTAL_na',
                                             'flag_CU_precioOrdinario_def__c_na',
                                             'flag_CU_precioAplicado_def__c_na'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 RandomForestClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000029C4DBEB600>)
2026-01-30 13:04:38,408:INFO:Checking exceptions
2026-01-30 13:04:38,408:INFO:Preloading libraries
2026-01-30 13:04:38,408:INFO:Set up data.
2026-01-30 13:04:39,418:INFO:Set up index.
2026-01-30 13:04:42,271:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\2381771573.py:82: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  for grupo, g in df.groupby(grupo_col):

2026-01-30 13:04:42,322:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\utils\_array_api.py:290: RuntimeWarning: invalid value encountered in cast
  return x.astype(dtype, copy=copy, casting=casting)

2026-01-30 13:07:31,057:INFO:Initializing load_model()
2026-01-30 13:07:31,057:INFO:load_model(model_name=..\datos\04. Modelos\modelo_final_explicable, platform=None, authentication=None, verbose=True)
2026-01-30 13:07:33,290:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\270635649.py:23: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-30 13:07:35,087:INFO:Initializing predict_model()
2026-01-30 13:07:35,087:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029C64151B50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdinario_def__c',
                                             'CU_precioAplicado_def__c',
                                             'PORCENTAJE_PAGADO_FINAL',
                                             'tie...
                                             'flag_CU_IMPORTE_TOTAL_na',
                                             'flag_CU_precioOrdinario_def__c_na',
                                             'flag_CU_precioAplicado_def__c_na'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 RandomForestClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000029C5DD10C20>)
2026-01-30 13:07:35,087:INFO:Checking exceptions
2026-01-30 13:07:35,087:INFO:Preloading libraries
2026-01-30 13:07:35,087:INFO:Set up data.
2026-01-30 13:07:36,020:INFO:Set up index.
2026-01-30 13:07:41,157:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\270635649.py:88: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.
  for grupo, g in df.groupby(grupo_col):

2026-01-30 13:07:42,104:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\270635649.py:113: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(data=df_plot, x=metric, y=col_name, palette="viridis")

2026-01-30 13:08:49,002:INFO:Initializing load_model()
2026-01-30 13:08:49,003:INFO:load_model(model_name=..\datos\04. Modelos\modelo_final_explicable, platform=None, authentication=None, verbose=True)
2026-01-30 13:08:52,362:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\2637609198.py:23: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-30 13:08:55,170:INFO:Initializing predict_model()
2026-01-30 13:08:55,170:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029C657CA750>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdinario_def__c',
                                             'CU_precioAplicado_def__c',
                                             'PORCENTAJE_PAGADO_FINAL',
                                             'tie...
                                             'flag_CU_IMPORTE_TOTAL_na',
                                             'flag_CU_precioOrdinario_def__c_na',
                                             'flag_CU_precioAplicado_def__c_na'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 RandomForestClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000029C32162200>)
2026-01-30 13:08:55,170:INFO:Checking exceptions
2026-01-30 13:08:55,170:INFO:Preloading libraries
2026-01-30 13:08:55,170:INFO:Set up data.
2026-01-30 13:08:56,319:INFO:Set up index.
2026-01-30 13:09:01,760:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\2637609198.py:120: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(data=df_plot, x=metric, y=col_name, palette="viridis")

2026-01-30 13:09:02,236:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\2637609198.py:120: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(data=df_plot, x=metric, y=col_name, palette="viridis")

2026-01-30 13:12:09,554:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\3466513485.py:20: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-30 13:12:11,653:INFO:PyCaret ClassificationExperiment
2026-01-30 13:12:11,653:INFO:Logging name: clf-default-name
2026-01-30 13:12:11,653:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-30 13:12:11,653:INFO:version 3.3.2
2026-01-30 13:12:11,653:INFO:Initializing setup()
2026-01-30 13:12:11,653:INFO:self.USI: b075
2026-01-30 13:12:11,653:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'n_jobs_param', 'data', 'X', 'idx', 'y_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'USI', 'target_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'y_train', 'X_test', 'seed', 'gpu_param', 'gpu_n_jobs_param', 'y', 'logging_param', 'pipeline', 'fold_generator', 'exp_id'}
2026-01-30 13:12:11,653:INFO:Checking environment
2026-01-30 13:12:11,653:INFO:python_version: 3.11.11
2026-01-30 13:12:11,653:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-30 13:12:11,653:INFO:machine: AMD64
2026-01-30 13:12:11,653:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-30 13:12:11,653:INFO:Memory: svmem(total=34009374720, available=13265219584, percent=61.0, used=20744155136, free=13265219584)
2026-01-30 13:12:11,653:INFO:Physical Core: 12
2026-01-30 13:12:11,653:INFO:Logical Core: 16
2026-01-30 13:12:11,653:INFO:Checking libraries
2026-01-30 13:12:11,653:INFO:System:
2026-01-30 13:12:11,653:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-30 13:12:11,653:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-30 13:12:11,653:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-30 13:12:11,653:INFO:PyCaret required dependencies:
2026-01-30 13:12:11,653:INFO:                 pip: 25.0
2026-01-30 13:12:11,653:INFO:          setuptools: 75.8.0
2026-01-30 13:12:11,653:INFO:             pycaret: 3.3.2
2026-01-30 13:12:11,653:INFO:             IPython: 9.9.0
2026-01-30 13:12:11,653:INFO:          ipywidgets: 8.1.8
2026-01-30 13:12:11,653:INFO:                tqdm: 4.67.1
2026-01-30 13:12:11,653:INFO:               numpy: 1.26.4
2026-01-30 13:12:11,653:INFO:              pandas: 2.1.4
2026-01-30 13:12:11,653:INFO:              jinja2: 3.1.6
2026-01-30 13:12:11,653:INFO:               scipy: 1.11.4
2026-01-30 13:12:11,653:INFO:              joblib: 1.3.2
2026-01-30 13:12:11,653:INFO:             sklearn: 1.4.2
2026-01-30 13:12:11,653:INFO:                pyod: 2.0.6
2026-01-30 13:12:11,653:INFO:            imblearn: 0.14.1
2026-01-30 13:12:11,666:INFO:   category_encoders: 2.7.0
2026-01-30 13:12:11,666:INFO:            lightgbm: 4.6.0
2026-01-30 13:12:11,666:INFO:               numba: 0.62.1
2026-01-30 13:12:11,666:INFO:            requests: 2.32.3
2026-01-30 13:12:11,666:INFO:          matplotlib: 3.7.5
2026-01-30 13:12:11,667:INFO:          scikitplot: 0.3.7
2026-01-30 13:12:11,667:INFO:         yellowbrick: 1.5
2026-01-30 13:12:11,667:INFO:              plotly: 5.24.1
2026-01-30 13:12:11,667:INFO:    plotly-resampler: Not installed
2026-01-30 13:12:11,667:INFO:             kaleido: 1.2.0
2026-01-30 13:12:11,667:INFO:           schemdraw: 0.15
2026-01-30 13:12:11,667:INFO:         statsmodels: 0.14.6
2026-01-30 13:12:11,667:INFO:              sktime: 0.26.0
2026-01-30 13:12:11,667:INFO:               tbats: 1.1.3
2026-01-30 13:12:11,667:INFO:            pmdarima: 2.0.4
2026-01-30 13:12:11,667:INFO:              psutil: 7.2.1
2026-01-30 13:12:11,667:INFO:          markupsafe: 3.0.3
2026-01-30 13:12:11,667:INFO:             pickle5: Not installed
2026-01-30 13:12:11,667:INFO:         cloudpickle: 3.0.0
2026-01-30 13:12:11,667:INFO:         deprecation: 2.1.0
2026-01-30 13:12:11,667:INFO:              xxhash: 3.6.0
2026-01-30 13:12:11,667:INFO:           wurlitzer: Not installed
2026-01-30 13:12:11,667:INFO:PyCaret optional dependencies:
2026-01-30 13:12:11,667:INFO:                shap: 0.44.1
2026-01-30 13:12:11,667:INFO:           interpret: 0.7.3
2026-01-30 13:12:11,667:INFO:                umap: 0.5.7
2026-01-30 13:12:11,667:INFO:     ydata_profiling: 4.18.1
2026-01-30 13:12:11,667:INFO:  explainerdashboard: 0.5.1
2026-01-30 13:12:11,667:INFO:             autoviz: Not installed
2026-01-30 13:12:11,667:INFO:           fairlearn: 0.7.0
2026-01-30 13:12:11,667:INFO:          deepchecks: Not installed
2026-01-30 13:12:11,667:INFO:             xgboost: Not installed
2026-01-30 13:12:11,667:INFO:            catboost: 1.2.8
2026-01-30 13:12:11,667:INFO:              kmodes: 0.12.2
2026-01-30 13:12:11,667:INFO:             mlxtend: 0.23.4
2026-01-30 13:12:11,667:INFO:       statsforecast: 1.5.0
2026-01-30 13:12:11,667:INFO:        tune_sklearn: Not installed
2026-01-30 13:12:11,667:INFO:                 ray: Not installed
2026-01-30 13:12:11,667:INFO:            hyperopt: 0.2.7
2026-01-30 13:12:11,667:INFO:              optuna: 4.6.0
2026-01-30 13:12:11,667:INFO:               skopt: 0.10.2
2026-01-30 13:12:11,667:INFO:              mlflow: 3.8.1
2026-01-30 13:12:11,667:INFO:              gradio: 6.3.0
2026-01-30 13:12:11,667:INFO:             fastapi: 0.128.0
2026-01-30 13:12:11,667:INFO:             uvicorn: 0.40.0
2026-01-30 13:12:11,667:INFO:              m2cgen: 0.10.0
2026-01-30 13:12:11,667:INFO:           evidently: 0.4.40
2026-01-30 13:12:11,667:INFO:               fugue: 0.8.7
2026-01-30 13:12:11,667:INFO:           streamlit: Not installed
2026-01-30 13:12:11,667:INFO:             prophet: Not installed
2026-01-30 13:12:11,667:INFO:None
2026-01-30 13:12:11,667:INFO:Set up data.
2026-01-30 13:12:11,800:INFO:Set up folding strategy.
2026-01-30 13:12:11,800:INFO:Set up train/test split.
2026-01-30 13:12:12,000:INFO:Set up index.
2026-01-30 13:12:12,017:INFO:Assigning column types.
2026-01-30 13:12:12,168:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-30 13:12:12,183:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 13:12:12,183:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 13:12:12,199:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 13:12:12,199:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 13:12:12,233:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 13:12:12,233:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 13:12:12,249:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 13:12:12,249:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 13:12:12,249:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-30 13:12:12,283:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 13:12:12,300:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 13:12:12,300:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 13:12:12,331:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 13:12:12,349:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 13:12:12,349:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 13:12:12,349:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-30 13:12:12,387:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 13:12:12,387:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 13:12:12,456:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 13:12:12,456:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 13:12:12,456:INFO:Preparing preprocessing pipeline...
2026-01-30 13:12:12,494:INFO:Set up simple imputation.
2026-01-30 13:12:12,494:INFO:Set up feature normalization.
2026-01-30 13:12:12,804:INFO:Finished creating preprocessing pipeline.
2026-01-30 13:12:12,804:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdinario_def__c',
                                             'C...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-30 13:12:12,804:INFO:Creating final display dataframe.
2026-01-30 13:12:13,600:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape      (482669, 27)
4        Transformed data shape      (482669, 27)
5   Transformed train set shape      (337868, 27)
6    Transformed test set shape      (144801, 27)
7              Numeric features                23
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                 3
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              b075
2026-01-30 13:12:13,666:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 13:12:13,666:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 13:12:13,717:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 13:12:13,717:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 13:12:13,717:INFO:setup() successfully completed in 2.08s...............
2026-01-30 13:12:13,717:INFO:Initializing compare_models()
2026-01-30 13:12:13,717:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04EA9F590>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A04EA9F590>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-30 13:12:13,717:INFO:Checking exceptions
2026-01-30 13:12:13,854:INFO:Preparing display monitor
2026-01-30 13:12:13,855:INFO:Initializing Logistic Regression
2026-01-30 13:12:13,855:INFO:Total runtime is 0.0 minutes
2026-01-30 13:12:13,855:INFO:SubProcess create_model() called ==================================
2026-01-30 13:12:13,855:INFO:Initializing create_model()
2026-01-30 13:12:13,855:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04EA9F590>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0484BB250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:12:13,855:INFO:Checking exceptions
2026-01-30 13:12:13,855:INFO:Importing libraries
2026-01-30 13:12:13,855:INFO:Copying training dataset
2026-01-30 13:12:14,083:INFO:Defining folds
2026-01-30 13:12:14,083:INFO:Declaring metric variables
2026-01-30 13:12:14,083:INFO:Importing untrained model
2026-01-30 13:12:14,083:INFO:Logistic Regression Imported successfully
2026-01-30 13:12:14,083:INFO:Starting cross validation
2026-01-30 13:12:14,083:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:12:22,567:INFO:Calculating mean and std
2026-01-30 13:12:22,567:INFO:Creating metrics dataframe
2026-01-30 13:12:22,567:INFO:Uploading results into container
2026-01-30 13:12:22,567:INFO:Uploading model into container now
2026-01-30 13:12:22,567:INFO:_master_model_container: 1
2026-01-30 13:12:22,567:INFO:_display_container: 2
2026-01-30 13:12:22,567:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-30 13:12:22,567:INFO:create_model() successfully completed......................................
2026-01-30 13:12:22,733:INFO:SubProcess create_model() end ==================================
2026-01-30 13:12:22,733:INFO:Creating metrics dataframe
2026-01-30 13:12:22,747:INFO:Initializing Decision Tree Classifier
2026-01-30 13:12:22,747:INFO:Total runtime is 0.1482052206993103 minutes
2026-01-30 13:12:22,747:INFO:SubProcess create_model() called ==================================
2026-01-30 13:12:22,747:INFO:Initializing create_model()
2026-01-30 13:12:22,747:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04EA9F590>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0484BB250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:12:22,747:INFO:Checking exceptions
2026-01-30 13:12:22,747:INFO:Importing libraries
2026-01-30 13:12:22,747:INFO:Copying training dataset
2026-01-30 13:12:22,919:INFO:Defining folds
2026-01-30 13:12:22,919:INFO:Declaring metric variables
2026-01-30 13:12:22,919:INFO:Importing untrained model
2026-01-30 13:12:22,919:INFO:Decision Tree Classifier Imported successfully
2026-01-30 13:12:22,920:INFO:Starting cross validation
2026-01-30 13:12:22,920:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:12:31,059:INFO:Calculating mean and std
2026-01-30 13:12:31,059:INFO:Creating metrics dataframe
2026-01-30 13:12:31,059:INFO:Uploading results into container
2026-01-30 13:12:31,059:INFO:Uploading model into container now
2026-01-30 13:12:31,059:INFO:_master_model_container: 2
2026-01-30 13:12:31,059:INFO:_display_container: 2
2026-01-30 13:12:31,059:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 13:12:31,059:INFO:create_model() successfully completed......................................
2026-01-30 13:12:31,258:INFO:SubProcess create_model() end ==================================
2026-01-30 13:12:31,258:INFO:Creating metrics dataframe
2026-01-30 13:12:31,258:INFO:Initializing Random Forest Classifier
2026-01-30 13:12:31,258:INFO:Total runtime is 0.29004819790522257 minutes
2026-01-30 13:12:31,258:INFO:SubProcess create_model() called ==================================
2026-01-30 13:12:31,258:INFO:Initializing create_model()
2026-01-30 13:12:31,258:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04EA9F590>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0484BB250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:12:31,258:INFO:Checking exceptions
2026-01-30 13:12:31,258:INFO:Importing libraries
2026-01-30 13:12:31,258:INFO:Copying training dataset
2026-01-30 13:12:31,458:INFO:Defining folds
2026-01-30 13:12:31,458:INFO:Declaring metric variables
2026-01-30 13:12:31,458:INFO:Importing untrained model
2026-01-30 13:12:31,458:INFO:Random Forest Classifier Imported successfully
2026-01-30 13:12:31,458:INFO:Starting cross validation
2026-01-30 13:12:31,458:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:12:52,224:INFO:Calculating mean and std
2026-01-30 13:12:52,226:INFO:Creating metrics dataframe
2026-01-30 13:12:52,228:INFO:Uploading results into container
2026-01-30 13:12:52,229:INFO:Uploading model into container now
2026-01-30 13:12:52,230:INFO:_master_model_container: 3
2026-01-30 13:12:52,230:INFO:_display_container: 2
2026-01-30 13:12:52,230:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 13:12:52,230:INFO:create_model() successfully completed......................................
2026-01-30 13:12:52,405:INFO:SubProcess create_model() end ==================================
2026-01-30 13:12:52,405:INFO:Creating metrics dataframe
2026-01-30 13:12:52,405:INFO:Initializing Light Gradient Boosting Machine
2026-01-30 13:12:52,405:INFO:Total runtime is 0.6425010442733765 minutes
2026-01-30 13:12:52,405:INFO:SubProcess create_model() called ==================================
2026-01-30 13:12:52,405:INFO:Initializing create_model()
2026-01-30 13:12:52,405:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04EA9F590>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0484BB250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:12:52,405:INFO:Checking exceptions
2026-01-30 13:12:52,405:INFO:Importing libraries
2026-01-30 13:12:52,405:INFO:Copying training dataset
2026-01-30 13:12:52,636:INFO:Defining folds
2026-01-30 13:12:52,636:INFO:Declaring metric variables
2026-01-30 13:12:52,636:INFO:Importing untrained model
2026-01-30 13:12:52,637:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 13:12:52,637:INFO:Starting cross validation
2026-01-30 13:12:52,638:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:13:00,105:INFO:Calculating mean and std
2026-01-30 13:13:00,105:INFO:Creating metrics dataframe
2026-01-30 13:13:00,105:INFO:Uploading results into container
2026-01-30 13:13:00,105:INFO:Uploading model into container now
2026-01-30 13:13:00,105:INFO:_master_model_container: 4
2026-01-30 13:13:00,105:INFO:_display_container: 2
2026-01-30 13:13:00,105:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 13:13:00,113:INFO:create_model() successfully completed......................................
2026-01-30 13:13:00,281:INFO:SubProcess create_model() end ==================================
2026-01-30 13:13:00,281:INFO:Creating metrics dataframe
2026-01-30 13:13:00,282:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-30 13:13:00,282:INFO:Initializing create_model()
2026-01-30 13:13:00,282:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04EA9F590>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:13:00,282:INFO:Checking exceptions
2026-01-30 13:13:00,282:INFO:Importing libraries
2026-01-30 13:13:00,282:INFO:Copying training dataset
2026-01-30 13:13:00,494:INFO:Defining folds
2026-01-30 13:13:00,494:INFO:Declaring metric variables
2026-01-30 13:13:00,494:INFO:Importing untrained model
2026-01-30 13:13:00,494:INFO:Declaring custom model
2026-01-30 13:13:00,494:INFO:Random Forest Classifier Imported successfully
2026-01-30 13:13:00,494:INFO:Cross validation set to False
2026-01-30 13:13:00,494:INFO:Fitting Model
2026-01-30 13:13:08,920:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 13:13:08,920:INFO:create_model() successfully completed......................................
2026-01-30 13:13:09,096:INFO:Initializing create_model()
2026-01-30 13:13:09,097:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04EA9F590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:13:09,097:INFO:Checking exceptions
2026-01-30 13:13:09,098:INFO:Importing libraries
2026-01-30 13:13:09,098:INFO:Copying training dataset
2026-01-30 13:13:09,318:INFO:Defining folds
2026-01-30 13:13:09,319:INFO:Declaring metric variables
2026-01-30 13:13:09,319:INFO:Importing untrained model
2026-01-30 13:13:09,319:INFO:Declaring custom model
2026-01-30 13:13:09,320:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 13:13:09,321:INFO:Cross validation set to False
2026-01-30 13:13:09,321:INFO:Fitting Model
2026-01-30 13:13:10,209:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 13:13:10,258:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012553 seconds.
2026-01-30 13:13:10,259:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 13:13:10,259:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 13:13:10,259:INFO:[LightGBM] [Info] Total Bins 2868
2026-01-30 13:13:10,260:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 26
2026-01-30 13:13:10,263:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 13:13:10,263:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 13:13:10,883:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 13:13:10,885:INFO:create_model() successfully completed......................................
2026-01-30 13:13:11,100:INFO:Initializing create_model()
2026-01-30 13:13:11,100:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04EA9F590>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:13:11,100:INFO:Checking exceptions
2026-01-30 13:13:11,100:INFO:Importing libraries
2026-01-30 13:13:11,101:INFO:Copying training dataset
2026-01-30 13:13:11,312:INFO:Defining folds
2026-01-30 13:13:11,312:INFO:Declaring metric variables
2026-01-30 13:13:11,312:INFO:Importing untrained model
2026-01-30 13:13:11,312:INFO:Declaring custom model
2026-01-30 13:13:11,313:INFO:Decision Tree Classifier Imported successfully
2026-01-30 13:13:11,313:INFO:Cross validation set to False
2026-01-30 13:13:11,313:INFO:Fitting Model
2026-01-30 13:13:14,730:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 13:13:14,730:INFO:create_model() successfully completed......................................
2026-01-30 13:13:14,913:INFO:_master_model_container: 4
2026-01-30 13:13:14,913:INFO:_display_container: 2
2026-01-30 13:13:14,914:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')]
2026-01-30 13:13:14,915:INFO:compare_models() successfully completed......................................
2026-01-30 13:13:14,927:INFO:Initializing tune_model()
2026-01-30 13:13:14,927:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04EA9F590>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 13:13:14,927:INFO:Checking exceptions
2026-01-30 13:13:14,998:INFO:Copying training dataset
2026-01-30 13:13:15,133:INFO:Checking base model
2026-01-30 13:13:15,133:INFO:Base model : Random Forest Classifier
2026-01-30 13:13:15,133:INFO:Declaring metric variables
2026-01-30 13:13:15,134:INFO:Defining Hyperparameters
2026-01-30 13:13:15,312:INFO:Tuning with n_jobs=-1
2026-01-30 13:13:15,312:INFO:Initializing RandomizedSearchCV
2026-01-30 13:15:24,668:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-30 13:15:24,668:INFO:Hyperparameter search completed
2026-01-30 13:15:24,670:INFO:SubProcess create_model() called ==================================
2026-01-30 13:15:24,670:INFO:Initializing create_model()
2026-01-30 13:15:24,672:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04EA9F590>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A036A97B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': True})
2026-01-30 13:15:24,672:INFO:Checking exceptions
2026-01-30 13:15:24,672:INFO:Importing libraries
2026-01-30 13:15:24,672:INFO:Copying training dataset
2026-01-30 13:15:24,896:INFO:Defining folds
2026-01-30 13:15:24,896:INFO:Declaring metric variables
2026-01-30 13:15:24,896:INFO:Importing untrained model
2026-01-30 13:15:24,896:INFO:Declaring custom model
2026-01-30 13:15:24,896:INFO:Random Forest Classifier Imported successfully
2026-01-30 13:15:24,896:INFO:Starting cross validation
2026-01-30 13:15:24,896:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:15:53,726:INFO:Calculating mean and std
2026-01-30 13:15:53,729:INFO:Creating metrics dataframe
2026-01-30 13:15:53,731:INFO:Finalizing model
2026-01-30 13:16:09,128:INFO:Uploading results into container
2026-01-30 13:16:09,129:INFO:Uploading model into container now
2026-01-30 13:16:09,130:INFO:_master_model_container: 5
2026-01-30 13:16:09,131:INFO:_display_container: 3
2026-01-30 13:16:09,131:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 13:16:09,131:INFO:create_model() successfully completed......................................
2026-01-30 13:16:09,337:INFO:SubProcess create_model() end ==================================
2026-01-30 13:16:09,337:INFO:choose_better activated
2026-01-30 13:16:09,337:INFO:SubProcess create_model() called ==================================
2026-01-30 13:16:09,338:INFO:Initializing create_model()
2026-01-30 13:16:09,338:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04EA9F590>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:16:09,338:INFO:Checking exceptions
2026-01-30 13:16:09,338:INFO:Importing libraries
2026-01-30 13:16:09,338:INFO:Copying training dataset
2026-01-30 13:16:09,560:INFO:Defining folds
2026-01-30 13:16:09,561:INFO:Declaring metric variables
2026-01-30 13:16:09,561:INFO:Importing untrained model
2026-01-30 13:16:09,561:INFO:Declaring custom model
2026-01-30 13:16:09,561:INFO:Random Forest Classifier Imported successfully
2026-01-30 13:16:09,562:INFO:Starting cross validation
2026-01-30 13:16:09,562:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:16:32,766:INFO:Calculating mean and std
2026-01-30 13:16:32,766:INFO:Creating metrics dataframe
2026-01-30 13:16:32,766:INFO:Finalizing model
2026-01-30 13:16:43,679:INFO:Uploading results into container
2026-01-30 13:16:43,679:INFO:Uploading model into container now
2026-01-30 13:16:43,679:INFO:_master_model_container: 6
2026-01-30 13:16:43,679:INFO:_display_container: 4
2026-01-30 13:16:43,679:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 13:16:43,679:INFO:create_model() successfully completed......................................
2026-01-30 13:16:43,869:INFO:SubProcess create_model() end ==================================
2026-01-30 13:16:43,870:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9962
2026-01-30 13:16:43,870:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9658
2026-01-30 13:16:43,870:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-30 13:16:43,870:INFO:choose_better completed
2026-01-30 13:16:43,871:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 13:16:43,873:INFO:_master_model_container: 6
2026-01-30 13:16:43,873:INFO:_display_container: 3
2026-01-30 13:16:43,873:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 13:16:43,873:INFO:tune_model() successfully completed......................................
2026-01-30 13:16:44,029:INFO:Initializing tune_model()
2026-01-30 13:16:44,029:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04EA9F590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 13:16:44,029:INFO:Checking exceptions
2026-01-30 13:16:44,120:INFO:Copying training dataset
2026-01-30 13:16:44,253:INFO:Checking base model
2026-01-30 13:16:44,253:INFO:Base model : Light Gradient Boosting Machine
2026-01-30 13:16:44,253:INFO:Declaring metric variables
2026-01-30 13:16:44,253:INFO:Defining Hyperparameters
2026-01-30 13:16:44,428:INFO:Tuning with n_jobs=-1
2026-01-30 13:16:44,428:INFO:Initializing RandomizedSearchCV
2026-01-30 13:17:27,569:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2026-01-30 13:17:27,569:INFO:Hyperparameter search completed
2026-01-30 13:17:27,569:INFO:SubProcess create_model() called ==================================
2026-01-30 13:17:27,575:INFO:Initializing create_model()
2026-01-30 13:17:27,575:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04EA9F590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03DBC4490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2026-01-30 13:17:27,575:INFO:Checking exceptions
2026-01-30 13:17:27,575:INFO:Importing libraries
2026-01-30 13:17:27,575:INFO:Copying training dataset
2026-01-30 13:17:27,776:INFO:Defining folds
2026-01-30 13:17:27,776:INFO:Declaring metric variables
2026-01-30 13:17:27,787:INFO:Importing untrained model
2026-01-30 13:17:27,787:INFO:Declaring custom model
2026-01-30 13:17:27,787:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 13:17:27,787:INFO:Starting cross validation
2026-01-30 13:17:27,787:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:17:37,510:INFO:Calculating mean and std
2026-01-30 13:17:37,510:INFO:Creating metrics dataframe
2026-01-30 13:17:37,515:INFO:Finalizing model
2026-01-30 13:17:38,236:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 13:17:38,236:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 13:17:38,236:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 13:17:38,418:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 13:17:38,420:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 13:17:38,420:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 13:17:38,420:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 13:17:38,488:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011528 seconds.
2026-01-30 13:17:38,488:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 13:17:38,488:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 13:17:38,488:INFO:[LightGBM] [Info] Total Bins 2868
2026-01-30 13:17:38,489:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 26
2026-01-30 13:17:38,494:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 13:17:38,494:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 13:17:41,992:INFO:Uploading results into container
2026-01-30 13:17:41,995:INFO:Uploading model into container now
2026-01-30 13:17:41,996:INFO:_master_model_container: 7
2026-01-30 13:17:41,996:INFO:_display_container: 4
2026-01-30 13:17:41,998:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 13:17:41,998:INFO:create_model() successfully completed......................................
2026-01-30 13:17:42,229:INFO:SubProcess create_model() end ==================================
2026-01-30 13:17:42,229:INFO:choose_better activated
2026-01-30 13:17:42,229:INFO:SubProcess create_model() called ==================================
2026-01-30 13:17:42,230:INFO:Initializing create_model()
2026-01-30 13:17:42,230:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04EA9F590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:17:42,230:INFO:Checking exceptions
2026-01-30 13:17:42,231:INFO:Importing libraries
2026-01-30 13:17:42,231:INFO:Copying training dataset
2026-01-30 13:17:42,441:INFO:Defining folds
2026-01-30 13:17:42,441:INFO:Declaring metric variables
2026-01-30 13:17:42,442:INFO:Importing untrained model
2026-01-30 13:17:42,442:INFO:Declaring custom model
2026-01-30 13:17:42,443:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 13:17:42,443:INFO:Starting cross validation
2026-01-30 13:17:42,443:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:17:47,233:INFO:Calculating mean and std
2026-01-30 13:17:47,233:INFO:Creating metrics dataframe
2026-01-30 13:17:47,233:INFO:Finalizing model
2026-01-30 13:17:48,090:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 13:17:48,237:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070962 seconds.
2026-01-30 13:17:48,237:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 13:17:48,237:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 13:17:48,237:INFO:[LightGBM] [Info] Total Bins 2868
2026-01-30 13:17:48,239:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 26
2026-01-30 13:17:48,242:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 13:17:48,244:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 13:17:49,359:INFO:Uploading results into container
2026-01-30 13:17:49,361:INFO:Uploading model into container now
2026-01-30 13:17:49,361:INFO:_master_model_container: 8
2026-01-30 13:17:49,361:INFO:_display_container: 5
2026-01-30 13:17:49,362:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 13:17:49,362:INFO:create_model() successfully completed......................................
2026-01-30 13:17:49,594:INFO:SubProcess create_model() end ==================================
2026-01-30 13:17:49,594:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9766
2026-01-30 13:17:49,610:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9936
2026-01-30 13:17:49,610:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2026-01-30 13:17:49,610:INFO:choose_better completed
2026-01-30 13:17:49,610:INFO:_master_model_container: 8
2026-01-30 13:17:49,610:INFO:_display_container: 4
2026-01-30 13:17:49,610:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 13:17:49,610:INFO:tune_model() successfully completed......................................
2026-01-30 13:17:49,803:INFO:Initializing tune_model()
2026-01-30 13:17:49,803:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04EA9F590>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 13:17:49,803:INFO:Checking exceptions
2026-01-30 13:17:49,880:INFO:Copying training dataset
2026-01-30 13:17:50,009:INFO:Checking base model
2026-01-30 13:17:50,009:INFO:Base model : Decision Tree Classifier
2026-01-30 13:17:50,010:INFO:Declaring metric variables
2026-01-30 13:17:50,010:INFO:Defining Hyperparameters
2026-01-30 13:17:50,176:INFO:Tuning with n_jobs=-1
2026-01-30 13:17:50,176:INFO:Initializing RandomizedSearchCV
2026-01-30 13:17:58,442:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 15, 'actual_estimator__criterion': 'gini'}
2026-01-30 13:17:58,442:INFO:Hyperparameter search completed
2026-01-30 13:17:58,442:INFO:SubProcess create_model() called ==================================
2026-01-30 13:17:58,442:INFO:Initializing create_model()
2026-01-30 13:17:58,442:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04EA9F590>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03CED7290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 2, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 15, 'criterion': 'gini'})
2026-01-30 13:17:58,442:INFO:Checking exceptions
2026-01-30 13:17:58,442:INFO:Importing libraries
2026-01-30 13:17:58,442:INFO:Copying training dataset
2026-01-30 13:17:58,711:INFO:Defining folds
2026-01-30 13:17:58,711:INFO:Declaring metric variables
2026-01-30 13:17:58,712:INFO:Importing untrained model
2026-01-30 13:17:58,712:INFO:Declaring custom model
2026-01-30 13:17:58,712:INFO:Decision Tree Classifier Imported successfully
2026-01-30 13:17:58,712:INFO:Starting cross validation
2026-01-30 13:17:58,713:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:18:01,511:INFO:Calculating mean and std
2026-01-30 13:18:01,512:INFO:Creating metrics dataframe
2026-01-30 13:18:01,514:INFO:Finalizing model
2026-01-30 13:18:03,446:INFO:Uploading results into container
2026-01-30 13:18:03,446:INFO:Uploading model into container now
2026-01-30 13:18:03,449:INFO:_master_model_container: 9
2026-01-30 13:18:03,449:INFO:_display_container: 5
2026-01-30 13:18:03,449:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 13:18:03,449:INFO:create_model() successfully completed......................................
2026-01-30 13:18:03,625:INFO:SubProcess create_model() end ==================================
2026-01-30 13:18:03,625:INFO:choose_better activated
2026-01-30 13:18:03,625:INFO:SubProcess create_model() called ==================================
2026-01-30 13:18:03,625:INFO:Initializing create_model()
2026-01-30 13:18:03,625:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04EA9F590>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:18:03,625:INFO:Checking exceptions
2026-01-30 13:18:03,625:INFO:Importing libraries
2026-01-30 13:18:03,627:INFO:Copying training dataset
2026-01-30 13:18:03,838:INFO:Defining folds
2026-01-30 13:18:03,838:INFO:Declaring metric variables
2026-01-30 13:18:03,838:INFO:Importing untrained model
2026-01-30 13:18:03,838:INFO:Declaring custom model
2026-01-30 13:18:03,838:INFO:Decision Tree Classifier Imported successfully
2026-01-30 13:18:03,838:INFO:Starting cross validation
2026-01-30 13:18:03,838:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:18:07,806:INFO:Calculating mean and std
2026-01-30 13:18:07,806:INFO:Creating metrics dataframe
2026-01-30 13:18:07,806:INFO:Finalizing model
2026-01-30 13:18:11,176:INFO:Uploading results into container
2026-01-30 13:18:11,177:INFO:Uploading model into container now
2026-01-30 13:18:11,177:INFO:_master_model_container: 10
2026-01-30 13:18:11,177:INFO:_display_container: 6
2026-01-30 13:18:11,177:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 13:18:11,177:INFO:create_model() successfully completed......................................
2026-01-30 13:18:11,341:INFO:SubProcess create_model() end ==================================
2026-01-30 13:18:11,341:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9701
2026-01-30 13:18:11,341:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9544
2026-01-30 13:18:11,341:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-30 13:18:11,341:INFO:choose_better completed
2026-01-30 13:18:11,341:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 13:18:11,341:INFO:_master_model_container: 10
2026-01-30 13:18:11,341:INFO:_display_container: 5
2026-01-30 13:18:11,341:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 13:18:11,341:INFO:tune_model() successfully completed......................................
2026-01-30 13:18:11,511:INFO:Initializing predict_model()
2026-01-30 13:18:11,511:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04EA9F590>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A04CF2B560>)
2026-01-30 13:18:11,511:INFO:Checking exceptions
2026-01-30 13:18:11,511:INFO:Preloading libraries
2026-01-30 13:18:11,511:INFO:Set up data.
2026-01-30 13:18:11,511:INFO:Set up index.
2026-01-30 13:18:11,911:INFO:Initializing predict_model()
2026-01-30 13:18:11,911:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04EA9F590>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A04CF2B560>)
2026-01-30 13:18:11,911:INFO:Checking exceptions
2026-01-30 13:18:11,911:INFO:Preloading libraries
2026-01-30 13:18:11,911:INFO:Set up data.
2026-01-30 13:18:11,926:INFO:Set up index.
2026-01-30 13:18:12,407:INFO:Initializing predict_model()
2026-01-30 13:18:12,407:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04EA9F590>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A03ED62E80>)
2026-01-30 13:18:12,407:INFO:Checking exceptions
2026-01-30 13:18:12,407:INFO:Preloading libraries
2026-01-30 13:18:12,407:INFO:Set up data.
2026-01-30 13:18:12,429:INFO:Set up index.
2026-01-30 13:18:12,980:INFO:Initializing plot_model()
2026-01-30 13:18:12,980:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04EA9F590>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 13:18:12,980:INFO:Checking exceptions
2026-01-30 13:18:13,074:INFO:Preloading libraries
2026-01-30 13:18:13,215:INFO:Copying training dataset
2026-01-30 13:18:13,215:INFO:Plot type: feature
2026-01-30 13:18:13,215:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 13:18:13,545:INFO:Visual Rendered Successfully
2026-01-30 13:18:13,711:INFO:plot_model() successfully completed......................................
2026-01-30 13:18:13,711:INFO:Initializing plot_model()
2026-01-30 13:18:13,711:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A04EA9F590>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature_all, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 13:18:13,711:INFO:Checking exceptions
2026-01-30 13:18:13,811:INFO:Preloading libraries
2026-01-30 13:18:13,927:INFO:Copying training dataset
2026-01-30 13:18:13,927:INFO:Plot type: feature_all
2026-01-30 13:18:14,133:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 13:18:14,573:INFO:Visual Rendered Successfully
2026-01-30 13:18:14,764:INFO:plot_model() successfully completed......................................
2026-01-30 13:18:14,779:INFO:Initializing save_model()
2026-01-30 13:18:14,780:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), model_name=..\datos\04. Modelos\modelo_final_explicable, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdinario_def__c',
                                             'C...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-30 13:18:14,780:INFO:Adding model into prep_pipe
2026-01-30 13:18:14,955:INFO:..\datos\04. Modelos\modelo_final_explicable.pkl saved in current working directory
2026-01-30 13:18:14,959:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdinario_def__c',
                                             'CU_precioAplicado_def__c',
                                             'PORCENTAJE_PAGAD...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=42, verbose=0,
                                        warm_start=False))],
         verbose=False)
2026-01-30 13:18:14,959:INFO:save_model() successfully completed......................................
2026-01-30 13:27:44,320:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\3810660801.py:20: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-30 13:27:46,576:INFO:PyCaret ClassificationExperiment
2026-01-30 13:27:46,576:INFO:Logging name: clf-default-name
2026-01-30 13:27:46,576:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-30 13:27:46,576:INFO:version 3.3.2
2026-01-30 13:27:46,577:INFO:Initializing setup()
2026-01-30 13:27:46,577:INFO:self.USI: 1663
2026-01-30 13:27:46,578:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'n_jobs_param', 'data', 'X', 'idx', 'y_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'USI', 'target_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'y_train', 'X_test', 'seed', 'gpu_param', 'gpu_n_jobs_param', 'y', 'logging_param', 'pipeline', 'fold_generator', 'exp_id'}
2026-01-30 13:27:46,578:INFO:Checking environment
2026-01-30 13:27:46,578:INFO:python_version: 3.11.11
2026-01-30 13:27:46,579:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-30 13:27:46,579:INFO:machine: AMD64
2026-01-30 13:27:46,579:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-30 13:27:46,580:INFO:Memory: svmem(total=34009374720, available=13250928640, percent=61.0, used=20758446080, free=13250928640)
2026-01-30 13:27:46,581:INFO:Physical Core: 12
2026-01-30 13:27:46,581:INFO:Logical Core: 16
2026-01-30 13:27:46,582:INFO:Checking libraries
2026-01-30 13:27:46,583:INFO:System:
2026-01-30 13:27:46,583:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-30 13:27:46,583:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-30 13:27:46,583:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-30 13:27:46,583:INFO:PyCaret required dependencies:
2026-01-30 13:27:46,584:INFO:                 pip: 25.0
2026-01-30 13:27:46,585:INFO:          setuptools: 75.8.0
2026-01-30 13:27:46,585:INFO:             pycaret: 3.3.2
2026-01-30 13:27:46,585:INFO:             IPython: 9.9.0
2026-01-30 13:27:46,585:INFO:          ipywidgets: 8.1.8
2026-01-30 13:27:46,587:INFO:                tqdm: 4.67.1
2026-01-30 13:27:46,587:INFO:               numpy: 1.26.4
2026-01-30 13:27:46,587:INFO:              pandas: 2.1.4
2026-01-30 13:27:46,587:INFO:              jinja2: 3.1.6
2026-01-30 13:27:46,587:INFO:               scipy: 1.11.4
2026-01-30 13:27:46,587:INFO:              joblib: 1.3.2
2026-01-30 13:27:46,587:INFO:             sklearn: 1.4.2
2026-01-30 13:27:46,587:INFO:                pyod: 2.0.6
2026-01-30 13:27:46,589:INFO:            imblearn: 0.14.1
2026-01-30 13:27:46,589:INFO:   category_encoders: 2.7.0
2026-01-30 13:27:46,590:INFO:            lightgbm: 4.6.0
2026-01-30 13:27:46,590:INFO:               numba: 0.62.1
2026-01-30 13:27:46,591:INFO:            requests: 2.32.3
2026-01-30 13:27:46,591:INFO:          matplotlib: 3.7.5
2026-01-30 13:27:46,591:INFO:          scikitplot: 0.3.7
2026-01-30 13:27:46,591:INFO:         yellowbrick: 1.5
2026-01-30 13:27:46,591:INFO:              plotly: 5.24.1
2026-01-30 13:27:46,592:INFO:    plotly-resampler: Not installed
2026-01-30 13:27:46,592:INFO:             kaleido: 1.2.0
2026-01-30 13:27:46,592:INFO:           schemdraw: 0.15
2026-01-30 13:27:46,592:INFO:         statsmodels: 0.14.6
2026-01-30 13:27:46,593:INFO:              sktime: 0.26.0
2026-01-30 13:27:46,593:INFO:               tbats: 1.1.3
2026-01-30 13:27:46,594:INFO:            pmdarima: 2.0.4
2026-01-30 13:27:46,594:INFO:              psutil: 7.2.1
2026-01-30 13:27:46,594:INFO:          markupsafe: 3.0.3
2026-01-30 13:27:46,595:INFO:             pickle5: Not installed
2026-01-30 13:27:46,595:INFO:         cloudpickle: 3.0.0
2026-01-30 13:27:46,595:INFO:         deprecation: 2.1.0
2026-01-30 13:27:46,595:INFO:              xxhash: 3.6.0
2026-01-30 13:27:46,595:INFO:           wurlitzer: Not installed
2026-01-30 13:27:46,595:INFO:PyCaret optional dependencies:
2026-01-30 13:27:46,595:INFO:                shap: 0.44.1
2026-01-30 13:27:46,595:INFO:           interpret: 0.7.3
2026-01-30 13:27:46,595:INFO:                umap: 0.5.7
2026-01-30 13:27:46,595:INFO:     ydata_profiling: 4.18.1
2026-01-30 13:27:46,595:INFO:  explainerdashboard: 0.5.1
2026-01-30 13:27:46,595:INFO:             autoviz: Not installed
2026-01-30 13:27:46,595:INFO:           fairlearn: 0.7.0
2026-01-30 13:27:46,596:INFO:          deepchecks: Not installed
2026-01-30 13:27:46,596:INFO:             xgboost: Not installed
2026-01-30 13:27:46,596:INFO:            catboost: 1.2.8
2026-01-30 13:27:46,597:INFO:              kmodes: 0.12.2
2026-01-30 13:27:46,597:INFO:             mlxtend: 0.23.4
2026-01-30 13:27:46,597:INFO:       statsforecast: 1.5.0
2026-01-30 13:27:46,597:INFO:        tune_sklearn: Not installed
2026-01-30 13:27:46,597:INFO:                 ray: Not installed
2026-01-30 13:27:46,597:INFO:            hyperopt: 0.2.7
2026-01-30 13:27:46,598:INFO:              optuna: 4.6.0
2026-01-30 13:27:46,598:INFO:               skopt: 0.10.2
2026-01-30 13:27:46,598:INFO:              mlflow: 3.8.1
2026-01-30 13:27:46,598:INFO:              gradio: 6.3.0
2026-01-30 13:27:46,598:INFO:             fastapi: 0.128.0
2026-01-30 13:27:46,598:INFO:             uvicorn: 0.40.0
2026-01-30 13:27:46,598:INFO:              m2cgen: 0.10.0
2026-01-30 13:27:46,598:INFO:           evidently: 0.4.40
2026-01-30 13:27:46,598:INFO:               fugue: 0.8.7
2026-01-30 13:27:46,598:INFO:           streamlit: Not installed
2026-01-30 13:27:46,598:INFO:             prophet: Not installed
2026-01-30 13:27:46,598:INFO:None
2026-01-30 13:27:46,598:INFO:Set up data.
2026-01-30 13:27:46,672:INFO:Set up folding strategy.
2026-01-30 13:27:46,672:INFO:Set up train/test split.
2026-01-30 13:27:46,821:INFO:Set up index.
2026-01-30 13:27:46,826:INFO:Assigning column types.
2026-01-30 13:27:46,909:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-30 13:27:46,943:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 13:27:46,943:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 13:27:46,959:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 13:27:46,959:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 13:27:46,989:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 13:27:46,990:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 13:27:47,007:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 13:27:47,011:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 13:27:47,011:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-30 13:27:47,041:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 13:27:47,058:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 13:27:47,058:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 13:27:47,087:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 13:27:47,104:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 13:27:47,104:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 13:27:47,104:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-30 13:27:47,151:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 13:27:47,151:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 13:27:47,187:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 13:27:47,187:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 13:27:47,187:INFO:Preparing preprocessing pipeline...
2026-01-30 13:27:47,203:INFO:Set up simple imputation.
2026-01-30 13:27:47,203:INFO:Set up feature normalization.
2026-01-30 13:27:47,520:INFO:Finished creating preprocessing pipeline.
2026-01-30 13:27:47,520:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'tiempo_etapa_dias',
                                             'tiempo_entre_etapas_dias',
                                             'num...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-30 13:27:47,520:INFO:Creating final display dataframe.
2026-01-30 13:27:48,636:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape      (373023, 21)
4        Transformed data shape      (373023, 21)
5   Transformed train set shape      (261116, 21)
6    Transformed test set shape      (111907, 21)
7              Numeric features                17
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                 3
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              1663
2026-01-30 13:27:48,720:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 13:27:48,720:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 13:27:48,787:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 13:27:48,787:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 13:27:48,787:INFO:setup() successfully completed in 2.22s...............
2026-01-30 13:27:48,787:INFO:Initializing compare_models()
2026-01-30 13:27:48,787:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-30 13:27:48,787:INFO:Checking exceptions
2026-01-30 13:27:48,903:INFO:Preparing display monitor
2026-01-30 13:27:48,903:INFO:Initializing Logistic Regression
2026-01-30 13:27:48,903:INFO:Total runtime is 0.0 minutes
2026-01-30 13:27:48,903:INFO:SubProcess create_model() called ==================================
2026-01-30 13:27:48,903:INFO:Initializing create_model()
2026-01-30 13:27:48,903:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A048A95610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:27:48,903:INFO:Checking exceptions
2026-01-30 13:27:48,903:INFO:Importing libraries
2026-01-30 13:27:48,903:INFO:Copying training dataset
2026-01-30 13:27:49,086:INFO:Defining folds
2026-01-30 13:27:49,086:INFO:Declaring metric variables
2026-01-30 13:27:49,086:INFO:Importing untrained model
2026-01-30 13:27:49,086:INFO:Logistic Regression Imported successfully
2026-01-30 13:27:49,086:INFO:Starting cross validation
2026-01-30 13:27:49,086:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:27:57,898:INFO:Calculating mean and std
2026-01-30 13:27:57,899:INFO:Creating metrics dataframe
2026-01-30 13:27:57,901:INFO:Uploading results into container
2026-01-30 13:27:57,901:INFO:Uploading model into container now
2026-01-30 13:27:57,902:INFO:_master_model_container: 1
2026-01-30 13:27:57,902:INFO:_display_container: 2
2026-01-30 13:27:57,902:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-30 13:27:57,903:INFO:create_model() successfully completed......................................
2026-01-30 13:27:58,070:INFO:SubProcess create_model() end ==================================
2026-01-30 13:27:58,070:INFO:Creating metrics dataframe
2026-01-30 13:27:58,070:INFO:Initializing Decision Tree Classifier
2026-01-30 13:27:58,070:INFO:Total runtime is 0.15277994473775228 minutes
2026-01-30 13:27:58,070:INFO:SubProcess create_model() called ==================================
2026-01-30 13:27:58,070:INFO:Initializing create_model()
2026-01-30 13:27:58,070:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A048A95610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:27:58,070:INFO:Checking exceptions
2026-01-30 13:27:58,070:INFO:Importing libraries
2026-01-30 13:27:58,070:INFO:Copying training dataset
2026-01-30 13:27:58,186:INFO:Defining folds
2026-01-30 13:27:58,186:INFO:Declaring metric variables
2026-01-30 13:27:58,186:INFO:Importing untrained model
2026-01-30 13:27:58,186:INFO:Decision Tree Classifier Imported successfully
2026-01-30 13:27:58,186:INFO:Starting cross validation
2026-01-30 13:27:58,186:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:28:04,144:INFO:Calculating mean and std
2026-01-30 13:28:04,144:INFO:Creating metrics dataframe
2026-01-30 13:28:04,152:INFO:Uploading results into container
2026-01-30 13:28:04,152:INFO:Uploading model into container now
2026-01-30 13:28:04,152:INFO:_master_model_container: 2
2026-01-30 13:28:04,153:INFO:_display_container: 2
2026-01-30 13:28:04,153:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 13:28:04,153:INFO:create_model() successfully completed......................................
2026-01-30 13:28:04,336:INFO:SubProcess create_model() end ==================================
2026-01-30 13:28:04,336:INFO:Creating metrics dataframe
2026-01-30 13:28:04,336:INFO:Initializing Random Forest Classifier
2026-01-30 13:28:04,336:INFO:Total runtime is 0.25721621910730996 minutes
2026-01-30 13:28:04,336:INFO:SubProcess create_model() called ==================================
2026-01-30 13:28:04,336:INFO:Initializing create_model()
2026-01-30 13:28:04,336:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A048A95610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:28:04,336:INFO:Checking exceptions
2026-01-30 13:28:04,336:INFO:Importing libraries
2026-01-30 13:28:04,336:INFO:Copying training dataset
2026-01-30 13:28:04,453:INFO:Defining folds
2026-01-30 13:28:04,453:INFO:Declaring metric variables
2026-01-30 13:28:04,454:INFO:Importing untrained model
2026-01-30 13:28:04,454:INFO:Random Forest Classifier Imported successfully
2026-01-30 13:28:04,454:INFO:Starting cross validation
2026-01-30 13:28:04,454:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:28:18,012:INFO:Calculating mean and std
2026-01-30 13:28:18,012:INFO:Creating metrics dataframe
2026-01-30 13:28:18,012:INFO:Uploading results into container
2026-01-30 13:28:18,012:INFO:Uploading model into container now
2026-01-30 13:28:18,012:INFO:_master_model_container: 3
2026-01-30 13:28:18,012:INFO:_display_container: 2
2026-01-30 13:28:18,012:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 13:28:18,012:INFO:create_model() successfully completed......................................
2026-01-30 13:28:18,203:INFO:SubProcess create_model() end ==================================
2026-01-30 13:28:18,203:INFO:Creating metrics dataframe
2026-01-30 13:28:18,203:INFO:Initializing Light Gradient Boosting Machine
2026-01-30 13:28:18,203:INFO:Total runtime is 0.4883267601331075 minutes
2026-01-30 13:28:18,203:INFO:SubProcess create_model() called ==================================
2026-01-30 13:28:18,203:INFO:Initializing create_model()
2026-01-30 13:28:18,203:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A048A95610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:28:18,203:INFO:Checking exceptions
2026-01-30 13:28:18,203:INFO:Importing libraries
2026-01-30 13:28:18,203:INFO:Copying training dataset
2026-01-30 13:28:18,319:INFO:Defining folds
2026-01-30 13:28:18,319:INFO:Declaring metric variables
2026-01-30 13:28:18,319:INFO:Importing untrained model
2026-01-30 13:28:18,319:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 13:28:18,319:INFO:Starting cross validation
2026-01-30 13:28:18,319:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:28:24,645:INFO:Calculating mean and std
2026-01-30 13:28:24,645:INFO:Creating metrics dataframe
2026-01-30 13:28:24,645:INFO:Uploading results into container
2026-01-30 13:28:24,645:INFO:Uploading model into container now
2026-01-30 13:28:24,645:INFO:_master_model_container: 4
2026-01-30 13:28:24,645:INFO:_display_container: 2
2026-01-30 13:28:24,645:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 13:28:24,645:INFO:create_model() successfully completed......................................
2026-01-30 13:28:24,818:INFO:SubProcess create_model() end ==================================
2026-01-30 13:28:24,818:INFO:Creating metrics dataframe
2026-01-30 13:28:24,819:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-30 13:28:24,819:INFO:Initializing create_model()
2026-01-30 13:28:24,819:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:28:24,819:INFO:Checking exceptions
2026-01-30 13:28:24,819:INFO:Importing libraries
2026-01-30 13:28:24,823:INFO:Copying training dataset
2026-01-30 13:28:24,939:INFO:Defining folds
2026-01-30 13:28:24,939:INFO:Declaring metric variables
2026-01-30 13:28:24,939:INFO:Importing untrained model
2026-01-30 13:28:24,939:INFO:Declaring custom model
2026-01-30 13:28:24,939:INFO:Random Forest Classifier Imported successfully
2026-01-30 13:28:24,939:INFO:Cross validation set to False
2026-01-30 13:28:24,939:INFO:Fitting Model
2026-01-30 13:28:30,123:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 13:28:30,123:INFO:create_model() successfully completed......................................
2026-01-30 13:28:30,303:INFO:Initializing create_model()
2026-01-30 13:28:30,303:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:28:30,303:INFO:Checking exceptions
2026-01-30 13:28:30,303:INFO:Importing libraries
2026-01-30 13:28:30,303:INFO:Copying training dataset
2026-01-30 13:28:30,436:INFO:Defining folds
2026-01-30 13:28:30,436:INFO:Declaring metric variables
2026-01-30 13:28:30,436:INFO:Importing untrained model
2026-01-30 13:28:30,436:INFO:Declaring custom model
2026-01-30 13:28:30,436:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 13:28:30,436:INFO:Cross validation set to False
2026-01-30 13:28:30,436:INFO:Fitting Model
2026-01-30 13:28:31,015:INFO:[LightGBM] [Info] Number of positive: 110231, number of negative: 150885
2026-01-30 13:28:31,033:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009011 seconds.
2026-01-30 13:28:31,033:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 13:28:31,033:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 13:28:31,034:INFO:[LightGBM] [Info] Total Bins 2108
2026-01-30 13:28:31,035:INFO:[LightGBM] [Info] Number of data points in the train set: 261116, number of used features: 20
2026-01-30 13:28:31,037:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.422153 -> initscore=-0.313940
2026-01-30 13:28:31,037:INFO:[LightGBM] [Info] Start training from score -0.313940
2026-01-30 13:28:31,687:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 13:28:31,688:INFO:create_model() successfully completed......................................
2026-01-30 13:28:31,886:INFO:Initializing create_model()
2026-01-30 13:28:31,886:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:28:31,886:INFO:Checking exceptions
2026-01-30 13:28:31,886:INFO:Importing libraries
2026-01-30 13:28:31,886:INFO:Copying training dataset
2026-01-30 13:28:32,019:INFO:Defining folds
2026-01-30 13:28:32,019:INFO:Declaring metric variables
2026-01-30 13:28:32,019:INFO:Importing untrained model
2026-01-30 13:28:32,019:INFO:Declaring custom model
2026-01-30 13:28:32,019:INFO:Decision Tree Classifier Imported successfully
2026-01-30 13:28:32,019:INFO:Cross validation set to False
2026-01-30 13:28:32,019:INFO:Fitting Model
2026-01-30 13:28:34,086:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 13:28:34,086:INFO:create_model() successfully completed......................................
2026-01-30 13:28:34,269:INFO:_master_model_container: 4
2026-01-30 13:28:34,269:INFO:_display_container: 2
2026-01-30 13:28:34,269:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')]
2026-01-30 13:28:34,269:INFO:compare_models() successfully completed......................................
2026-01-30 13:28:34,286:INFO:Initializing tune_model()
2026-01-30 13:28:34,286:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 13:28:34,286:INFO:Checking exceptions
2026-01-30 13:28:34,339:INFO:Copying training dataset
2026-01-30 13:28:34,425:INFO:Checking base model
2026-01-30 13:28:34,425:INFO:Base model : Random Forest Classifier
2026-01-30 13:28:34,425:INFO:Declaring metric variables
2026-01-30 13:28:34,425:INFO:Defining Hyperparameters
2026-01-30 13:28:34,589:INFO:Tuning with n_jobs=-1
2026-01-30 13:28:34,589:INFO:Initializing RandomizedSearchCV
2026-01-30 13:30:02,275:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-30 13:30:02,276:INFO:Hyperparameter search completed
2026-01-30 13:30:02,277:INFO:SubProcess create_model() called ==================================
2026-01-30 13:30:02,277:INFO:Initializing create_model()
2026-01-30 13:30:02,277:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04850B250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': True})
2026-01-30 13:30:02,278:INFO:Checking exceptions
2026-01-30 13:30:02,278:INFO:Importing libraries
2026-01-30 13:30:02,278:INFO:Copying training dataset
2026-01-30 13:30:02,458:INFO:Defining folds
2026-01-30 13:30:02,458:INFO:Declaring metric variables
2026-01-30 13:30:02,458:INFO:Importing untrained model
2026-01-30 13:30:02,458:INFO:Declaring custom model
2026-01-30 13:30:02,459:INFO:Random Forest Classifier Imported successfully
2026-01-30 13:30:02,459:INFO:Starting cross validation
2026-01-30 13:30:02,460:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:30:20,902:INFO:Calculating mean and std
2026-01-30 13:30:20,902:INFO:Creating metrics dataframe
2026-01-30 13:30:20,902:INFO:Finalizing model
2026-01-30 13:30:29,787:INFO:Uploading results into container
2026-01-30 13:30:29,787:INFO:Uploading model into container now
2026-01-30 13:30:29,787:INFO:_master_model_container: 5
2026-01-30 13:30:29,787:INFO:_display_container: 3
2026-01-30 13:30:29,787:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 13:30:29,787:INFO:create_model() successfully completed......................................
2026-01-30 13:30:29,982:INFO:SubProcess create_model() end ==================================
2026-01-30 13:30:29,982:INFO:choose_better activated
2026-01-30 13:30:29,982:INFO:SubProcess create_model() called ==================================
2026-01-30 13:30:29,982:INFO:Initializing create_model()
2026-01-30 13:30:29,982:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:30:29,982:INFO:Checking exceptions
2026-01-30 13:30:29,982:INFO:Importing libraries
2026-01-30 13:30:29,982:INFO:Copying training dataset
2026-01-30 13:30:30,150:INFO:Defining folds
2026-01-30 13:30:30,150:INFO:Declaring metric variables
2026-01-30 13:30:30,150:INFO:Importing untrained model
2026-01-30 13:30:30,150:INFO:Declaring custom model
2026-01-30 13:30:30,150:INFO:Random Forest Classifier Imported successfully
2026-01-30 13:30:30,150:INFO:Starting cross validation
2026-01-30 13:30:30,150:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:30:42,988:INFO:Calculating mean and std
2026-01-30 13:30:42,988:INFO:Creating metrics dataframe
2026-01-30 13:30:42,989:INFO:Finalizing model
2026-01-30 13:30:49,274:INFO:Uploading results into container
2026-01-30 13:30:49,275:INFO:Uploading model into container now
2026-01-30 13:30:49,276:INFO:_master_model_container: 6
2026-01-30 13:30:49,276:INFO:_display_container: 4
2026-01-30 13:30:49,276:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 13:30:49,277:INFO:create_model() successfully completed......................................
2026-01-30 13:30:49,448:INFO:SubProcess create_model() end ==================================
2026-01-30 13:30:49,448:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9957
2026-01-30 13:30:49,448:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9656
2026-01-30 13:30:49,448:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-30 13:30:49,448:INFO:choose_better completed
2026-01-30 13:30:49,448:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 13:30:49,448:INFO:_master_model_container: 6
2026-01-30 13:30:49,448:INFO:_display_container: 3
2026-01-30 13:30:49,448:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 13:30:49,448:INFO:tune_model() successfully completed......................................
2026-01-30 13:30:49,621:INFO:Initializing tune_model()
2026-01-30 13:30:49,621:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 13:30:49,621:INFO:Checking exceptions
2026-01-30 13:30:49,674:INFO:Copying training dataset
2026-01-30 13:30:49,750:INFO:Checking base model
2026-01-30 13:30:49,750:INFO:Base model : Light Gradient Boosting Machine
2026-01-30 13:30:49,750:INFO:Declaring metric variables
2026-01-30 13:30:49,750:INFO:Defining Hyperparameters
2026-01-30 13:30:49,936:INFO:Tuning with n_jobs=-1
2026-01-30 13:30:49,936:INFO:Initializing RandomizedSearchCV
2026-01-30 13:31:18,131:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2026-01-30 13:31:18,134:INFO:Hyperparameter search completed
2026-01-30 13:31:18,134:INFO:SubProcess create_model() called ==================================
2026-01-30 13:31:18,134:INFO:Initializing create_model()
2026-01-30 13:31:18,134:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0CCBF3BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2026-01-30 13:31:18,134:INFO:Checking exceptions
2026-01-30 13:31:18,134:INFO:Importing libraries
2026-01-30 13:31:18,134:INFO:Copying training dataset
2026-01-30 13:31:18,270:INFO:Defining folds
2026-01-30 13:31:18,270:INFO:Declaring metric variables
2026-01-30 13:31:18,270:INFO:Importing untrained model
2026-01-30 13:31:18,270:INFO:Declaring custom model
2026-01-30 13:31:18,270:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 13:31:18,270:INFO:Starting cross validation
2026-01-30 13:31:18,281:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:31:25,355:INFO:Calculating mean and std
2026-01-30 13:31:25,355:INFO:Creating metrics dataframe
2026-01-30 13:31:25,355:INFO:Finalizing model
2026-01-30 13:31:25,803:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 13:31:25,803:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 13:31:25,803:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 13:31:25,959:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 13:31:25,959:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 13:31:25,959:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 13:31:25,961:INFO:[LightGBM] [Info] Number of positive: 110231, number of negative: 150885
2026-01-30 13:31:25,978:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009307 seconds.
2026-01-30 13:31:25,978:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 13:31:25,978:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 13:31:25,980:INFO:[LightGBM] [Info] Total Bins 2108
2026-01-30 13:31:25,980:INFO:[LightGBM] [Info] Number of data points in the train set: 261116, number of used features: 20
2026-01-30 13:31:25,984:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.422153 -> initscore=-0.313940
2026-01-30 13:31:25,984:INFO:[LightGBM] [Info] Start training from score -0.313940
2026-01-30 13:31:28,378:INFO:Uploading results into container
2026-01-30 13:31:28,378:INFO:Uploading model into container now
2026-01-30 13:31:28,380:INFO:_master_model_container: 7
2026-01-30 13:31:28,380:INFO:_display_container: 4
2026-01-30 13:31:28,382:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 13:31:28,382:INFO:create_model() successfully completed......................................
2026-01-30 13:31:28,599:INFO:SubProcess create_model() end ==================================
2026-01-30 13:31:28,599:INFO:choose_better activated
2026-01-30 13:31:28,615:INFO:SubProcess create_model() called ==================================
2026-01-30 13:31:28,615:INFO:Initializing create_model()
2026-01-30 13:31:28,616:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:31:28,616:INFO:Checking exceptions
2026-01-30 13:31:28,616:INFO:Importing libraries
2026-01-30 13:31:28,616:INFO:Copying training dataset
2026-01-30 13:31:28,744:INFO:Defining folds
2026-01-30 13:31:28,744:INFO:Declaring metric variables
2026-01-30 13:31:28,744:INFO:Importing untrained model
2026-01-30 13:31:28,744:INFO:Declaring custom model
2026-01-30 13:31:28,744:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 13:31:28,744:INFO:Starting cross validation
2026-01-30 13:31:28,744:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:31:32,270:INFO:Calculating mean and std
2026-01-30 13:31:32,270:INFO:Creating metrics dataframe
2026-01-30 13:31:32,270:INFO:Finalizing model
2026-01-30 13:31:32,843:INFO:[LightGBM] [Info] Number of positive: 110231, number of negative: 150885
2026-01-30 13:31:32,863:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011038 seconds.
2026-01-30 13:31:32,863:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 13:31:32,863:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 13:31:32,863:INFO:[LightGBM] [Info] Total Bins 2108
2026-01-30 13:31:32,863:INFO:[LightGBM] [Info] Number of data points in the train set: 261116, number of used features: 20
2026-01-30 13:31:32,867:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.422153 -> initscore=-0.313940
2026-01-30 13:31:32,867:INFO:[LightGBM] [Info] Start training from score -0.313940
2026-01-30 13:31:33,714:INFO:Uploading results into container
2026-01-30 13:31:33,716:INFO:Uploading model into container now
2026-01-30 13:31:33,716:INFO:_master_model_container: 8
2026-01-30 13:31:33,718:INFO:_display_container: 5
2026-01-30 13:31:33,718:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 13:31:33,718:INFO:create_model() successfully completed......................................
2026-01-30 13:31:33,950:INFO:SubProcess create_model() end ==================================
2026-01-30 13:31:33,950:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9785
2026-01-30 13:31:33,950:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9938
2026-01-30 13:31:33,950:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2026-01-30 13:31:33,950:INFO:choose_better completed
2026-01-30 13:31:33,950:INFO:_master_model_container: 8
2026-01-30 13:31:33,950:INFO:_display_container: 4
2026-01-30 13:31:33,950:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 13:31:33,950:INFO:tune_model() successfully completed......................................
2026-01-30 13:31:34,133:INFO:Initializing tune_model()
2026-01-30 13:31:34,137:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 13:31:34,137:INFO:Checking exceptions
2026-01-30 13:31:34,187:INFO:Copying training dataset
2026-01-30 13:31:34,267:INFO:Checking base model
2026-01-30 13:31:34,267:INFO:Base model : Decision Tree Classifier
2026-01-30 13:31:34,267:INFO:Declaring metric variables
2026-01-30 13:31:34,267:INFO:Defining Hyperparameters
2026-01-30 13:31:34,436:INFO:Tuning with n_jobs=-1
2026-01-30 13:31:34,436:INFO:Initializing RandomizedSearchCV
2026-01-30 13:31:39,777:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 15, 'actual_estimator__criterion': 'gini'}
2026-01-30 13:31:39,777:INFO:Hyperparameter search completed
2026-01-30 13:31:39,777:INFO:SubProcess create_model() called ==================================
2026-01-30 13:31:39,777:INFO:Initializing create_model()
2026-01-30 13:31:39,777:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04C2373D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 2, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 15, 'criterion': 'gini'})
2026-01-30 13:31:39,777:INFO:Checking exceptions
2026-01-30 13:31:39,777:INFO:Importing libraries
2026-01-30 13:31:39,777:INFO:Copying training dataset
2026-01-30 13:31:39,902:INFO:Defining folds
2026-01-30 13:31:39,902:INFO:Declaring metric variables
2026-01-30 13:31:39,902:INFO:Importing untrained model
2026-01-30 13:31:39,902:INFO:Declaring custom model
2026-01-30 13:31:39,902:INFO:Decision Tree Classifier Imported successfully
2026-01-30 13:31:39,902:INFO:Starting cross validation
2026-01-30 13:31:39,902:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:31:41,710:INFO:Calculating mean and std
2026-01-30 13:31:41,710:INFO:Creating metrics dataframe
2026-01-30 13:31:41,710:INFO:Finalizing model
2026-01-30 13:31:42,970:INFO:Uploading results into container
2026-01-30 13:31:42,970:INFO:Uploading model into container now
2026-01-30 13:31:42,970:INFO:_master_model_container: 9
2026-01-30 13:31:42,970:INFO:_display_container: 5
2026-01-30 13:31:42,970:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 13:31:42,970:INFO:create_model() successfully completed......................................
2026-01-30 13:31:43,148:INFO:SubProcess create_model() end ==================================
2026-01-30 13:31:43,148:INFO:choose_better activated
2026-01-30 13:31:43,148:INFO:SubProcess create_model() called ==================================
2026-01-30 13:31:43,148:INFO:Initializing create_model()
2026-01-30 13:31:43,148:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:31:43,148:INFO:Checking exceptions
2026-01-30 13:31:43,160:INFO:Importing libraries
2026-01-30 13:31:43,160:INFO:Copying training dataset
2026-01-30 13:31:43,283:INFO:Defining folds
2026-01-30 13:31:43,283:INFO:Declaring metric variables
2026-01-30 13:31:43,283:INFO:Importing untrained model
2026-01-30 13:31:43,283:INFO:Declaring custom model
2026-01-30 13:31:43,283:INFO:Decision Tree Classifier Imported successfully
2026-01-30 13:31:43,283:INFO:Starting cross validation
2026-01-30 13:31:43,283:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:31:45,774:INFO:Calculating mean and std
2026-01-30 13:31:45,774:INFO:Creating metrics dataframe
2026-01-30 13:31:45,774:INFO:Finalizing model
2026-01-30 13:31:47,851:INFO:Uploading results into container
2026-01-30 13:31:47,852:INFO:Uploading model into container now
2026-01-30 13:31:47,853:INFO:_master_model_container: 10
2026-01-30 13:31:47,853:INFO:_display_container: 6
2026-01-30 13:31:47,853:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 13:31:47,853:INFO:create_model() successfully completed......................................
2026-01-30 13:31:48,024:INFO:SubProcess create_model() end ==================================
2026-01-30 13:31:48,026:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9752
2026-01-30 13:31:48,026:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9572
2026-01-30 13:31:48,026:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-30 13:31:48,026:INFO:choose_better completed
2026-01-30 13:31:48,026:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 13:31:48,029:INFO:_master_model_container: 10
2026-01-30 13:31:48,029:INFO:_display_container: 5
2026-01-30 13:31:48,029:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 13:31:48,029:INFO:tune_model() successfully completed......................................
2026-01-30 13:31:48,199:INFO:Initializing predict_model()
2026-01-30 13:31:48,199:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03D1EFA90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A03B48FA60>)
2026-01-30 13:31:48,199:INFO:Checking exceptions
2026-01-30 13:31:48,199:INFO:Preloading libraries
2026-01-30 13:31:48,199:INFO:Set up data.
2026-01-30 13:31:48,199:INFO:Set up index.
2026-01-30 13:34:41,174:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\2655064592.py:20: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-30 13:34:43,384:INFO:PyCaret ClassificationExperiment
2026-01-30 13:34:43,384:INFO:Logging name: clf-default-name
2026-01-30 13:34:43,384:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-30 13:34:43,384:INFO:version 3.3.2
2026-01-30 13:34:43,384:INFO:Initializing setup()
2026-01-30 13:34:43,384:INFO:self.USI: fb0c
2026-01-30 13:34:43,384:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'n_jobs_param', 'data', 'X', 'idx', 'y_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'USI', 'target_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'y_train', 'X_test', 'seed', 'gpu_param', 'gpu_n_jobs_param', 'y', 'logging_param', 'pipeline', 'fold_generator', 'exp_id'}
2026-01-30 13:34:43,384:INFO:Checking environment
2026-01-30 13:34:43,384:INFO:python_version: 3.11.11
2026-01-30 13:34:43,384:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-30 13:34:43,384:INFO:machine: AMD64
2026-01-30 13:34:43,384:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-30 13:34:43,384:INFO:Memory: svmem(total=34009374720, available=9635639296, percent=71.7, used=24373735424, free=9635639296)
2026-01-30 13:34:43,384:INFO:Physical Core: 12
2026-01-30 13:34:43,384:INFO:Logical Core: 16
2026-01-30 13:34:43,384:INFO:Checking libraries
2026-01-30 13:34:43,384:INFO:System:
2026-01-30 13:34:43,384:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-30 13:34:43,384:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-30 13:34:43,384:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-30 13:34:43,384:INFO:PyCaret required dependencies:
2026-01-30 13:34:43,384:INFO:                 pip: 25.0
2026-01-30 13:34:43,384:INFO:          setuptools: 75.8.0
2026-01-30 13:34:43,384:INFO:             pycaret: 3.3.2
2026-01-30 13:34:43,384:INFO:             IPython: 9.9.0
2026-01-30 13:34:43,384:INFO:          ipywidgets: 8.1.8
2026-01-30 13:34:43,384:INFO:                tqdm: 4.67.1
2026-01-30 13:34:43,384:INFO:               numpy: 1.26.4
2026-01-30 13:34:43,384:INFO:              pandas: 2.1.4
2026-01-30 13:34:43,384:INFO:              jinja2: 3.1.6
2026-01-30 13:34:43,384:INFO:               scipy: 1.11.4
2026-01-30 13:34:43,384:INFO:              joblib: 1.3.2
2026-01-30 13:34:43,384:INFO:             sklearn: 1.4.2
2026-01-30 13:34:43,384:INFO:                pyod: 2.0.6
2026-01-30 13:34:43,384:INFO:            imblearn: 0.14.1
2026-01-30 13:34:43,384:INFO:   category_encoders: 2.7.0
2026-01-30 13:34:43,384:INFO:            lightgbm: 4.6.0
2026-01-30 13:34:43,384:INFO:               numba: 0.62.1
2026-01-30 13:34:43,384:INFO:            requests: 2.32.3
2026-01-30 13:34:43,384:INFO:          matplotlib: 3.7.5
2026-01-30 13:34:43,384:INFO:          scikitplot: 0.3.7
2026-01-30 13:34:43,384:INFO:         yellowbrick: 1.5
2026-01-30 13:34:43,384:INFO:              plotly: 5.24.1
2026-01-30 13:34:43,384:INFO:    plotly-resampler: Not installed
2026-01-30 13:34:43,384:INFO:             kaleido: 1.2.0
2026-01-30 13:34:43,384:INFO:           schemdraw: 0.15
2026-01-30 13:34:43,384:INFO:         statsmodels: 0.14.6
2026-01-30 13:34:43,384:INFO:              sktime: 0.26.0
2026-01-30 13:34:43,384:INFO:               tbats: 1.1.3
2026-01-30 13:34:43,384:INFO:            pmdarima: 2.0.4
2026-01-30 13:34:43,384:INFO:              psutil: 7.2.1
2026-01-30 13:34:43,384:INFO:          markupsafe: 3.0.3
2026-01-30 13:34:43,384:INFO:             pickle5: Not installed
2026-01-30 13:34:43,384:INFO:         cloudpickle: 3.0.0
2026-01-30 13:34:43,384:INFO:         deprecation: 2.1.0
2026-01-30 13:34:43,384:INFO:              xxhash: 3.6.0
2026-01-30 13:34:43,384:INFO:           wurlitzer: Not installed
2026-01-30 13:34:43,384:INFO:PyCaret optional dependencies:
2026-01-30 13:34:43,384:INFO:                shap: 0.44.1
2026-01-30 13:34:43,384:INFO:           interpret: 0.7.3
2026-01-30 13:34:43,384:INFO:                umap: 0.5.7
2026-01-30 13:34:43,384:INFO:     ydata_profiling: 4.18.1
2026-01-30 13:34:43,384:INFO:  explainerdashboard: 0.5.1
2026-01-30 13:34:43,384:INFO:             autoviz: Not installed
2026-01-30 13:34:43,384:INFO:           fairlearn: 0.7.0
2026-01-30 13:34:43,384:INFO:          deepchecks: Not installed
2026-01-30 13:34:43,384:INFO:             xgboost: Not installed
2026-01-30 13:34:43,384:INFO:            catboost: 1.2.8
2026-01-30 13:34:43,384:INFO:              kmodes: 0.12.2
2026-01-30 13:34:43,384:INFO:             mlxtend: 0.23.4
2026-01-30 13:34:43,384:INFO:       statsforecast: 1.5.0
2026-01-30 13:34:43,384:INFO:        tune_sklearn: Not installed
2026-01-30 13:34:43,396:INFO:                 ray: Not installed
2026-01-30 13:34:43,396:INFO:            hyperopt: 0.2.7
2026-01-30 13:34:43,396:INFO:              optuna: 4.6.0
2026-01-30 13:34:43,396:INFO:               skopt: 0.10.2
2026-01-30 13:34:43,396:INFO:              mlflow: 3.8.1
2026-01-30 13:34:43,396:INFO:              gradio: 6.3.0
2026-01-30 13:34:43,396:INFO:             fastapi: 0.128.0
2026-01-30 13:34:43,396:INFO:             uvicorn: 0.40.0
2026-01-30 13:34:43,396:INFO:              m2cgen: 0.10.0
2026-01-30 13:34:43,396:INFO:           evidently: 0.4.40
2026-01-30 13:34:43,396:INFO:               fugue: 0.8.7
2026-01-30 13:34:43,397:INFO:           streamlit: Not installed
2026-01-30 13:34:43,397:INFO:             prophet: Not installed
2026-01-30 13:34:43,397:INFO:None
2026-01-30 13:34:43,397:INFO:Set up data.
2026-01-30 13:34:43,464:INFO:Set up folding strategy.
2026-01-30 13:34:43,464:INFO:Set up train/test split.
2026-01-30 13:34:43,627:INFO:Set up index.
2026-01-30 13:34:43,636:INFO:Assigning column types.
2026-01-30 13:34:43,729:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-30 13:34:43,757:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 13:34:43,757:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 13:34:43,764:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 13:34:43,764:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 13:34:43,800:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 13:34:43,800:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 13:34:43,819:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 13:34:43,819:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 13:34:43,819:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-30 13:34:43,847:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 13:34:43,864:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 13:34:43,864:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 13:34:43,897:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 13:34:43,914:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 13:34:43,914:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 13:34:43,914:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-30 13:34:43,963:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 13:34:43,963:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 13:34:43,997:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 13:34:43,997:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 13:34:43,997:INFO:Preparing preprocessing pipeline...
2026-01-30 13:34:44,019:INFO:Set up simple imputation.
2026-01-30 13:34:44,019:INFO:Set up feature normalization.
2026-01-30 13:34:44,291:INFO:Finished creating preprocessing pipeline.
2026-01-30 13:34:44,299:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'tiempo_etapa_dias',
                                             'tiempo_entre_etapas_dias',
                                             'num...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-30 13:34:44,299:INFO:Creating final display dataframe.
2026-01-30 13:34:44,695:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape      (373023, 21)
4        Transformed data shape      (373023, 21)
5   Transformed train set shape      (261116, 21)
6    Transformed test set shape      (111907, 21)
7              Numeric features                17
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                 3
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              fb0c
2026-01-30 13:34:44,742:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 13:34:44,742:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 13:34:44,790:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 13:34:44,790:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 13:34:44,796:INFO:setup() successfully completed in 1.43s...............
2026-01-30 13:34:44,796:INFO:Initializing compare_models()
2026-01-30 13:34:44,796:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCBD1090>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCBD1090>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-30 13:34:44,796:INFO:Checking exceptions
2026-01-30 13:34:44,864:INFO:Preparing display monitor
2026-01-30 13:34:44,864:INFO:Initializing Logistic Regression
2026-01-30 13:34:44,864:INFO:Total runtime is 0.0 minutes
2026-01-30 13:34:44,864:INFO:SubProcess create_model() called ==================================
2026-01-30 13:34:44,864:INFO:Initializing create_model()
2026-01-30 13:34:44,864:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCBD1090>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04C609A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:34:44,864:INFO:Checking exceptions
2026-01-30 13:34:44,864:INFO:Importing libraries
2026-01-30 13:34:44,864:INFO:Copying training dataset
2026-01-30 13:34:44,980:INFO:Defining folds
2026-01-30 13:34:44,980:INFO:Declaring metric variables
2026-01-30 13:34:44,980:INFO:Importing untrained model
2026-01-30 13:34:44,980:INFO:Logistic Regression Imported successfully
2026-01-30 13:34:44,980:INFO:Starting cross validation
2026-01-30 13:34:44,980:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:34:46,649:INFO:Calculating mean and std
2026-01-30 13:34:46,649:INFO:Creating metrics dataframe
2026-01-30 13:34:46,650:INFO:Uploading results into container
2026-01-30 13:34:46,650:INFO:Uploading model into container now
2026-01-30 13:34:46,650:INFO:_master_model_container: 1
2026-01-30 13:34:46,650:INFO:_display_container: 2
2026-01-30 13:34:46,650:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-30 13:34:46,650:INFO:create_model() successfully completed......................................
2026-01-30 13:34:46,831:INFO:SubProcess create_model() end ==================================
2026-01-30 13:34:46,831:INFO:Creating metrics dataframe
2026-01-30 13:34:46,831:INFO:Initializing Decision Tree Classifier
2026-01-30 13:34:46,831:INFO:Total runtime is 0.03278047243754069 minutes
2026-01-30 13:34:46,831:INFO:SubProcess create_model() called ==================================
2026-01-30 13:34:46,831:INFO:Initializing create_model()
2026-01-30 13:34:46,831:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCBD1090>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04C609A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:34:46,831:INFO:Checking exceptions
2026-01-30 13:34:46,831:INFO:Importing libraries
2026-01-30 13:34:46,831:INFO:Copying training dataset
2026-01-30 13:34:46,950:INFO:Defining folds
2026-01-30 13:34:46,950:INFO:Declaring metric variables
2026-01-30 13:34:46,950:INFO:Importing untrained model
2026-01-30 13:34:46,950:INFO:Decision Tree Classifier Imported successfully
2026-01-30 13:34:46,950:INFO:Starting cross validation
2026-01-30 13:34:46,950:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:34:49,178:INFO:Calculating mean and std
2026-01-30 13:34:49,178:INFO:Creating metrics dataframe
2026-01-30 13:34:49,178:INFO:Uploading results into container
2026-01-30 13:34:49,178:INFO:Uploading model into container now
2026-01-30 13:34:49,178:INFO:_master_model_container: 2
2026-01-30 13:34:49,178:INFO:_display_container: 2
2026-01-30 13:34:49,184:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 13:34:49,184:INFO:create_model() successfully completed......................................
2026-01-30 13:34:49,370:INFO:SubProcess create_model() end ==================================
2026-01-30 13:34:49,370:INFO:Creating metrics dataframe
2026-01-30 13:34:49,372:INFO:Initializing Random Forest Classifier
2026-01-30 13:34:49,372:INFO:Total runtime is 0.0751427133878072 minutes
2026-01-30 13:34:49,372:INFO:SubProcess create_model() called ==================================
2026-01-30 13:34:49,372:INFO:Initializing create_model()
2026-01-30 13:34:49,372:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCBD1090>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04C609A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:34:49,373:INFO:Checking exceptions
2026-01-30 13:34:49,373:INFO:Importing libraries
2026-01-30 13:34:49,373:INFO:Copying training dataset
2026-01-30 13:34:49,480:INFO:Defining folds
2026-01-30 13:34:49,480:INFO:Declaring metric variables
2026-01-30 13:34:49,480:INFO:Importing untrained model
2026-01-30 13:34:49,480:INFO:Random Forest Classifier Imported successfully
2026-01-30 13:34:49,480:INFO:Starting cross validation
2026-01-30 13:34:49,480:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:35:01,089:INFO:Calculating mean and std
2026-01-30 13:35:01,089:INFO:Creating metrics dataframe
2026-01-30 13:35:01,089:INFO:Uploading results into container
2026-01-30 13:35:01,097:INFO:Uploading model into container now
2026-01-30 13:35:01,097:INFO:_master_model_container: 3
2026-01-30 13:35:01,097:INFO:_display_container: 2
2026-01-30 13:35:01,097:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 13:35:01,097:INFO:create_model() successfully completed......................................
2026-01-30 13:35:01,280:INFO:SubProcess create_model() end ==================================
2026-01-30 13:35:01,280:INFO:Creating metrics dataframe
2026-01-30 13:35:01,280:INFO:Initializing Light Gradient Boosting Machine
2026-01-30 13:35:01,280:INFO:Total runtime is 0.27360623677571616 minutes
2026-01-30 13:35:01,280:INFO:SubProcess create_model() called ==================================
2026-01-30 13:35:01,280:INFO:Initializing create_model()
2026-01-30 13:35:01,280:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCBD1090>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04C609A10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:35:01,280:INFO:Checking exceptions
2026-01-30 13:35:01,280:INFO:Importing libraries
2026-01-30 13:35:01,280:INFO:Copying training dataset
2026-01-30 13:35:01,413:INFO:Defining folds
2026-01-30 13:35:01,413:INFO:Declaring metric variables
2026-01-30 13:35:01,413:INFO:Importing untrained model
2026-01-30 13:35:01,413:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 13:35:01,413:INFO:Starting cross validation
2026-01-30 13:35:01,413:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:35:04,700:INFO:Calculating mean and std
2026-01-30 13:35:04,700:INFO:Creating metrics dataframe
2026-01-30 13:35:04,700:INFO:Uploading results into container
2026-01-30 13:35:04,700:INFO:Uploading model into container now
2026-01-30 13:35:04,700:INFO:_master_model_container: 4
2026-01-30 13:35:04,700:INFO:_display_container: 2
2026-01-30 13:35:04,700:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 13:35:04,700:INFO:create_model() successfully completed......................................
2026-01-30 13:35:04,867:INFO:SubProcess create_model() end ==================================
2026-01-30 13:35:04,867:INFO:Creating metrics dataframe
2026-01-30 13:35:04,880:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-30 13:35:04,880:INFO:Initializing create_model()
2026-01-30 13:35:04,880:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCBD1090>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:35:04,880:INFO:Checking exceptions
2026-01-30 13:35:04,880:INFO:Importing libraries
2026-01-30 13:35:04,880:INFO:Copying training dataset
2026-01-30 13:35:04,997:INFO:Defining folds
2026-01-30 13:35:04,997:INFO:Declaring metric variables
2026-01-30 13:35:04,997:INFO:Importing untrained model
2026-01-30 13:35:04,997:INFO:Declaring custom model
2026-01-30 13:35:04,997:INFO:Random Forest Classifier Imported successfully
2026-01-30 13:35:04,997:INFO:Cross validation set to False
2026-01-30 13:35:04,997:INFO:Fitting Model
2026-01-30 13:35:11,081:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 13:35:11,081:INFO:create_model() successfully completed......................................
2026-01-30 13:35:11,263:INFO:Initializing create_model()
2026-01-30 13:35:11,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCBD1090>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:35:11,263:INFO:Checking exceptions
2026-01-30 13:35:11,263:INFO:Importing libraries
2026-01-30 13:35:11,263:INFO:Copying training dataset
2026-01-30 13:35:11,380:INFO:Defining folds
2026-01-30 13:35:11,380:INFO:Declaring metric variables
2026-01-30 13:35:11,380:INFO:Importing untrained model
2026-01-30 13:35:11,380:INFO:Declaring custom model
2026-01-30 13:35:11,380:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 13:35:11,380:INFO:Cross validation set to False
2026-01-30 13:35:11,380:INFO:Fitting Model
2026-01-30 13:35:11,927:INFO:[LightGBM] [Info] Number of positive: 110231, number of negative: 150885
2026-01-30 13:35:11,945:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009485 seconds.
2026-01-30 13:35:11,945:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 13:35:11,945:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 13:35:11,946:INFO:[LightGBM] [Info] Total Bins 2108
2026-01-30 13:35:11,946:INFO:[LightGBM] [Info] Number of data points in the train set: 261116, number of used features: 20
2026-01-30 13:35:11,946:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.422153 -> initscore=-0.313940
2026-01-30 13:35:11,946:INFO:[LightGBM] [Info] Start training from score -0.313940
2026-01-30 13:35:12,547:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 13:35:12,547:INFO:create_model() successfully completed......................................
2026-01-30 13:35:12,763:INFO:Initializing create_model()
2026-01-30 13:35:12,763:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCBD1090>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:35:12,763:INFO:Checking exceptions
2026-01-30 13:35:12,763:INFO:Importing libraries
2026-01-30 13:35:12,763:INFO:Copying training dataset
2026-01-30 13:35:12,897:INFO:Defining folds
2026-01-30 13:35:12,897:INFO:Declaring metric variables
2026-01-30 13:35:12,897:INFO:Importing untrained model
2026-01-30 13:35:12,897:INFO:Declaring custom model
2026-01-30 13:35:12,897:INFO:Decision Tree Classifier Imported successfully
2026-01-30 13:35:12,897:INFO:Cross validation set to False
2026-01-30 13:35:12,897:INFO:Fitting Model
2026-01-30 13:35:14,813:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 13:35:14,813:INFO:create_model() successfully completed......................................
2026-01-30 13:35:14,997:INFO:_master_model_container: 4
2026-01-30 13:35:14,997:INFO:_display_container: 2
2026-01-30 13:35:14,997:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')]
2026-01-30 13:35:14,997:INFO:compare_models() successfully completed......................................
2026-01-30 13:35:15,012:INFO:Initializing tune_model()
2026-01-30 13:35:15,012:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCBD1090>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 13:35:15,012:INFO:Checking exceptions
2026-01-30 13:35:15,050:INFO:Copying training dataset
2026-01-30 13:35:15,138:INFO:Checking base model
2026-01-30 13:35:15,138:INFO:Base model : Random Forest Classifier
2026-01-30 13:35:15,138:INFO:Declaring metric variables
2026-01-30 13:35:15,138:INFO:Defining Hyperparameters
2026-01-30 13:35:15,297:INFO:Tuning with n_jobs=-1
2026-01-30 13:35:15,297:INFO:Initializing RandomizedSearchCV
2026-01-30 13:37:02,023:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-30 13:37:02,023:INFO:Hyperparameter search completed
2026-01-30 13:37:02,023:INFO:SubProcess create_model() called ==================================
2026-01-30 13:37:02,028:INFO:Initializing create_model()
2026-01-30 13:37:02,028:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCBD1090>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0530E6C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': True})
2026-01-30 13:37:02,028:INFO:Checking exceptions
2026-01-30 13:37:02,028:INFO:Importing libraries
2026-01-30 13:37:02,028:INFO:Copying training dataset
2026-01-30 13:37:02,195:INFO:Defining folds
2026-01-30 13:37:02,195:INFO:Declaring metric variables
2026-01-30 13:37:02,195:INFO:Importing untrained model
2026-01-30 13:37:02,195:INFO:Declaring custom model
2026-01-30 13:37:02,195:INFO:Random Forest Classifier Imported successfully
2026-01-30 13:37:02,195:INFO:Starting cross validation
2026-01-30 13:37:02,195:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:37:25,680:INFO:Calculating mean and std
2026-01-30 13:37:25,680:INFO:Creating metrics dataframe
2026-01-30 13:37:25,680:INFO:Finalizing model
2026-01-30 13:37:36,898:INFO:Uploading results into container
2026-01-30 13:37:36,901:INFO:Uploading model into container now
2026-01-30 13:37:36,901:INFO:_master_model_container: 5
2026-01-30 13:37:36,901:INFO:_display_container: 3
2026-01-30 13:37:36,901:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 13:37:36,901:INFO:create_model() successfully completed......................................
2026-01-30 13:37:37,120:INFO:SubProcess create_model() end ==================================
2026-01-30 13:37:37,121:INFO:choose_better activated
2026-01-30 13:37:37,121:INFO:SubProcess create_model() called ==================================
2026-01-30 13:37:37,121:INFO:Initializing create_model()
2026-01-30 13:37:37,121:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCBD1090>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:37:37,121:INFO:Checking exceptions
2026-01-30 13:37:37,123:INFO:Importing libraries
2026-01-30 13:37:37,123:INFO:Copying training dataset
2026-01-30 13:37:37,245:INFO:Defining folds
2026-01-30 13:37:37,245:INFO:Declaring metric variables
2026-01-30 13:37:37,245:INFO:Importing untrained model
2026-01-30 13:37:37,245:INFO:Declaring custom model
2026-01-30 13:37:37,245:INFO:Random Forest Classifier Imported successfully
2026-01-30 13:37:37,245:INFO:Starting cross validation
2026-01-30 13:37:37,245:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:37:52,727:INFO:Calculating mean and std
2026-01-30 13:37:52,727:INFO:Creating metrics dataframe
2026-01-30 13:37:52,727:INFO:Finalizing model
2026-01-30 13:37:59,667:INFO:Uploading results into container
2026-01-30 13:37:59,667:INFO:Uploading model into container now
2026-01-30 13:37:59,669:INFO:_master_model_container: 6
2026-01-30 13:37:59,669:INFO:_display_container: 4
2026-01-30 13:37:59,669:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 13:37:59,669:INFO:create_model() successfully completed......................................
2026-01-30 13:37:59,861:INFO:SubProcess create_model() end ==================================
2026-01-30 13:37:59,861:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9957
2026-01-30 13:37:59,861:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9656
2026-01-30 13:37:59,861:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-30 13:37:59,861:INFO:choose_better completed
2026-01-30 13:37:59,861:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 13:37:59,861:INFO:_master_model_container: 6
2026-01-30 13:37:59,861:INFO:_display_container: 3
2026-01-30 13:37:59,861:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 13:37:59,861:INFO:tune_model() successfully completed......................................
2026-01-30 13:38:00,046:INFO:Initializing tune_model()
2026-01-30 13:38:00,047:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCBD1090>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 13:38:00,047:INFO:Checking exceptions
2026-01-30 13:38:00,078:INFO:Copying training dataset
2026-01-30 13:38:00,169:INFO:Checking base model
2026-01-30 13:38:00,169:INFO:Base model : Light Gradient Boosting Machine
2026-01-30 13:38:00,169:INFO:Declaring metric variables
2026-01-30 13:38:00,170:INFO:Defining Hyperparameters
2026-01-30 13:38:00,331:INFO:Tuning with n_jobs=-1
2026-01-30 13:38:00,331:INFO:Initializing RandomizedSearchCV
2026-01-30 13:38:33,138:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2026-01-30 13:38:33,138:INFO:Hyperparameter search completed
2026-01-30 13:38:33,138:INFO:SubProcess create_model() called ==================================
2026-01-30 13:38:33,144:INFO:Initializing create_model()
2026-01-30 13:38:33,144:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCBD1090>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C3631650>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2026-01-30 13:38:33,144:INFO:Checking exceptions
2026-01-30 13:38:33,144:INFO:Importing libraries
2026-01-30 13:38:33,144:INFO:Copying training dataset
2026-01-30 13:38:33,322:INFO:Defining folds
2026-01-30 13:38:33,322:INFO:Declaring metric variables
2026-01-30 13:38:33,322:INFO:Importing untrained model
2026-01-30 13:38:33,323:INFO:Declaring custom model
2026-01-30 13:38:33,324:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 13:38:33,324:INFO:Starting cross validation
2026-01-30 13:38:33,325:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:38:41,089:INFO:Calculating mean and std
2026-01-30 13:38:41,089:INFO:Creating metrics dataframe
2026-01-30 13:38:41,093:INFO:Finalizing model
2026-01-30 13:38:41,526:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 13:38:41,526:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 13:38:41,526:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 13:38:41,686:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 13:38:41,686:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 13:38:41,686:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 13:38:41,686:INFO:[LightGBM] [Info] Number of positive: 110231, number of negative: 150885
2026-01-30 13:38:41,706:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009164 seconds.
2026-01-30 13:38:41,706:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 13:38:41,706:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 13:38:41,706:INFO:[LightGBM] [Info] Total Bins 2108
2026-01-30 13:38:41,708:INFO:[LightGBM] [Info] Number of data points in the train set: 261116, number of used features: 20
2026-01-30 13:38:41,712:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.422153 -> initscore=-0.313940
2026-01-30 13:38:41,714:INFO:[LightGBM] [Info] Start training from score -0.313940
2026-01-30 13:38:44,729:INFO:Uploading results into container
2026-01-30 13:38:44,731:INFO:Uploading model into container now
2026-01-30 13:38:44,732:INFO:_master_model_container: 7
2026-01-30 13:38:44,732:INFO:_display_container: 4
2026-01-30 13:38:44,734:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 13:38:44,734:INFO:create_model() successfully completed......................................
2026-01-30 13:38:44,977:INFO:SubProcess create_model() end ==================================
2026-01-30 13:38:44,977:INFO:choose_better activated
2026-01-30 13:38:44,977:INFO:SubProcess create_model() called ==================================
2026-01-30 13:38:44,977:INFO:Initializing create_model()
2026-01-30 13:38:44,977:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCBD1090>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:38:44,977:INFO:Checking exceptions
2026-01-30 13:38:44,977:INFO:Importing libraries
2026-01-30 13:38:44,977:INFO:Copying training dataset
2026-01-30 13:38:45,110:INFO:Defining folds
2026-01-30 13:38:45,110:INFO:Declaring metric variables
2026-01-30 13:38:45,110:INFO:Importing untrained model
2026-01-30 13:38:45,110:INFO:Declaring custom model
2026-01-30 13:38:45,110:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 13:38:45,110:INFO:Starting cross validation
2026-01-30 13:38:45,110:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:38:48,885:INFO:Calculating mean and std
2026-01-30 13:38:48,885:INFO:Creating metrics dataframe
2026-01-30 13:38:48,885:INFO:Finalizing model
2026-01-30 13:38:49,539:INFO:[LightGBM] [Info] Number of positive: 110231, number of negative: 150885
2026-01-30 13:38:49,559:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009335 seconds.
2026-01-30 13:38:49,559:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 13:38:49,560:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 13:38:49,560:INFO:[LightGBM] [Info] Total Bins 2108
2026-01-30 13:38:49,560:INFO:[LightGBM] [Info] Number of data points in the train set: 261116, number of used features: 20
2026-01-30 13:38:49,563:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.422153 -> initscore=-0.313940
2026-01-30 13:38:49,563:INFO:[LightGBM] [Info] Start training from score -0.313940
2026-01-30 13:38:50,348:INFO:Uploading results into container
2026-01-30 13:38:50,348:INFO:Uploading model into container now
2026-01-30 13:38:50,350:INFO:_master_model_container: 8
2026-01-30 13:38:50,350:INFO:_display_container: 5
2026-01-30 13:38:50,350:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 13:38:50,350:INFO:create_model() successfully completed......................................
2026-01-30 13:38:50,595:INFO:SubProcess create_model() end ==================================
2026-01-30 13:38:50,596:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9785
2026-01-30 13:38:50,597:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9938
2026-01-30 13:38:50,598:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2026-01-30 13:38:50,598:INFO:choose_better completed
2026-01-30 13:38:50,599:INFO:_master_model_container: 8
2026-01-30 13:38:50,599:INFO:_display_container: 4
2026-01-30 13:38:50,599:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 13:38:50,599:INFO:tune_model() successfully completed......................................
2026-01-30 13:38:50,777:INFO:Initializing tune_model()
2026-01-30 13:38:50,777:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCBD1090>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 13:38:50,777:INFO:Checking exceptions
2026-01-30 13:38:50,827:INFO:Copying training dataset
2026-01-30 13:38:50,896:INFO:Checking base model
2026-01-30 13:38:50,896:INFO:Base model : Decision Tree Classifier
2026-01-30 13:38:50,896:INFO:Declaring metric variables
2026-01-30 13:38:50,896:INFO:Defining Hyperparameters
2026-01-30 13:38:51,080:INFO:Tuning with n_jobs=-1
2026-01-30 13:38:51,080:INFO:Initializing RandomizedSearchCV
2026-01-30 13:38:56,533:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 15, 'actual_estimator__criterion': 'gini'}
2026-01-30 13:38:56,533:INFO:Hyperparameter search completed
2026-01-30 13:38:56,533:INFO:SubProcess create_model() called ==================================
2026-01-30 13:38:56,533:INFO:Initializing create_model()
2026-01-30 13:38:56,533:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCBD1090>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A048A82750>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 2, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 15, 'criterion': 'gini'})
2026-01-30 13:38:56,533:INFO:Checking exceptions
2026-01-30 13:38:56,533:INFO:Importing libraries
2026-01-30 13:38:56,533:INFO:Copying training dataset
2026-01-30 13:38:56,665:INFO:Defining folds
2026-01-30 13:38:56,665:INFO:Declaring metric variables
2026-01-30 13:38:56,665:INFO:Importing untrained model
2026-01-30 13:38:56,665:INFO:Declaring custom model
2026-01-30 13:38:56,667:INFO:Decision Tree Classifier Imported successfully
2026-01-30 13:38:56,667:INFO:Starting cross validation
2026-01-30 13:38:56,667:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:38:58,462:INFO:Calculating mean and std
2026-01-30 13:38:58,462:INFO:Creating metrics dataframe
2026-01-30 13:38:58,462:INFO:Finalizing model
2026-01-30 13:38:59,643:INFO:Uploading results into container
2026-01-30 13:38:59,643:INFO:Uploading model into container now
2026-01-30 13:38:59,643:INFO:_master_model_container: 9
2026-01-30 13:38:59,643:INFO:_display_container: 5
2026-01-30 13:38:59,643:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 13:38:59,643:INFO:create_model() successfully completed......................................
2026-01-30 13:38:59,810:INFO:SubProcess create_model() end ==================================
2026-01-30 13:38:59,810:INFO:choose_better activated
2026-01-30 13:38:59,810:INFO:SubProcess create_model() called ==================================
2026-01-30 13:38:59,810:INFO:Initializing create_model()
2026-01-30 13:38:59,810:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCBD1090>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 13:38:59,810:INFO:Checking exceptions
2026-01-30 13:38:59,810:INFO:Importing libraries
2026-01-30 13:38:59,810:INFO:Copying training dataset
2026-01-30 13:38:59,943:INFO:Defining folds
2026-01-30 13:38:59,943:INFO:Declaring metric variables
2026-01-30 13:38:59,943:INFO:Importing untrained model
2026-01-30 13:38:59,943:INFO:Declaring custom model
2026-01-30 13:38:59,943:INFO:Decision Tree Classifier Imported successfully
2026-01-30 13:38:59,943:INFO:Starting cross validation
2026-01-30 13:38:59,943:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 13:39:02,504:INFO:Calculating mean and std
2026-01-30 13:39:02,504:INFO:Creating metrics dataframe
2026-01-30 13:39:02,504:INFO:Finalizing model
2026-01-30 13:39:04,410:INFO:Uploading results into container
2026-01-30 13:39:04,410:INFO:Uploading model into container now
2026-01-30 13:39:04,410:INFO:_master_model_container: 10
2026-01-30 13:39:04,410:INFO:_display_container: 6
2026-01-30 13:39:04,410:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 13:39:04,410:INFO:create_model() successfully completed......................................
2026-01-30 13:39:04,585:INFO:SubProcess create_model() end ==================================
2026-01-30 13:39:04,585:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9752
2026-01-30 13:39:04,585:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9572
2026-01-30 13:39:04,585:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-30 13:39:04,585:INFO:choose_better completed
2026-01-30 13:39:04,585:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 13:39:04,593:INFO:_master_model_container: 10
2026-01-30 13:39:04,593:INFO:_display_container: 5
2026-01-30 13:39:04,593:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 13:39:04,593:INFO:tune_model() successfully completed......................................
2026-01-30 13:39:04,781:INFO:Initializing predict_model()
2026-01-30 13:39:04,781:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCBD1090>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A120455A80>)
2026-01-30 13:39:04,781:INFO:Checking exceptions
2026-01-30 13:39:04,781:INFO:Preloading libraries
2026-01-30 13:39:04,781:INFO:Set up data.
2026-01-30 13:39:04,793:INFO:Set up index.
2026-01-30 13:39:05,560:INFO:Initializing predict_model()
2026-01-30 13:39:05,560:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCBD1090>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A01562A5C0>)
2026-01-30 13:39:05,560:INFO:Checking exceptions
2026-01-30 13:39:05,560:INFO:Preloading libraries
2026-01-30 13:39:05,560:INFO:Set up data.
2026-01-30 13:39:05,580:INFO:Set up index.
2026-01-30 13:39:06,399:INFO:Initializing predict_model()
2026-01-30 13:39:06,399:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCBD1090>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A01562A5C0>)
2026-01-30 13:39:06,399:INFO:Checking exceptions
2026-01-30 13:39:06,399:INFO:Preloading libraries
2026-01-30 13:39:06,399:INFO:Set up data.
2026-01-30 13:39:06,421:INFO:Set up index.
2026-01-30 13:39:07,148:INFO:Initializing plot_model()
2026-01-30 13:39:07,148:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCBD1090>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 13:39:07,148:INFO:Checking exceptions
2026-01-30 13:39:07,227:INFO:Preloading libraries
2026-01-30 13:39:07,343:INFO:Copying training dataset
2026-01-30 13:39:07,343:INFO:Plot type: feature
2026-01-30 13:39:07,343:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 13:39:07,610:INFO:Visual Rendered Successfully
2026-01-30 13:39:07,776:INFO:plot_model() successfully completed......................................
2026-01-30 13:39:07,797:INFO:Initializing plot_model()
2026-01-30 13:39:07,799:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCBD1090>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature_all, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 13:39:07,799:INFO:Checking exceptions
2026-01-30 13:39:07,879:INFO:Preloading libraries
2026-01-30 13:39:07,979:INFO:Copying training dataset
2026-01-30 13:39:07,979:INFO:Plot type: feature_all
2026-01-30 13:39:08,108:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 13:39:08,437:INFO:Visual Rendered Successfully
2026-01-30 13:39:08,632:INFO:plot_model() successfully completed......................................
2026-01-30 13:39:08,648:INFO:Initializing save_model()
2026-01-30 13:39:08,648:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), model_name=..\datos\04. Modelos\modelo_final_explicable, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'tiempo_etapa_dias',
                                             'tiempo_entre_etapas_dias',
                                             'num...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-30 13:39:08,648:INFO:Adding model into prep_pipe
2026-01-30 13:39:08,835:INFO:..\datos\04. Modelos\modelo_final_explicable.pkl saved in current working directory
2026-01-30 13:39:08,835:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'tiempo_etapa_dias',
                                             'tiempo_entre_etapas_dias',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum',...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=42, verbose=0,
                                        warm_start=False))],
         verbose=False)
2026-01-30 13:39:08,835:INFO:save_model() successfully completed......................................
2026-01-30 13:39:51,489:INFO:Initializing load_model()
2026-01-30 13:39:51,489:INFO:load_model(model_name=..\datos\04. Modelos\modelo_final_explicable, platform=None, authentication=None, verbose=True)
2026-01-30 13:39:53,676:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\2637609198.py:23: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-30 13:39:55,593:INFO:Initializing predict_model()
2026-01-30 13:39:55,593:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029C50F0B310>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'tiempo_etapa_dias',
                                             'tiempo_entre_etapas_dias',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum', 'PCA1',
                                             'PCA2'...
                                             'flag_NU_NOTA_MEDIA_1_BACH__PC_na',
                                             'flag_NU_RESULTADO_ADMISION_PUNTOS_na',
                                             'flag_CU_IMPORTE_TOTAL_na'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model',
                 RandomForestClassifier(n_jobs=-1, random_state=42))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000029C60835B20>)
2026-01-30 13:39:55,593:INFO:Checking exceptions
2026-01-30 13:39:55,593:INFO:Preloading libraries
2026-01-30 13:39:55,593:INFO:Set up data.
2026-01-30 13:39:56,546:INFO:Set up index.
2026-01-30 13:39:59,680:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\2637609198.py:120: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(data=df_plot, x=metric, y=col_name, palette="viridis")

2026-01-30 13:40:00,067:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_27688\2637609198.py:120: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(data=df_plot, x=metric, y=col_name, palette="viridis")

