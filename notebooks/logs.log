2026-01-19 10:24:16,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-19 10:24:16,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-19 10:24:16,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-19 10:24:16,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-29 15:21:31,736:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-29 15:21:31,736:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-29 15:21:31,736:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-29 15:21:31,736:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-29 15:21:35,750:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\2388759396.py:16: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-29 15:25:39,783:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\2256906154.py:17: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-29 15:26:50,165:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\1372246288.py:16: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-29 15:26:51,818:INFO:PyCaret ClassificationExperiment
2026-01-29 15:26:51,819:INFO:Logging name: clf-default-name
2026-01-29 15:26:51,819:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-29 15:26:51,820:INFO:version 3.3.2
2026-01-29 15:26:51,820:INFO:Initializing setup()
2026-01-29 15:26:51,820:INFO:self.USI: f012
2026-01-29 15:26:51,820:INFO:self._variable_keys: {'X_test', 'fold_groups_param', 'pipeline', 'fix_imbalance', 'exp_name_log', 'data', 'y_test', 'seed', 'fold_shuffle_param', 'n_jobs_param', 'is_multiclass', 'gpu_n_jobs_param', 'memory', 'log_plots_param', 'logging_param', 'idx', 'y', 'target_param', 'fold_generator', 'y_train', 'gpu_param', 'USI', 'exp_id', '_available_plots', 'X', 'X_train', 'html_param', '_ml_usecase'}
2026-01-29 15:26:51,820:INFO:Checking environment
2026-01-29 15:26:51,820:INFO:python_version: 3.11.11
2026-01-29 15:26:51,821:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-29 15:26:51,821:INFO:machine: AMD64
2026-01-29 15:26:51,821:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-29 15:26:51,821:INFO:Memory: svmem(total=34009374720, available=16823705600, percent=50.5, used=17185669120, free=16823705600)
2026-01-29 15:26:51,822:INFO:Physical Core: 12
2026-01-29 15:26:51,822:INFO:Logical Core: 16
2026-01-29 15:26:51,822:INFO:Checking libraries
2026-01-29 15:26:51,822:INFO:System:
2026-01-29 15:26:51,822:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-29 15:26:51,822:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-29 15:26:51,822:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-29 15:26:51,823:INFO:PyCaret required dependencies:
2026-01-29 15:26:54,258:INFO:                 pip: 25.0
2026-01-29 15:26:54,258:INFO:          setuptools: 75.8.0
2026-01-29 15:26:54,258:INFO:             pycaret: 3.3.2
2026-01-29 15:26:54,258:INFO:             IPython: 9.9.0
2026-01-29 15:26:54,258:INFO:          ipywidgets: 8.1.8
2026-01-29 15:26:54,258:INFO:                tqdm: 4.67.1
2026-01-29 15:26:54,258:INFO:               numpy: 1.26.4
2026-01-29 15:26:54,259:INFO:              pandas: 2.1.4
2026-01-29 15:26:54,259:INFO:              jinja2: 3.1.6
2026-01-29 15:26:54,259:INFO:               scipy: 1.11.4
2026-01-29 15:26:54,259:INFO:              joblib: 1.3.2
2026-01-29 15:26:54,259:INFO:             sklearn: 1.4.2
2026-01-29 15:26:54,259:INFO:                pyod: 2.0.6
2026-01-29 15:26:54,259:INFO:            imblearn: 0.14.1
2026-01-29 15:26:54,259:INFO:   category_encoders: 2.7.0
2026-01-29 15:26:54,259:INFO:            lightgbm: 4.6.0
2026-01-29 15:26:54,259:INFO:               numba: 0.62.1
2026-01-29 15:26:54,259:INFO:            requests: 2.32.3
2026-01-29 15:26:54,259:INFO:          matplotlib: 3.7.5
2026-01-29 15:26:54,259:INFO:          scikitplot: 0.3.7
2026-01-29 15:26:54,259:INFO:         yellowbrick: 1.5
2026-01-29 15:26:54,259:INFO:              plotly: 5.24.1
2026-01-29 15:26:54,259:INFO:    plotly-resampler: Not installed
2026-01-29 15:26:54,259:INFO:             kaleido: 1.2.0
2026-01-29 15:26:54,259:INFO:           schemdraw: 0.15
2026-01-29 15:26:54,259:INFO:         statsmodels: 0.14.6
2026-01-29 15:26:54,259:INFO:              sktime: 0.26.0
2026-01-29 15:26:54,259:INFO:               tbats: 1.1.3
2026-01-29 15:26:54,259:INFO:            pmdarima: 2.0.4
2026-01-29 15:26:54,259:INFO:              psutil: 7.2.1
2026-01-29 15:26:54,260:INFO:          markupsafe: 3.0.3
2026-01-29 15:26:54,260:INFO:             pickle5: Not installed
2026-01-29 15:26:54,260:INFO:         cloudpickle: 3.0.0
2026-01-29 15:26:54,260:INFO:         deprecation: 2.1.0
2026-01-29 15:26:54,260:INFO:              xxhash: 3.6.0
2026-01-29 15:26:54,260:INFO:           wurlitzer: Not installed
2026-01-29 15:26:54,260:INFO:PyCaret optional dependencies:
2026-01-29 15:27:00,934:INFO:                shap: 0.44.1
2026-01-29 15:27:00,934:INFO:           interpret: 0.7.3
2026-01-29 15:27:00,934:INFO:                umap: 0.5.7
2026-01-29 15:27:00,934:INFO:     ydata_profiling: 4.18.1
2026-01-29 15:27:00,934:INFO:  explainerdashboard: 0.5.1
2026-01-29 15:27:00,934:INFO:             autoviz: Not installed
2026-01-29 15:27:00,936:INFO:           fairlearn: 0.7.0
2026-01-29 15:27:00,936:INFO:          deepchecks: Not installed
2026-01-29 15:27:00,936:INFO:             xgboost: Not installed
2026-01-29 15:27:00,936:INFO:            catboost: 1.2.8
2026-01-29 15:27:00,936:INFO:              kmodes: 0.12.2
2026-01-29 15:27:00,936:INFO:             mlxtend: 0.23.4
2026-01-29 15:27:00,936:INFO:       statsforecast: 1.5.0
2026-01-29 15:27:00,936:INFO:        tune_sklearn: Not installed
2026-01-29 15:27:00,936:INFO:                 ray: Not installed
2026-01-29 15:27:00,936:INFO:            hyperopt: 0.2.7
2026-01-29 15:27:00,936:INFO:              optuna: 4.6.0
2026-01-29 15:27:00,936:INFO:               skopt: 0.10.2
2026-01-29 15:27:00,938:INFO:              mlflow: 3.8.1
2026-01-29 15:27:00,938:INFO:              gradio: 6.3.0
2026-01-29 15:27:00,938:INFO:             fastapi: 0.128.0
2026-01-29 15:27:00,938:INFO:             uvicorn: 0.40.0
2026-01-29 15:27:00,938:INFO:              m2cgen: 0.10.0
2026-01-29 15:27:00,939:INFO:           evidently: 0.4.40
2026-01-29 15:27:00,939:INFO:               fugue: 0.8.7
2026-01-29 15:27:00,939:INFO:           streamlit: Not installed
2026-01-29 15:27:00,939:INFO:             prophet: Not installed
2026-01-29 15:27:00,939:INFO:None
2026-01-29 15:27:00,940:INFO:Set up data.
2026-01-29 15:27:02,745:INFO:Set up folding strategy.
2026-01-29 15:27:02,746:INFO:Set up train/test split.
2026-01-29 15:27:03,016:INFO:Set up index.
2026-01-29 15:27:03,029:INFO:Assigning column types.
2026-01-29 15:27:03,163:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-29 15:27:03,188:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 15:27:03,198:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:27:03,235:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:27:03,235:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:27:03,439:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 15:27:03,440:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:27:03,455:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:27:03,456:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:27:03,456:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-29 15:27:03,493:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:27:03,516:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:27:03,516:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:27:03,543:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:27:03,559:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:27:03,560:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:27:03,560:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-29 15:27:03,617:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:27:03,617:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:27:03,661:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:27:03,661:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:27:03,663:INFO:Preparing preprocessing pipeline...
2026-01-29 15:27:03,692:INFO:Set up simple imputation.
2026-01-29 15:27:03,845:INFO:Set up encoding of ordinal features.
2026-01-29 15:27:04,428:INFO:Set up encoding of categorical features.
2026-01-29 15:27:04,430:INFO:Set up column transformation.
2026-01-29 15:27:04,430:INFO:Set up feature normalization.
2026-01-29 15:29:42,743:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\3853355163.py:16: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-29 15:29:43,543:INFO:PyCaret ClassificationExperiment
2026-01-29 15:29:43,544:INFO:Logging name: clf-default-name
2026-01-29 15:29:43,544:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-29 15:29:43,544:INFO:version 3.3.2
2026-01-29 15:29:43,544:INFO:Initializing setup()
2026-01-29 15:29:43,544:INFO:self.USI: 2dfb
2026-01-29 15:29:43,545:INFO:self._variable_keys: {'X_test', 'fold_groups_param', 'pipeline', 'fix_imbalance', 'exp_name_log', 'data', 'y_test', 'seed', 'fold_shuffle_param', 'n_jobs_param', 'is_multiclass', 'gpu_n_jobs_param', 'memory', 'log_plots_param', 'logging_param', 'idx', 'y', 'target_param', 'fold_generator', 'y_train', 'gpu_param', 'USI', 'exp_id', '_available_plots', 'X', 'X_train', 'html_param', '_ml_usecase'}
2026-01-29 15:29:43,545:INFO:Checking environment
2026-01-29 15:29:43,545:INFO:python_version: 3.11.11
2026-01-29 15:29:43,545:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-29 15:29:43,545:INFO:machine: AMD64
2026-01-29 15:29:43,545:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-29 15:29:43,546:INFO:Memory: svmem(total=34009374720, available=16752574464, percent=50.7, used=17256800256, free=16752574464)
2026-01-29 15:29:43,546:INFO:Physical Core: 12
2026-01-29 15:29:43,546:INFO:Logical Core: 16
2026-01-29 15:29:43,546:INFO:Checking libraries
2026-01-29 15:29:43,546:INFO:System:
2026-01-29 15:29:43,546:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-29 15:29:43,546:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-29 15:29:43,546:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-29 15:29:43,546:INFO:PyCaret required dependencies:
2026-01-29 15:29:43,546:INFO:                 pip: 25.0
2026-01-29 15:29:43,546:INFO:          setuptools: 75.8.0
2026-01-29 15:29:43,546:INFO:             pycaret: 3.3.2
2026-01-29 15:29:43,546:INFO:             IPython: 9.9.0
2026-01-29 15:29:43,546:INFO:          ipywidgets: 8.1.8
2026-01-29 15:29:43,547:INFO:                tqdm: 4.67.1
2026-01-29 15:29:43,547:INFO:               numpy: 1.26.4
2026-01-29 15:29:43,547:INFO:              pandas: 2.1.4
2026-01-29 15:29:43,547:INFO:              jinja2: 3.1.6
2026-01-29 15:29:43,547:INFO:               scipy: 1.11.4
2026-01-29 15:29:43,547:INFO:              joblib: 1.3.2
2026-01-29 15:29:43,547:INFO:             sklearn: 1.4.2
2026-01-29 15:29:43,547:INFO:                pyod: 2.0.6
2026-01-29 15:29:43,547:INFO:            imblearn: 0.14.1
2026-01-29 15:29:43,547:INFO:   category_encoders: 2.7.0
2026-01-29 15:29:43,547:INFO:            lightgbm: 4.6.0
2026-01-29 15:29:43,547:INFO:               numba: 0.62.1
2026-01-29 15:29:43,547:INFO:            requests: 2.32.3
2026-01-29 15:29:43,547:INFO:          matplotlib: 3.7.5
2026-01-29 15:29:43,547:INFO:          scikitplot: 0.3.7
2026-01-29 15:29:43,547:INFO:         yellowbrick: 1.5
2026-01-29 15:29:43,547:INFO:              plotly: 5.24.1
2026-01-29 15:29:43,547:INFO:    plotly-resampler: Not installed
2026-01-29 15:29:43,547:INFO:             kaleido: 1.2.0
2026-01-29 15:29:43,547:INFO:           schemdraw: 0.15
2026-01-29 15:29:43,548:INFO:         statsmodels: 0.14.6
2026-01-29 15:29:43,548:INFO:              sktime: 0.26.0
2026-01-29 15:29:43,548:INFO:               tbats: 1.1.3
2026-01-29 15:29:43,548:INFO:            pmdarima: 2.0.4
2026-01-29 15:29:43,548:INFO:              psutil: 7.2.1
2026-01-29 15:29:43,548:INFO:          markupsafe: 3.0.3
2026-01-29 15:29:43,548:INFO:             pickle5: Not installed
2026-01-29 15:29:43,548:INFO:         cloudpickle: 3.0.0
2026-01-29 15:29:43,548:INFO:         deprecation: 2.1.0
2026-01-29 15:29:43,548:INFO:              xxhash: 3.6.0
2026-01-29 15:29:43,548:INFO:           wurlitzer: Not installed
2026-01-29 15:29:43,548:INFO:PyCaret optional dependencies:
2026-01-29 15:29:43,548:INFO:                shap: 0.44.1
2026-01-29 15:29:43,548:INFO:           interpret: 0.7.3
2026-01-29 15:29:43,548:INFO:                umap: 0.5.7
2026-01-29 15:29:43,549:INFO:     ydata_profiling: 4.18.1
2026-01-29 15:29:43,549:INFO:  explainerdashboard: 0.5.1
2026-01-29 15:29:43,549:INFO:             autoviz: Not installed
2026-01-29 15:29:43,549:INFO:           fairlearn: 0.7.0
2026-01-29 15:29:43,549:INFO:          deepchecks: Not installed
2026-01-29 15:29:43,549:INFO:             xgboost: Not installed
2026-01-29 15:29:43,549:INFO:            catboost: 1.2.8
2026-01-29 15:29:43,549:INFO:              kmodes: 0.12.2
2026-01-29 15:29:43,549:INFO:             mlxtend: 0.23.4
2026-01-29 15:29:43,549:INFO:       statsforecast: 1.5.0
2026-01-29 15:29:43,549:INFO:        tune_sklearn: Not installed
2026-01-29 15:29:43,549:INFO:                 ray: Not installed
2026-01-29 15:29:43,549:INFO:            hyperopt: 0.2.7
2026-01-29 15:29:43,549:INFO:              optuna: 4.6.0
2026-01-29 15:29:43,549:INFO:               skopt: 0.10.2
2026-01-29 15:29:43,549:INFO:              mlflow: 3.8.1
2026-01-29 15:29:43,549:INFO:              gradio: 6.3.0
2026-01-29 15:29:43,549:INFO:             fastapi: 0.128.0
2026-01-29 15:29:43,549:INFO:             uvicorn: 0.40.0
2026-01-29 15:29:43,549:INFO:              m2cgen: 0.10.0
2026-01-29 15:29:43,549:INFO:           evidently: 0.4.40
2026-01-29 15:29:43,549:INFO:               fugue: 0.8.7
2026-01-29 15:29:43,549:INFO:           streamlit: Not installed
2026-01-29 15:29:43,549:INFO:             prophet: Not installed
2026-01-29 15:29:43,549:INFO:None
2026-01-29 15:29:43,549:INFO:Set up data.
2026-01-29 15:29:43,754:INFO:Set up folding strategy.
2026-01-29 15:29:43,754:INFO:Set up train/test split.
2026-01-29 15:29:43,990:INFO:Set up index.
2026-01-29 15:29:43,993:INFO:Assigning column types.
2026-01-29 15:29:44,136:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-29 15:29:44,174:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 15:29:44,175:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:29:44,200:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:29:44,200:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:29:44,238:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 15:29:44,239:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:29:44,263:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:29:44,264:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:29:44,265:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-29 15:29:44,304:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:29:44,327:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:29:44,327:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:29:44,359:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:29:44,395:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:29:44,395:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:29:44,396:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-29 15:29:44,471:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:29:44,472:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:29:44,530:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:29:44,530:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:29:44,545:INFO:Preparing preprocessing pipeline...
2026-01-29 15:29:44,564:INFO:Set up simple imputation.
2026-01-29 15:29:44,564:INFO:Set up column transformation.
2026-01-29 15:29:44,564:INFO:Set up feature normalization.
2026-01-29 15:29:46,181:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\numpy\core\_methods.py:176: RuntimeWarning: overflow encountered in multiply

2026-01-29 15:29:47,054:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\preprocessing\_data.py:3408: RuntimeWarning: overflow encountered in power

2026-01-29 15:29:47,057:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\numpy\core\_methods.py:152: RuntimeWarning: overflow encountered in reduce

2026-01-29 15:32:51,925:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\306957030.py:15: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-29 15:33:59,293:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\1040826916.py:15: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-29 15:34:57,609:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\4055341079.py:18: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-29 15:34:59,879:INFO:PyCaret ClassificationExperiment
2026-01-29 15:34:59,879:INFO:Logging name: clf-default-name
2026-01-29 15:34:59,879:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-29 15:34:59,879:INFO:version 3.3.2
2026-01-29 15:34:59,879:INFO:Initializing setup()
2026-01-29 15:34:59,879:INFO:self.USI: 732d
2026-01-29 15:34:59,879:INFO:self._variable_keys: {'X_test', 'fold_groups_param', 'pipeline', 'fix_imbalance', 'exp_name_log', 'data', 'y_test', 'seed', 'fold_shuffle_param', 'n_jobs_param', 'is_multiclass', 'gpu_n_jobs_param', 'memory', 'log_plots_param', 'logging_param', 'idx', 'y', 'target_param', 'fold_generator', 'y_train', 'gpu_param', 'USI', 'exp_id', '_available_plots', 'X', 'X_train', 'html_param', '_ml_usecase'}
2026-01-29 15:34:59,879:INFO:Checking environment
2026-01-29 15:34:59,879:INFO:python_version: 3.11.11
2026-01-29 15:34:59,879:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-29 15:34:59,879:INFO:machine: AMD64
2026-01-29 15:34:59,879:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-29 15:34:59,879:INFO:Memory: svmem(total=34009374720, available=15858475008, percent=53.4, used=18150899712, free=15858475008)
2026-01-29 15:34:59,879:INFO:Physical Core: 12
2026-01-29 15:34:59,879:INFO:Logical Core: 16
2026-01-29 15:34:59,879:INFO:Checking libraries
2026-01-29 15:34:59,879:INFO:System:
2026-01-29 15:34:59,879:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-29 15:34:59,879:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-29 15:34:59,879:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-29 15:34:59,879:INFO:PyCaret required dependencies:
2026-01-29 15:34:59,879:INFO:                 pip: 25.0
2026-01-29 15:34:59,879:INFO:          setuptools: 75.8.0
2026-01-29 15:34:59,879:INFO:             pycaret: 3.3.2
2026-01-29 15:34:59,879:INFO:             IPython: 9.9.0
2026-01-29 15:34:59,879:INFO:          ipywidgets: 8.1.8
2026-01-29 15:34:59,879:INFO:                tqdm: 4.67.1
2026-01-29 15:34:59,879:INFO:               numpy: 1.26.4
2026-01-29 15:34:59,879:INFO:              pandas: 2.1.4
2026-01-29 15:34:59,879:INFO:              jinja2: 3.1.6
2026-01-29 15:34:59,879:INFO:               scipy: 1.11.4
2026-01-29 15:34:59,879:INFO:              joblib: 1.3.2
2026-01-29 15:34:59,879:INFO:             sklearn: 1.4.2
2026-01-29 15:34:59,879:INFO:                pyod: 2.0.6
2026-01-29 15:34:59,879:INFO:            imblearn: 0.14.1
2026-01-29 15:34:59,879:INFO:   category_encoders: 2.7.0
2026-01-29 15:34:59,879:INFO:            lightgbm: 4.6.0
2026-01-29 15:34:59,879:INFO:               numba: 0.62.1
2026-01-29 15:34:59,879:INFO:            requests: 2.32.3
2026-01-29 15:34:59,879:INFO:          matplotlib: 3.7.5
2026-01-29 15:34:59,879:INFO:          scikitplot: 0.3.7
2026-01-29 15:34:59,879:INFO:         yellowbrick: 1.5
2026-01-29 15:34:59,879:INFO:              plotly: 5.24.1
2026-01-29 15:34:59,879:INFO:    plotly-resampler: Not installed
2026-01-29 15:34:59,879:INFO:             kaleido: 1.2.0
2026-01-29 15:34:59,879:INFO:           schemdraw: 0.15
2026-01-29 15:34:59,879:INFO:         statsmodels: 0.14.6
2026-01-29 15:34:59,879:INFO:              sktime: 0.26.0
2026-01-29 15:34:59,879:INFO:               tbats: 1.1.3
2026-01-29 15:34:59,879:INFO:            pmdarima: 2.0.4
2026-01-29 15:34:59,879:INFO:              psutil: 7.2.1
2026-01-29 15:34:59,879:INFO:          markupsafe: 3.0.3
2026-01-29 15:34:59,879:INFO:             pickle5: Not installed
2026-01-29 15:34:59,879:INFO:         cloudpickle: 3.0.0
2026-01-29 15:34:59,879:INFO:         deprecation: 2.1.0
2026-01-29 15:34:59,879:INFO:              xxhash: 3.6.0
2026-01-29 15:34:59,879:INFO:           wurlitzer: Not installed
2026-01-29 15:34:59,879:INFO:PyCaret optional dependencies:
2026-01-29 15:34:59,879:INFO:                shap: 0.44.1
2026-01-29 15:34:59,879:INFO:           interpret: 0.7.3
2026-01-29 15:34:59,879:INFO:                umap: 0.5.7
2026-01-29 15:34:59,888:INFO:     ydata_profiling: 4.18.1
2026-01-29 15:34:59,888:INFO:  explainerdashboard: 0.5.1
2026-01-29 15:34:59,889:INFO:             autoviz: Not installed
2026-01-29 15:34:59,889:INFO:           fairlearn: 0.7.0
2026-01-29 15:34:59,890:INFO:          deepchecks: Not installed
2026-01-29 15:34:59,890:INFO:             xgboost: Not installed
2026-01-29 15:34:59,890:INFO:            catboost: 1.2.8
2026-01-29 15:34:59,890:INFO:              kmodes: 0.12.2
2026-01-29 15:34:59,890:INFO:             mlxtend: 0.23.4
2026-01-29 15:34:59,890:INFO:       statsforecast: 1.5.0
2026-01-29 15:34:59,890:INFO:        tune_sklearn: Not installed
2026-01-29 15:34:59,890:INFO:                 ray: Not installed
2026-01-29 15:34:59,890:INFO:            hyperopt: 0.2.7
2026-01-29 15:34:59,890:INFO:              optuna: 4.6.0
2026-01-29 15:34:59,890:INFO:               skopt: 0.10.2
2026-01-29 15:34:59,890:INFO:              mlflow: 3.8.1
2026-01-29 15:34:59,890:INFO:              gradio: 6.3.0
2026-01-29 15:34:59,890:INFO:             fastapi: 0.128.0
2026-01-29 15:34:59,890:INFO:             uvicorn: 0.40.0
2026-01-29 15:34:59,890:INFO:              m2cgen: 0.10.0
2026-01-29 15:34:59,890:INFO:           evidently: 0.4.40
2026-01-29 15:34:59,890:INFO:               fugue: 0.8.7
2026-01-29 15:34:59,890:INFO:           streamlit: Not installed
2026-01-29 15:34:59,890:INFO:             prophet: Not installed
2026-01-29 15:34:59,890:INFO:None
2026-01-29 15:34:59,890:INFO:Set up data.
2026-01-29 15:34:59,923:INFO:Set up folding strategy.
2026-01-29 15:34:59,923:INFO:Set up train/test split.
2026-01-29 15:35:00,060:INFO:Set up index.
2026-01-29 15:35:00,073:INFO:Assigning column types.
2026-01-29 15:35:00,090:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-29 15:35:00,140:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 15:35:00,140:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:35:00,180:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:35:00,180:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:35:00,227:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 15:35:00,228:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:35:00,257:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:35:00,258:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:35:00,259:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-29 15:35:00,303:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:35:00,329:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:35:00,329:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:35:00,373:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:35:00,396:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:35:00,396:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:35:00,396:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-29 15:35:00,468:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:35:00,468:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:35:00,529:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:35:00,529:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:35:00,529:INFO:Preparing preprocessing pipeline...
2026-01-29 15:35:00,546:INFO:Set up simple imputation.
2026-01-29 15:35:00,546:INFO:Set up feature normalization.
2026-01-29 15:35:00,642:INFO:Finished creating preprocessing pipeline.
2026-01-29 15:35:00,646:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-29 15:35:00,646:INFO:Creating final display dataframe.
2026-01-29 15:35:00,911:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape       (429278, 4)
4        Transformed data shape       (429278, 4)
5   Transformed train set shape       (343422, 4)
6    Transformed test set shape        (85856, 4)
7               Ignore features                58
8              Numeric features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                 5
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              732d
2026-01-29 15:35:00,956:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:35:00,956:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:35:01,023:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:35:01,023:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:35:01,023:INFO:setup() successfully completed in 1.17s...............
2026-01-29 15:35:01,023:INFO:Initializing compare_models()
2026-01-29 15:35:01,023:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-29 15:35:01,023:INFO:Checking exceptions
2026-01-29 15:35:01,057:INFO:Preparing display monitor
2026-01-29 15:35:01,089:INFO:Initializing Logistic Regression
2026-01-29 15:35:01,090:INFO:Total runtime is 1.8715858459472656e-05 minutes
2026-01-29 15:35:01,093:INFO:SubProcess create_model() called ==================================
2026-01-29 15:35:01,094:INFO:Initializing create_model()
2026-01-29 15:35:01,094:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:35:01,094:INFO:Checking exceptions
2026-01-29 15:35:01,094:INFO:Importing libraries
2026-01-29 15:35:01,095:INFO:Copying training dataset
2026-01-29 15:35:01,178:INFO:Defining folds
2026-01-29 15:35:01,178:INFO:Declaring metric variables
2026-01-29 15:35:01,181:INFO:Importing untrained model
2026-01-29 15:35:01,184:INFO:Logistic Regression Imported successfully
2026-01-29 15:35:01,191:INFO:Starting cross validation
2026-01-29 15:35:01,192:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:35:12,429:INFO:Calculating mean and std
2026-01-29 15:35:12,429:INFO:Creating metrics dataframe
2026-01-29 15:35:12,429:INFO:Uploading results into container
2026-01-29 15:35:12,429:INFO:Uploading model into container now
2026-01-29 15:35:12,429:INFO:_master_model_container: 1
2026-01-29 15:35:12,436:INFO:_display_container: 2
2026-01-29 15:35:12,436:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 15:35:12,436:INFO:create_model() successfully completed......................................
2026-01-29 15:35:12,639:INFO:SubProcess create_model() end ==================================
2026-01-29 15:35:12,639:INFO:Creating metrics dataframe
2026-01-29 15:35:12,643:INFO:Initializing K Neighbors Classifier
2026-01-29 15:35:12,643:INFO:Total runtime is 0.1925755222638448 minutes
2026-01-29 15:35:12,645:INFO:SubProcess create_model() called ==================================
2026-01-29 15:35:12,645:INFO:Initializing create_model()
2026-01-29 15:35:12,645:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:35:12,645:INFO:Checking exceptions
2026-01-29 15:35:12,645:INFO:Importing libraries
2026-01-29 15:35:12,646:INFO:Copying training dataset
2026-01-29 15:35:12,695:INFO:Defining folds
2026-01-29 15:35:12,706:INFO:Declaring metric variables
2026-01-29 15:35:12,708:INFO:Importing untrained model
2026-01-29 15:35:12,708:INFO:K Neighbors Classifier Imported successfully
2026-01-29 15:35:12,708:INFO:Starting cross validation
2026-01-29 15:35:12,708:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:52:50,271:INFO:Calculating mean and std
2026-01-29 15:52:50,273:INFO:Creating metrics dataframe
2026-01-29 15:52:50,276:INFO:Uploading results into container
2026-01-29 15:52:50,277:INFO:Uploading model into container now
2026-01-29 15:52:50,277:INFO:_master_model_container: 2
2026-01-29 15:52:50,278:INFO:_display_container: 2
2026-01-29 15:52:50,278:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2026-01-29 15:52:50,278:INFO:create_model() successfully completed......................................
2026-01-29 15:52:50,493:INFO:SubProcess create_model() end ==================================
2026-01-29 15:52:50,493:INFO:Creating metrics dataframe
2026-01-29 15:52:50,498:INFO:Initializing Naive Bayes
2026-01-29 15:52:50,498:INFO:Total runtime is 17.823485747973123 minutes
2026-01-29 15:52:50,501:INFO:SubProcess create_model() called ==================================
2026-01-29 15:52:50,502:INFO:Initializing create_model()
2026-01-29 15:52:50,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:52:50,502:INFO:Checking exceptions
2026-01-29 15:52:50,502:INFO:Importing libraries
2026-01-29 15:52:50,502:INFO:Copying training dataset
2026-01-29 15:52:50,576:INFO:Defining folds
2026-01-29 15:52:50,576:INFO:Declaring metric variables
2026-01-29 15:52:50,581:INFO:Importing untrained model
2026-01-29 15:52:50,581:INFO:Naive Bayes Imported successfully
2026-01-29 15:52:50,595:INFO:Starting cross validation
2026-01-29 15:52:50,596:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:52:52,044:INFO:Calculating mean and std
2026-01-29 15:52:52,047:INFO:Creating metrics dataframe
2026-01-29 15:52:52,052:INFO:Uploading results into container
2026-01-29 15:52:52,053:INFO:Uploading model into container now
2026-01-29 15:52:52,054:INFO:_master_model_container: 3
2026-01-29 15:52:52,056:INFO:_display_container: 2
2026-01-29 15:52:52,057:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-01-29 15:52:52,057:INFO:create_model() successfully completed......................................
2026-01-29 15:52:52,389:INFO:SubProcess create_model() end ==================================
2026-01-29 15:52:52,389:INFO:Creating metrics dataframe
2026-01-29 15:52:52,402:INFO:Initializing Decision Tree Classifier
2026-01-29 15:52:52,402:INFO:Total runtime is 17.855215458075204 minutes
2026-01-29 15:52:52,407:INFO:SubProcess create_model() called ==================================
2026-01-29 15:52:52,408:INFO:Initializing create_model()
2026-01-29 15:52:52,408:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:52:52,409:INFO:Checking exceptions
2026-01-29 15:52:52,409:INFO:Importing libraries
2026-01-29 15:52:52,409:INFO:Copying training dataset
2026-01-29 15:52:52,533:INFO:Defining folds
2026-01-29 15:52:52,533:INFO:Declaring metric variables
2026-01-29 15:52:52,537:INFO:Importing untrained model
2026-01-29 15:52:52,542:INFO:Decision Tree Classifier Imported successfully
2026-01-29 15:52:52,552:INFO:Starting cross validation
2026-01-29 15:52:52,554:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:52:57,251:INFO:Calculating mean and std
2026-01-29 15:52:57,251:INFO:Creating metrics dataframe
2026-01-29 15:52:57,251:INFO:Uploading results into container
2026-01-29 15:52:57,251:INFO:Uploading model into container now
2026-01-29 15:52:57,251:INFO:_master_model_container: 4
2026-01-29 15:52:57,251:INFO:_display_container: 2
2026-01-29 15:52:57,251:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 15:52:57,251:INFO:create_model() successfully completed......................................
2026-01-29 15:52:57,451:INFO:SubProcess create_model() end ==================================
2026-01-29 15:52:57,451:INFO:Creating metrics dataframe
2026-01-29 15:52:57,456:INFO:Initializing SVM - Linear Kernel
2026-01-29 15:52:57,456:INFO:Total runtime is 17.939451269308723 minutes
2026-01-29 15:52:57,459:INFO:SubProcess create_model() called ==================================
2026-01-29 15:52:57,459:INFO:Initializing create_model()
2026-01-29 15:52:57,459:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:52:57,460:INFO:Checking exceptions
2026-01-29 15:52:57,460:INFO:Importing libraries
2026-01-29 15:52:57,460:INFO:Copying training dataset
2026-01-29 15:52:57,538:INFO:Defining folds
2026-01-29 15:52:57,538:INFO:Declaring metric variables
2026-01-29 15:52:57,542:INFO:Importing untrained model
2026-01-29 15:52:57,546:INFO:SVM - Linear Kernel Imported successfully
2026-01-29 15:52:57,550:INFO:Starting cross validation
2026-01-29 15:52:57,550:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:53:05,859:INFO:Calculating mean and std
2026-01-29 15:53:05,860:INFO:Creating metrics dataframe
2026-01-29 15:53:05,862:INFO:Uploading results into container
2026-01-29 15:53:05,862:INFO:Uploading model into container now
2026-01-29 15:53:05,863:INFO:_master_model_container: 5
2026-01-29 15:53:05,863:INFO:_display_container: 2
2026-01-29 15:53:05,864:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2026-01-29 15:53:05,864:INFO:create_model() successfully completed......................................
2026-01-29 15:53:06,108:INFO:SubProcess create_model() end ==================================
2026-01-29 15:53:06,109:INFO:Creating metrics dataframe
2026-01-29 15:53:06,114:INFO:Initializing Ridge Classifier
2026-01-29 15:53:06,114:INFO:Total runtime is 18.083745956420895 minutes
2026-01-29 15:53:06,114:INFO:SubProcess create_model() called ==================================
2026-01-29 15:53:06,114:INFO:Initializing create_model()
2026-01-29 15:53:06,114:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:53:06,114:INFO:Checking exceptions
2026-01-29 15:53:06,114:INFO:Importing libraries
2026-01-29 15:53:06,114:INFO:Copying training dataset
2026-01-29 15:53:06,230:INFO:Defining folds
2026-01-29 15:53:06,230:INFO:Declaring metric variables
2026-01-29 15:53:06,235:INFO:Importing untrained model
2026-01-29 15:53:06,240:INFO:Ridge Classifier Imported successfully
2026-01-29 15:53:06,249:INFO:Starting cross validation
2026-01-29 15:53:06,251:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:53:14,237:INFO:Calculating mean and std
2026-01-29 15:53:14,239:INFO:Creating metrics dataframe
2026-01-29 15:53:14,242:INFO:Uploading results into container
2026-01-29 15:53:14,243:INFO:Uploading model into container now
2026-01-29 15:53:14,243:INFO:_master_model_container: 6
2026-01-29 15:53:14,243:INFO:_display_container: 2
2026-01-29 15:53:14,243:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2026-01-29 15:53:14,243:INFO:create_model() successfully completed......................................
2026-01-29 15:53:14,441:INFO:SubProcess create_model() end ==================================
2026-01-29 15:53:14,442:INFO:Creating metrics dataframe
2026-01-29 15:53:14,443:INFO:Initializing Random Forest Classifier
2026-01-29 15:53:14,443:INFO:Total runtime is 18.222563024361925 minutes
2026-01-29 15:53:14,443:INFO:SubProcess create_model() called ==================================
2026-01-29 15:53:14,443:INFO:Initializing create_model()
2026-01-29 15:53:14,443:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:53:14,443:INFO:Checking exceptions
2026-01-29 15:53:14,443:INFO:Importing libraries
2026-01-29 15:53:14,443:INFO:Copying training dataset
2026-01-29 15:53:14,516:INFO:Defining folds
2026-01-29 15:53:14,523:INFO:Declaring metric variables
2026-01-29 15:53:14,526:INFO:Importing untrained model
2026-01-29 15:53:14,526:INFO:Random Forest Classifier Imported successfully
2026-01-29 15:53:14,533:INFO:Starting cross validation
2026-01-29 15:53:14,533:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:53:24,811:INFO:Calculating mean and std
2026-01-29 15:53:24,811:INFO:Creating metrics dataframe
2026-01-29 15:53:24,811:INFO:Uploading results into container
2026-01-29 15:53:24,811:INFO:Uploading model into container now
2026-01-29 15:53:24,811:INFO:_master_model_container: 7
2026-01-29 15:53:24,811:INFO:_display_container: 2
2026-01-29 15:53:24,811:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 15:53:24,811:INFO:create_model() successfully completed......................................
2026-01-29 15:53:24,985:INFO:SubProcess create_model() end ==================================
2026-01-29 15:53:24,986:INFO:Creating metrics dataframe
2026-01-29 15:53:24,991:INFO:Initializing Quadratic Discriminant Analysis
2026-01-29 15:53:24,991:INFO:Total runtime is 18.3983648498853 minutes
2026-01-29 15:53:24,991:INFO:SubProcess create_model() called ==================================
2026-01-29 15:53:24,991:INFO:Initializing create_model()
2026-01-29 15:53:24,991:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:53:24,991:INFO:Checking exceptions
2026-01-29 15:53:24,991:INFO:Importing libraries
2026-01-29 15:53:24,991:INFO:Copying training dataset
2026-01-29 15:53:25,058:INFO:Defining folds
2026-01-29 15:53:25,059:INFO:Declaring metric variables
2026-01-29 15:53:25,061:INFO:Importing untrained model
2026-01-29 15:53:25,064:INFO:Quadratic Discriminant Analysis Imported successfully
2026-01-29 15:53:25,064:INFO:Starting cross validation
2026-01-29 15:53:25,064:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:53:25,727:INFO:Calculating mean and std
2026-01-29 15:53:25,728:INFO:Creating metrics dataframe
2026-01-29 15:53:25,730:INFO:Uploading results into container
2026-01-29 15:53:25,730:INFO:Uploading model into container now
2026-01-29 15:53:25,730:INFO:_master_model_container: 8
2026-01-29 15:53:25,732:INFO:_display_container: 2
2026-01-29 15:53:25,732:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2026-01-29 15:53:25,732:INFO:create_model() successfully completed......................................
2026-01-29 15:53:25,925:INFO:SubProcess create_model() end ==================================
2026-01-29 15:53:25,925:INFO:Creating metrics dataframe
2026-01-29 15:53:25,932:INFO:Initializing Ada Boost Classifier
2026-01-29 15:53:25,933:INFO:Total runtime is 18.414068611462906 minutes
2026-01-29 15:53:25,936:INFO:SubProcess create_model() called ==================================
2026-01-29 15:53:25,936:INFO:Initializing create_model()
2026-01-29 15:53:25,937:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:53:25,937:INFO:Checking exceptions
2026-01-29 15:53:25,937:INFO:Importing libraries
2026-01-29 15:53:25,937:INFO:Copying training dataset
2026-01-29 15:53:26,012:INFO:Defining folds
2026-01-29 15:53:26,012:INFO:Declaring metric variables
2026-01-29 15:53:26,016:INFO:Importing untrained model
2026-01-29 15:53:26,020:INFO:Ada Boost Classifier Imported successfully
2026-01-29 15:53:26,028:INFO:Starting cross validation
2026-01-29 15:53:26,029:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:53:26,189:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-01-29 15:53:26,215:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-01-29 15:53:26,237:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-01-29 15:53:26,264:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-01-29 15:53:26,282:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-01-29 15:53:33,521:INFO:Calculating mean and std
2026-01-29 15:53:33,524:INFO:Creating metrics dataframe
2026-01-29 15:53:33,527:INFO:Uploading results into container
2026-01-29 15:53:33,528:INFO:Uploading model into container now
2026-01-29 15:53:33,528:INFO:_master_model_container: 9
2026-01-29 15:53:33,530:INFO:_display_container: 2
2026-01-29 15:53:33,531:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2026-01-29 15:53:33,531:INFO:create_model() successfully completed......................................
2026-01-29 15:53:33,725:INFO:SubProcess create_model() end ==================================
2026-01-29 15:53:33,725:INFO:Creating metrics dataframe
2026-01-29 15:53:33,733:INFO:Initializing Gradient Boosting Classifier
2026-01-29 15:53:33,733:INFO:Total runtime is 18.544077916940047 minutes
2026-01-29 15:53:33,737:INFO:SubProcess create_model() called ==================================
2026-01-29 15:53:33,738:INFO:Initializing create_model()
2026-01-29 15:53:33,738:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:53:33,738:INFO:Checking exceptions
2026-01-29 15:53:33,740:INFO:Importing libraries
2026-01-29 15:53:33,740:INFO:Copying training dataset
2026-01-29 15:53:33,822:INFO:Defining folds
2026-01-29 15:53:33,822:INFO:Declaring metric variables
2026-01-29 15:53:33,826:INFO:Importing untrained model
2026-01-29 15:53:33,830:INFO:Gradient Boosting Classifier Imported successfully
2026-01-29 15:53:33,835:INFO:Starting cross validation
2026-01-29 15:53:33,836:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:53:41,968:INFO:Calculating mean and std
2026-01-29 15:53:41,969:INFO:Creating metrics dataframe
2026-01-29 15:53:41,971:INFO:Uploading results into container
2026-01-29 15:53:41,972:INFO:Uploading model into container now
2026-01-29 15:53:41,972:INFO:_master_model_container: 10
2026-01-29 15:53:41,973:INFO:_display_container: 2
2026-01-29 15:53:41,973:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2026-01-29 15:53:41,973:INFO:create_model() successfully completed......................................
2026-01-29 15:53:42,168:INFO:SubProcess create_model() end ==================================
2026-01-29 15:53:42,168:INFO:Creating metrics dataframe
2026-01-29 15:53:42,175:INFO:Initializing Linear Discriminant Analysis
2026-01-29 15:53:42,176:INFO:Total runtime is 18.684785914421074 minutes
2026-01-29 15:53:42,178:INFO:SubProcess create_model() called ==================================
2026-01-29 15:53:42,178:INFO:Initializing create_model()
2026-01-29 15:53:42,178:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:53:42,178:INFO:Checking exceptions
2026-01-29 15:53:42,178:INFO:Importing libraries
2026-01-29 15:53:42,178:INFO:Copying training dataset
2026-01-29 15:53:42,247:INFO:Defining folds
2026-01-29 15:53:42,247:INFO:Declaring metric variables
2026-01-29 15:53:42,250:INFO:Importing untrained model
2026-01-29 15:53:42,250:INFO:Linear Discriminant Analysis Imported successfully
2026-01-29 15:53:42,260:INFO:Starting cross validation
2026-01-29 15:53:42,261:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:53:42,938:INFO:Calculating mean and std
2026-01-29 15:53:42,939:INFO:Creating metrics dataframe
2026-01-29 15:53:42,942:INFO:Uploading results into container
2026-01-29 15:53:42,942:INFO:Uploading model into container now
2026-01-29 15:53:42,943:INFO:_master_model_container: 11
2026-01-29 15:53:42,943:INFO:_display_container: 2
2026-01-29 15:53:42,943:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2026-01-29 15:53:42,943:INFO:create_model() successfully completed......................................
2026-01-29 15:53:43,137:INFO:SubProcess create_model() end ==================================
2026-01-29 15:53:43,138:INFO:Creating metrics dataframe
2026-01-29 15:53:43,145:INFO:Initializing Extra Trees Classifier
2026-01-29 15:53:43,146:INFO:Total runtime is 18.70095623334248 minutes
2026-01-29 15:53:43,149:INFO:SubProcess create_model() called ==================================
2026-01-29 15:53:43,149:INFO:Initializing create_model()
2026-01-29 15:53:43,149:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:53:43,149:INFO:Checking exceptions
2026-01-29 15:53:43,150:INFO:Importing libraries
2026-01-29 15:53:43,150:INFO:Copying training dataset
2026-01-29 15:53:43,242:INFO:Defining folds
2026-01-29 15:53:43,242:INFO:Declaring metric variables
2026-01-29 15:53:43,244:INFO:Importing untrained model
2026-01-29 15:53:43,244:INFO:Extra Trees Classifier Imported successfully
2026-01-29 15:53:43,256:INFO:Starting cross validation
2026-01-29 15:53:43,258:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:53:47,881:INFO:Calculating mean and std
2026-01-29 15:53:47,882:INFO:Creating metrics dataframe
2026-01-29 15:53:47,886:INFO:Uploading results into container
2026-01-29 15:53:47,887:INFO:Uploading model into container now
2026-01-29 15:53:47,887:INFO:_master_model_container: 12
2026-01-29 15:53:47,888:INFO:_display_container: 2
2026-01-29 15:53:47,889:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2026-01-29 15:53:47,889:INFO:create_model() successfully completed......................................
2026-01-29 15:53:48,126:INFO:SubProcess create_model() end ==================================
2026-01-29 15:53:48,126:INFO:Creating metrics dataframe
2026-01-29 15:53:48,135:INFO:Initializing Light Gradient Boosting Machine
2026-01-29 15:53:48,135:INFO:Total runtime is 18.78410774469375 minutes
2026-01-29 15:53:48,139:INFO:SubProcess create_model() called ==================================
2026-01-29 15:53:48,140:INFO:Initializing create_model()
2026-01-29 15:53:48,141:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:53:48,141:INFO:Checking exceptions
2026-01-29 15:53:48,141:INFO:Importing libraries
2026-01-29 15:53:48,141:INFO:Copying training dataset
2026-01-29 15:53:48,246:INFO:Defining folds
2026-01-29 15:53:48,246:INFO:Declaring metric variables
2026-01-29 15:53:48,250:INFO:Importing untrained model
2026-01-29 15:53:48,255:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-29 15:53:48,262:INFO:Starting cross validation
2026-01-29 15:53:48,263:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:53:50,367:INFO:Calculating mean and std
2026-01-29 15:53:50,368:INFO:Creating metrics dataframe
2026-01-29 15:53:50,371:INFO:Uploading results into container
2026-01-29 15:53:50,372:INFO:Uploading model into container now
2026-01-29 15:53:50,372:INFO:_master_model_container: 13
2026-01-29 15:53:50,373:INFO:_display_container: 2
2026-01-29 15:53:50,374:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-29 15:53:50,375:INFO:create_model() successfully completed......................................
2026-01-29 15:53:50,573:INFO:SubProcess create_model() end ==================================
2026-01-29 15:53:50,573:INFO:Creating metrics dataframe
2026-01-29 15:53:50,582:INFO:Initializing CatBoost Classifier
2026-01-29 15:53:50,582:INFO:Total runtime is 18.824895695845278 minutes
2026-01-29 15:53:50,582:INFO:SubProcess create_model() called ==================================
2026-01-29 15:53:50,582:INFO:Initializing create_model()
2026-01-29 15:53:50,582:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:53:50,582:INFO:Checking exceptions
2026-01-29 15:53:50,582:INFO:Importing libraries
2026-01-29 15:53:50,582:INFO:Copying training dataset
2026-01-29 15:53:50,668:INFO:Defining folds
2026-01-29 15:53:50,668:INFO:Declaring metric variables
2026-01-29 15:53:50,672:INFO:Importing untrained model
2026-01-29 15:53:50,675:INFO:CatBoost Classifier Imported successfully
2026-01-29 15:53:50,675:INFO:Starting cross validation
2026-01-29 15:53:50,675:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:54:46,154:INFO:Calculating mean and std
2026-01-29 15:54:46,158:INFO:Creating metrics dataframe
2026-01-29 15:54:46,158:INFO:Uploading results into container
2026-01-29 15:54:46,164:INFO:Uploading model into container now
2026-01-29 15:54:46,165:INFO:_master_model_container: 14
2026-01-29 15:54:46,165:INFO:_display_container: 2
2026-01-29 15:54:46,165:INFO:<catboost.core.CatBoostClassifier object at 0x0000024870CE2650>
2026-01-29 15:54:46,165:INFO:create_model() successfully completed......................................
2026-01-29 15:54:46,341:INFO:SubProcess create_model() end ==================================
2026-01-29 15:54:46,341:INFO:Creating metrics dataframe
2026-01-29 15:54:46,350:INFO:Initializing Dummy Classifier
2026-01-29 15:54:46,357:INFO:Total runtime is 19.754346024990074 minutes
2026-01-29 15:54:46,357:INFO:SubProcess create_model() called ==================================
2026-01-29 15:54:46,357:INFO:Initializing create_model()
2026-01-29 15:54:46,357:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:54:46,357:INFO:Checking exceptions
2026-01-29 15:54:46,357:INFO:Importing libraries
2026-01-29 15:54:46,357:INFO:Copying training dataset
2026-01-29 15:54:46,432:INFO:Defining folds
2026-01-29 15:54:46,432:INFO:Declaring metric variables
2026-01-29 15:54:46,436:INFO:Importing untrained model
2026-01-29 15:54:46,439:INFO:Dummy Classifier Imported successfully
2026-01-29 15:54:46,443:INFO:Starting cross validation
2026-01-29 15:54:46,443:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:54:46,724:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-01-29 15:54:46,745:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-01-29 15:54:46,757:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-01-29 15:54:46,776:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-01-29 15:54:46,808:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-01-29 15:54:47,025:INFO:Calculating mean and std
2026-01-29 15:54:47,025:INFO:Creating metrics dataframe
2026-01-29 15:54:47,025:INFO:Uploading results into container
2026-01-29 15:54:47,025:INFO:Uploading model into container now
2026-01-29 15:54:47,025:INFO:_master_model_container: 15
2026-01-29 15:54:47,025:INFO:_display_container: 2
2026-01-29 15:54:47,025:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2026-01-29 15:54:47,025:INFO:create_model() successfully completed......................................
2026-01-29 15:54:47,207:INFO:SubProcess create_model() end ==================================
2026-01-29 15:54:47,207:INFO:Creating metrics dataframe
2026-01-29 15:54:47,222:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-29 15:54:47,236:INFO:Initializing create_model()
2026-01-29 15:54:47,236:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:54:47,239:INFO:Checking exceptions
2026-01-29 15:54:47,240:INFO:Importing libraries
2026-01-29 15:54:47,240:INFO:Copying training dataset
2026-01-29 15:54:47,336:INFO:Defining folds
2026-01-29 15:54:47,337:INFO:Declaring metric variables
2026-01-29 15:54:47,337:INFO:Importing untrained model
2026-01-29 15:54:47,337:INFO:Declaring custom model
2026-01-29 15:54:47,337:INFO:Logistic Regression Imported successfully
2026-01-29 15:54:47,338:INFO:Cross validation set to False
2026-01-29 15:54:47,338:INFO:Fitting Model
2026-01-29 15:54:47,607:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 15:54:47,607:INFO:create_model() successfully completed......................................
2026-01-29 15:54:47,789:INFO:Initializing create_model()
2026-01-29 15:54:47,790:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:54:47,790:INFO:Checking exceptions
2026-01-29 15:54:47,791:INFO:Importing libraries
2026-01-29 15:54:47,791:INFO:Copying training dataset
2026-01-29 15:54:47,872:INFO:Defining folds
2026-01-29 15:54:47,872:INFO:Declaring metric variables
2026-01-29 15:54:47,872:INFO:Importing untrained model
2026-01-29 15:54:47,872:INFO:Declaring custom model
2026-01-29 15:54:47,872:INFO:Naive Bayes Imported successfully
2026-01-29 15:54:47,872:INFO:Cross validation set to False
2026-01-29 15:54:47,872:INFO:Fitting Model
2026-01-29 15:54:47,940:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-01-29 15:54:47,940:INFO:create_model() successfully completed......................................
2026-01-29 15:54:48,107:INFO:Initializing create_model()
2026-01-29 15:54:48,107:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:54:48,107:INFO:Checking exceptions
2026-01-29 15:54:48,118:INFO:Importing libraries
2026-01-29 15:54:48,118:INFO:Copying training dataset
2026-01-29 15:54:48,179:INFO:Defining folds
2026-01-29 15:54:48,179:INFO:Declaring metric variables
2026-01-29 15:54:48,180:INFO:Importing untrained model
2026-01-29 15:54:48,180:INFO:Declaring custom model
2026-01-29 15:54:48,180:INFO:Decision Tree Classifier Imported successfully
2026-01-29 15:54:48,180:INFO:Cross validation set to False
2026-01-29 15:54:48,180:INFO:Fitting Model
2026-01-29 15:54:48,241:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 15:54:48,241:INFO:create_model() successfully completed......................................
2026-01-29 15:54:48,425:INFO:_master_model_container: 15
2026-01-29 15:54:48,425:INFO:_display_container: 2
2026-01-29 15:54:48,425:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')]
2026-01-29 15:54:48,425:INFO:compare_models() successfully completed......................................
2026-01-29 15:54:48,425:INFO:Initializing tune_model()
2026-01-29 15:54:48,425:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 15:54:48,425:INFO:Checking exceptions
2026-01-29 15:54:48,475:INFO:Copying training dataset
2026-01-29 15:54:48,544:INFO:Checking base model
2026-01-29 15:54:48,544:INFO:Base model : Logistic Regression
2026-01-29 15:54:48,548:INFO:Declaring metric variables
2026-01-29 15:54:48,552:INFO:Defining Hyperparameters
2026-01-29 15:54:48,729:INFO:Tuning with n_jobs=-1
2026-01-29 15:54:48,729:INFO:Initializing RandomizedSearchCV
2026-01-29 15:54:52,415:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 5.682}
2026-01-29 15:54:52,415:INFO:Hyperparameter search completed
2026-01-29 15:54:52,415:INFO:SubProcess create_model() called ==================================
2026-01-29 15:54:52,415:INFO:Initializing create_model()
2026-01-29 15:54:52,415:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002480469E050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 5.682})
2026-01-29 15:54:52,415:INFO:Checking exceptions
2026-01-29 15:54:52,415:INFO:Importing libraries
2026-01-29 15:54:52,415:INFO:Copying training dataset
2026-01-29 15:54:52,490:INFO:Defining folds
2026-01-29 15:54:52,490:INFO:Declaring metric variables
2026-01-29 15:54:52,490:INFO:Importing untrained model
2026-01-29 15:54:52,490:INFO:Declaring custom model
2026-01-29 15:54:52,490:INFO:Logistic Regression Imported successfully
2026-01-29 15:54:52,505:INFO:Starting cross validation
2026-01-29 15:54:52,509:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:54:53,488:INFO:Calculating mean and std
2026-01-29 15:54:53,489:INFO:Creating metrics dataframe
2026-01-29 15:54:53,495:INFO:Finalizing model
2026-01-29 15:54:53,827:INFO:Uploading results into container
2026-01-29 15:54:53,828:INFO:Uploading model into container now
2026-01-29 15:54:53,829:INFO:_master_model_container: 16
2026-01-29 15:54:53,829:INFO:_display_container: 3
2026-01-29 15:54:53,830:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 15:54:53,830:INFO:create_model() successfully completed......................................
2026-01-29 15:54:54,012:INFO:SubProcess create_model() end ==================================
2026-01-29 15:54:54,012:INFO:choose_better activated
2026-01-29 15:54:54,015:INFO:SubProcess create_model() called ==================================
2026-01-29 15:54:54,016:INFO:Initializing create_model()
2026-01-29 15:54:54,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:54:54,016:INFO:Checking exceptions
2026-01-29 15:54:54,018:INFO:Importing libraries
2026-01-29 15:54:54,019:INFO:Copying training dataset
2026-01-29 15:54:54,074:INFO:Defining folds
2026-01-29 15:54:54,074:INFO:Declaring metric variables
2026-01-29 15:54:54,074:INFO:Importing untrained model
2026-01-29 15:54:54,074:INFO:Declaring custom model
2026-01-29 15:54:54,074:INFO:Logistic Regression Imported successfully
2026-01-29 15:54:54,074:INFO:Starting cross validation
2026-01-29 15:54:54,074:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:54:54,963:INFO:Calculating mean and std
2026-01-29 15:54:54,967:INFO:Creating metrics dataframe
2026-01-29 15:54:54,969:INFO:Finalizing model
2026-01-29 15:54:55,205:INFO:Uploading results into container
2026-01-29 15:54:55,206:INFO:Uploading model into container now
2026-01-29 15:54:55,206:INFO:_master_model_container: 17
2026-01-29 15:54:55,206:INFO:_display_container: 4
2026-01-29 15:54:55,207:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 15:54:55,207:INFO:create_model() successfully completed......................................
2026-01-29 15:54:55,422:INFO:SubProcess create_model() end ==================================
2026-01-29 15:54:55,423:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 15:54:55,423:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 15:54:55,423:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2026-01-29 15:54:55,423:INFO:choose_better completed
2026-01-29 15:54:55,424:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 15:54:55,429:INFO:_master_model_container: 17
2026-01-29 15:54:55,429:INFO:_display_container: 3
2026-01-29 15:54:55,429:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 15:54:55,429:INFO:tune_model() successfully completed......................................
2026-01-29 15:54:55,641:INFO:Initializing tune_model()
2026-01-29 15:54:55,641:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 15:54:55,641:INFO:Checking exceptions
2026-01-29 15:54:55,677:INFO:Copying training dataset
2026-01-29 15:54:55,754:INFO:Checking base model
2026-01-29 15:54:55,754:INFO:Base model : Naive Bayes
2026-01-29 15:54:55,758:INFO:Declaring metric variables
2026-01-29 15:54:55,762:INFO:Defining Hyperparameters
2026-01-29 15:54:55,983:INFO:Tuning with n_jobs=-1
2026-01-29 15:54:55,983:INFO:Initializing RandomizedSearchCV
2026-01-29 15:54:57,835:INFO:best_params: {'actual_estimator__var_smoothing': 2e-07}
2026-01-29 15:54:57,836:INFO:Hyperparameter search completed
2026-01-29 15:54:57,836:INFO:SubProcess create_model() called ==================================
2026-01-29 15:54:57,837:INFO:Initializing create_model()
2026-01-29 15:54:57,837:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024804682610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'var_smoothing': 2e-07})
2026-01-29 15:54:57,837:INFO:Checking exceptions
2026-01-29 15:54:57,838:INFO:Importing libraries
2026-01-29 15:54:57,838:INFO:Copying training dataset
2026-01-29 15:54:57,990:INFO:Defining folds
2026-01-29 15:54:57,990:INFO:Declaring metric variables
2026-01-29 15:54:57,995:INFO:Importing untrained model
2026-01-29 15:54:57,995:INFO:Declaring custom model
2026-01-29 15:54:58,000:INFO:Naive Bayes Imported successfully
2026-01-29 15:54:58,010:INFO:Starting cross validation
2026-01-29 15:54:58,011:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:54:58,780:INFO:Calculating mean and std
2026-01-29 15:54:58,780:INFO:Creating metrics dataframe
2026-01-29 15:54:58,790:INFO:Finalizing model
2026-01-29 15:54:58,883:INFO:Uploading results into container
2026-01-29 15:54:58,884:INFO:Uploading model into container now
2026-01-29 15:54:58,885:INFO:_master_model_container: 18
2026-01-29 15:54:58,885:INFO:_display_container: 4
2026-01-29 15:54:58,885:INFO:GaussianNB(priors=None, var_smoothing=2e-07)
2026-01-29 15:54:58,885:INFO:create_model() successfully completed......................................
2026-01-29 15:54:59,109:INFO:SubProcess create_model() end ==================================
2026-01-29 15:54:59,110:INFO:choose_better activated
2026-01-29 15:54:59,112:INFO:SubProcess create_model() called ==================================
2026-01-29 15:54:59,112:INFO:Initializing create_model()
2026-01-29 15:54:59,112:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:54:59,112:INFO:Checking exceptions
2026-01-29 15:54:59,114:INFO:Importing libraries
2026-01-29 15:54:59,114:INFO:Copying training dataset
2026-01-29 15:54:59,188:INFO:Defining folds
2026-01-29 15:54:59,188:INFO:Declaring metric variables
2026-01-29 15:54:59,188:INFO:Importing untrained model
2026-01-29 15:54:59,188:INFO:Declaring custom model
2026-01-29 15:54:59,189:INFO:Naive Bayes Imported successfully
2026-01-29 15:54:59,189:INFO:Starting cross validation
2026-01-29 15:54:59,190:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:54:59,915:INFO:Calculating mean and std
2026-01-29 15:54:59,916:INFO:Creating metrics dataframe
2026-01-29 15:54:59,918:INFO:Finalizing model
2026-01-29 15:54:59,995:INFO:Uploading results into container
2026-01-29 15:54:59,996:INFO:Uploading model into container now
2026-01-29 15:54:59,996:INFO:_master_model_container: 19
2026-01-29 15:54:59,996:INFO:_display_container: 5
2026-01-29 15:54:59,996:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-01-29 15:54:59,997:INFO:create_model() successfully completed......................................
2026-01-29 15:55:00,211:INFO:SubProcess create_model() end ==================================
2026-01-29 15:55:00,211:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for AUC is 0.5369
2026-01-29 15:55:00,212:INFO:GaussianNB(priors=None, var_smoothing=2e-07) result for AUC is 0.5369
2026-01-29 15:55:00,212:INFO:GaussianNB(priors=None, var_smoothing=1e-09) is best model
2026-01-29 15:55:00,212:INFO:choose_better completed
2026-01-29 15:55:00,212:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 15:55:00,223:INFO:_master_model_container: 19
2026-01-29 15:55:00,224:INFO:_display_container: 4
2026-01-29 15:55:00,224:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-01-29 15:55:00,224:INFO:tune_model() successfully completed......................................
2026-01-29 15:55:00,429:INFO:Initializing tune_model()
2026-01-29 15:55:00,430:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 15:55:00,430:INFO:Checking exceptions
2026-01-29 15:55:00,466:INFO:Copying training dataset
2026-01-29 15:55:00,543:INFO:Checking base model
2026-01-29 15:55:00,544:INFO:Base model : Decision Tree Classifier
2026-01-29 15:55:00,548:INFO:Declaring metric variables
2026-01-29 15:55:00,552:INFO:Defining Hyperparameters
2026-01-29 15:55:00,802:INFO:Tuning with n_jobs=-1
2026-01-29 15:55:00,802:INFO:Initializing RandomizedSearchCV
2026-01-29 15:55:02,562:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.0005, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 3, 'actual_estimator__criterion': 'gini'}
2026-01-29 15:55:02,563:INFO:Hyperparameter search completed
2026-01-29 15:55:02,564:INFO:SubProcess create_model() called ==================================
2026-01-29 15:55:02,564:INFO:Initializing create_model()
2026-01-29 15:55:02,565:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024870C3D290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0005, 'max_features': 1.0, 'max_depth': 3, 'criterion': 'gini'})
2026-01-29 15:55:02,566:INFO:Checking exceptions
2026-01-29 15:55:02,566:INFO:Importing libraries
2026-01-29 15:55:02,567:INFO:Copying training dataset
2026-01-29 15:55:02,706:INFO:Defining folds
2026-01-29 15:55:02,706:INFO:Declaring metric variables
2026-01-29 15:55:02,724:INFO:Importing untrained model
2026-01-29 15:55:02,724:INFO:Declaring custom model
2026-01-29 15:55:02,729:INFO:Decision Tree Classifier Imported successfully
2026-01-29 15:55:02,737:INFO:Starting cross validation
2026-01-29 15:55:02,738:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:55:03,450:INFO:Calculating mean and std
2026-01-29 15:55:03,452:INFO:Creating metrics dataframe
2026-01-29 15:55:03,458:INFO:Finalizing model
2026-01-29 15:55:03,607:INFO:Uploading results into container
2026-01-29 15:55:03,609:INFO:Uploading model into container now
2026-01-29 15:55:03,609:INFO:_master_model_container: 20
2026-01-29 15:55:03,609:INFO:_display_container: 5
2026-01-29 15:55:03,610:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 15:55:03,610:INFO:create_model() successfully completed......................................
2026-01-29 15:55:03,874:INFO:SubProcess create_model() end ==================================
2026-01-29 15:55:03,874:INFO:choose_better activated
2026-01-29 15:55:03,880:INFO:SubProcess create_model() called ==================================
2026-01-29 15:55:03,881:INFO:Initializing create_model()
2026-01-29 15:55:03,881:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:55:03,882:INFO:Checking exceptions
2026-01-29 15:55:03,884:INFO:Importing libraries
2026-01-29 15:55:03,884:INFO:Copying training dataset
2026-01-29 15:55:03,986:INFO:Defining folds
2026-01-29 15:55:03,986:INFO:Declaring metric variables
2026-01-29 15:55:03,986:INFO:Importing untrained model
2026-01-29 15:55:03,986:INFO:Declaring custom model
2026-01-29 15:55:03,986:INFO:Decision Tree Classifier Imported successfully
2026-01-29 15:55:03,987:INFO:Starting cross validation
2026-01-29 15:55:03,987:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:55:04,751:INFO:Calculating mean and std
2026-01-29 15:55:04,751:INFO:Creating metrics dataframe
2026-01-29 15:55:04,758:INFO:Finalizing model
2026-01-29 15:55:04,852:INFO:Uploading results into container
2026-01-29 15:55:04,853:INFO:Uploading model into container now
2026-01-29 15:55:04,853:INFO:_master_model_container: 21
2026-01-29 15:55:04,853:INFO:_display_container: 6
2026-01-29 15:55:04,854:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 15:55:04,854:INFO:create_model() successfully completed......................................
2026-01-29 15:55:05,120:INFO:SubProcess create_model() end ==================================
2026-01-29 15:55:05,122:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5369
2026-01-29 15:55:05,123:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5366
2026-01-29 15:55:05,124:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-29 15:55:05,124:INFO:choose_better completed
2026-01-29 15:55:05,125:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 15:55:05,142:INFO:_master_model_container: 21
2026-01-29 15:55:05,142:INFO:_display_container: 5
2026-01-29 15:55:05,144:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 15:55:05,144:INFO:tune_model() successfully completed......................................
2026-01-29 15:55:05,552:INFO:Initializing evaluate_model()
2026-01-29 15:55:05,555:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 15:55:05,613:INFO:Initializing plot_model()
2026-01-29 15:55:05,614:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:55:05,614:INFO:Checking exceptions
2026-01-29 15:55:05,661:INFO:Preloading libraries
2026-01-29 15:55:05,661:INFO:Copying training dataset
2026-01-29 15:55:05,661:INFO:Plot type: pipeline
2026-01-29 15:55:05,825:INFO:Visual Rendered Successfully
2026-01-29 15:55:06,016:INFO:plot_model() successfully completed......................................
2026-01-29 15:55:06,019:INFO:Initializing evaluate_model()
2026-01-29 15:55:06,019:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 15:55:06,050:INFO:Initializing plot_model()
2026-01-29 15:55:06,051:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:55:06,051:INFO:Checking exceptions
2026-01-29 15:55:06,082:INFO:Preloading libraries
2026-01-29 15:55:06,082:INFO:Copying training dataset
2026-01-29 15:55:06,082:INFO:Plot type: pipeline
2026-01-29 15:55:06,148:INFO:Visual Rendered Successfully
2026-01-29 15:55:06,324:INFO:plot_model() successfully completed......................................
2026-01-29 15:55:06,326:INFO:Initializing evaluate_model()
2026-01-29 15:55:06,326:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 15:55:06,370:INFO:Initializing plot_model()
2026-01-29 15:55:06,371:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:55:06,371:INFO:Checking exceptions
2026-01-29 15:55:06,408:INFO:Preloading libraries
2026-01-29 15:55:06,408:INFO:Copying training dataset
2026-01-29 15:55:06,408:INFO:Plot type: pipeline
2026-01-29 15:55:06,476:INFO:Visual Rendered Successfully
2026-01-29 15:55:06,656:INFO:plot_model() successfully completed......................................
2026-01-29 15:55:06,662:INFO:Initializing predict_model()
2026-01-29 15:55:06,662:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000248048BC720>)
2026-01-29 15:55:06,662:INFO:Checking exceptions
2026-01-29 15:55:06,662:INFO:Preloading libraries
2026-01-29 15:55:06,664:INFO:Set up data.
2026-01-29 15:55:06,673:INFO:Set up index.
2026-01-29 15:55:07,155:INFO:Initializing predict_model()
2026-01-29 15:55:07,155:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024810D7FC40>)
2026-01-29 15:55:07,155:INFO:Checking exceptions
2026-01-29 15:55:07,155:INFO:Preloading libraries
2026-01-29 15:55:07,158:INFO:Set up data.
2026-01-29 15:55:07,164:INFO:Set up index.
2026-01-29 15:55:07,640:INFO:Initializing predict_model()
2026-01-29 15:55:07,640:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000248048BC720>)
2026-01-29 15:55:07,640:INFO:Checking exceptions
2026-01-29 15:55:07,640:INFO:Preloading libraries
2026-01-29 15:55:07,640:INFO:Set up data.
2026-01-29 15:55:07,640:INFO:Set up index.
2026-01-29 15:55:08,108:INFO:Initializing plot_model()
2026-01-29 15:55:08,109:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-29 15:55:08,109:INFO:Checking exceptions
2026-01-29 15:55:08,132:INFO:Preloading libraries
2026-01-29 15:55:08,132:INFO:Copying training dataset
2026-01-29 15:55:08,132:INFO:Plot type: feature
2026-01-29 15:55:08,386:INFO:Visual Rendered Successfully
2026-01-29 15:55:08,561:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:15,782:INFO:Initializing plot_model()
2026-01-29 15:57:15,783:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=dimension, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:15,783:INFO:Checking exceptions
2026-01-29 15:57:15,812:INFO:Preloading libraries
2026-01-29 15:57:15,812:INFO:Copying training dataset
2026-01-29 15:57:15,812:INFO:Plot type: dimension
2026-01-29 15:57:15,933:INFO:Fitting StandardScaler()
2026-01-29 15:57:16,020:INFO:Fitting PCA()
2026-01-29 15:57:16,274:INFO:Fitting & Transforming Model
2026-01-29 15:57:16,291:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\yellowbrick\features\radviz.py:199: RuntimeWarning: invalid value encountered in divide

2026-01-29 15:57:21,111:INFO:Visual Rendered Successfully
2026-01-29 15:57:21,307:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:21,319:INFO:Initializing plot_model()
2026-01-29 15:57:21,319:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:21,319:INFO:Checking exceptions
2026-01-29 15:57:21,340:INFO:Preloading libraries
2026-01-29 15:57:21,340:INFO:Copying training dataset
2026-01-29 15:57:21,340:INFO:Plot type: pipeline
2026-01-29 15:57:21,393:INFO:Visual Rendered Successfully
2026-01-29 15:57:21,588:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:27,131:INFO:Initializing plot_model()
2026-01-29 15:57:27,132:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=calibration, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:27,132:INFO:Checking exceptions
2026-01-29 15:57:27,152:INFO:Preloading libraries
2026-01-29 15:57:27,152:INFO:Copying training dataset
2026-01-29 15:57:27,152:INFO:Plot type: calibration
2026-01-29 15:57:27,159:INFO:Scoring test/hold-out set
2026-01-29 15:57:27,297:INFO:Visual Rendered Successfully
2026-01-29 15:57:27,504:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:28,477:INFO:Initializing plot_model()
2026-01-29 15:57:28,477:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:28,477:INFO:Checking exceptions
2026-01-29 15:57:28,499:INFO:Preloading libraries
2026-01-29 15:57:28,499:INFO:Copying training dataset
2026-01-29 15:57:28,499:INFO:Plot type: pipeline
2026-01-29 15:57:28,547:INFO:Visual Rendered Successfully
2026-01-29 15:57:28,750:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:29,658:INFO:Initializing plot_model()
2026-01-29 15:57:29,658:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=calibration, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:29,659:INFO:Checking exceptions
2026-01-29 15:57:29,684:INFO:Preloading libraries
2026-01-29 15:57:29,684:INFO:Copying training dataset
2026-01-29 15:57:29,684:INFO:Plot type: calibration
2026-01-29 15:57:29,691:INFO:Scoring test/hold-out set
2026-01-29 15:57:29,825:INFO:Visual Rendered Successfully
2026-01-29 15:57:30,020:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:33,354:INFO:Initializing plot_model()
2026-01-29 15:57:33,356:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=dimension, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:33,356:INFO:Checking exceptions
2026-01-29 15:57:33,377:INFO:Preloading libraries
2026-01-29 15:57:33,377:INFO:Copying training dataset
2026-01-29 15:57:33,377:INFO:Plot type: dimension
2026-01-29 15:57:33,443:INFO:Fitting StandardScaler()
2026-01-29 15:57:33,513:INFO:Fitting PCA()
2026-01-29 15:57:33,756:INFO:Fitting & Transforming Model
2026-01-29 15:57:33,771:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\yellowbrick\features\radviz.py:199: RuntimeWarning: invalid value encountered in divide

2026-01-29 15:57:41,864:INFO:Visual Rendered Successfully
2026-01-29 15:57:42,103:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:42,136:INFO:Initializing plot_model()
2026-01-29 15:57:42,136:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=tree, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:42,136:INFO:Checking exceptions
2026-01-29 15:57:43,864:INFO:Initializing plot_model()
2026-01-29 15:57:43,864:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=learning, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:43,864:INFO:Checking exceptions
2026-01-29 15:57:43,884:INFO:Preloading libraries
2026-01-29 15:57:43,885:INFO:Copying training dataset
2026-01-29 15:57:43,885:INFO:Plot type: learning
2026-01-29 15:57:44,051:INFO:Fitting Model
2026-01-29 15:57:51,354:INFO:Visual Rendered Successfully
2026-01-29 15:57:51,565:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:51,615:INFO:Initializing plot_model()
2026-01-29 15:57:51,615:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=calibration, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:51,615:INFO:Checking exceptions
2026-01-29 15:57:51,646:INFO:Preloading libraries
2026-01-29 15:57:51,646:INFO:Copying training dataset
2026-01-29 15:57:51,646:INFO:Plot type: calibration
2026-01-29 15:57:51,655:INFO:Scoring test/hold-out set
2026-01-29 15:57:51,848:INFO:Visual Rendered Successfully
2026-01-29 15:57:52,080:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:53,370:INFO:Initializing plot_model()
2026-01-29 15:57:53,371:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:53,371:INFO:Checking exceptions
2026-01-29 15:57:53,391:INFO:Preloading libraries
2026-01-29 15:57:53,391:INFO:Copying training dataset
2026-01-29 15:57:53,391:INFO:Plot type: feature
2026-01-29 15:57:53,580:INFO:Visual Rendered Successfully
2026-01-29 15:57:53,778:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:55,745:INFO:Initializing plot_model()
2026-01-29 15:57:55,745:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature_all, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:55,745:INFO:Checking exceptions
2026-01-29 15:57:55,770:INFO:Preloading libraries
2026-01-29 15:57:55,770:INFO:Copying training dataset
2026-01-29 15:57:55,770:INFO:Plot type: feature_all
2026-01-29 15:57:56,029:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\matplotlib\_tight_bbox.py:67: RuntimeWarning: divide by zero encountered in scalar divide

2026-01-29 15:57:56,029:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\matplotlib\_tight_bbox.py:68: RuntimeWarning: divide by zero encountered in scalar divide

2026-01-29 15:57:56,029:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\matplotlib\patches.py:739: RuntimeWarning: invalid value encountered in scalar add

2026-01-29 15:57:56,029:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\matplotlib\transforms.py:2050: RuntimeWarning: invalid value encountered in scalar add

2026-01-29 15:57:56,046:INFO:Visual Rendered Successfully
2026-01-29 15:57:56,254:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:59,486:INFO:Initializing plot_model()
2026-01-29 15:57:59,487:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=boundary, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:59,487:INFO:Checking exceptions
2026-01-29 15:57:59,514:INFO:Preloading libraries
2026-01-29 15:57:59,514:INFO:Copying training dataset
2026-01-29 15:57:59,514:INFO:Plot type: boundary
2026-01-29 15:57:59,620:INFO:Fitting StandardScaler()
2026-01-29 15:57:59,634:INFO:Fitting PCA()
2026-01-29 15:57:59,813:INFO:Fitting Model
2026-01-29 15:58:01,610:INFO:Visual Rendered Successfully
2026-01-29 15:58:01,860:INFO:plot_model() successfully completed......................................
2026-01-29 15:58:03,737:INFO:Initializing plot_model()
2026-01-29 15:58:03,738:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=gain, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:58:03,739:INFO:Checking exceptions
2026-01-29 15:58:03,761:INFO:Preloading libraries
2026-01-29 15:58:03,761:INFO:Copying training dataset
2026-01-29 15:58:03,761:INFO:Plot type: gain
2026-01-29 15:58:03,761:INFO:Generating predictions / predict_proba on X_test
2026-01-29 15:58:03,925:INFO:Visual Rendered Successfully
2026-01-29 15:58:04,113:INFO:plot_model() successfully completed......................................
2026-01-29 15:58:05,457:INFO:Initializing plot_model()
2026-01-29 15:58:05,457:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=tree, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:58:05,457:INFO:Checking exceptions
2026-01-29 15:58:06,613:INFO:Initializing plot_model()
2026-01-29 15:58:06,613:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=learning, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:58:06,613:INFO:Checking exceptions
2026-01-29 15:58:06,633:INFO:Preloading libraries
2026-01-29 15:58:06,633:INFO:Copying training dataset
2026-01-29 15:58:06,633:INFO:Plot type: learning
2026-01-29 15:58:06,829:INFO:Fitting Model
2026-01-29 15:58:13,907:INFO:Visual Rendered Successfully
2026-01-29 15:58:14,118:INFO:plot_model() successfully completed......................................
2026-01-29 15:58:14,128:INFO:Initializing plot_model()
2026-01-29 15:58:14,128:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=rfe, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:58:14,128:INFO:Checking exceptions
2026-01-29 15:58:14,166:INFO:Preloading libraries
2026-01-29 15:58:14,166:INFO:Copying training dataset
2026-01-29 15:58:14,166:INFO:Plot type: rfe
2026-01-29 15:58:14,382:INFO:Fitting Model
2026-01-29 15:58:19,436:INFO:Visual Rendered Successfully
2026-01-29 15:58:19,632:INFO:plot_model() successfully completed......................................
2026-01-29 15:58:33,959:INFO:Initializing plot_model()
2026-01-29 15:58:33,959:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=gain, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:58:33,959:INFO:Checking exceptions
2026-01-29 15:58:33,999:INFO:Preloading libraries
2026-01-29 15:58:34,000:INFO:Copying training dataset
2026-01-29 15:58:34,000:INFO:Plot type: gain
2026-01-29 15:58:34,000:INFO:Generating predictions / predict_proba on X_test
2026-01-29 15:58:34,216:INFO:Visual Rendered Successfully
2026-01-29 15:58:34,430:INFO:plot_model() successfully completed......................................
2026-01-29 15:58:36,177:INFO:Initializing plot_model()
2026-01-29 15:58:36,177:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=lift, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:58:36,177:INFO:Checking exceptions
2026-01-29 15:58:36,199:INFO:Preloading libraries
2026-01-29 15:58:36,199:INFO:Copying training dataset
2026-01-29 15:58:36,199:INFO:Plot type: lift
2026-01-29 15:58:36,199:INFO:Generating predictions / predict_proba on X_test
2026-01-29 15:58:36,361:INFO:Visual Rendered Successfully
2026-01-29 15:58:36,563:INFO:plot_model() successfully completed......................................
2026-01-29 15:58:55,094:INFO:Initializing plot_model()
2026-01-29 15:58:55,094:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=learning, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:58:55,094:INFO:Checking exceptions
2026-01-29 15:58:55,121:INFO:Preloading libraries
2026-01-29 15:58:55,121:INFO:Copying training dataset
2026-01-29 15:58:55,121:INFO:Plot type: learning
2026-01-29 15:58:55,330:INFO:Fitting Model
2026-01-29 15:58:56,460:INFO:Visual Rendered Successfully
2026-01-29 15:58:56,670:INFO:plot_model() successfully completed......................................
2026-01-29 15:59:04,839:INFO:Initializing plot_model()
2026-01-29 15:59:04,839:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), plot=learning, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:59:04,839:INFO:Checking exceptions
2026-01-29 15:59:04,870:INFO:Preloading libraries
2026-01-29 15:59:04,870:INFO:Copying training dataset
2026-01-29 15:59:04,870:INFO:Plot type: learning
2026-01-29 15:59:05,056:INFO:Fitting Model
2026-01-29 15:59:06,092:INFO:Visual Rendered Successfully
2026-01-29 15:59:06,293:INFO:plot_model() successfully completed......................................
2026-01-29 16:03:10,077:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\1833453759.py:18: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-29 16:03:12,331:INFO:PyCaret ClassificationExperiment
2026-01-29 16:03:12,332:INFO:Logging name: clf-default-name
2026-01-29 16:03:12,332:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-29 16:03:12,332:INFO:version 3.3.2
2026-01-29 16:03:12,332:INFO:Initializing setup()
2026-01-29 16:03:12,332:INFO:self.USI: e0d6
2026-01-29 16:03:12,332:INFO:self._variable_keys: {'X_test', 'fold_groups_param', 'pipeline', 'fix_imbalance', 'exp_name_log', 'data', 'y_test', 'seed', 'fold_shuffle_param', 'n_jobs_param', 'is_multiclass', 'gpu_n_jobs_param', 'memory', 'log_plots_param', 'logging_param', 'idx', 'y', 'target_param', 'fold_generator', 'y_train', 'gpu_param', 'USI', 'exp_id', '_available_plots', 'X', 'X_train', 'html_param', '_ml_usecase'}
2026-01-29 16:03:12,332:INFO:Checking environment
2026-01-29 16:03:12,332:INFO:python_version: 3.11.11
2026-01-29 16:03:12,333:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-29 16:03:12,333:INFO:machine: AMD64
2026-01-29 16:03:12,334:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-29 16:03:12,334:INFO:Memory: svmem(total=34009374720, available=12534964224, percent=63.1, used=21474410496, free=12534964224)
2026-01-29 16:03:12,334:INFO:Physical Core: 12
2026-01-29 16:03:12,334:INFO:Logical Core: 16
2026-01-29 16:03:12,334:INFO:Checking libraries
2026-01-29 16:03:12,334:INFO:System:
2026-01-29 16:03:12,334:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-29 16:03:12,334:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-29 16:03:12,335:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-29 16:03:12,335:INFO:PyCaret required dependencies:
2026-01-29 16:03:12,335:INFO:                 pip: 25.0
2026-01-29 16:03:12,335:INFO:          setuptools: 75.8.0
2026-01-29 16:03:12,335:INFO:             pycaret: 3.3.2
2026-01-29 16:03:12,335:INFO:             IPython: 9.9.0
2026-01-29 16:03:12,335:INFO:          ipywidgets: 8.1.8
2026-01-29 16:03:12,335:INFO:                tqdm: 4.67.1
2026-01-29 16:03:12,335:INFO:               numpy: 1.26.4
2026-01-29 16:03:12,335:INFO:              pandas: 2.1.4
2026-01-29 16:03:12,335:INFO:              jinja2: 3.1.6
2026-01-29 16:03:12,335:INFO:               scipy: 1.11.4
2026-01-29 16:03:12,335:INFO:              joblib: 1.3.2
2026-01-29 16:03:12,335:INFO:             sklearn: 1.4.2
2026-01-29 16:03:12,335:INFO:                pyod: 2.0.6
2026-01-29 16:03:12,335:INFO:            imblearn: 0.14.1
2026-01-29 16:03:12,335:INFO:   category_encoders: 2.7.0
2026-01-29 16:03:12,335:INFO:            lightgbm: 4.6.0
2026-01-29 16:03:12,335:INFO:               numba: 0.62.1
2026-01-29 16:03:12,335:INFO:            requests: 2.32.3
2026-01-29 16:03:12,335:INFO:          matplotlib: 3.7.5
2026-01-29 16:03:12,336:INFO:          scikitplot: 0.3.7
2026-01-29 16:03:12,336:INFO:         yellowbrick: 1.5
2026-01-29 16:03:12,336:INFO:              plotly: 5.24.1
2026-01-29 16:03:12,336:INFO:    plotly-resampler: Not installed
2026-01-29 16:03:12,336:INFO:             kaleido: 1.2.0
2026-01-29 16:03:12,336:INFO:           schemdraw: 0.15
2026-01-29 16:03:12,336:INFO:         statsmodels: 0.14.6
2026-01-29 16:03:12,336:INFO:              sktime: 0.26.0
2026-01-29 16:03:12,336:INFO:               tbats: 1.1.3
2026-01-29 16:03:12,336:INFO:            pmdarima: 2.0.4
2026-01-29 16:03:12,336:INFO:              psutil: 7.2.1
2026-01-29 16:03:12,336:INFO:          markupsafe: 3.0.3
2026-01-29 16:03:12,336:INFO:             pickle5: Not installed
2026-01-29 16:03:12,336:INFO:         cloudpickle: 3.0.0
2026-01-29 16:03:12,336:INFO:         deprecation: 2.1.0
2026-01-29 16:03:12,336:INFO:              xxhash: 3.6.0
2026-01-29 16:03:12,336:INFO:           wurlitzer: Not installed
2026-01-29 16:03:12,336:INFO:PyCaret optional dependencies:
2026-01-29 16:03:12,336:INFO:                shap: 0.44.1
2026-01-29 16:03:12,337:INFO:           interpret: 0.7.3
2026-01-29 16:03:12,338:INFO:                umap: 0.5.7
2026-01-29 16:03:12,338:INFO:     ydata_profiling: 4.18.1
2026-01-29 16:03:12,339:INFO:  explainerdashboard: 0.5.1
2026-01-29 16:03:12,339:INFO:             autoviz: Not installed
2026-01-29 16:03:12,339:INFO:           fairlearn: 0.7.0
2026-01-29 16:03:12,339:INFO:          deepchecks: Not installed
2026-01-29 16:03:12,339:INFO:             xgboost: Not installed
2026-01-29 16:03:12,339:INFO:            catboost: 1.2.8
2026-01-29 16:03:12,339:INFO:              kmodes: 0.12.2
2026-01-29 16:03:12,339:INFO:             mlxtend: 0.23.4
2026-01-29 16:03:12,339:INFO:       statsforecast: 1.5.0
2026-01-29 16:03:12,339:INFO:        tune_sklearn: Not installed
2026-01-29 16:03:12,339:INFO:                 ray: Not installed
2026-01-29 16:03:12,341:INFO:            hyperopt: 0.2.7
2026-01-29 16:03:12,341:INFO:              optuna: 4.6.0
2026-01-29 16:03:12,341:INFO:               skopt: 0.10.2
2026-01-29 16:03:12,341:INFO:              mlflow: 3.8.1
2026-01-29 16:03:12,341:INFO:              gradio: 6.3.0
2026-01-29 16:03:12,341:INFO:             fastapi: 0.128.0
2026-01-29 16:03:12,341:INFO:             uvicorn: 0.40.0
2026-01-29 16:03:12,342:INFO:              m2cgen: 0.10.0
2026-01-29 16:03:12,342:INFO:           evidently: 0.4.40
2026-01-29 16:03:12,342:INFO:               fugue: 0.8.7
2026-01-29 16:03:12,342:INFO:           streamlit: Not installed
2026-01-29 16:03:12,342:INFO:             prophet: Not installed
2026-01-29 16:03:12,342:INFO:None
2026-01-29 16:03:12,342:INFO:Set up data.
2026-01-29 16:03:12,377:INFO:Set up folding strategy.
2026-01-29 16:03:12,377:INFO:Set up train/test split.
2026-01-29 16:03:12,487:INFO:Set up index.
2026-01-29 16:03:12,495:INFO:Assigning column types.
2026-01-29 16:03:12,512:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-29 16:03:12,546:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:03:12,546:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:03:12,564:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:03:12,564:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:03:12,585:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:03:12,585:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:03:12,613:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:03:12,613:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:03:12,614:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-29 16:03:12,634:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:03:12,653:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:03:12,653:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:03:12,684:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:03:12,703:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:03:12,709:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:03:12,709:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-29 16:03:12,753:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:03:12,753:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:03:12,803:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:03:12,803:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:03:12,808:INFO:Preparing preprocessing pipeline...
2026-01-29 16:03:12,815:INFO:Set up simple imputation.
2026-01-29 16:03:12,816:INFO:Set up feature normalization.
2026-01-29 16:03:12,902:INFO:Finished creating preprocessing pipeline.
2026-01-29 16:03:12,914:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-29 16:03:12,914:INFO:Creating final display dataframe.
2026-01-29 16:03:13,181:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape       (429278, 4)
4        Transformed data shape       (429278, 4)
5   Transformed train set shape       (343422, 4)
6    Transformed test set shape        (85856, 4)
7               Ignore features                58
8              Numeric features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                 5
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              e0d6
2026-01-29 16:03:13,230:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:03:13,230:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:03:13,287:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:03:13,289:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:03:13,291:INFO:setup() successfully completed in 0.97s...............
2026-01-29 16:03:13,291:INFO:Initializing compare_models()
2026-01-29 16:03:13,291:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002481F5FA790>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002481F5FA790>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-29 16:03:13,293:INFO:Checking exceptions
2026-01-29 16:03:13,333:INFO:Preparing display monitor
2026-01-29 16:03:13,354:INFO:Initializing Logistic Regression
2026-01-29 16:03:13,355:INFO:Total runtime is 7.474422454833985e-06 minutes
2026-01-29 16:03:13,360:INFO:SubProcess create_model() called ==================================
2026-01-29 16:03:13,360:INFO:Initializing create_model()
2026-01-29 16:03:13,360:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002481F5FA790>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002480EE11E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:03:13,360:INFO:Checking exceptions
2026-01-29 16:03:13,361:INFO:Importing libraries
2026-01-29 16:03:13,361:INFO:Copying training dataset
2026-01-29 16:03:13,481:INFO:Defining folds
2026-01-29 16:03:13,482:INFO:Declaring metric variables
2026-01-29 16:03:13,485:INFO:Importing untrained model
2026-01-29 16:03:13,489:INFO:Logistic Regression Imported successfully
2026-01-29 16:03:13,497:INFO:Starting cross validation
2026-01-29 16:03:13,498:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:03:14,246:INFO:Calculating mean and std
2026-01-29 16:03:14,247:INFO:Creating metrics dataframe
2026-01-29 16:03:14,249:INFO:Uploading results into container
2026-01-29 16:03:14,249:INFO:Uploading model into container now
2026-01-29 16:03:14,250:INFO:_master_model_container: 1
2026-01-29 16:03:14,250:INFO:_display_container: 2
2026-01-29 16:03:14,250:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:03:14,250:INFO:create_model() successfully completed......................................
2026-01-29 16:03:14,536:INFO:SubProcess create_model() end ==================================
2026-01-29 16:03:14,536:INFO:Creating metrics dataframe
2026-01-29 16:03:14,543:INFO:Initializing K Neighbors Classifier
2026-01-29 16:03:14,544:INFO:Total runtime is 0.019810458024342857 minutes
2026-01-29 16:03:14,547:INFO:SubProcess create_model() called ==================================
2026-01-29 16:03:14,548:INFO:Initializing create_model()
2026-01-29 16:03:14,548:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002481F5FA790>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002480EE11E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:03:14,548:INFO:Checking exceptions
2026-01-29 16:03:14,548:INFO:Importing libraries
2026-01-29 16:03:14,548:INFO:Copying training dataset
2026-01-29 16:03:14,649:INFO:Defining folds
2026-01-29 16:03:14,649:INFO:Declaring metric variables
2026-01-29 16:03:14,656:INFO:Importing untrained model
2026-01-29 16:03:14,660:INFO:K Neighbors Classifier Imported successfully
2026-01-29 16:03:14,666:INFO:Starting cross validation
2026-01-29 16:03:14,667:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:09:45,976:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\2961347337.py:18: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-29 16:09:47,884:INFO:PyCaret ClassificationExperiment
2026-01-29 16:09:47,884:INFO:Logging name: clf-default-name
2026-01-29 16:09:47,885:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-29 16:09:47,885:INFO:version 3.3.2
2026-01-29 16:09:47,885:INFO:Initializing setup()
2026-01-29 16:09:47,885:INFO:self.USI: a7a0
2026-01-29 16:09:47,885:INFO:self._variable_keys: {'X_test', 'fold_groups_param', 'pipeline', 'fix_imbalance', 'exp_name_log', 'data', 'y_test', 'seed', 'fold_shuffle_param', 'n_jobs_param', 'is_multiclass', 'gpu_n_jobs_param', 'memory', 'log_plots_param', 'logging_param', 'idx', 'y', 'target_param', 'fold_generator', 'y_train', 'gpu_param', 'USI', 'exp_id', '_available_plots', 'X', 'X_train', 'html_param', '_ml_usecase'}
2026-01-29 16:09:47,886:INFO:Checking environment
2026-01-29 16:09:47,886:INFO:python_version: 3.11.11
2026-01-29 16:09:47,887:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-29 16:09:47,887:INFO:machine: AMD64
2026-01-29 16:09:47,887:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-29 16:09:47,887:INFO:Memory: svmem(total=34009374720, available=15785549824, percent=53.6, used=18223824896, free=15785549824)
2026-01-29 16:09:47,887:INFO:Physical Core: 12
2026-01-29 16:09:47,887:INFO:Logical Core: 16
2026-01-29 16:09:47,887:INFO:Checking libraries
2026-01-29 16:09:47,887:INFO:System:
2026-01-29 16:09:47,887:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-29 16:09:47,887:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-29 16:09:47,887:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-29 16:09:47,887:INFO:PyCaret required dependencies:
2026-01-29 16:09:47,887:INFO:                 pip: 25.0
2026-01-29 16:09:47,888:INFO:          setuptools: 75.8.0
2026-01-29 16:09:47,888:INFO:             pycaret: 3.3.2
2026-01-29 16:09:47,888:INFO:             IPython: 9.9.0
2026-01-29 16:09:47,888:INFO:          ipywidgets: 8.1.8
2026-01-29 16:09:47,888:INFO:                tqdm: 4.67.1
2026-01-29 16:09:47,888:INFO:               numpy: 1.26.4
2026-01-29 16:09:47,888:INFO:              pandas: 2.1.4
2026-01-29 16:09:47,888:INFO:              jinja2: 3.1.6
2026-01-29 16:09:47,888:INFO:               scipy: 1.11.4
2026-01-29 16:09:47,888:INFO:              joblib: 1.3.2
2026-01-29 16:09:47,888:INFO:             sklearn: 1.4.2
2026-01-29 16:09:47,888:INFO:                pyod: 2.0.6
2026-01-29 16:09:47,888:INFO:            imblearn: 0.14.1
2026-01-29 16:09:47,888:INFO:   category_encoders: 2.7.0
2026-01-29 16:09:47,888:INFO:            lightgbm: 4.6.0
2026-01-29 16:09:47,888:INFO:               numba: 0.62.1
2026-01-29 16:09:47,888:INFO:            requests: 2.32.3
2026-01-29 16:09:47,888:INFO:          matplotlib: 3.7.5
2026-01-29 16:09:47,888:INFO:          scikitplot: 0.3.7
2026-01-29 16:09:47,888:INFO:         yellowbrick: 1.5
2026-01-29 16:09:47,888:INFO:              plotly: 5.24.1
2026-01-29 16:09:47,888:INFO:    plotly-resampler: Not installed
2026-01-29 16:09:47,888:INFO:             kaleido: 1.2.0
2026-01-29 16:09:47,888:INFO:           schemdraw: 0.15
2026-01-29 16:09:47,888:INFO:         statsmodels: 0.14.6
2026-01-29 16:09:47,888:INFO:              sktime: 0.26.0
2026-01-29 16:09:47,888:INFO:               tbats: 1.1.3
2026-01-29 16:09:47,888:INFO:            pmdarima: 2.0.4
2026-01-29 16:09:47,888:INFO:              psutil: 7.2.1
2026-01-29 16:09:47,888:INFO:          markupsafe: 3.0.3
2026-01-29 16:09:47,889:INFO:             pickle5: Not installed
2026-01-29 16:09:47,889:INFO:         cloudpickle: 3.0.0
2026-01-29 16:09:47,889:INFO:         deprecation: 2.1.0
2026-01-29 16:09:47,889:INFO:              xxhash: 3.6.0
2026-01-29 16:09:47,889:INFO:           wurlitzer: Not installed
2026-01-29 16:09:47,889:INFO:PyCaret optional dependencies:
2026-01-29 16:09:47,889:INFO:                shap: 0.44.1
2026-01-29 16:09:47,889:INFO:           interpret: 0.7.3
2026-01-29 16:09:47,889:INFO:                umap: 0.5.7
2026-01-29 16:09:47,889:INFO:     ydata_profiling: 4.18.1
2026-01-29 16:09:47,889:INFO:  explainerdashboard: 0.5.1
2026-01-29 16:09:47,889:INFO:             autoviz: Not installed
2026-01-29 16:09:47,889:INFO:           fairlearn: 0.7.0
2026-01-29 16:09:47,889:INFO:          deepchecks: Not installed
2026-01-29 16:09:47,890:INFO:             xgboost: Not installed
2026-01-29 16:09:47,890:INFO:            catboost: 1.2.8
2026-01-29 16:09:47,890:INFO:              kmodes: 0.12.2
2026-01-29 16:09:47,890:INFO:             mlxtend: 0.23.4
2026-01-29 16:09:47,890:INFO:       statsforecast: 1.5.0
2026-01-29 16:09:47,890:INFO:        tune_sklearn: Not installed
2026-01-29 16:09:47,890:INFO:                 ray: Not installed
2026-01-29 16:09:47,890:INFO:            hyperopt: 0.2.7
2026-01-29 16:09:47,890:INFO:              optuna: 4.6.0
2026-01-29 16:09:47,890:INFO:               skopt: 0.10.2
2026-01-29 16:09:47,890:INFO:              mlflow: 3.8.1
2026-01-29 16:09:47,890:INFO:              gradio: 6.3.0
2026-01-29 16:09:47,890:INFO:             fastapi: 0.128.0
2026-01-29 16:09:47,890:INFO:             uvicorn: 0.40.0
2026-01-29 16:09:47,891:INFO:              m2cgen: 0.10.0
2026-01-29 16:09:47,891:INFO:           evidently: 0.4.40
2026-01-29 16:09:47,891:INFO:               fugue: 0.8.7
2026-01-29 16:09:47,891:INFO:           streamlit: Not installed
2026-01-29 16:09:47,891:INFO:             prophet: Not installed
2026-01-29 16:09:47,891:INFO:None
2026-01-29 16:09:47,891:INFO:Set up data.
2026-01-29 16:09:47,923:INFO:Set up folding strategy.
2026-01-29 16:09:47,923:INFO:Set up train/test split.
2026-01-29 16:09:48,043:INFO:Set up index.
2026-01-29 16:09:48,043:INFO:Assigning column types.
2026-01-29 16:09:48,060:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-29 16:09:48,093:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:09:48,093:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:09:48,110:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:09:48,110:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:09:48,160:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:09:48,161:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:09:48,183:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:09:48,184:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:09:48,184:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-29 16:09:48,219:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:09:48,241:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:09:48,241:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:09:48,277:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:09:48,298:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:09:48,298:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:09:48,299:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-29 16:09:48,347:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:09:48,347:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:09:48,409:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:09:48,410:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:09:48,410:INFO:Preparing preprocessing pipeline...
2026-01-29 16:09:48,410:INFO:Set up simple imputation.
2026-01-29 16:09:48,410:INFO:Set up feature normalization.
2026-01-29 16:09:48,510:INFO:Finished creating preprocessing pipeline.
2026-01-29 16:09:48,510:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-29 16:09:48,510:INFO:Creating final display dataframe.
2026-01-29 16:09:48,710:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape       (429278, 4)
4        Transformed data shape       (429278, 4)
5   Transformed train set shape       (343422, 4)
6    Transformed test set shape        (85856, 4)
7               Ignore features                58
8              Numeric features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                 3
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              a7a0
2026-01-29 16:09:48,767:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:09:48,767:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:09:48,826:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:09:48,826:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:09:48,831:INFO:setup() successfully completed in 0.95s...............
2026-01-29 16:09:48,831:INFO:Initializing compare_models()
2026-01-29 16:09:48,831:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-29 16:09:48,831:INFO:Checking exceptions
2026-01-29 16:09:48,860:INFO:Preparing display monitor
2026-01-29 16:09:48,876:INFO:Initializing Logistic Regression
2026-01-29 16:09:48,876:INFO:Total runtime is 0.0 minutes
2026-01-29 16:09:48,878:INFO:SubProcess create_model() called ==================================
2026-01-29 16:09:48,879:INFO:Initializing create_model()
2026-01-29 16:09:48,879:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816D43CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:09:48,879:INFO:Checking exceptions
2026-01-29 16:09:48,879:INFO:Importing libraries
2026-01-29 16:09:48,879:INFO:Copying training dataset
2026-01-29 16:09:48,949:INFO:Defining folds
2026-01-29 16:09:48,950:INFO:Declaring metric variables
2026-01-29 16:09:48,952:INFO:Importing untrained model
2026-01-29 16:09:48,954:INFO:Logistic Regression Imported successfully
2026-01-29 16:09:48,959:INFO:Starting cross validation
2026-01-29 16:09:48,960:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:09:55,362:INFO:Calculating mean and std
2026-01-29 16:09:55,362:INFO:Creating metrics dataframe
2026-01-29 16:09:55,362:INFO:Uploading results into container
2026-01-29 16:09:55,362:INFO:Uploading model into container now
2026-01-29 16:09:55,366:INFO:_master_model_container: 1
2026-01-29 16:09:55,366:INFO:_display_container: 2
2026-01-29 16:09:55,367:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:09:55,368:INFO:create_model() successfully completed......................................
2026-01-29 16:09:55,680:INFO:SubProcess create_model() end ==================================
2026-01-29 16:09:55,680:INFO:Creating metrics dataframe
2026-01-29 16:09:55,686:INFO:Initializing Decision Tree Classifier
2026-01-29 16:09:55,686:INFO:Total runtime is 0.11348706881205241 minutes
2026-01-29 16:09:55,690:INFO:SubProcess create_model() called ==================================
2026-01-29 16:09:55,690:INFO:Initializing create_model()
2026-01-29 16:09:55,691:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816D43CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:09:55,691:INFO:Checking exceptions
2026-01-29 16:09:55,691:INFO:Importing libraries
2026-01-29 16:09:55,691:INFO:Copying training dataset
2026-01-29 16:09:55,760:INFO:Defining folds
2026-01-29 16:09:55,760:INFO:Declaring metric variables
2026-01-29 16:09:55,760:INFO:Importing untrained model
2026-01-29 16:09:55,777:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:09:55,777:INFO:Starting cross validation
2026-01-29 16:09:55,777:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:10:00,720:INFO:Calculating mean and std
2026-01-29 16:10:00,725:INFO:Creating metrics dataframe
2026-01-29 16:10:00,731:INFO:Uploading results into container
2026-01-29 16:10:00,731:INFO:Uploading model into container now
2026-01-29 16:10:00,733:INFO:_master_model_container: 2
2026-01-29 16:10:00,734:INFO:_display_container: 2
2026-01-29 16:10:00,735:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:10:00,735:INFO:create_model() successfully completed......................................
2026-01-29 16:10:00,943:INFO:SubProcess create_model() end ==================================
2026-01-29 16:10:00,943:INFO:Creating metrics dataframe
2026-01-29 16:10:00,943:INFO:Initializing Random Forest Classifier
2026-01-29 16:10:00,943:INFO:Total runtime is 0.2011061708132426 minutes
2026-01-29 16:10:00,951:INFO:SubProcess create_model() called ==================================
2026-01-29 16:10:00,951:INFO:Initializing create_model()
2026-01-29 16:10:00,951:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816D43CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:10:00,951:INFO:Checking exceptions
2026-01-29 16:10:00,951:INFO:Importing libraries
2026-01-29 16:10:00,951:INFO:Copying training dataset
2026-01-29 16:10:01,011:INFO:Defining folds
2026-01-29 16:10:01,011:INFO:Declaring metric variables
2026-01-29 16:10:01,011:INFO:Importing untrained model
2026-01-29 16:10:01,011:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:10:01,026:INFO:Starting cross validation
2026-01-29 16:10:01,027:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:10:08,114:INFO:Calculating mean and std
2026-01-29 16:10:08,114:INFO:Creating metrics dataframe
2026-01-29 16:10:08,114:INFO:Uploading results into container
2026-01-29 16:10:08,114:INFO:Uploading model into container now
2026-01-29 16:10:08,114:INFO:_master_model_container: 3
2026-01-29 16:10:08,114:INFO:_display_container: 2
2026-01-29 16:10:08,114:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:10:08,114:INFO:create_model() successfully completed......................................
2026-01-29 16:10:08,309:INFO:SubProcess create_model() end ==================================
2026-01-29 16:10:08,309:INFO:Creating metrics dataframe
2026-01-29 16:10:08,326:INFO:Initializing Light Gradient Boosting Machine
2026-01-29 16:10:08,326:INFO:Total runtime is 0.32416341304779056 minutes
2026-01-29 16:10:08,326:INFO:SubProcess create_model() called ==================================
2026-01-29 16:10:08,326:INFO:Initializing create_model()
2026-01-29 16:10:08,326:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816D43CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:10:08,326:INFO:Checking exceptions
2026-01-29 16:10:08,326:INFO:Importing libraries
2026-01-29 16:10:08,326:INFO:Copying training dataset
2026-01-29 16:10:08,403:INFO:Defining folds
2026-01-29 16:10:08,403:INFO:Declaring metric variables
2026-01-29 16:10:08,406:INFO:Importing untrained model
2026-01-29 16:10:08,410:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-29 16:10:08,411:INFO:Starting cross validation
2026-01-29 16:10:08,411:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:10:15,067:INFO:Calculating mean and std
2026-01-29 16:10:15,067:INFO:Creating metrics dataframe
2026-01-29 16:10:15,071:INFO:Uploading results into container
2026-01-29 16:10:15,071:INFO:Uploading model into container now
2026-01-29 16:10:15,071:INFO:_master_model_container: 4
2026-01-29 16:10:15,071:INFO:_display_container: 2
2026-01-29 16:10:15,073:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-29 16:10:15,073:INFO:create_model() successfully completed......................................
2026-01-29 16:10:15,276:INFO:SubProcess create_model() end ==================================
2026-01-29 16:10:15,276:INFO:Creating metrics dataframe
2026-01-29 16:10:15,279:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-29 16:10:15,289:INFO:Initializing create_model()
2026-01-29 16:10:15,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:10:15,289:INFO:Checking exceptions
2026-01-29 16:10:15,294:INFO:Importing libraries
2026-01-29 16:10:15,294:INFO:Copying training dataset
2026-01-29 16:10:15,359:INFO:Defining folds
2026-01-29 16:10:15,359:INFO:Declaring metric variables
2026-01-29 16:10:15,359:INFO:Importing untrained model
2026-01-29 16:10:15,359:INFO:Declaring custom model
2026-01-29 16:10:15,359:INFO:Logistic Regression Imported successfully
2026-01-29 16:10:15,359:INFO:Cross validation set to False
2026-01-29 16:10:15,359:INFO:Fitting Model
2026-01-29 16:10:15,576:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:10:15,576:INFO:create_model() successfully completed......................................
2026-01-29 16:10:15,776:INFO:Initializing create_model()
2026-01-29 16:10:15,776:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:10:15,776:INFO:Checking exceptions
2026-01-29 16:10:15,787:INFO:Importing libraries
2026-01-29 16:10:15,787:INFO:Copying training dataset
2026-01-29 16:10:15,843:INFO:Defining folds
2026-01-29 16:10:15,843:INFO:Declaring metric variables
2026-01-29 16:10:15,843:INFO:Importing untrained model
2026-01-29 16:10:15,843:INFO:Declaring custom model
2026-01-29 16:10:15,843:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:10:15,843:INFO:Cross validation set to False
2026-01-29 16:10:15,843:INFO:Fitting Model
2026-01-29 16:10:15,909:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:10:15,909:INFO:create_model() successfully completed......................................
2026-01-29 16:10:16,110:INFO:Initializing create_model()
2026-01-29 16:10:16,110:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:10:16,124:INFO:Checking exceptions
2026-01-29 16:10:16,126:INFO:Importing libraries
2026-01-29 16:10:16,126:INFO:Copying training dataset
2026-01-29 16:10:16,185:INFO:Defining folds
2026-01-29 16:10:16,185:INFO:Declaring metric variables
2026-01-29 16:10:16,185:INFO:Importing untrained model
2026-01-29 16:10:16,185:INFO:Declaring custom model
2026-01-29 16:10:16,186:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:10:16,186:INFO:Cross validation set to False
2026-01-29 16:10:16,186:INFO:Fitting Model
2026-01-29 16:10:17,494:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:10:17,494:INFO:create_model() successfully completed......................................
2026-01-29 16:10:17,719:INFO:_master_model_container: 4
2026-01-29 16:10:17,719:INFO:_display_container: 2
2026-01-29 16:10:17,719:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2026-01-29 16:10:17,719:INFO:compare_models() successfully completed......................................
2026-01-29 16:10:17,719:INFO:Initializing tune_model()
2026-01-29 16:10:17,719:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:10:17,719:INFO:Checking exceptions
2026-01-29 16:10:17,761:INFO:Copying training dataset
2026-01-29 16:10:17,826:INFO:Checking base model
2026-01-29 16:10:17,827:INFO:Base model : Logistic Regression
2026-01-29 16:10:17,831:INFO:Declaring metric variables
2026-01-29 16:10:17,833:INFO:Defining Hyperparameters
2026-01-29 16:10:18,043:INFO:Tuning with n_jobs=-1
2026-01-29 16:10:18,043:INFO:Initializing RandomizedSearchCV
2026-01-29 16:10:24,819:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 5.682}
2026-01-29 16:10:24,819:INFO:Hyperparameter search completed
2026-01-29 16:10:24,819:INFO:SubProcess create_model() called ==================================
2026-01-29 16:10:24,826:INFO:Initializing create_model()
2026-01-29 16:10:24,826:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816DC4BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 5.682})
2026-01-29 16:10:24,827:INFO:Checking exceptions
2026-01-29 16:10:24,827:INFO:Importing libraries
2026-01-29 16:10:24,827:INFO:Copying training dataset
2026-01-29 16:10:24,893:INFO:Defining folds
2026-01-29 16:10:24,893:INFO:Declaring metric variables
2026-01-29 16:10:24,893:INFO:Importing untrained model
2026-01-29 16:10:24,893:INFO:Declaring custom model
2026-01-29 16:10:24,893:INFO:Logistic Regression Imported successfully
2026-01-29 16:10:24,909:INFO:Starting cross validation
2026-01-29 16:10:24,909:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:10:25,795:INFO:Calculating mean and std
2026-01-29 16:10:25,795:INFO:Creating metrics dataframe
2026-01-29 16:10:25,809:INFO:Finalizing model
2026-01-29 16:10:26,120:INFO:Uploading results into container
2026-01-29 16:10:26,121:INFO:Uploading model into container now
2026-01-29 16:10:26,122:INFO:_master_model_container: 5
2026-01-29 16:10:26,122:INFO:_display_container: 3
2026-01-29 16:10:26,122:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:10:26,122:INFO:create_model() successfully completed......................................
2026-01-29 16:10:26,343:INFO:SubProcess create_model() end ==================================
2026-01-29 16:10:26,343:INFO:choose_better activated
2026-01-29 16:10:26,343:INFO:SubProcess create_model() called ==================================
2026-01-29 16:10:26,343:INFO:Initializing create_model()
2026-01-29 16:10:26,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:10:26,343:INFO:Checking exceptions
2026-01-29 16:10:26,343:INFO:Importing libraries
2026-01-29 16:10:26,343:INFO:Copying training dataset
2026-01-29 16:10:26,424:INFO:Defining folds
2026-01-29 16:10:26,426:INFO:Declaring metric variables
2026-01-29 16:10:26,426:INFO:Importing untrained model
2026-01-29 16:10:26,426:INFO:Declaring custom model
2026-01-29 16:10:26,426:INFO:Logistic Regression Imported successfully
2026-01-29 16:10:26,426:INFO:Starting cross validation
2026-01-29 16:10:26,426:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:10:27,222:INFO:Calculating mean and std
2026-01-29 16:10:27,224:INFO:Creating metrics dataframe
2026-01-29 16:10:27,226:INFO:Finalizing model
2026-01-29 16:10:27,446:INFO:Uploading results into container
2026-01-29 16:10:27,460:INFO:Uploading model into container now
2026-01-29 16:10:27,460:INFO:_master_model_container: 6
2026-01-29 16:10:27,460:INFO:_display_container: 4
2026-01-29 16:10:27,460:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:10:27,460:INFO:create_model() successfully completed......................................
2026-01-29 16:10:27,659:INFO:SubProcess create_model() end ==================================
2026-01-29 16:10:27,659:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 16:10:27,659:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 16:10:27,659:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2026-01-29 16:10:27,659:INFO:choose_better completed
2026-01-29 16:10:27,659:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:10:27,676:INFO:_master_model_container: 6
2026-01-29 16:10:27,676:INFO:_display_container: 3
2026-01-29 16:10:27,676:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:10:27,676:INFO:tune_model() successfully completed......................................
2026-01-29 16:10:27,876:INFO:Initializing tune_model()
2026-01-29 16:10:27,876:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:10:27,876:INFO:Checking exceptions
2026-01-29 16:10:27,919:INFO:Copying training dataset
2026-01-29 16:10:28,002:INFO:Checking base model
2026-01-29 16:10:28,003:INFO:Base model : Decision Tree Classifier
2026-01-29 16:10:28,008:INFO:Declaring metric variables
2026-01-29 16:10:28,012:INFO:Defining Hyperparameters
2026-01-29 16:10:28,209:INFO:Tuning with n_jobs=-1
2026-01-29 16:10:28,209:INFO:Initializing RandomizedSearchCV
2026-01-29 16:10:29,211:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.0005, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 3, 'actual_estimator__criterion': 'gini'}
2026-01-29 16:10:29,211:INFO:Hyperparameter search completed
2026-01-29 16:10:29,211:INFO:SubProcess create_model() called ==================================
2026-01-29 16:10:29,211:INFO:Initializing create_model()
2026-01-29 16:10:29,211:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024871ADDC10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0005, 'max_features': 1.0, 'max_depth': 3, 'criterion': 'gini'})
2026-01-29 16:10:29,211:INFO:Checking exceptions
2026-01-29 16:10:29,211:INFO:Importing libraries
2026-01-29 16:10:29,211:INFO:Copying training dataset
2026-01-29 16:10:29,276:INFO:Defining folds
2026-01-29 16:10:29,276:INFO:Declaring metric variables
2026-01-29 16:10:29,276:INFO:Importing untrained model
2026-01-29 16:10:29,276:INFO:Declaring custom model
2026-01-29 16:10:29,276:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:10:29,293:INFO:Starting cross validation
2026-01-29 16:10:29,293:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:10:29,963:INFO:Calculating mean and std
2026-01-29 16:10:29,963:INFO:Creating metrics dataframe
2026-01-29 16:10:29,963:INFO:Finalizing model
2026-01-29 16:10:30,026:INFO:Uploading results into container
2026-01-29 16:10:30,026:INFO:Uploading model into container now
2026-01-29 16:10:30,026:INFO:_master_model_container: 7
2026-01-29 16:10:30,026:INFO:_display_container: 4
2026-01-29 16:10:30,026:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:10:30,026:INFO:create_model() successfully completed......................................
2026-01-29 16:10:30,264:INFO:SubProcess create_model() end ==================================
2026-01-29 16:10:30,264:INFO:choose_better activated
2026-01-29 16:10:30,276:INFO:SubProcess create_model() called ==================================
2026-01-29 16:10:30,276:INFO:Initializing create_model()
2026-01-29 16:10:30,276:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:10:30,276:INFO:Checking exceptions
2026-01-29 16:10:30,276:INFO:Importing libraries
2026-01-29 16:10:30,276:INFO:Copying training dataset
2026-01-29 16:10:30,400:INFO:Defining folds
2026-01-29 16:10:30,400:INFO:Declaring metric variables
2026-01-29 16:10:30,400:INFO:Importing untrained model
2026-01-29 16:10:30,400:INFO:Declaring custom model
2026-01-29 16:10:30,400:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:10:30,400:INFO:Starting cross validation
2026-01-29 16:10:30,400:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:10:31,146:INFO:Calculating mean and std
2026-01-29 16:10:31,147:INFO:Creating metrics dataframe
2026-01-29 16:10:31,148:INFO:Finalizing model
2026-01-29 16:10:31,226:INFO:Uploading results into container
2026-01-29 16:10:31,226:INFO:Uploading model into container now
2026-01-29 16:10:31,226:INFO:_master_model_container: 8
2026-01-29 16:10:31,226:INFO:_display_container: 5
2026-01-29 16:10:31,226:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:10:31,226:INFO:create_model() successfully completed......................................
2026-01-29 16:10:31,493:INFO:SubProcess create_model() end ==================================
2026-01-29 16:10:31,493:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5369
2026-01-29 16:10:31,493:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5366
2026-01-29 16:10:31,493:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-29 16:10:31,493:INFO:choose_better completed
2026-01-29 16:10:31,493:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:10:31,503:INFO:_master_model_container: 8
2026-01-29 16:10:31,503:INFO:_display_container: 4
2026-01-29 16:10:31,503:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:10:31,503:INFO:tune_model() successfully completed......................................
2026-01-29 16:10:31,709:INFO:Initializing tune_model()
2026-01-29 16:10:31,709:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:10:31,709:INFO:Checking exceptions
2026-01-29 16:10:31,743:INFO:Copying training dataset
2026-01-29 16:10:31,816:INFO:Checking base model
2026-01-29 16:10:31,816:INFO:Base model : Random Forest Classifier
2026-01-29 16:10:31,819:INFO:Declaring metric variables
2026-01-29 16:10:31,823:INFO:Defining Hyperparameters
2026-01-29 16:10:32,043:INFO:Tuning with n_jobs=-1
2026-01-29 16:10:32,043:INFO:Initializing RandomizedSearchCV
2026-01-29 16:10:58,903:INFO:best_params: {'actual_estimator__n_estimators': 120, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-29 16:10:58,904:INFO:Hyperparameter search completed
2026-01-29 16:10:58,904:INFO:SubProcess create_model() called ==================================
2026-01-29 16:10:58,904:INFO:Initializing create_model()
2026-01-29 16:10:58,905:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024870A8CF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 120, 'min_samples_split': 5, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': True})
2026-01-29 16:10:58,906:INFO:Checking exceptions
2026-01-29 16:10:58,906:INFO:Importing libraries
2026-01-29 16:10:58,906:INFO:Copying training dataset
2026-01-29 16:10:58,978:INFO:Defining folds
2026-01-29 16:10:58,978:INFO:Declaring metric variables
2026-01-29 16:10:58,981:INFO:Importing untrained model
2026-01-29 16:10:58,981:INFO:Declaring custom model
2026-01-29 16:10:58,981:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:10:58,993:INFO:Starting cross validation
2026-01-29 16:10:58,994:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:11:01,930:INFO:Calculating mean and std
2026-01-29 16:11:01,930:INFO:Creating metrics dataframe
2026-01-29 16:11:01,930:INFO:Finalizing model
2026-01-29 16:11:03,712:INFO:Uploading results into container
2026-01-29 16:11:03,712:INFO:Uploading model into container now
2026-01-29 16:11:03,712:INFO:_master_model_container: 9
2026-01-29 16:11:03,712:INFO:_display_container: 5
2026-01-29 16:11:03,712:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=120, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:11:03,712:INFO:create_model() successfully completed......................................
2026-01-29 16:11:03,960:INFO:SubProcess create_model() end ==================================
2026-01-29 16:11:03,960:INFO:choose_better activated
2026-01-29 16:11:03,975:INFO:SubProcess create_model() called ==================================
2026-01-29 16:11:03,975:INFO:Initializing create_model()
2026-01-29 16:11:03,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:11:03,975:INFO:Checking exceptions
2026-01-29 16:11:03,975:INFO:Importing libraries
2026-01-29 16:11:03,975:INFO:Copying training dataset
2026-01-29 16:11:04,045:INFO:Defining folds
2026-01-29 16:11:04,045:INFO:Declaring metric variables
2026-01-29 16:11:04,045:INFO:Importing untrained model
2026-01-29 16:11:04,045:INFO:Declaring custom model
2026-01-29 16:11:04,045:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:11:04,045:INFO:Starting cross validation
2026-01-29 16:11:04,045:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:11:06,566:INFO:Calculating mean and std
2026-01-29 16:11:06,566:INFO:Creating metrics dataframe
2026-01-29 16:11:06,566:INFO:Finalizing model
2026-01-29 16:11:08,046:INFO:Uploading results into container
2026-01-29 16:11:08,046:INFO:Uploading model into container now
2026-01-29 16:11:08,046:INFO:_master_model_container: 10
2026-01-29 16:11:08,046:INFO:_display_container: 6
2026-01-29 16:11:08,046:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:11:08,046:INFO:create_model() successfully completed......................................
2026-01-29 16:11:08,258:INFO:SubProcess create_model() end ==================================
2026-01-29 16:11:08,258:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.5369
2026-01-29 16:11:08,258:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=120, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.5369
2026-01-29 16:11:08,258:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-29 16:11:08,258:INFO:choose_better completed
2026-01-29 16:11:08,258:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:11:08,272:INFO:_master_model_container: 10
2026-01-29 16:11:08,272:INFO:_display_container: 5
2026-01-29 16:11:08,272:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:11:08,274:INFO:tune_model() successfully completed......................................
2026-01-29 16:11:08,491:INFO:Initializing evaluate_model()
2026-01-29 16:11:08,491:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:11:08,531:INFO:Initializing plot_model()
2026-01-29 16:11:08,531:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:11:08,532:INFO:Checking exceptions
2026-01-29 16:11:08,561:INFO:Preloading libraries
2026-01-29 16:11:08,561:INFO:Copying training dataset
2026-01-29 16:11:08,561:INFO:Plot type: pipeline
2026-01-29 16:11:08,628:INFO:Visual Rendered Successfully
2026-01-29 16:11:08,862:INFO:plot_model() successfully completed......................................
2026-01-29 16:11:08,866:INFO:Initializing evaluate_model()
2026-01-29 16:11:08,867:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:11:08,917:INFO:Initializing plot_model()
2026-01-29 16:11:08,918:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:11:08,918:INFO:Checking exceptions
2026-01-29 16:11:08,964:INFO:Preloading libraries
2026-01-29 16:11:08,964:INFO:Copying training dataset
2026-01-29 16:11:08,964:INFO:Plot type: pipeline
2026-01-29 16:11:09,024:INFO:Visual Rendered Successfully
2026-01-29 16:11:09,224:INFO:plot_model() successfully completed......................................
2026-01-29 16:11:09,240:INFO:Initializing evaluate_model()
2026-01-29 16:11:09,242:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:11:09,283:INFO:Initializing plot_model()
2026-01-29 16:11:09,283:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:11:09,283:INFO:Checking exceptions
2026-01-29 16:11:09,328:INFO:Preloading libraries
2026-01-29 16:11:09,346:INFO:Copying training dataset
2026-01-29 16:11:09,346:INFO:Plot type: pipeline
2026-01-29 16:11:09,412:INFO:Visual Rendered Successfully
2026-01-29 16:11:09,627:INFO:plot_model() successfully completed......................................
2026-01-29 16:11:09,636:INFO:Initializing predict_model()
2026-01-29 16:11:09,636:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024871470B80>)
2026-01-29 16:11:09,637:INFO:Checking exceptions
2026-01-29 16:11:09,637:INFO:Preloading libraries
2026-01-29 16:11:09,638:INFO:Set up data.
2026-01-29 16:11:09,647:INFO:Set up index.
2026-01-29 16:11:10,159:INFO:Initializing predict_model()
2026-01-29 16:11:10,159:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002480475F6A0>)
2026-01-29 16:11:10,159:INFO:Checking exceptions
2026-01-29 16:11:10,159:INFO:Preloading libraries
2026-01-29 16:11:10,175:INFO:Set up data.
2026-01-29 16:11:10,177:INFO:Set up index.
2026-01-29 16:11:10,729:INFO:Initializing predict_model()
2026-01-29 16:11:10,729:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024871470680>)
2026-01-29 16:11:10,729:INFO:Checking exceptions
2026-01-29 16:11:10,729:INFO:Preloading libraries
2026-01-29 16:11:10,731:INFO:Set up data.
2026-01-29 16:11:10,740:INFO:Set up index.
2026-01-29 16:11:11,434:INFO:Initializing plot_model()
2026-01-29 16:11:11,434:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-29 16:11:11,434:INFO:Checking exceptions
2026-01-29 16:11:11,460:INFO:Preloading libraries
2026-01-29 16:11:11,460:INFO:Copying training dataset
2026-01-29 16:11:11,460:INFO:Plot type: feature
2026-01-29 16:11:11,714:INFO:Visual Rendered Successfully
2026-01-29 16:11:11,931:INFO:plot_model() successfully completed......................................
2026-01-29 16:11:11,931:INFO:Initializing save_model()
2026-01-29 16:11:11,931:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=..\modelos\modelo_general, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-29 16:11:11,931:INFO:Adding model into prep_pipe
2026-01-29 16:13:57,407:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\1855575028.py:18: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-29 16:13:59,973:INFO:PyCaret ClassificationExperiment
2026-01-29 16:13:59,973:INFO:Logging name: clf-default-name
2026-01-29 16:13:59,986:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-29 16:13:59,986:INFO:version 3.3.2
2026-01-29 16:13:59,986:INFO:Initializing setup()
2026-01-29 16:13:59,986:INFO:self.USI: b0bf
2026-01-29 16:13:59,986:INFO:self._variable_keys: {'X_test', 'fold_groups_param', 'pipeline', 'fix_imbalance', 'exp_name_log', 'data', 'y_test', 'seed', 'fold_shuffle_param', 'n_jobs_param', 'is_multiclass', 'gpu_n_jobs_param', 'memory', 'log_plots_param', 'logging_param', 'idx', 'y', 'target_param', 'fold_generator', 'y_train', 'gpu_param', 'USI', 'exp_id', '_available_plots', 'X', 'X_train', 'html_param', '_ml_usecase'}
2026-01-29 16:13:59,988:INFO:Checking environment
2026-01-29 16:13:59,988:INFO:python_version: 3.11.11
2026-01-29 16:13:59,988:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-29 16:13:59,988:INFO:machine: AMD64
2026-01-29 16:13:59,988:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-29 16:13:59,988:INFO:Memory: svmem(total=34009374720, available=12933509120, percent=62.0, used=21075865600, free=12933509120)
2026-01-29 16:13:59,989:INFO:Physical Core: 12
2026-01-29 16:13:59,990:INFO:Logical Core: 16
2026-01-29 16:13:59,990:INFO:Checking libraries
2026-01-29 16:13:59,990:INFO:System:
2026-01-29 16:13:59,990:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-29 16:13:59,990:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-29 16:13:59,990:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-29 16:13:59,990:INFO:PyCaret required dependencies:
2026-01-29 16:13:59,990:INFO:                 pip: 25.0
2026-01-29 16:13:59,990:INFO:          setuptools: 75.8.0
2026-01-29 16:13:59,990:INFO:             pycaret: 3.3.2
2026-01-29 16:13:59,990:INFO:             IPython: 9.9.0
2026-01-29 16:13:59,990:INFO:          ipywidgets: 8.1.8
2026-01-29 16:13:59,990:INFO:                tqdm: 4.67.1
2026-01-29 16:13:59,990:INFO:               numpy: 1.26.4
2026-01-29 16:13:59,990:INFO:              pandas: 2.1.4
2026-01-29 16:13:59,990:INFO:              jinja2: 3.1.6
2026-01-29 16:13:59,990:INFO:               scipy: 1.11.4
2026-01-29 16:13:59,990:INFO:              joblib: 1.3.2
2026-01-29 16:13:59,990:INFO:             sklearn: 1.4.2
2026-01-29 16:13:59,990:INFO:                pyod: 2.0.6
2026-01-29 16:13:59,990:INFO:            imblearn: 0.14.1
2026-01-29 16:13:59,990:INFO:   category_encoders: 2.7.0
2026-01-29 16:13:59,990:INFO:            lightgbm: 4.6.0
2026-01-29 16:13:59,990:INFO:               numba: 0.62.1
2026-01-29 16:13:59,990:INFO:            requests: 2.32.3
2026-01-29 16:13:59,990:INFO:          matplotlib: 3.7.5
2026-01-29 16:13:59,990:INFO:          scikitplot: 0.3.7
2026-01-29 16:13:59,990:INFO:         yellowbrick: 1.5
2026-01-29 16:13:59,999:INFO:              plotly: 5.24.1
2026-01-29 16:13:59,999:INFO:    plotly-resampler: Not installed
2026-01-29 16:13:59,999:INFO:             kaleido: 1.2.0
2026-01-29 16:13:59,999:INFO:           schemdraw: 0.15
2026-01-29 16:13:59,999:INFO:         statsmodels: 0.14.6
2026-01-29 16:13:59,999:INFO:              sktime: 0.26.0
2026-01-29 16:13:59,999:INFO:               tbats: 1.1.3
2026-01-29 16:13:59,999:INFO:            pmdarima: 2.0.4
2026-01-29 16:13:59,999:INFO:              psutil: 7.2.1
2026-01-29 16:13:59,999:INFO:          markupsafe: 3.0.3
2026-01-29 16:13:59,999:INFO:             pickle5: Not installed
2026-01-29 16:14:00,005:INFO:         cloudpickle: 3.0.0
2026-01-29 16:14:00,005:INFO:         deprecation: 2.1.0
2026-01-29 16:14:00,006:INFO:              xxhash: 3.6.0
2026-01-29 16:14:00,006:INFO:           wurlitzer: Not installed
2026-01-29 16:14:00,006:INFO:PyCaret optional dependencies:
2026-01-29 16:14:00,006:INFO:                shap: 0.44.1
2026-01-29 16:14:00,007:INFO:           interpret: 0.7.3
2026-01-29 16:14:00,007:INFO:                umap: 0.5.7
2026-01-29 16:14:00,007:INFO:     ydata_profiling: 4.18.1
2026-01-29 16:14:00,007:INFO:  explainerdashboard: 0.5.1
2026-01-29 16:14:00,007:INFO:             autoviz: Not installed
2026-01-29 16:14:00,007:INFO:           fairlearn: 0.7.0
2026-01-29 16:14:00,007:INFO:          deepchecks: Not installed
2026-01-29 16:14:00,007:INFO:             xgboost: Not installed
2026-01-29 16:14:00,007:INFO:            catboost: 1.2.8
2026-01-29 16:14:00,007:INFO:              kmodes: 0.12.2
2026-01-29 16:14:00,007:INFO:             mlxtend: 0.23.4
2026-01-29 16:14:00,007:INFO:       statsforecast: 1.5.0
2026-01-29 16:14:00,007:INFO:        tune_sklearn: Not installed
2026-01-29 16:14:00,007:INFO:                 ray: Not installed
2026-01-29 16:14:00,007:INFO:            hyperopt: 0.2.7
2026-01-29 16:14:00,007:INFO:              optuna: 4.6.0
2026-01-29 16:14:00,007:INFO:               skopt: 0.10.2
2026-01-29 16:14:00,007:INFO:              mlflow: 3.8.1
2026-01-29 16:14:00,007:INFO:              gradio: 6.3.0
2026-01-29 16:14:00,007:INFO:             fastapi: 0.128.0
2026-01-29 16:14:00,007:INFO:             uvicorn: 0.40.0
2026-01-29 16:14:00,007:INFO:              m2cgen: 0.10.0
2026-01-29 16:14:00,007:INFO:           evidently: 0.4.40
2026-01-29 16:14:00,007:INFO:               fugue: 0.8.7
2026-01-29 16:14:00,015:INFO:           streamlit: Not installed
2026-01-29 16:14:00,015:INFO:             prophet: Not installed
2026-01-29 16:14:00,015:INFO:None
2026-01-29 16:14:00,015:INFO:Set up data.
2026-01-29 16:14:00,090:INFO:Set up folding strategy.
2026-01-29 16:14:00,090:INFO:Set up train/test split.
2026-01-29 16:14:00,474:INFO:Set up index.
2026-01-29 16:14:00,507:INFO:Assigning column types.
2026-01-29 16:14:00,586:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-29 16:14:00,686:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:14:00,689:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:14:00,741:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:14:00,741:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:14:00,824:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:14:00,824:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:14:00,873:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:14:00,873:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:14:00,874:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-29 16:14:00,940:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:14:00,973:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:14:00,987:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:14:01,040:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:14:01,090:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:14:01,090:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:14:01,090:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-29 16:14:01,191:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:14:01,191:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:14:01,290:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:14:01,290:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:14:01,290:INFO:Preparing preprocessing pipeline...
2026-01-29 16:14:01,308:INFO:Set up simple imputation.
2026-01-29 16:14:01,308:INFO:Set up feature normalization.
2026-01-29 16:14:01,456:INFO:Finished creating preprocessing pipeline.
2026-01-29 16:14:01,473:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-29 16:14:01,473:INFO:Creating final display dataframe.
2026-01-29 16:14:01,890:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape       (429278, 4)
4        Transformed data shape       (429278, 4)
5   Transformed train set shape       (343422, 4)
6    Transformed test set shape        (85856, 4)
7               Ignore features                58
8              Numeric features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                 3
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              b0bf
2026-01-29 16:14:01,973:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:14:01,973:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:14:02,073:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:14:02,073:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:14:02,073:INFO:setup() successfully completed in 2.1s...............
2026-01-29 16:14:02,073:INFO:Initializing compare_models()
2026-01-29 16:14:02,073:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-29 16:14:02,073:INFO:Checking exceptions
2026-01-29 16:14:02,128:INFO:Preparing display monitor
2026-01-29 16:14:02,166:INFO:Initializing Logistic Regression
2026-01-29 16:14:02,167:INFO:Total runtime is 1.7237663269042968e-05 minutes
2026-01-29 16:14:02,172:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:02,173:INFO:Initializing create_model()
2026-01-29 16:14:02,174:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002481729F910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:02,174:INFO:Checking exceptions
2026-01-29 16:14:02,174:INFO:Importing libraries
2026-01-29 16:14:02,174:INFO:Copying training dataset
2026-01-29 16:14:02,330:INFO:Defining folds
2026-01-29 16:14:02,330:INFO:Declaring metric variables
2026-01-29 16:14:02,340:INFO:Importing untrained model
2026-01-29 16:14:02,340:INFO:Logistic Regression Imported successfully
2026-01-29 16:14:02,359:INFO:Starting cross validation
2026-01-29 16:14:02,361:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:03,601:INFO:Calculating mean and std
2026-01-29 16:14:03,601:INFO:Creating metrics dataframe
2026-01-29 16:14:03,607:INFO:Uploading results into container
2026-01-29 16:14:03,609:INFO:Uploading model into container now
2026-01-29 16:14:03,610:INFO:_master_model_container: 1
2026-01-29 16:14:03,611:INFO:_display_container: 2
2026-01-29 16:14:03,611:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:14:03,612:INFO:create_model() successfully completed......................................
2026-01-29 16:14:03,947:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:03,947:INFO:Creating metrics dataframe
2026-01-29 16:14:03,957:INFO:Initializing Decision Tree Classifier
2026-01-29 16:14:03,957:INFO:Total runtime is 0.029845261573791505 minutes
2026-01-29 16:14:03,957:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:03,957:INFO:Initializing create_model()
2026-01-29 16:14:03,957:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002481729F910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:03,957:INFO:Checking exceptions
2026-01-29 16:14:03,957:INFO:Importing libraries
2026-01-29 16:14:03,957:INFO:Copying training dataset
2026-01-29 16:14:04,061:INFO:Defining folds
2026-01-29 16:14:04,061:INFO:Declaring metric variables
2026-01-29 16:14:04,070:INFO:Importing untrained model
2026-01-29 16:14:04,074:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:14:04,082:INFO:Starting cross validation
2026-01-29 16:14:04,083:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:04,760:INFO:Calculating mean and std
2026-01-29 16:14:04,760:INFO:Creating metrics dataframe
2026-01-29 16:14:04,760:INFO:Uploading results into container
2026-01-29 16:14:04,760:INFO:Uploading model into container now
2026-01-29 16:14:04,765:INFO:_master_model_container: 2
2026-01-29 16:14:04,765:INFO:_display_container: 2
2026-01-29 16:14:04,766:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:14:04,766:INFO:create_model() successfully completed......................................
2026-01-29 16:14:05,022:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:05,023:INFO:Creating metrics dataframe
2026-01-29 16:14:05,023:INFO:Initializing Random Forest Classifier
2026-01-29 16:14:05,023:INFO:Total runtime is 0.047616843382517496 minutes
2026-01-29 16:14:05,023:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:05,023:INFO:Initializing create_model()
2026-01-29 16:14:05,023:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002481729F910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:05,023:INFO:Checking exceptions
2026-01-29 16:14:05,023:INFO:Importing libraries
2026-01-29 16:14:05,023:INFO:Copying training dataset
2026-01-29 16:14:05,110:INFO:Defining folds
2026-01-29 16:14:05,111:INFO:Declaring metric variables
2026-01-29 16:14:05,114:INFO:Importing untrained model
2026-01-29 16:14:05,116:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:14:05,122:INFO:Starting cross validation
2026-01-29 16:14:05,123:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:10,285:INFO:Calculating mean and std
2026-01-29 16:14:10,289:INFO:Creating metrics dataframe
2026-01-29 16:14:10,290:INFO:Uploading results into container
2026-01-29 16:14:10,290:INFO:Uploading model into container now
2026-01-29 16:14:10,294:INFO:_master_model_container: 3
2026-01-29 16:14:10,294:INFO:_display_container: 2
2026-01-29 16:14:10,296:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:14:10,296:INFO:create_model() successfully completed......................................
2026-01-29 16:14:10,540:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:10,540:INFO:Creating metrics dataframe
2026-01-29 16:14:10,559:INFO:Initializing Light Gradient Boosting Machine
2026-01-29 16:14:10,560:INFO:Total runtime is 0.1398939530054728 minutes
2026-01-29 16:14:10,560:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:10,560:INFO:Initializing create_model()
2026-01-29 16:14:10,560:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002481729F910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:10,560:INFO:Checking exceptions
2026-01-29 16:14:10,560:INFO:Importing libraries
2026-01-29 16:14:10,560:INFO:Copying training dataset
2026-01-29 16:14:10,640:INFO:Defining folds
2026-01-29 16:14:10,640:INFO:Declaring metric variables
2026-01-29 16:14:10,640:INFO:Importing untrained model
2026-01-29 16:14:10,640:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-29 16:14:10,655:INFO:Starting cross validation
2026-01-29 16:14:10,657:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:12,436:INFO:Calculating mean and std
2026-01-29 16:14:12,440:INFO:Creating metrics dataframe
2026-01-29 16:14:12,442:INFO:Uploading results into container
2026-01-29 16:14:12,443:INFO:Uploading model into container now
2026-01-29 16:14:12,444:INFO:_master_model_container: 4
2026-01-29 16:14:12,444:INFO:_display_container: 2
2026-01-29 16:14:12,444:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-29 16:14:12,444:INFO:create_model() successfully completed......................................
2026-01-29 16:14:12,673:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:12,673:INFO:Creating metrics dataframe
2026-01-29 16:14:12,691:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-29 16:14:12,697:INFO:Initializing create_model()
2026-01-29 16:14:12,697:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:12,697:INFO:Checking exceptions
2026-01-29 16:14:12,697:INFO:Importing libraries
2026-01-29 16:14:12,697:INFO:Copying training dataset
2026-01-29 16:14:12,802:INFO:Defining folds
2026-01-29 16:14:12,802:INFO:Declaring metric variables
2026-01-29 16:14:12,802:INFO:Importing untrained model
2026-01-29 16:14:12,802:INFO:Declaring custom model
2026-01-29 16:14:12,802:INFO:Logistic Regression Imported successfully
2026-01-29 16:14:12,804:INFO:Cross validation set to False
2026-01-29 16:14:12,804:INFO:Fitting Model
2026-01-29 16:14:13,075:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:14:13,076:INFO:create_model() successfully completed......................................
2026-01-29 16:14:13,308:INFO:Initializing create_model()
2026-01-29 16:14:13,308:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:13,308:INFO:Checking exceptions
2026-01-29 16:14:13,308:INFO:Importing libraries
2026-01-29 16:14:13,313:INFO:Copying training dataset
2026-01-29 16:14:13,373:INFO:Defining folds
2026-01-29 16:14:13,373:INFO:Declaring metric variables
2026-01-29 16:14:13,373:INFO:Importing untrained model
2026-01-29 16:14:13,373:INFO:Declaring custom model
2026-01-29 16:14:13,373:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:14:13,373:INFO:Cross validation set to False
2026-01-29 16:14:13,373:INFO:Fitting Model
2026-01-29 16:14:13,455:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:14:13,455:INFO:create_model() successfully completed......................................
2026-01-29 16:14:13,687:INFO:Initializing create_model()
2026-01-29 16:14:13,687:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:13,687:INFO:Checking exceptions
2026-01-29 16:14:13,691:INFO:Importing libraries
2026-01-29 16:14:13,692:INFO:Copying training dataset
2026-01-29 16:14:13,755:INFO:Defining folds
2026-01-29 16:14:13,755:INFO:Declaring metric variables
2026-01-29 16:14:13,756:INFO:Importing untrained model
2026-01-29 16:14:13,756:INFO:Declaring custom model
2026-01-29 16:14:13,756:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:14:13,756:INFO:Cross validation set to False
2026-01-29 16:14:13,756:INFO:Fitting Model
2026-01-29 16:14:15,632:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:14:15,632:INFO:create_model() successfully completed......................................
2026-01-29 16:14:16,010:INFO:_master_model_container: 4
2026-01-29 16:14:16,010:INFO:_display_container: 2
2026-01-29 16:14:16,010:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2026-01-29 16:14:16,010:INFO:compare_models() successfully completed......................................
2026-01-29 16:14:16,010:INFO:Initializing tune_model()
2026-01-29 16:14:16,010:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:14:16,010:INFO:Checking exceptions
2026-01-29 16:14:16,062:INFO:Copying training dataset
2026-01-29 16:14:16,144:INFO:Checking base model
2026-01-29 16:14:16,145:INFO:Base model : Logistic Regression
2026-01-29 16:14:16,149:INFO:Declaring metric variables
2026-01-29 16:14:16,152:INFO:Defining Hyperparameters
2026-01-29 16:14:16,404:INFO:Tuning with n_jobs=-1
2026-01-29 16:14:16,404:INFO:Initializing RandomizedSearchCV
2026-01-29 16:14:19,085:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 5.682}
2026-01-29 16:14:19,085:INFO:Hyperparameter search completed
2026-01-29 16:14:19,085:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:19,088:INFO:Initializing create_model()
2026-01-29 16:14:19,088:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002481711D210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 5.682})
2026-01-29 16:14:19,088:INFO:Checking exceptions
2026-01-29 16:14:19,088:INFO:Importing libraries
2026-01-29 16:14:19,088:INFO:Copying training dataset
2026-01-29 16:14:19,189:INFO:Defining folds
2026-01-29 16:14:19,189:INFO:Declaring metric variables
2026-01-29 16:14:19,193:INFO:Importing untrained model
2026-01-29 16:14:19,193:INFO:Declaring custom model
2026-01-29 16:14:19,193:INFO:Logistic Regression Imported successfully
2026-01-29 16:14:19,205:INFO:Starting cross validation
2026-01-29 16:14:19,206:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:20,078:INFO:Calculating mean and std
2026-01-29 16:14:20,078:INFO:Creating metrics dataframe
2026-01-29 16:14:20,078:INFO:Finalizing model
2026-01-29 16:14:20,403:INFO:Uploading results into container
2026-01-29 16:14:20,414:INFO:Uploading model into container now
2026-01-29 16:14:20,414:INFO:_master_model_container: 5
2026-01-29 16:14:20,414:INFO:_display_container: 3
2026-01-29 16:14:20,414:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:14:20,414:INFO:create_model() successfully completed......................................
2026-01-29 16:14:20,655:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:20,655:INFO:choose_better activated
2026-01-29 16:14:20,655:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:20,655:INFO:Initializing create_model()
2026-01-29 16:14:20,655:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:20,655:INFO:Checking exceptions
2026-01-29 16:14:20,655:INFO:Importing libraries
2026-01-29 16:14:20,655:INFO:Copying training dataset
2026-01-29 16:14:20,725:INFO:Defining folds
2026-01-29 16:14:20,725:INFO:Declaring metric variables
2026-01-29 16:14:20,725:INFO:Importing untrained model
2026-01-29 16:14:20,725:INFO:Declaring custom model
2026-01-29 16:14:20,725:INFO:Logistic Regression Imported successfully
2026-01-29 16:14:20,725:INFO:Starting cross validation
2026-01-29 16:14:20,725:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:21,370:INFO:Calculating mean and std
2026-01-29 16:14:21,370:INFO:Creating metrics dataframe
2026-01-29 16:14:21,374:INFO:Finalizing model
2026-01-29 16:14:21,576:INFO:Uploading results into container
2026-01-29 16:14:21,576:INFO:Uploading model into container now
2026-01-29 16:14:21,576:INFO:_master_model_container: 6
2026-01-29 16:14:21,576:INFO:_display_container: 4
2026-01-29 16:14:21,576:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:14:21,576:INFO:create_model() successfully completed......................................
2026-01-29 16:14:21,774:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:21,774:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 16:14:21,774:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 16:14:21,774:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2026-01-29 16:14:21,774:INFO:choose_better completed
2026-01-29 16:14:21,774:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:14:21,792:INFO:_master_model_container: 6
2026-01-29 16:14:21,792:INFO:_display_container: 3
2026-01-29 16:14:21,792:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:14:21,792:INFO:tune_model() successfully completed......................................
2026-01-29 16:14:21,993:INFO:Initializing tune_model()
2026-01-29 16:14:21,993:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:14:21,993:INFO:Checking exceptions
2026-01-29 16:14:22,032:INFO:Copying training dataset
2026-01-29 16:14:22,078:INFO:Checking base model
2026-01-29 16:14:22,078:INFO:Base model : Decision Tree Classifier
2026-01-29 16:14:22,081:INFO:Declaring metric variables
2026-01-29 16:14:22,083:INFO:Defining Hyperparameters
2026-01-29 16:14:22,292:INFO:Tuning with n_jobs=-1
2026-01-29 16:14:22,292:INFO:Initializing RandomizedSearchCV
2026-01-29 16:14:23,116:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.0005, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 3, 'actual_estimator__criterion': 'gini'}
2026-01-29 16:14:23,116:INFO:Hyperparameter search completed
2026-01-29 16:14:23,116:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:23,116:INFO:Initializing create_model()
2026-01-29 16:14:23,116:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024870AE0C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0005, 'max_features': 1.0, 'max_depth': 3, 'criterion': 'gini'})
2026-01-29 16:14:23,116:INFO:Checking exceptions
2026-01-29 16:14:23,116:INFO:Importing libraries
2026-01-29 16:14:23,116:INFO:Copying training dataset
2026-01-29 16:14:23,173:INFO:Defining folds
2026-01-29 16:14:23,173:INFO:Declaring metric variables
2026-01-29 16:14:23,173:INFO:Importing untrained model
2026-01-29 16:14:23,173:INFO:Declaring custom model
2026-01-29 16:14:23,173:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:14:23,173:INFO:Starting cross validation
2026-01-29 16:14:23,173:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:23,652:INFO:Calculating mean and std
2026-01-29 16:14:23,652:INFO:Creating metrics dataframe
2026-01-29 16:14:23,659:INFO:Finalizing model
2026-01-29 16:14:23,722:INFO:Uploading results into container
2026-01-29 16:14:23,723:INFO:Uploading model into container now
2026-01-29 16:14:23,724:INFO:_master_model_container: 7
2026-01-29 16:14:23,724:INFO:_display_container: 4
2026-01-29 16:14:23,725:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:14:23,725:INFO:create_model() successfully completed......................................
2026-01-29 16:14:23,925:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:23,925:INFO:choose_better activated
2026-01-29 16:14:23,925:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:23,925:INFO:Initializing create_model()
2026-01-29 16:14:23,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:23,925:INFO:Checking exceptions
2026-01-29 16:14:23,925:INFO:Importing libraries
2026-01-29 16:14:23,925:INFO:Copying training dataset
2026-01-29 16:14:23,989:INFO:Defining folds
2026-01-29 16:14:23,989:INFO:Declaring metric variables
2026-01-29 16:14:23,989:INFO:Importing untrained model
2026-01-29 16:14:23,989:INFO:Declaring custom model
2026-01-29 16:14:23,989:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:14:23,989:INFO:Starting cross validation
2026-01-29 16:14:23,989:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:24,460:INFO:Calculating mean and std
2026-01-29 16:14:24,460:INFO:Creating metrics dataframe
2026-01-29 16:14:24,460:INFO:Finalizing model
2026-01-29 16:14:24,522:INFO:Uploading results into container
2026-01-29 16:14:24,525:INFO:Uploading model into container now
2026-01-29 16:14:24,525:INFO:_master_model_container: 8
2026-01-29 16:14:24,525:INFO:_display_container: 5
2026-01-29 16:14:24,525:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:14:24,525:INFO:create_model() successfully completed......................................
2026-01-29 16:14:24,738:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:24,738:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5369
2026-01-29 16:14:24,738:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5366
2026-01-29 16:14:24,738:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-29 16:14:24,738:INFO:choose_better completed
2026-01-29 16:14:24,738:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:14:24,738:INFO:_master_model_container: 8
2026-01-29 16:14:24,738:INFO:_display_container: 4
2026-01-29 16:14:24,738:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:14:24,738:INFO:tune_model() successfully completed......................................
2026-01-29 16:14:24,953:INFO:Initializing tune_model()
2026-01-29 16:14:24,953:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:14:24,953:INFO:Checking exceptions
2026-01-29 16:14:24,975:INFO:Copying training dataset
2026-01-29 16:14:25,028:INFO:Checking base model
2026-01-29 16:14:25,028:INFO:Base model : Random Forest Classifier
2026-01-29 16:14:25,030:INFO:Declaring metric variables
2026-01-29 16:14:25,032:INFO:Defining Hyperparameters
2026-01-29 16:14:25,240:INFO:Tuning with n_jobs=-1
2026-01-29 16:14:25,240:INFO:Initializing RandomizedSearchCV
2026-01-29 16:14:47,898:INFO:best_params: {'actual_estimator__n_estimators': 120, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-29 16:14:47,900:INFO:Hyperparameter search completed
2026-01-29 16:14:47,900:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:47,900:INFO:Initializing create_model()
2026-01-29 16:14:47,902:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002481B5D2C90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 120, 'min_samples_split': 5, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': True})
2026-01-29 16:14:47,902:INFO:Checking exceptions
2026-01-29 16:14:47,902:INFO:Importing libraries
2026-01-29 16:14:47,902:INFO:Copying training dataset
2026-01-29 16:14:47,975:INFO:Defining folds
2026-01-29 16:14:47,975:INFO:Declaring metric variables
2026-01-29 16:14:47,977:INFO:Importing untrained model
2026-01-29 16:14:47,977:INFO:Declaring custom model
2026-01-29 16:14:47,981:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:14:47,984:INFO:Starting cross validation
2026-01-29 16:14:47,987:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:50,600:INFO:Calculating mean and std
2026-01-29 16:14:50,600:INFO:Creating metrics dataframe
2026-01-29 16:14:50,606:INFO:Finalizing model
2026-01-29 16:14:52,198:INFO:Uploading results into container
2026-01-29 16:14:52,198:INFO:Uploading model into container now
2026-01-29 16:14:52,198:INFO:_master_model_container: 9
2026-01-29 16:14:52,198:INFO:_display_container: 5
2026-01-29 16:14:52,198:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=120, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:14:52,198:INFO:create_model() successfully completed......................................
2026-01-29 16:14:52,421:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:52,421:INFO:choose_better activated
2026-01-29 16:14:52,421:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:52,421:INFO:Initializing create_model()
2026-01-29 16:14:52,421:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:52,421:INFO:Checking exceptions
2026-01-29 16:14:52,421:INFO:Importing libraries
2026-01-29 16:14:52,421:INFO:Copying training dataset
2026-01-29 16:14:52,489:INFO:Defining folds
2026-01-29 16:14:52,489:INFO:Declaring metric variables
2026-01-29 16:14:52,489:INFO:Importing untrained model
2026-01-29 16:14:52,489:INFO:Declaring custom model
2026-01-29 16:14:52,489:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:14:52,489:INFO:Starting cross validation
2026-01-29 16:14:52,489:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:54,667:INFO:Calculating mean and std
2026-01-29 16:14:54,667:INFO:Creating metrics dataframe
2026-01-29 16:14:54,672:INFO:Finalizing model
2026-01-29 16:14:56,041:INFO:Uploading results into container
2026-01-29 16:14:56,043:INFO:Uploading model into container now
2026-01-29 16:14:56,043:INFO:_master_model_container: 10
2026-01-29 16:14:56,043:INFO:_display_container: 6
2026-01-29 16:14:56,043:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:14:56,043:INFO:create_model() successfully completed......................................
2026-01-29 16:14:56,258:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:56,269:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.5369
2026-01-29 16:14:56,269:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=120, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.5369
2026-01-29 16:14:56,269:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-29 16:14:56,269:INFO:choose_better completed
2026-01-29 16:14:56,269:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:14:56,273:INFO:_master_model_container: 10
2026-01-29 16:14:56,273:INFO:_display_container: 5
2026-01-29 16:14:56,273:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:14:56,273:INFO:tune_model() successfully completed......................................
2026-01-29 16:14:56,489:INFO:Initializing evaluate_model()
2026-01-29 16:14:56,489:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:14:56,528:INFO:Initializing plot_model()
2026-01-29 16:14:56,528:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:14:56,528:INFO:Checking exceptions
2026-01-29 16:14:56,556:INFO:Preloading libraries
2026-01-29 16:14:56,556:INFO:Copying training dataset
2026-01-29 16:14:56,556:INFO:Plot type: pipeline
2026-01-29 16:14:56,622:INFO:Visual Rendered Successfully
2026-01-29 16:14:56,822:INFO:plot_model() successfully completed......................................
2026-01-29 16:14:56,838:INFO:Initializing evaluate_model()
2026-01-29 16:14:56,838:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:14:56,889:INFO:Initializing plot_model()
2026-01-29 16:14:56,890:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:14:56,890:INFO:Checking exceptions
2026-01-29 16:14:56,929:INFO:Preloading libraries
2026-01-29 16:14:56,930:INFO:Copying training dataset
2026-01-29 16:14:56,930:INFO:Plot type: pipeline
2026-01-29 16:14:56,989:INFO:Visual Rendered Successfully
2026-01-29 16:14:57,205:INFO:plot_model() successfully completed......................................
2026-01-29 16:14:57,205:INFO:Initializing evaluate_model()
2026-01-29 16:14:57,205:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:14:57,241:INFO:Initializing plot_model()
2026-01-29 16:14:57,241:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:14:57,241:INFO:Checking exceptions
2026-01-29 16:14:57,292:INFO:Preloading libraries
2026-01-29 16:14:57,292:INFO:Copying training dataset
2026-01-29 16:14:57,292:INFO:Plot type: pipeline
2026-01-29 16:14:57,355:INFO:Visual Rendered Successfully
2026-01-29 16:14:57,574:INFO:plot_model() successfully completed......................................
2026-01-29 16:14:57,583:INFO:Initializing predict_model()
2026-01-29 16:14:57,583:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024810D7FE20>)
2026-01-29 16:14:57,583:INFO:Checking exceptions
2026-01-29 16:14:57,583:INFO:Preloading libraries
2026-01-29 16:14:57,585:INFO:Set up data.
2026-01-29 16:14:57,594:INFO:Set up index.
2026-01-29 16:14:58,122:INFO:Initializing predict_model()
2026-01-29 16:14:58,122:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002487E4E7BA0>)
2026-01-29 16:14:58,122:INFO:Checking exceptions
2026-01-29 16:14:58,122:INFO:Preloading libraries
2026-01-29 16:14:58,122:INFO:Set up data.
2026-01-29 16:14:58,122:INFO:Set up index.
2026-01-29 16:14:58,674:INFO:Initializing predict_model()
2026-01-29 16:14:58,674:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002487E426200>)
2026-01-29 16:14:58,674:INFO:Checking exceptions
2026-01-29 16:14:58,674:INFO:Preloading libraries
2026-01-29 16:14:58,674:INFO:Set up data.
2026-01-29 16:14:58,674:INFO:Set up index.
2026-01-29 16:14:59,338:INFO:Initializing plot_model()
2026-01-29 16:14:59,338:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-29 16:14:59,340:INFO:Checking exceptions
2026-01-29 16:14:59,355:INFO:Preloading libraries
2026-01-29 16:14:59,355:INFO:Copying training dataset
2026-01-29 16:14:59,355:INFO:Plot type: feature
2026-01-29 16:14:59,608:INFO:Visual Rendered Successfully
2026-01-29 16:14:59,828:INFO:plot_model() successfully completed......................................
2026-01-29 16:14:59,828:INFO:Initializing save_model()
2026-01-29 16:14:59,828:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=..\datos\04. Modelos, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-29 16:14:59,828:INFO:Adding model into prep_pipe
2026-01-29 16:14:59,838:INFO:..\datos\04. Modelos.pkl saved in current working directory
2026-01-29 16:14:59,838:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(e...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=42,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2026-01-29 16:14:59,838:INFO:save_model() successfully completed......................................
2026-01-29 16:16:46,887:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\2531746454.py:18: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-29 16:16:48,804:INFO:PyCaret ClassificationExperiment
2026-01-29 16:16:48,804:INFO:Logging name: clf-default-name
2026-01-29 16:16:48,804:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-29 16:16:48,804:INFO:version 3.3.2
2026-01-29 16:16:48,804:INFO:Initializing setup()
2026-01-29 16:16:48,804:INFO:self.USI: 8fc6
2026-01-29 16:16:48,807:INFO:self._variable_keys: {'X_test', 'fold_groups_param', 'pipeline', 'fix_imbalance', 'exp_name_log', 'data', 'y_test', 'seed', 'fold_shuffle_param', 'n_jobs_param', 'is_multiclass', 'gpu_n_jobs_param', 'memory', 'log_plots_param', 'logging_param', 'idx', 'y', 'target_param', 'fold_generator', 'y_train', 'gpu_param', 'USI', 'exp_id', '_available_plots', 'X', 'X_train', 'html_param', '_ml_usecase'}
2026-01-29 16:16:48,807:INFO:Checking environment
2026-01-29 16:16:48,807:INFO:python_version: 3.11.11
2026-01-29 16:16:48,807:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-29 16:16:48,807:INFO:machine: AMD64
2026-01-29 16:16:48,807:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-29 16:16:48,807:INFO:Memory: svmem(total=34009374720, available=13133869056, percent=61.4, used=20875505664, free=13133869056)
2026-01-29 16:16:48,807:INFO:Physical Core: 12
2026-01-29 16:16:48,807:INFO:Logical Core: 16
2026-01-29 16:16:48,807:INFO:Checking libraries
2026-01-29 16:16:48,807:INFO:System:
2026-01-29 16:16:48,807:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-29 16:16:48,807:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-29 16:16:48,807:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-29 16:16:48,807:INFO:PyCaret required dependencies:
2026-01-29 16:16:48,807:INFO:                 pip: 25.0
2026-01-29 16:16:48,807:INFO:          setuptools: 75.8.0
2026-01-29 16:16:48,807:INFO:             pycaret: 3.3.2
2026-01-29 16:16:48,807:INFO:             IPython: 9.9.0
2026-01-29 16:16:48,807:INFO:          ipywidgets: 8.1.8
2026-01-29 16:16:48,807:INFO:                tqdm: 4.67.1
2026-01-29 16:16:48,807:INFO:               numpy: 1.26.4
2026-01-29 16:16:48,807:INFO:              pandas: 2.1.4
2026-01-29 16:16:48,807:INFO:              jinja2: 3.1.6
2026-01-29 16:16:48,807:INFO:               scipy: 1.11.4
2026-01-29 16:16:48,807:INFO:              joblib: 1.3.2
2026-01-29 16:16:48,807:INFO:             sklearn: 1.4.2
2026-01-29 16:16:48,807:INFO:                pyod: 2.0.6
2026-01-29 16:16:48,807:INFO:            imblearn: 0.14.1
2026-01-29 16:16:48,807:INFO:   category_encoders: 2.7.0
2026-01-29 16:16:48,807:INFO:            lightgbm: 4.6.0
2026-01-29 16:16:48,807:INFO:               numba: 0.62.1
2026-01-29 16:16:48,807:INFO:            requests: 2.32.3
2026-01-29 16:16:48,807:INFO:          matplotlib: 3.7.5
2026-01-29 16:16:48,807:INFO:          scikitplot: 0.3.7
2026-01-29 16:16:48,807:INFO:         yellowbrick: 1.5
2026-01-29 16:16:48,807:INFO:              plotly: 5.24.1
2026-01-29 16:16:48,807:INFO:    plotly-resampler: Not installed
2026-01-29 16:16:48,807:INFO:             kaleido: 1.2.0
2026-01-29 16:16:48,807:INFO:           schemdraw: 0.15
2026-01-29 16:16:48,807:INFO:         statsmodels: 0.14.6
2026-01-29 16:16:48,807:INFO:              sktime: 0.26.0
2026-01-29 16:16:48,807:INFO:               tbats: 1.1.3
2026-01-29 16:16:48,807:INFO:            pmdarima: 2.0.4
2026-01-29 16:16:48,807:INFO:              psutil: 7.2.1
2026-01-29 16:16:48,807:INFO:          markupsafe: 3.0.3
2026-01-29 16:16:48,807:INFO:             pickle5: Not installed
2026-01-29 16:16:48,807:INFO:         cloudpickle: 3.0.0
2026-01-29 16:16:48,807:INFO:         deprecation: 2.1.0
2026-01-29 16:16:48,807:INFO:              xxhash: 3.6.0
2026-01-29 16:16:48,807:INFO:           wurlitzer: Not installed
2026-01-29 16:16:48,807:INFO:PyCaret optional dependencies:
2026-01-29 16:16:48,807:INFO:                shap: 0.44.1
2026-01-29 16:16:48,807:INFO:           interpret: 0.7.3
2026-01-29 16:16:48,807:INFO:                umap: 0.5.7
2026-01-29 16:16:48,807:INFO:     ydata_profiling: 4.18.1
2026-01-29 16:16:48,807:INFO:  explainerdashboard: 0.5.1
2026-01-29 16:16:48,807:INFO:             autoviz: Not installed
2026-01-29 16:16:48,807:INFO:           fairlearn: 0.7.0
2026-01-29 16:16:48,807:INFO:          deepchecks: Not installed
2026-01-29 16:16:48,807:INFO:             xgboost: Not installed
2026-01-29 16:16:48,807:INFO:            catboost: 1.2.8
2026-01-29 16:16:48,807:INFO:              kmodes: 0.12.2
2026-01-29 16:16:48,807:INFO:             mlxtend: 0.23.4
2026-01-29 16:16:48,807:INFO:       statsforecast: 1.5.0
2026-01-29 16:16:48,807:INFO:        tune_sklearn: Not installed
2026-01-29 16:16:48,820:INFO:                 ray: Not installed
2026-01-29 16:16:48,820:INFO:            hyperopt: 0.2.7
2026-01-29 16:16:48,820:INFO:              optuna: 4.6.0
2026-01-29 16:16:48,820:INFO:               skopt: 0.10.2
2026-01-29 16:16:48,820:INFO:              mlflow: 3.8.1
2026-01-29 16:16:48,820:INFO:              gradio: 6.3.0
2026-01-29 16:16:48,820:INFO:             fastapi: 0.128.0
2026-01-29 16:16:48,820:INFO:             uvicorn: 0.40.0
2026-01-29 16:16:48,820:INFO:              m2cgen: 0.10.0
2026-01-29 16:16:48,820:INFO:           evidently: 0.4.40
2026-01-29 16:16:48,820:INFO:               fugue: 0.8.7
2026-01-29 16:16:48,820:INFO:           streamlit: Not installed
2026-01-29 16:16:48,820:INFO:             prophet: Not installed
2026-01-29 16:16:48,820:INFO:None
2026-01-29 16:16:48,820:INFO:Set up data.
2026-01-29 16:16:48,841:INFO:Set up folding strategy.
2026-01-29 16:16:48,841:INFO:Set up train/test split.
2026-01-29 16:16:48,939:INFO:Set up index.
2026-01-29 16:16:48,939:INFO:Assigning column types.
2026-01-29 16:16:48,970:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-29 16:16:48,986:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:16:48,986:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:16:49,017:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:16:49,017:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:16:49,040:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:16:49,040:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:16:49,070:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:16:49,070:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:16:49,070:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-29 16:16:49,117:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:16:49,135:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:16:49,135:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:16:49,172:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:16:49,188:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:16:49,188:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:16:49,188:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-29 16:16:49,240:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:16:49,240:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:16:49,286:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:16:49,286:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:16:49,286:INFO:Preparing preprocessing pipeline...
2026-01-29 16:16:49,286:INFO:Set up simple imputation.
2026-01-29 16:16:49,302:INFO:Set up feature normalization.
2026-01-29 16:16:49,388:INFO:Finished creating preprocessing pipeline.
2026-01-29 16:16:49,390:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-29 16:16:49,390:INFO:Creating final display dataframe.
2026-01-29 16:16:49,588:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape       (429278, 4)
4        Transformed data shape       (429278, 4)
5   Transformed train set shape       (343422, 4)
6    Transformed test set shape        (85856, 4)
7               Ignore features                58
8              Numeric features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                 3
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              8fc6
2026-01-29 16:16:49,636:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:16:49,636:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:16:49,673:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:16:49,673:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:16:49,673:INFO:setup() successfully completed in 0.88s...............
2026-01-29 16:16:49,673:INFO:Initializing compare_models()
2026-01-29 16:16:49,673:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-29 16:16:49,673:INFO:Checking exceptions
2026-01-29 16:16:49,710:INFO:Preparing display monitor
2026-01-29 16:16:49,738:INFO:Initializing Logistic Regression
2026-01-29 16:16:49,738:INFO:Total runtime is 0.0 minutes
2026-01-29 16:16:49,742:INFO:SubProcess create_model() called ==================================
2026-01-29 16:16:49,742:INFO:Initializing create_model()
2026-01-29 16:16:49,742:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816CE95D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:16:49,742:INFO:Checking exceptions
2026-01-29 16:16:49,744:INFO:Importing libraries
2026-01-29 16:16:49,744:INFO:Copying training dataset
2026-01-29 16:16:49,817:INFO:Defining folds
2026-01-29 16:16:49,817:INFO:Declaring metric variables
2026-01-29 16:16:49,820:INFO:Importing untrained model
2026-01-29 16:16:49,825:INFO:Logistic Regression Imported successfully
2026-01-29 16:16:49,825:INFO:Starting cross validation
2026-01-29 16:16:49,825:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:16:50,495:INFO:Calculating mean and std
2026-01-29 16:16:50,495:INFO:Creating metrics dataframe
2026-01-29 16:16:50,495:INFO:Uploading results into container
2026-01-29 16:16:50,495:INFO:Uploading model into container now
2026-01-29 16:16:50,495:INFO:_master_model_container: 1
2026-01-29 16:16:50,495:INFO:_display_container: 2
2026-01-29 16:16:50,495:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:16:50,495:INFO:create_model() successfully completed......................................
2026-01-29 16:16:50,712:INFO:SubProcess create_model() end ==================================
2026-01-29 16:16:50,712:INFO:Creating metrics dataframe
2026-01-29 16:16:50,723:INFO:Initializing Decision Tree Classifier
2026-01-29 16:16:50,723:INFO:Total runtime is 0.016418596108754475 minutes
2026-01-29 16:16:50,723:INFO:SubProcess create_model() called ==================================
2026-01-29 16:16:50,723:INFO:Initializing create_model()
2026-01-29 16:16:50,723:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816CE95D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:16:50,723:INFO:Checking exceptions
2026-01-29 16:16:50,723:INFO:Importing libraries
2026-01-29 16:16:50,723:INFO:Copying training dataset
2026-01-29 16:16:50,787:INFO:Defining folds
2026-01-29 16:16:50,788:INFO:Declaring metric variables
2026-01-29 16:16:50,791:INFO:Importing untrained model
2026-01-29 16:16:50,791:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:16:50,791:INFO:Starting cross validation
2026-01-29 16:16:50,791:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:16:51,325:INFO:Calculating mean and std
2026-01-29 16:16:51,326:INFO:Creating metrics dataframe
2026-01-29 16:16:51,327:INFO:Uploading results into container
2026-01-29 16:16:51,328:INFO:Uploading model into container now
2026-01-29 16:16:51,328:INFO:_master_model_container: 2
2026-01-29 16:16:51,328:INFO:_display_container: 2
2026-01-29 16:16:51,329:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:16:51,329:INFO:create_model() successfully completed......................................
2026-01-29 16:16:51,550:INFO:SubProcess create_model() end ==================================
2026-01-29 16:16:51,550:INFO:Creating metrics dataframe
2026-01-29 16:16:51,556:INFO:Initializing Random Forest Classifier
2026-01-29 16:16:51,556:INFO:Total runtime is 0.030309824148813884 minutes
2026-01-29 16:16:51,558:INFO:SubProcess create_model() called ==================================
2026-01-29 16:16:51,558:INFO:Initializing create_model()
2026-01-29 16:16:51,558:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816CE95D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:16:51,558:INFO:Checking exceptions
2026-01-29 16:16:51,558:INFO:Importing libraries
2026-01-29 16:16:51,558:INFO:Copying training dataset
2026-01-29 16:16:51,631:INFO:Defining folds
2026-01-29 16:16:51,631:INFO:Declaring metric variables
2026-01-29 16:16:51,635:INFO:Importing untrained model
2026-01-29 16:16:51,638:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:16:51,643:INFO:Starting cross validation
2026-01-29 16:16:51,643:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:16:54,095:INFO:Calculating mean and std
2026-01-29 16:16:54,095:INFO:Creating metrics dataframe
2026-01-29 16:16:54,102:INFO:Uploading results into container
2026-01-29 16:16:54,102:INFO:Uploading model into container now
2026-01-29 16:16:54,103:INFO:_master_model_container: 3
2026-01-29 16:16:54,103:INFO:_display_container: 2
2026-01-29 16:16:54,104:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:16:54,105:INFO:create_model() successfully completed......................................
2026-01-29 16:16:54,317:INFO:SubProcess create_model() end ==================================
2026-01-29 16:16:54,317:INFO:Creating metrics dataframe
2026-01-29 16:16:54,321:INFO:Initializing Light Gradient Boosting Machine
2026-01-29 16:16:54,321:INFO:Total runtime is 0.07638957500457763 minutes
2026-01-29 16:16:54,321:INFO:SubProcess create_model() called ==================================
2026-01-29 16:16:54,321:INFO:Initializing create_model()
2026-01-29 16:16:54,321:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816CE95D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:16:54,321:INFO:Checking exceptions
2026-01-29 16:16:54,321:INFO:Importing libraries
2026-01-29 16:16:54,321:INFO:Copying training dataset
2026-01-29 16:16:54,390:INFO:Defining folds
2026-01-29 16:16:54,390:INFO:Declaring metric variables
2026-01-29 16:16:54,407:INFO:Importing untrained model
2026-01-29 16:16:54,407:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-29 16:16:54,407:INFO:Starting cross validation
2026-01-29 16:16:54,407:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:16:55,803:INFO:Calculating mean and std
2026-01-29 16:16:55,807:INFO:Creating metrics dataframe
2026-01-29 16:16:55,812:INFO:Uploading results into container
2026-01-29 16:16:55,813:INFO:Uploading model into container now
2026-01-29 16:16:55,813:INFO:_master_model_container: 4
2026-01-29 16:16:55,813:INFO:_display_container: 2
2026-01-29 16:16:55,813:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-29 16:16:55,813:INFO:create_model() successfully completed......................................
2026-01-29 16:16:56,004:INFO:SubProcess create_model() end ==================================
2026-01-29 16:16:56,004:INFO:Creating metrics dataframe
2026-01-29 16:16:56,020:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-29 16:16:56,025:INFO:Initializing create_model()
2026-01-29 16:16:56,025:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:16:56,025:INFO:Checking exceptions
2026-01-29 16:16:56,025:INFO:Importing libraries
2026-01-29 16:16:56,025:INFO:Copying training dataset
2026-01-29 16:16:56,071:INFO:Defining folds
2026-01-29 16:16:56,071:INFO:Declaring metric variables
2026-01-29 16:16:56,071:INFO:Importing untrained model
2026-01-29 16:16:56,071:INFO:Declaring custom model
2026-01-29 16:16:56,071:INFO:Logistic Regression Imported successfully
2026-01-29 16:16:56,071:INFO:Cross validation set to False
2026-01-29 16:16:56,071:INFO:Fitting Model
2026-01-29 16:16:56,290:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:16:56,290:INFO:create_model() successfully completed......................................
2026-01-29 16:16:56,505:INFO:Initializing create_model()
2026-01-29 16:16:56,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:16:56,505:INFO:Checking exceptions
2026-01-29 16:16:56,511:INFO:Importing libraries
2026-01-29 16:16:56,512:INFO:Copying training dataset
2026-01-29 16:16:56,568:INFO:Defining folds
2026-01-29 16:16:56,568:INFO:Declaring metric variables
2026-01-29 16:16:56,568:INFO:Importing untrained model
2026-01-29 16:16:56,568:INFO:Declaring custom model
2026-01-29 16:16:56,568:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:16:56,569:INFO:Cross validation set to False
2026-01-29 16:16:56,569:INFO:Fitting Model
2026-01-29 16:16:56,621:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:16:56,621:INFO:create_model() successfully completed......................................
2026-01-29 16:16:56,841:INFO:Initializing create_model()
2026-01-29 16:16:56,841:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:16:56,841:INFO:Checking exceptions
2026-01-29 16:16:56,845:INFO:Importing libraries
2026-01-29 16:16:56,845:INFO:Copying training dataset
2026-01-29 16:16:56,920:INFO:Defining folds
2026-01-29 16:16:56,920:INFO:Declaring metric variables
2026-01-29 16:16:56,920:INFO:Importing untrained model
2026-01-29 16:16:56,920:INFO:Declaring custom model
2026-01-29 16:16:56,920:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:16:56,920:INFO:Cross validation set to False
2026-01-29 16:16:56,920:INFO:Fitting Model
2026-01-29 16:16:58,137:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:16:58,137:INFO:create_model() successfully completed......................................
2026-01-29 16:16:58,359:INFO:_master_model_container: 4
2026-01-29 16:16:58,359:INFO:_display_container: 2
2026-01-29 16:16:58,359:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2026-01-29 16:16:58,359:INFO:compare_models() successfully completed......................................
2026-01-29 16:16:58,371:INFO:Initializing tune_model()
2026-01-29 16:16:58,371:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:16:58,371:INFO:Checking exceptions
2026-01-29 16:16:58,409:INFO:Copying training dataset
2026-01-29 16:16:58,490:INFO:Checking base model
2026-01-29 16:16:58,491:INFO:Base model : Logistic Regression
2026-01-29 16:16:58,493:INFO:Declaring metric variables
2026-01-29 16:16:58,495:INFO:Defining Hyperparameters
2026-01-29 16:16:58,687:INFO:Tuning with n_jobs=-1
2026-01-29 16:16:58,687:INFO:Initializing RandomizedSearchCV
2026-01-29 16:17:00,322:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 5.682}
2026-01-29 16:17:00,322:INFO:Hyperparameter search completed
2026-01-29 16:17:00,322:INFO:SubProcess create_model() called ==================================
2026-01-29 16:17:00,322:INFO:Initializing create_model()
2026-01-29 16:17:00,322:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024871B10E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 5.682})
2026-01-29 16:17:00,322:INFO:Checking exceptions
2026-01-29 16:17:00,322:INFO:Importing libraries
2026-01-29 16:17:00,322:INFO:Copying training dataset
2026-01-29 16:17:00,387:INFO:Defining folds
2026-01-29 16:17:00,387:INFO:Declaring metric variables
2026-01-29 16:17:00,387:INFO:Importing untrained model
2026-01-29 16:17:00,387:INFO:Declaring custom model
2026-01-29 16:17:00,402:INFO:Logistic Regression Imported successfully
2026-01-29 16:17:00,407:INFO:Starting cross validation
2026-01-29 16:17:00,407:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:17:01,161:INFO:Calculating mean and std
2026-01-29 16:17:01,161:INFO:Creating metrics dataframe
2026-01-29 16:17:01,170:INFO:Finalizing model
2026-01-29 16:17:01,448:INFO:Uploading results into container
2026-01-29 16:17:01,448:INFO:Uploading model into container now
2026-01-29 16:17:01,448:INFO:_master_model_container: 5
2026-01-29 16:17:01,448:INFO:_display_container: 3
2026-01-29 16:17:01,448:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:17:01,448:INFO:create_model() successfully completed......................................
2026-01-29 16:17:01,654:INFO:SubProcess create_model() end ==================================
2026-01-29 16:17:01,654:INFO:choose_better activated
2026-01-29 16:17:01,654:INFO:SubProcess create_model() called ==================================
2026-01-29 16:17:01,654:INFO:Initializing create_model()
2026-01-29 16:17:01,654:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:17:01,654:INFO:Checking exceptions
2026-01-29 16:17:01,654:INFO:Importing libraries
2026-01-29 16:17:01,654:INFO:Copying training dataset
2026-01-29 16:17:01,721:INFO:Defining folds
2026-01-29 16:17:01,721:INFO:Declaring metric variables
2026-01-29 16:17:01,721:INFO:Importing untrained model
2026-01-29 16:17:01,721:INFO:Declaring custom model
2026-01-29 16:17:01,721:INFO:Logistic Regression Imported successfully
2026-01-29 16:17:01,721:INFO:Starting cross validation
2026-01-29 16:17:01,721:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:17:02,373:INFO:Calculating mean and std
2026-01-29 16:17:02,375:INFO:Creating metrics dataframe
2026-01-29 16:17:02,377:INFO:Finalizing model
2026-01-29 16:17:02,610:INFO:Uploading results into container
2026-01-29 16:17:02,610:INFO:Uploading model into container now
2026-01-29 16:17:02,610:INFO:_master_model_container: 6
2026-01-29 16:17:02,610:INFO:_display_container: 4
2026-01-29 16:17:02,610:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:17:02,610:INFO:create_model() successfully completed......................................
2026-01-29 16:17:02,820:INFO:SubProcess create_model() end ==================================
2026-01-29 16:17:02,820:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 16:17:02,820:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 16:17:02,820:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2026-01-29 16:17:02,820:INFO:choose_better completed
2026-01-29 16:17:02,820:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:17:02,825:INFO:_master_model_container: 6
2026-01-29 16:17:02,825:INFO:_display_container: 3
2026-01-29 16:17:02,825:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:17:02,825:INFO:tune_model() successfully completed......................................
2026-01-29 16:17:03,039:INFO:Initializing tune_model()
2026-01-29 16:17:03,039:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:17:03,040:INFO:Checking exceptions
2026-01-29 16:17:03,068:INFO:Copying training dataset
2026-01-29 16:17:03,129:INFO:Checking base model
2026-01-29 16:17:03,130:INFO:Base model : Decision Tree Classifier
2026-01-29 16:17:03,133:INFO:Declaring metric variables
2026-01-29 16:17:03,138:INFO:Defining Hyperparameters
2026-01-29 16:17:03,353:INFO:Tuning with n_jobs=-1
2026-01-29 16:17:03,353:INFO:Initializing RandomizedSearchCV
2026-01-29 16:17:04,328:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.0005, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 3, 'actual_estimator__criterion': 'gini'}
2026-01-29 16:17:04,328:INFO:Hyperparameter search completed
2026-01-29 16:17:04,328:INFO:SubProcess create_model() called ==================================
2026-01-29 16:17:04,328:INFO:Initializing create_model()
2026-01-29 16:17:04,328:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002487DF698D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0005, 'max_features': 1.0, 'max_depth': 3, 'criterion': 'gini'})
2026-01-29 16:17:04,328:INFO:Checking exceptions
2026-01-29 16:17:04,328:INFO:Importing libraries
2026-01-29 16:17:04,328:INFO:Copying training dataset
2026-01-29 16:17:04,387:INFO:Defining folds
2026-01-29 16:17:04,387:INFO:Declaring metric variables
2026-01-29 16:17:04,387:INFO:Importing untrained model
2026-01-29 16:17:04,387:INFO:Declaring custom model
2026-01-29 16:17:04,387:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:17:04,404:INFO:Starting cross validation
2026-01-29 16:17:04,404:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:17:04,946:INFO:Calculating mean and std
2026-01-29 16:17:04,948:INFO:Creating metrics dataframe
2026-01-29 16:17:04,954:INFO:Finalizing model
2026-01-29 16:17:05,030:INFO:Uploading results into container
2026-01-29 16:17:05,030:INFO:Uploading model into container now
2026-01-29 16:17:05,030:INFO:_master_model_container: 7
2026-01-29 16:17:05,030:INFO:_display_container: 4
2026-01-29 16:17:05,034:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:17:05,034:INFO:create_model() successfully completed......................................
2026-01-29 16:17:05,276:INFO:SubProcess create_model() end ==================================
2026-01-29 16:17:05,276:INFO:choose_better activated
2026-01-29 16:17:05,279:INFO:SubProcess create_model() called ==================================
2026-01-29 16:17:05,279:INFO:Initializing create_model()
2026-01-29 16:17:05,279:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:17:05,280:INFO:Checking exceptions
2026-01-29 16:17:05,281:INFO:Importing libraries
2026-01-29 16:17:05,282:INFO:Copying training dataset
2026-01-29 16:17:05,364:INFO:Defining folds
2026-01-29 16:17:05,364:INFO:Declaring metric variables
2026-01-29 16:17:05,365:INFO:Importing untrained model
2026-01-29 16:17:05,365:INFO:Declaring custom model
2026-01-29 16:17:05,365:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:17:05,365:INFO:Starting cross validation
2026-01-29 16:17:05,366:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:17:05,959:INFO:Calculating mean and std
2026-01-29 16:17:05,959:INFO:Creating metrics dataframe
2026-01-29 16:17:05,959:INFO:Finalizing model
2026-01-29 16:17:06,040:INFO:Uploading results into container
2026-01-29 16:17:06,040:INFO:Uploading model into container now
2026-01-29 16:17:06,040:INFO:_master_model_container: 8
2026-01-29 16:17:06,040:INFO:_display_container: 5
2026-01-29 16:17:06,040:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:17:06,040:INFO:create_model() successfully completed......................................
2026-01-29 16:17:06,270:INFO:SubProcess create_model() end ==================================
2026-01-29 16:17:06,270:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5369
2026-01-29 16:17:06,270:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5366
2026-01-29 16:17:06,270:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-29 16:17:06,270:INFO:choose_better completed
2026-01-29 16:17:06,270:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:17:06,287:INFO:_master_model_container: 8
2026-01-29 16:17:06,287:INFO:_display_container: 4
2026-01-29 16:17:06,287:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:17:06,287:INFO:tune_model() successfully completed......................................
2026-01-29 16:17:06,503:INFO:Initializing tune_model()
2026-01-29 16:17:06,503:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:17:06,503:INFO:Checking exceptions
2026-01-29 16:17:06,553:INFO:Copying training dataset
2026-01-29 16:17:06,620:INFO:Checking base model
2026-01-29 16:17:06,620:INFO:Base model : Random Forest Classifier
2026-01-29 16:17:06,626:INFO:Declaring metric variables
2026-01-29 16:17:06,630:INFO:Defining Hyperparameters
2026-01-29 16:17:06,869:INFO:Tuning with n_jobs=-1
2026-01-29 16:17:06,869:INFO:Initializing RandomizedSearchCV
2026-01-29 16:17:34,874:INFO:best_params: {'actual_estimator__n_estimators': 120, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-29 16:17:34,874:INFO:Hyperparameter search completed
2026-01-29 16:17:34,874:INFO:SubProcess create_model() called ==================================
2026-01-29 16:17:34,874:INFO:Initializing create_model()
2026-01-29 16:17:34,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024827B0F5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 120, 'min_samples_split': 5, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': True})
2026-01-29 16:17:34,874:INFO:Checking exceptions
2026-01-29 16:17:34,874:INFO:Importing libraries
2026-01-29 16:17:34,874:INFO:Copying training dataset
2026-01-29 16:17:34,953:INFO:Defining folds
2026-01-29 16:17:34,953:INFO:Declaring metric variables
2026-01-29 16:17:34,956:INFO:Importing untrained model
2026-01-29 16:17:34,956:INFO:Declaring custom model
2026-01-29 16:17:34,956:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:17:34,971:INFO:Starting cross validation
2026-01-29 16:17:34,972:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:17:38,064:INFO:Calculating mean and std
2026-01-29 16:17:38,064:INFO:Creating metrics dataframe
2026-01-29 16:17:38,073:INFO:Finalizing model
2026-01-29 16:17:39,755:INFO:Uploading results into container
2026-01-29 16:17:39,756:INFO:Uploading model into container now
2026-01-29 16:17:39,756:INFO:_master_model_container: 9
2026-01-29 16:17:39,756:INFO:_display_container: 5
2026-01-29 16:17:39,756:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=120, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:17:39,756:INFO:create_model() successfully completed......................................
2026-01-29 16:17:39,984:INFO:SubProcess create_model() end ==================================
2026-01-29 16:17:39,984:INFO:choose_better activated
2026-01-29 16:17:39,984:INFO:SubProcess create_model() called ==================================
2026-01-29 16:17:39,984:INFO:Initializing create_model()
2026-01-29 16:17:39,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:17:39,984:INFO:Checking exceptions
2026-01-29 16:17:39,984:INFO:Importing libraries
2026-01-29 16:17:39,984:INFO:Copying training dataset
2026-01-29 16:17:40,053:INFO:Defining folds
2026-01-29 16:17:40,053:INFO:Declaring metric variables
2026-01-29 16:17:40,053:INFO:Importing untrained model
2026-01-29 16:17:40,053:INFO:Declaring custom model
2026-01-29 16:17:40,053:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:17:40,053:INFO:Starting cross validation
2026-01-29 16:17:40,053:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:17:42,552:INFO:Calculating mean and std
2026-01-29 16:17:42,552:INFO:Creating metrics dataframe
2026-01-29 16:17:42,558:INFO:Finalizing model
2026-01-29 16:17:43,833:INFO:Uploading results into container
2026-01-29 16:17:43,833:INFO:Uploading model into container now
2026-01-29 16:17:43,833:INFO:_master_model_container: 10
2026-01-29 16:17:43,833:INFO:_display_container: 6
2026-01-29 16:17:43,833:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:17:43,833:INFO:create_model() successfully completed......................................
2026-01-29 16:17:44,038:INFO:SubProcess create_model() end ==================================
2026-01-29 16:17:44,038:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.5369
2026-01-29 16:17:44,038:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=120, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.5369
2026-01-29 16:17:44,038:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-29 16:17:44,038:INFO:choose_better completed
2026-01-29 16:17:44,038:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:17:44,053:INFO:_master_model_container: 10
2026-01-29 16:17:44,053:INFO:_display_container: 5
2026-01-29 16:17:44,053:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:17:44,053:INFO:tune_model() successfully completed......................................
2026-01-29 16:17:44,254:INFO:Initializing evaluate_model()
2026-01-29 16:17:44,254:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:17:44,294:INFO:Initializing plot_model()
2026-01-29 16:17:44,294:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:17:44,295:INFO:Checking exceptions
2026-01-29 16:17:44,321:INFO:Preloading libraries
2026-01-29 16:17:44,321:INFO:Copying training dataset
2026-01-29 16:17:44,321:INFO:Plot type: pipeline
2026-01-29 16:17:44,371:INFO:Visual Rendered Successfully
2026-01-29 16:17:44,572:INFO:plot_model() successfully completed......................................
2026-01-29 16:17:44,572:INFO:Initializing evaluate_model()
2026-01-29 16:17:44,585:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:17:44,617:INFO:Initializing plot_model()
2026-01-29 16:17:44,617:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:17:44,617:INFO:Checking exceptions
2026-01-29 16:17:44,657:INFO:Preloading libraries
2026-01-29 16:17:44,658:INFO:Copying training dataset
2026-01-29 16:17:44,658:INFO:Plot type: pipeline
2026-01-29 16:17:44,750:INFO:Visual Rendered Successfully
2026-01-29 16:17:44,955:INFO:plot_model() successfully completed......................................
2026-01-29 16:17:44,955:INFO:Initializing evaluate_model()
2026-01-29 16:17:44,955:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:17:44,995:INFO:Initializing plot_model()
2026-01-29 16:17:44,995:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:17:44,995:INFO:Checking exceptions
2026-01-29 16:17:45,038:INFO:Preloading libraries
2026-01-29 16:17:45,038:INFO:Copying training dataset
2026-01-29 16:17:45,038:INFO:Plot type: pipeline
2026-01-29 16:17:45,101:INFO:Visual Rendered Successfully
2026-01-29 16:17:45,301:INFO:plot_model() successfully completed......................................
2026-01-29 16:17:45,312:INFO:Initializing predict_model()
2026-01-29 16:17:45,312:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002481E4E31A0>)
2026-01-29 16:17:45,312:INFO:Checking exceptions
2026-01-29 16:17:45,312:INFO:Preloading libraries
2026-01-29 16:17:45,314:INFO:Set up data.
2026-01-29 16:17:45,320:INFO:Set up index.
2026-01-29 16:17:45,803:INFO:Initializing predict_model()
2026-01-29 16:17:45,803:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000248172B4720>)
2026-01-29 16:17:45,803:INFO:Checking exceptions
2026-01-29 16:17:45,803:INFO:Preloading libraries
2026-01-29 16:17:45,803:INFO:Set up data.
2026-01-29 16:17:45,819:INFO:Set up index.
2026-01-29 16:17:46,305:INFO:Initializing predict_model()
2026-01-29 16:17:46,305:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002480F570EA0>)
2026-01-29 16:17:46,305:INFO:Checking exceptions
2026-01-29 16:17:46,305:INFO:Preloading libraries
2026-01-29 16:17:46,305:INFO:Set up data.
2026-01-29 16:17:46,305:INFO:Set up index.
2026-01-29 16:17:47,093:INFO:Initializing plot_model()
2026-01-29 16:17:47,093:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-29 16:17:47,093:INFO:Checking exceptions
2026-01-29 16:17:47,156:INFO:Preloading libraries
2026-01-29 16:17:47,156:INFO:Copying training dataset
2026-01-29 16:17:47,156:INFO:Plot type: feature
2026-01-29 16:17:47,476:INFO:Visual Rendered Successfully
2026-01-29 16:17:47,725:INFO:plot_model() successfully completed......................................
2026-01-29 16:17:47,725:INFO:Initializing save_model()
2026-01-29 16:17:47,725:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=..\datos\04. Modelos, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-29 16:17:47,725:INFO:Adding model into prep_pipe
2026-01-29 16:17:47,740:INFO:..\datos\04. Modelos.pkl saved in current working directory
2026-01-29 16:17:47,741:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(e...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=42,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2026-01-29 16:17:47,741:INFO:save_model() successfully completed......................................
2026-01-29 16:19:05,735:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\1878984716.py:18: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-29 16:19:07,449:INFO:PyCaret ClassificationExperiment
2026-01-29 16:19:07,449:INFO:Logging name: clf-default-name
2026-01-29 16:19:07,449:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-29 16:19:07,449:INFO:version 3.3.2
2026-01-29 16:19:07,451:INFO:Initializing setup()
2026-01-29 16:19:07,451:INFO:self.USI: e4f4
2026-01-29 16:19:07,451:INFO:self._variable_keys: {'X_test', 'fold_groups_param', 'pipeline', 'fix_imbalance', 'exp_name_log', 'data', 'y_test', 'seed', 'fold_shuffle_param', 'n_jobs_param', 'is_multiclass', 'gpu_n_jobs_param', 'memory', 'log_plots_param', 'logging_param', 'idx', 'y', 'target_param', 'fold_generator', 'y_train', 'gpu_param', 'USI', 'exp_id', '_available_plots', 'X', 'X_train', 'html_param', '_ml_usecase'}
2026-01-29 16:19:07,451:INFO:Checking environment
2026-01-29 16:19:07,451:INFO:python_version: 3.11.11
2026-01-29 16:19:07,451:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-29 16:19:07,451:INFO:machine: AMD64
2026-01-29 16:19:07,451:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-29 16:19:07,451:INFO:Memory: svmem(total=34009374720, available=13444653056, percent=60.5, used=20564721664, free=13444653056)
2026-01-29 16:19:07,451:INFO:Physical Core: 12
2026-01-29 16:19:07,452:INFO:Logical Core: 16
2026-01-29 16:19:07,452:INFO:Checking libraries
2026-01-29 16:19:07,452:INFO:System:
2026-01-29 16:19:07,452:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-29 16:19:07,452:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-29 16:19:07,452:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-29 16:19:07,452:INFO:PyCaret required dependencies:
2026-01-29 16:19:07,452:INFO:                 pip: 25.0
2026-01-29 16:19:07,452:INFO:          setuptools: 75.8.0
2026-01-29 16:19:07,452:INFO:             pycaret: 3.3.2
2026-01-29 16:19:07,452:INFO:             IPython: 9.9.0
2026-01-29 16:19:07,452:INFO:          ipywidgets: 8.1.8
2026-01-29 16:19:07,452:INFO:                tqdm: 4.67.1
2026-01-29 16:19:07,452:INFO:               numpy: 1.26.4
2026-01-29 16:19:07,452:INFO:              pandas: 2.1.4
2026-01-29 16:19:07,452:INFO:              jinja2: 3.1.6
2026-01-29 16:19:07,452:INFO:               scipy: 1.11.4
2026-01-29 16:19:07,452:INFO:              joblib: 1.3.2
2026-01-29 16:19:07,452:INFO:             sklearn: 1.4.2
2026-01-29 16:19:07,452:INFO:                pyod: 2.0.6
2026-01-29 16:19:07,452:INFO:            imblearn: 0.14.1
2026-01-29 16:19:07,452:INFO:   category_encoders: 2.7.0
2026-01-29 16:19:07,452:INFO:            lightgbm: 4.6.0
2026-01-29 16:19:07,452:INFO:               numba: 0.62.1
2026-01-29 16:19:07,452:INFO:            requests: 2.32.3
2026-01-29 16:19:07,452:INFO:          matplotlib: 3.7.5
2026-01-29 16:19:07,452:INFO:          scikitplot: 0.3.7
2026-01-29 16:19:07,452:INFO:         yellowbrick: 1.5
2026-01-29 16:19:07,452:INFO:              plotly: 5.24.1
2026-01-29 16:19:07,452:INFO:    plotly-resampler: Not installed
2026-01-29 16:19:07,452:INFO:             kaleido: 1.2.0
2026-01-29 16:19:07,452:INFO:           schemdraw: 0.15
2026-01-29 16:19:07,452:INFO:         statsmodels: 0.14.6
2026-01-29 16:19:07,452:INFO:              sktime: 0.26.0
2026-01-29 16:19:07,452:INFO:               tbats: 1.1.3
2026-01-29 16:19:07,452:INFO:            pmdarima: 2.0.4
2026-01-29 16:19:07,452:INFO:              psutil: 7.2.1
2026-01-29 16:19:07,452:INFO:          markupsafe: 3.0.3
2026-01-29 16:19:07,452:INFO:             pickle5: Not installed
2026-01-29 16:19:07,452:INFO:         cloudpickle: 3.0.0
2026-01-29 16:19:07,452:INFO:         deprecation: 2.1.0
2026-01-29 16:19:07,452:INFO:              xxhash: 3.6.0
2026-01-29 16:19:07,452:INFO:           wurlitzer: Not installed
2026-01-29 16:19:07,452:INFO:PyCaret optional dependencies:
2026-01-29 16:19:07,452:INFO:                shap: 0.44.1
2026-01-29 16:19:07,452:INFO:           interpret: 0.7.3
2026-01-29 16:19:07,452:INFO:                umap: 0.5.7
2026-01-29 16:19:07,452:INFO:     ydata_profiling: 4.18.1
2026-01-29 16:19:07,452:INFO:  explainerdashboard: 0.5.1
2026-01-29 16:19:07,452:INFO:             autoviz: Not installed
2026-01-29 16:19:07,452:INFO:           fairlearn: 0.7.0
2026-01-29 16:19:07,452:INFO:          deepchecks: Not installed
2026-01-29 16:19:07,452:INFO:             xgboost: Not installed
2026-01-29 16:19:07,452:INFO:            catboost: 1.2.8
2026-01-29 16:19:07,452:INFO:              kmodes: 0.12.2
2026-01-29 16:19:07,452:INFO:             mlxtend: 0.23.4
2026-01-29 16:19:07,452:INFO:       statsforecast: 1.5.0
2026-01-29 16:19:07,452:INFO:        tune_sklearn: Not installed
2026-01-29 16:19:07,452:INFO:                 ray: Not installed
2026-01-29 16:19:07,452:INFO:            hyperopt: 0.2.7
2026-01-29 16:19:07,452:INFO:              optuna: 4.6.0
2026-01-29 16:19:07,452:INFO:               skopt: 0.10.2
2026-01-29 16:19:07,452:INFO:              mlflow: 3.8.1
2026-01-29 16:19:07,452:INFO:              gradio: 6.3.0
2026-01-29 16:19:07,452:INFO:             fastapi: 0.128.0
2026-01-29 16:19:07,452:INFO:             uvicorn: 0.40.0
2026-01-29 16:19:07,452:INFO:              m2cgen: 0.10.0
2026-01-29 16:19:07,452:INFO:           evidently: 0.4.40
2026-01-29 16:19:07,452:INFO:               fugue: 0.8.7
2026-01-29 16:19:07,452:INFO:           streamlit: Not installed
2026-01-29 16:19:07,452:INFO:             prophet: Not installed
2026-01-29 16:19:07,452:INFO:None
2026-01-29 16:19:07,452:INFO:Set up data.
2026-01-29 16:19:07,485:INFO:Set up folding strategy.
2026-01-29 16:19:07,485:INFO:Set up train/test split.
2026-01-29 16:19:07,585:INFO:Set up index.
2026-01-29 16:19:07,585:INFO:Assigning column types.
2026-01-29 16:19:07,602:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-29 16:19:07,635:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:19:07,635:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:19:07,656:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:19:07,656:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:19:07,684:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:19:07,685:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:19:07,702:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:19:07,702:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:19:07,702:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-29 16:19:07,719:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:19:07,735:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:19:07,735:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:19:07,769:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:19:07,785:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:19:07,785:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:19:07,785:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-29 16:19:07,835:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:19:07,835:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:19:07,885:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:19:07,885:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:19:07,885:INFO:Preparing preprocessing pipeline...
2026-01-29 16:19:07,895:INFO:Set up simple imputation.
2026-01-29 16:19:07,895:INFO:Set up feature normalization.
2026-01-29 16:19:07,971:INFO:Finished creating preprocessing pipeline.
2026-01-29 16:19:07,971:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-29 16:19:07,971:INFO:Creating final display dataframe.
2026-01-29 16:19:08,186:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape       (429278, 4)
4        Transformed data shape       (429278, 4)
5   Transformed train set shape       (343422, 4)
6    Transformed test set shape        (85856, 4)
7               Ignore features                58
8              Numeric features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                 3
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              e4f4
2026-01-29 16:19:08,236:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:19:08,236:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:19:08,285:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:19:08,286:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:19:08,287:INFO:setup() successfully completed in 0.85s...............
2026-01-29 16:19:08,287:INFO:Initializing compare_models()
2026-01-29 16:19:08,287:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-29 16:19:08,287:INFO:Checking exceptions
2026-01-29 16:19:08,302:INFO:Preparing display monitor
2026-01-29 16:19:08,330:INFO:Initializing Logistic Regression
2026-01-29 16:19:08,330:INFO:Total runtime is 6.67572021484375e-06 minutes
2026-01-29 16:19:08,332:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:08,333:INFO:Initializing create_model()
2026-01-29 16:19:08,333:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002480E442290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:08,333:INFO:Checking exceptions
2026-01-29 16:19:08,333:INFO:Importing libraries
2026-01-29 16:19:08,333:INFO:Copying training dataset
2026-01-29 16:19:08,417:INFO:Defining folds
2026-01-29 16:19:08,417:INFO:Declaring metric variables
2026-01-29 16:19:08,420:INFO:Importing untrained model
2026-01-29 16:19:08,422:INFO:Logistic Regression Imported successfully
2026-01-29 16:19:08,427:INFO:Starting cross validation
2026-01-29 16:19:08,428:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:08,980:INFO:Calculating mean and std
2026-01-29 16:19:08,980:INFO:Creating metrics dataframe
2026-01-29 16:19:08,980:INFO:Uploading results into container
2026-01-29 16:19:08,980:INFO:Uploading model into container now
2026-01-29 16:19:08,984:INFO:_master_model_container: 1
2026-01-29 16:19:08,984:INFO:_display_container: 2
2026-01-29 16:19:08,984:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:19:08,984:INFO:create_model() successfully completed......................................
2026-01-29 16:19:09,185:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:09,185:INFO:Creating metrics dataframe
2026-01-29 16:19:09,185:INFO:Initializing Decision Tree Classifier
2026-01-29 16:19:09,185:INFO:Total runtime is 0.014251784483591715 minutes
2026-01-29 16:19:09,185:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:09,185:INFO:Initializing create_model()
2026-01-29 16:19:09,185:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002480E442290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:09,185:INFO:Checking exceptions
2026-01-29 16:19:09,185:INFO:Importing libraries
2026-01-29 16:19:09,185:INFO:Copying training dataset
2026-01-29 16:19:09,238:INFO:Defining folds
2026-01-29 16:19:09,251:INFO:Declaring metric variables
2026-01-29 16:19:09,253:INFO:Importing untrained model
2026-01-29 16:19:09,253:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:19:09,253:INFO:Starting cross validation
2026-01-29 16:19:09,253:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:09,718:INFO:Calculating mean and std
2026-01-29 16:19:09,719:INFO:Creating metrics dataframe
2026-01-29 16:19:09,719:INFO:Uploading results into container
2026-01-29 16:19:09,719:INFO:Uploading model into container now
2026-01-29 16:19:09,719:INFO:_master_model_container: 2
2026-01-29 16:19:09,723:INFO:_display_container: 2
2026-01-29 16:19:09,724:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:19:09,724:INFO:create_model() successfully completed......................................
2026-01-29 16:19:09,919:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:09,919:INFO:Creating metrics dataframe
2026-01-29 16:19:09,919:INFO:Initializing Random Forest Classifier
2026-01-29 16:19:09,919:INFO:Total runtime is 0.02647436459859212 minutes
2026-01-29 16:19:09,934:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:09,935:INFO:Initializing create_model()
2026-01-29 16:19:09,935:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002480E442290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:09,935:INFO:Checking exceptions
2026-01-29 16:19:09,935:INFO:Importing libraries
2026-01-29 16:19:09,935:INFO:Copying training dataset
2026-01-29 16:19:09,987:INFO:Defining folds
2026-01-29 16:19:09,987:INFO:Declaring metric variables
2026-01-29 16:19:09,987:INFO:Importing untrained model
2026-01-29 16:19:09,987:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:19:09,987:INFO:Starting cross validation
2026-01-29 16:19:09,987:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:12,204:INFO:Calculating mean and std
2026-01-29 16:19:12,204:INFO:Creating metrics dataframe
2026-01-29 16:19:12,217:INFO:Uploading results into container
2026-01-29 16:19:12,219:INFO:Uploading model into container now
2026-01-29 16:19:12,220:INFO:_master_model_container: 3
2026-01-29 16:19:12,220:INFO:_display_container: 2
2026-01-29 16:19:12,220:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:19:12,220:INFO:create_model() successfully completed......................................
2026-01-29 16:19:12,419:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:12,419:INFO:Creating metrics dataframe
2026-01-29 16:19:12,419:INFO:Initializing Light Gradient Boosting Machine
2026-01-29 16:19:12,419:INFO:Total runtime is 0.0681542714436849 minutes
2026-01-29 16:19:12,419:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:12,435:INFO:Initializing create_model()
2026-01-29 16:19:12,435:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002480E442290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:12,435:INFO:Checking exceptions
2026-01-29 16:19:12,435:INFO:Importing libraries
2026-01-29 16:19:12,435:INFO:Copying training dataset
2026-01-29 16:19:12,486:INFO:Defining folds
2026-01-29 16:19:12,486:INFO:Declaring metric variables
2026-01-29 16:19:12,486:INFO:Importing untrained model
2026-01-29 16:19:12,486:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-29 16:19:12,486:INFO:Starting cross validation
2026-01-29 16:19:12,502:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:13,632:INFO:Calculating mean and std
2026-01-29 16:19:13,632:INFO:Creating metrics dataframe
2026-01-29 16:19:13,632:INFO:Uploading results into container
2026-01-29 16:19:13,632:INFO:Uploading model into container now
2026-01-29 16:19:13,632:INFO:_master_model_container: 4
2026-01-29 16:19:13,632:INFO:_display_container: 2
2026-01-29 16:19:13,636:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-29 16:19:13,636:INFO:create_model() successfully completed......................................
2026-01-29 16:19:13,839:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:13,839:INFO:Creating metrics dataframe
2026-01-29 16:19:13,845:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-29 16:19:13,854:INFO:Initializing create_model()
2026-01-29 16:19:13,854:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:13,854:INFO:Checking exceptions
2026-01-29 16:19:13,854:INFO:Importing libraries
2026-01-29 16:19:13,854:INFO:Copying training dataset
2026-01-29 16:19:13,920:INFO:Defining folds
2026-01-29 16:19:13,920:INFO:Declaring metric variables
2026-01-29 16:19:13,920:INFO:Importing untrained model
2026-01-29 16:19:13,920:INFO:Declaring custom model
2026-01-29 16:19:13,921:INFO:Logistic Regression Imported successfully
2026-01-29 16:19:13,921:INFO:Cross validation set to False
2026-01-29 16:19:13,921:INFO:Fitting Model
2026-01-29 16:19:14,117:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:19:14,117:INFO:create_model() successfully completed......................................
2026-01-29 16:19:14,333:INFO:Initializing create_model()
2026-01-29 16:19:14,333:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:14,333:INFO:Checking exceptions
2026-01-29 16:19:14,345:INFO:Importing libraries
2026-01-29 16:19:14,345:INFO:Copying training dataset
2026-01-29 16:19:14,402:INFO:Defining folds
2026-01-29 16:19:14,402:INFO:Declaring metric variables
2026-01-29 16:19:14,402:INFO:Importing untrained model
2026-01-29 16:19:14,402:INFO:Declaring custom model
2026-01-29 16:19:14,402:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:19:14,402:INFO:Cross validation set to False
2026-01-29 16:19:14,402:INFO:Fitting Model
2026-01-29 16:19:14,469:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:19:14,469:INFO:create_model() successfully completed......................................
2026-01-29 16:19:14,671:INFO:Initializing create_model()
2026-01-29 16:19:14,671:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:14,671:INFO:Checking exceptions
2026-01-29 16:19:14,676:INFO:Importing libraries
2026-01-29 16:19:14,676:INFO:Copying training dataset
2026-01-29 16:19:14,735:INFO:Defining folds
2026-01-29 16:19:14,735:INFO:Declaring metric variables
2026-01-29 16:19:14,735:INFO:Importing untrained model
2026-01-29 16:19:14,735:INFO:Declaring custom model
2026-01-29 16:19:14,735:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:19:14,735:INFO:Cross validation set to False
2026-01-29 16:19:14,735:INFO:Fitting Model
2026-01-29 16:19:15,867:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:19:15,867:INFO:create_model() successfully completed......................................
2026-01-29 16:19:16,086:INFO:_master_model_container: 4
2026-01-29 16:19:16,086:INFO:_display_container: 2
2026-01-29 16:19:16,086:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2026-01-29 16:19:16,086:INFO:compare_models() successfully completed......................................
2026-01-29 16:19:16,086:INFO:Initializing tune_model()
2026-01-29 16:19:16,086:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:19:16,086:INFO:Checking exceptions
2026-01-29 16:19:16,134:INFO:Copying training dataset
2026-01-29 16:19:16,196:INFO:Checking base model
2026-01-29 16:19:16,196:INFO:Base model : Logistic Regression
2026-01-29 16:19:16,199:INFO:Declaring metric variables
2026-01-29 16:19:16,201:INFO:Defining Hyperparameters
2026-01-29 16:19:16,418:INFO:Tuning with n_jobs=-1
2026-01-29 16:19:16,418:INFO:Initializing RandomizedSearchCV
2026-01-29 16:19:17,823:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 5.682}
2026-01-29 16:19:17,823:INFO:Hyperparameter search completed
2026-01-29 16:19:17,823:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:17,823:INFO:Initializing create_model()
2026-01-29 16:19:17,823:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816DB8910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 5.682})
2026-01-29 16:19:17,823:INFO:Checking exceptions
2026-01-29 16:19:17,823:INFO:Importing libraries
2026-01-29 16:19:17,823:INFO:Copying training dataset
2026-01-29 16:19:17,886:INFO:Defining folds
2026-01-29 16:19:17,886:INFO:Declaring metric variables
2026-01-29 16:19:17,886:INFO:Importing untrained model
2026-01-29 16:19:17,886:INFO:Declaring custom model
2026-01-29 16:19:17,886:INFO:Logistic Regression Imported successfully
2026-01-29 16:19:17,901:INFO:Starting cross validation
2026-01-29 16:19:17,901:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:18,608:INFO:Calculating mean and std
2026-01-29 16:19:18,608:INFO:Creating metrics dataframe
2026-01-29 16:19:18,608:INFO:Finalizing model
2026-01-29 16:19:18,909:INFO:Uploading results into container
2026-01-29 16:19:18,911:INFO:Uploading model into container now
2026-01-29 16:19:18,911:INFO:_master_model_container: 5
2026-01-29 16:19:18,911:INFO:_display_container: 3
2026-01-29 16:19:18,911:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:19:18,911:INFO:create_model() successfully completed......................................
2026-01-29 16:19:19,120:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:19,120:INFO:choose_better activated
2026-01-29 16:19:19,120:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:19,120:INFO:Initializing create_model()
2026-01-29 16:19:19,120:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:19,120:INFO:Checking exceptions
2026-01-29 16:19:19,120:INFO:Importing libraries
2026-01-29 16:19:19,120:INFO:Copying training dataset
2026-01-29 16:19:19,185:INFO:Defining folds
2026-01-29 16:19:19,185:INFO:Declaring metric variables
2026-01-29 16:19:19,185:INFO:Importing untrained model
2026-01-29 16:19:19,185:INFO:Declaring custom model
2026-01-29 16:19:19,185:INFO:Logistic Regression Imported successfully
2026-01-29 16:19:19,189:INFO:Starting cross validation
2026-01-29 16:19:19,189:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:19,920:INFO:Calculating mean and std
2026-01-29 16:19:19,920:INFO:Creating metrics dataframe
2026-01-29 16:19:19,920:INFO:Finalizing model
2026-01-29 16:19:20,154:INFO:Uploading results into container
2026-01-29 16:19:20,154:INFO:Uploading model into container now
2026-01-29 16:19:20,154:INFO:_master_model_container: 6
2026-01-29 16:19:20,154:INFO:_display_container: 4
2026-01-29 16:19:20,154:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:19:20,154:INFO:create_model() successfully completed......................................
2026-01-29 16:19:20,371:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:20,371:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 16:19:20,371:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 16:19:20,371:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2026-01-29 16:19:20,371:INFO:choose_better completed
2026-01-29 16:19:20,371:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:19:20,371:INFO:_master_model_container: 6
2026-01-29 16:19:20,371:INFO:_display_container: 3
2026-01-29 16:19:20,371:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:19:20,371:INFO:tune_model() successfully completed......................................
2026-01-29 16:19:20,592:INFO:Initializing tune_model()
2026-01-29 16:19:20,592:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:19:20,592:INFO:Checking exceptions
2026-01-29 16:19:20,619:INFO:Copying training dataset
2026-01-29 16:19:20,690:INFO:Checking base model
2026-01-29 16:19:20,692:INFO:Base model : Decision Tree Classifier
2026-01-29 16:19:20,694:INFO:Declaring metric variables
2026-01-29 16:19:20,697:INFO:Defining Hyperparameters
2026-01-29 16:19:20,903:INFO:Tuning with n_jobs=-1
2026-01-29 16:19:20,903:INFO:Initializing RandomizedSearchCV
2026-01-29 16:19:21,772:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.0005, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 3, 'actual_estimator__criterion': 'gini'}
2026-01-29 16:19:21,772:INFO:Hyperparameter search completed
2026-01-29 16:19:21,772:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:21,772:INFO:Initializing create_model()
2026-01-29 16:19:21,772:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002487E3F3ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0005, 'max_features': 1.0, 'max_depth': 3, 'criterion': 'gini'})
2026-01-29 16:19:21,772:INFO:Checking exceptions
2026-01-29 16:19:21,772:INFO:Importing libraries
2026-01-29 16:19:21,772:INFO:Copying training dataset
2026-01-29 16:19:21,834:INFO:Defining folds
2026-01-29 16:19:21,834:INFO:Declaring metric variables
2026-01-29 16:19:21,834:INFO:Importing untrained model
2026-01-29 16:19:21,834:INFO:Declaring custom model
2026-01-29 16:19:21,834:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:19:21,834:INFO:Starting cross validation
2026-01-29 16:19:21,834:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:22,491:INFO:Calculating mean and std
2026-01-29 16:19:22,491:INFO:Creating metrics dataframe
2026-01-29 16:19:22,501:INFO:Finalizing model
2026-01-29 16:19:22,568:INFO:Uploading results into container
2026-01-29 16:19:22,568:INFO:Uploading model into container now
2026-01-29 16:19:22,568:INFO:_master_model_container: 7
2026-01-29 16:19:22,568:INFO:_display_container: 4
2026-01-29 16:19:22,568:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:19:22,568:INFO:create_model() successfully completed......................................
2026-01-29 16:19:22,817:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:22,818:INFO:choose_better activated
2026-01-29 16:19:22,821:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:22,822:INFO:Initializing create_model()
2026-01-29 16:19:22,822:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:22,822:INFO:Checking exceptions
2026-01-29 16:19:22,822:INFO:Importing libraries
2026-01-29 16:19:22,822:INFO:Copying training dataset
2026-01-29 16:19:22,894:INFO:Defining folds
2026-01-29 16:19:22,894:INFO:Declaring metric variables
2026-01-29 16:19:22,894:INFO:Importing untrained model
2026-01-29 16:19:22,894:INFO:Declaring custom model
2026-01-29 16:19:22,896:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:19:22,896:INFO:Starting cross validation
2026-01-29 16:19:22,896:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:23,496:INFO:Calculating mean and std
2026-01-29 16:19:23,496:INFO:Creating metrics dataframe
2026-01-29 16:19:23,500:INFO:Finalizing model
2026-01-29 16:19:23,563:INFO:Uploading results into container
2026-01-29 16:19:23,570:INFO:Uploading model into container now
2026-01-29 16:19:23,570:INFO:_master_model_container: 8
2026-01-29 16:19:23,570:INFO:_display_container: 5
2026-01-29 16:19:23,570:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:19:23,570:INFO:create_model() successfully completed......................................
2026-01-29 16:19:23,786:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:23,786:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5369
2026-01-29 16:19:23,786:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5366
2026-01-29 16:19:23,786:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-29 16:19:23,786:INFO:choose_better completed
2026-01-29 16:19:23,786:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:19:23,801:INFO:_master_model_container: 8
2026-01-29 16:19:23,802:INFO:_display_container: 4
2026-01-29 16:19:23,802:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:19:23,802:INFO:tune_model() successfully completed......................................
2026-01-29 16:19:24,019:INFO:Initializing tune_model()
2026-01-29 16:19:24,019:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:19:24,019:INFO:Checking exceptions
2026-01-29 16:19:24,054:INFO:Copying training dataset
2026-01-29 16:19:24,109:INFO:Checking base model
2026-01-29 16:19:24,109:INFO:Base model : Random Forest Classifier
2026-01-29 16:19:24,112:INFO:Declaring metric variables
2026-01-29 16:19:24,115:INFO:Defining Hyperparameters
2026-01-29 16:19:24,335:INFO:Tuning with n_jobs=-1
2026-01-29 16:19:24,335:INFO:Initializing RandomizedSearchCV
2026-01-29 16:19:48,174:INFO:best_params: {'actual_estimator__n_estimators': 120, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-29 16:19:48,174:INFO:Hyperparameter search completed
2026-01-29 16:19:48,174:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:48,174:INFO:Initializing create_model()
2026-01-29 16:19:48,174:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816D828D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 120, 'min_samples_split': 5, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': True})
2026-01-29 16:19:48,174:INFO:Checking exceptions
2026-01-29 16:19:48,174:INFO:Importing libraries
2026-01-29 16:19:48,174:INFO:Copying training dataset
2026-01-29 16:19:48,289:INFO:Defining folds
2026-01-29 16:19:48,289:INFO:Declaring metric variables
2026-01-29 16:19:48,292:INFO:Importing untrained model
2026-01-29 16:19:48,292:INFO:Declaring custom model
2026-01-29 16:19:48,297:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:19:48,306:INFO:Starting cross validation
2026-01-29 16:19:48,306:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:51,069:INFO:Calculating mean and std
2026-01-29 16:19:51,069:INFO:Creating metrics dataframe
2026-01-29 16:19:51,069:INFO:Finalizing model
2026-01-29 16:19:52,812:INFO:Uploading results into container
2026-01-29 16:19:52,812:INFO:Uploading model into container now
2026-01-29 16:19:52,812:INFO:_master_model_container: 9
2026-01-29 16:19:52,812:INFO:_display_container: 5
2026-01-29 16:19:52,812:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=120, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:19:52,812:INFO:create_model() successfully completed......................................
2026-01-29 16:19:53,037:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:53,037:INFO:choose_better activated
2026-01-29 16:19:53,037:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:53,037:INFO:Initializing create_model()
2026-01-29 16:19:53,037:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:53,037:INFO:Checking exceptions
2026-01-29 16:19:53,037:INFO:Importing libraries
2026-01-29 16:19:53,037:INFO:Copying training dataset
2026-01-29 16:19:53,102:INFO:Defining folds
2026-01-29 16:19:53,102:INFO:Declaring metric variables
2026-01-29 16:19:53,102:INFO:Importing untrained model
2026-01-29 16:19:53,102:INFO:Declaring custom model
2026-01-29 16:19:53,102:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:19:53,102:INFO:Starting cross validation
2026-01-29 16:19:53,102:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:55,455:INFO:Calculating mean and std
2026-01-29 16:19:55,455:INFO:Creating metrics dataframe
2026-01-29 16:19:55,455:INFO:Finalizing model
2026-01-29 16:19:56,823:INFO:Uploading results into container
2026-01-29 16:19:56,823:INFO:Uploading model into container now
2026-01-29 16:19:56,823:INFO:_master_model_container: 10
2026-01-29 16:19:56,823:INFO:_display_container: 6
2026-01-29 16:19:56,823:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:19:56,823:INFO:create_model() successfully completed......................................
2026-01-29 16:19:57,035:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:57,035:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.5369
2026-01-29 16:19:57,035:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=120, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.5369
2026-01-29 16:19:57,035:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-29 16:19:57,035:INFO:choose_better completed
2026-01-29 16:19:57,035:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:19:57,051:INFO:_master_model_container: 10
2026-01-29 16:19:57,051:INFO:_display_container: 5
2026-01-29 16:19:57,051:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:19:57,051:INFO:tune_model() successfully completed......................................
2026-01-29 16:19:57,302:INFO:Initializing evaluate_model()
2026-01-29 16:19:57,302:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:19:57,338:INFO:Initializing plot_model()
2026-01-29 16:19:57,339:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:19:57,339:INFO:Checking exceptions
2026-01-29 16:19:57,371:INFO:Preloading libraries
2026-01-29 16:19:57,371:INFO:Copying training dataset
2026-01-29 16:19:57,371:INFO:Plot type: pipeline
2026-01-29 16:19:57,435:INFO:Visual Rendered Successfully
2026-01-29 16:19:57,701:INFO:plot_model() successfully completed......................................
2026-01-29 16:19:57,701:INFO:Initializing evaluate_model()
2026-01-29 16:19:57,701:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:19:57,754:INFO:Initializing plot_model()
2026-01-29 16:19:57,754:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:19:57,754:INFO:Checking exceptions
2026-01-29 16:19:57,786:INFO:Preloading libraries
2026-01-29 16:19:57,786:INFO:Copying training dataset
2026-01-29 16:19:57,786:INFO:Plot type: pipeline
2026-01-29 16:19:57,895:INFO:Visual Rendered Successfully
2026-01-29 16:19:58,118:INFO:plot_model() successfully completed......................................
2026-01-29 16:19:58,126:INFO:Initializing evaluate_model()
2026-01-29 16:19:58,127:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:19:58,162:INFO:Initializing plot_model()
2026-01-29 16:19:58,163:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:19:58,163:INFO:Checking exceptions
2026-01-29 16:19:58,239:INFO:Preloading libraries
2026-01-29 16:19:58,239:INFO:Copying training dataset
2026-01-29 16:19:58,239:INFO:Plot type: pipeline
2026-01-29 16:19:58,325:INFO:Visual Rendered Successfully
2026-01-29 16:19:58,540:INFO:plot_model() successfully completed......................................
2026-01-29 16:19:58,551:INFO:Initializing predict_model()
2026-01-29 16:19:58,552:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000248488BA8E0>)
2026-01-29 16:19:58,552:INFO:Checking exceptions
2026-01-29 16:19:58,552:INFO:Preloading libraries
2026-01-29 16:19:58,553:INFO:Set up data.
2026-01-29 16:19:58,564:INFO:Set up index.
2026-01-29 16:19:59,152:INFO:Initializing predict_model()
2026-01-29 16:19:59,152:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002480F572AC0>)
2026-01-29 16:19:59,152:INFO:Checking exceptions
2026-01-29 16:19:59,152:INFO:Preloading libraries
2026-01-29 16:19:59,154:INFO:Set up data.
2026-01-29 16:19:59,154:INFO:Set up index.
2026-01-29 16:19:59,685:INFO:Initializing predict_model()
2026-01-29 16:19:59,685:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002487FF34220>)
2026-01-29 16:19:59,685:INFO:Checking exceptions
2026-01-29 16:19:59,685:INFO:Preloading libraries
2026-01-29 16:19:59,685:INFO:Set up data.
2026-01-29 16:19:59,685:INFO:Set up index.
2026-01-29 16:20:00,418:INFO:Initializing plot_model()
2026-01-29 16:20:00,419:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-29 16:20:00,419:INFO:Checking exceptions
2026-01-29 16:20:00,442:INFO:Preloading libraries
2026-01-29 16:20:00,442:INFO:Copying training dataset
2026-01-29 16:20:00,442:INFO:Plot type: feature
2026-01-29 16:20:00,728:INFO:Visual Rendered Successfully
2026-01-29 16:20:00,970:INFO:plot_model() successfully completed......................................
2026-01-29 16:20:00,973:INFO:Initializing save_model()
2026-01-29 16:20:00,973:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=..\datos\04. Modelos, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-29 16:20:00,973:INFO:Adding model into prep_pipe
2026-01-29 16:20:00,973:INFO:..\datos\04. Modelos.pkl saved in current working directory
2026-01-29 16:20:00,988:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(e...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=42,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2026-01-29 16:20:00,988:INFO:save_model() successfully completed......................................
