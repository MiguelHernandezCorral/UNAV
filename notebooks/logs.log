2026-01-19 10:24:16,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-19 10:24:16,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-19 10:24:16,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-19 10:24:16,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-29 15:21:31,736:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-29 15:21:31,736:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-29 15:21:31,736:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-29 15:21:31,736:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-29 15:21:35,750:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\2388759396.py:16: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-29 15:25:39,783:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\2256906154.py:17: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-29 15:26:50,165:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\1372246288.py:16: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-29 15:26:51,818:INFO:PyCaret ClassificationExperiment
2026-01-29 15:26:51,819:INFO:Logging name: clf-default-name
2026-01-29 15:26:51,819:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-29 15:26:51,820:INFO:version 3.3.2
2026-01-29 15:26:51,820:INFO:Initializing setup()
2026-01-29 15:26:51,820:INFO:self.USI: f012
2026-01-29 15:26:51,820:INFO:self._variable_keys: {'X_test', 'fold_groups_param', 'pipeline', 'fix_imbalance', 'exp_name_log', 'data', 'y_test', 'seed', 'fold_shuffle_param', 'n_jobs_param', 'is_multiclass', 'gpu_n_jobs_param', 'memory', 'log_plots_param', 'logging_param', 'idx', 'y', 'target_param', 'fold_generator', 'y_train', 'gpu_param', 'USI', 'exp_id', '_available_plots', 'X', 'X_train', 'html_param', '_ml_usecase'}
2026-01-29 15:26:51,820:INFO:Checking environment
2026-01-29 15:26:51,820:INFO:python_version: 3.11.11
2026-01-29 15:26:51,821:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-29 15:26:51,821:INFO:machine: AMD64
2026-01-29 15:26:51,821:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-29 15:26:51,821:INFO:Memory: svmem(total=34009374720, available=16823705600, percent=50.5, used=17185669120, free=16823705600)
2026-01-29 15:26:51,822:INFO:Physical Core: 12
2026-01-29 15:26:51,822:INFO:Logical Core: 16
2026-01-29 15:26:51,822:INFO:Checking libraries
2026-01-29 15:26:51,822:INFO:System:
2026-01-29 15:26:51,822:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-29 15:26:51,822:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-29 15:26:51,822:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-29 15:26:51,823:INFO:PyCaret required dependencies:
2026-01-29 15:26:54,258:INFO:                 pip: 25.0
2026-01-29 15:26:54,258:INFO:          setuptools: 75.8.0
2026-01-29 15:26:54,258:INFO:             pycaret: 3.3.2
2026-01-29 15:26:54,258:INFO:             IPython: 9.9.0
2026-01-29 15:26:54,258:INFO:          ipywidgets: 8.1.8
2026-01-29 15:26:54,258:INFO:                tqdm: 4.67.1
2026-01-29 15:26:54,258:INFO:               numpy: 1.26.4
2026-01-29 15:26:54,259:INFO:              pandas: 2.1.4
2026-01-29 15:26:54,259:INFO:              jinja2: 3.1.6
2026-01-29 15:26:54,259:INFO:               scipy: 1.11.4
2026-01-29 15:26:54,259:INFO:              joblib: 1.3.2
2026-01-29 15:26:54,259:INFO:             sklearn: 1.4.2
2026-01-29 15:26:54,259:INFO:                pyod: 2.0.6
2026-01-29 15:26:54,259:INFO:            imblearn: 0.14.1
2026-01-29 15:26:54,259:INFO:   category_encoders: 2.7.0
2026-01-29 15:26:54,259:INFO:            lightgbm: 4.6.0
2026-01-29 15:26:54,259:INFO:               numba: 0.62.1
2026-01-29 15:26:54,259:INFO:            requests: 2.32.3
2026-01-29 15:26:54,259:INFO:          matplotlib: 3.7.5
2026-01-29 15:26:54,259:INFO:          scikitplot: 0.3.7
2026-01-29 15:26:54,259:INFO:         yellowbrick: 1.5
2026-01-29 15:26:54,259:INFO:              plotly: 5.24.1
2026-01-29 15:26:54,259:INFO:    plotly-resampler: Not installed
2026-01-29 15:26:54,259:INFO:             kaleido: 1.2.0
2026-01-29 15:26:54,259:INFO:           schemdraw: 0.15
2026-01-29 15:26:54,259:INFO:         statsmodels: 0.14.6
2026-01-29 15:26:54,259:INFO:              sktime: 0.26.0
2026-01-29 15:26:54,259:INFO:               tbats: 1.1.3
2026-01-29 15:26:54,259:INFO:            pmdarima: 2.0.4
2026-01-29 15:26:54,259:INFO:              psutil: 7.2.1
2026-01-29 15:26:54,260:INFO:          markupsafe: 3.0.3
2026-01-29 15:26:54,260:INFO:             pickle5: Not installed
2026-01-29 15:26:54,260:INFO:         cloudpickle: 3.0.0
2026-01-29 15:26:54,260:INFO:         deprecation: 2.1.0
2026-01-29 15:26:54,260:INFO:              xxhash: 3.6.0
2026-01-29 15:26:54,260:INFO:           wurlitzer: Not installed
2026-01-29 15:26:54,260:INFO:PyCaret optional dependencies:
2026-01-29 15:27:00,934:INFO:                shap: 0.44.1
2026-01-29 15:27:00,934:INFO:           interpret: 0.7.3
2026-01-29 15:27:00,934:INFO:                umap: 0.5.7
2026-01-29 15:27:00,934:INFO:     ydata_profiling: 4.18.1
2026-01-29 15:27:00,934:INFO:  explainerdashboard: 0.5.1
2026-01-29 15:27:00,934:INFO:             autoviz: Not installed
2026-01-29 15:27:00,936:INFO:           fairlearn: 0.7.0
2026-01-29 15:27:00,936:INFO:          deepchecks: Not installed
2026-01-29 15:27:00,936:INFO:             xgboost: Not installed
2026-01-29 15:27:00,936:INFO:            catboost: 1.2.8
2026-01-29 15:27:00,936:INFO:              kmodes: 0.12.2
2026-01-29 15:27:00,936:INFO:             mlxtend: 0.23.4
2026-01-29 15:27:00,936:INFO:       statsforecast: 1.5.0
2026-01-29 15:27:00,936:INFO:        tune_sklearn: Not installed
2026-01-29 15:27:00,936:INFO:                 ray: Not installed
2026-01-29 15:27:00,936:INFO:            hyperopt: 0.2.7
2026-01-29 15:27:00,936:INFO:              optuna: 4.6.0
2026-01-29 15:27:00,936:INFO:               skopt: 0.10.2
2026-01-29 15:27:00,938:INFO:              mlflow: 3.8.1
2026-01-29 15:27:00,938:INFO:              gradio: 6.3.0
2026-01-29 15:27:00,938:INFO:             fastapi: 0.128.0
2026-01-29 15:27:00,938:INFO:             uvicorn: 0.40.0
2026-01-29 15:27:00,938:INFO:              m2cgen: 0.10.0
2026-01-29 15:27:00,939:INFO:           evidently: 0.4.40
2026-01-29 15:27:00,939:INFO:               fugue: 0.8.7
2026-01-29 15:27:00,939:INFO:           streamlit: Not installed
2026-01-29 15:27:00,939:INFO:             prophet: Not installed
2026-01-29 15:27:00,939:INFO:None
2026-01-29 15:27:00,940:INFO:Set up data.
2026-01-29 15:27:02,745:INFO:Set up folding strategy.
2026-01-29 15:27:02,746:INFO:Set up train/test split.
2026-01-29 15:27:03,016:INFO:Set up index.
2026-01-29 15:27:03,029:INFO:Assigning column types.
2026-01-29 15:27:03,163:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-29 15:27:03,188:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 15:27:03,198:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:27:03,235:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:27:03,235:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:27:03,439:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 15:27:03,440:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:27:03,455:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:27:03,456:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:27:03,456:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-29 15:27:03,493:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:27:03,516:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:27:03,516:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:27:03,543:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:27:03,559:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:27:03,560:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:27:03,560:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-29 15:27:03,617:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:27:03,617:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:27:03,661:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:27:03,661:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:27:03,663:INFO:Preparing preprocessing pipeline...
2026-01-29 15:27:03,692:INFO:Set up simple imputation.
2026-01-29 15:27:03,845:INFO:Set up encoding of ordinal features.
2026-01-29 15:27:04,428:INFO:Set up encoding of categorical features.
2026-01-29 15:27:04,430:INFO:Set up column transformation.
2026-01-29 15:27:04,430:INFO:Set up feature normalization.
2026-01-29 15:29:42,743:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\3853355163.py:16: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-29 15:29:43,543:INFO:PyCaret ClassificationExperiment
2026-01-29 15:29:43,544:INFO:Logging name: clf-default-name
2026-01-29 15:29:43,544:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-29 15:29:43,544:INFO:version 3.3.2
2026-01-29 15:29:43,544:INFO:Initializing setup()
2026-01-29 15:29:43,544:INFO:self.USI: 2dfb
2026-01-29 15:29:43,545:INFO:self._variable_keys: {'X_test', 'fold_groups_param', 'pipeline', 'fix_imbalance', 'exp_name_log', 'data', 'y_test', 'seed', 'fold_shuffle_param', 'n_jobs_param', 'is_multiclass', 'gpu_n_jobs_param', 'memory', 'log_plots_param', 'logging_param', 'idx', 'y', 'target_param', 'fold_generator', 'y_train', 'gpu_param', 'USI', 'exp_id', '_available_plots', 'X', 'X_train', 'html_param', '_ml_usecase'}
2026-01-29 15:29:43,545:INFO:Checking environment
2026-01-29 15:29:43,545:INFO:python_version: 3.11.11
2026-01-29 15:29:43,545:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-29 15:29:43,545:INFO:machine: AMD64
2026-01-29 15:29:43,545:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-29 15:29:43,546:INFO:Memory: svmem(total=34009374720, available=16752574464, percent=50.7, used=17256800256, free=16752574464)
2026-01-29 15:29:43,546:INFO:Physical Core: 12
2026-01-29 15:29:43,546:INFO:Logical Core: 16
2026-01-29 15:29:43,546:INFO:Checking libraries
2026-01-29 15:29:43,546:INFO:System:
2026-01-29 15:29:43,546:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-29 15:29:43,546:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-29 15:29:43,546:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-29 15:29:43,546:INFO:PyCaret required dependencies:
2026-01-29 15:29:43,546:INFO:                 pip: 25.0
2026-01-29 15:29:43,546:INFO:          setuptools: 75.8.0
2026-01-29 15:29:43,546:INFO:             pycaret: 3.3.2
2026-01-29 15:29:43,546:INFO:             IPython: 9.9.0
2026-01-29 15:29:43,546:INFO:          ipywidgets: 8.1.8
2026-01-29 15:29:43,547:INFO:                tqdm: 4.67.1
2026-01-29 15:29:43,547:INFO:               numpy: 1.26.4
2026-01-29 15:29:43,547:INFO:              pandas: 2.1.4
2026-01-29 15:29:43,547:INFO:              jinja2: 3.1.6
2026-01-29 15:29:43,547:INFO:               scipy: 1.11.4
2026-01-29 15:29:43,547:INFO:              joblib: 1.3.2
2026-01-29 15:29:43,547:INFO:             sklearn: 1.4.2
2026-01-29 15:29:43,547:INFO:                pyod: 2.0.6
2026-01-29 15:29:43,547:INFO:            imblearn: 0.14.1
2026-01-29 15:29:43,547:INFO:   category_encoders: 2.7.0
2026-01-29 15:29:43,547:INFO:            lightgbm: 4.6.0
2026-01-29 15:29:43,547:INFO:               numba: 0.62.1
2026-01-29 15:29:43,547:INFO:            requests: 2.32.3
2026-01-29 15:29:43,547:INFO:          matplotlib: 3.7.5
2026-01-29 15:29:43,547:INFO:          scikitplot: 0.3.7
2026-01-29 15:29:43,547:INFO:         yellowbrick: 1.5
2026-01-29 15:29:43,547:INFO:              plotly: 5.24.1
2026-01-29 15:29:43,547:INFO:    plotly-resampler: Not installed
2026-01-29 15:29:43,547:INFO:             kaleido: 1.2.0
2026-01-29 15:29:43,547:INFO:           schemdraw: 0.15
2026-01-29 15:29:43,548:INFO:         statsmodels: 0.14.6
2026-01-29 15:29:43,548:INFO:              sktime: 0.26.0
2026-01-29 15:29:43,548:INFO:               tbats: 1.1.3
2026-01-29 15:29:43,548:INFO:            pmdarima: 2.0.4
2026-01-29 15:29:43,548:INFO:              psutil: 7.2.1
2026-01-29 15:29:43,548:INFO:          markupsafe: 3.0.3
2026-01-29 15:29:43,548:INFO:             pickle5: Not installed
2026-01-29 15:29:43,548:INFO:         cloudpickle: 3.0.0
2026-01-29 15:29:43,548:INFO:         deprecation: 2.1.0
2026-01-29 15:29:43,548:INFO:              xxhash: 3.6.0
2026-01-29 15:29:43,548:INFO:           wurlitzer: Not installed
2026-01-29 15:29:43,548:INFO:PyCaret optional dependencies:
2026-01-29 15:29:43,548:INFO:                shap: 0.44.1
2026-01-29 15:29:43,548:INFO:           interpret: 0.7.3
2026-01-29 15:29:43,548:INFO:                umap: 0.5.7
2026-01-29 15:29:43,549:INFO:     ydata_profiling: 4.18.1
2026-01-29 15:29:43,549:INFO:  explainerdashboard: 0.5.1
2026-01-29 15:29:43,549:INFO:             autoviz: Not installed
2026-01-29 15:29:43,549:INFO:           fairlearn: 0.7.0
2026-01-29 15:29:43,549:INFO:          deepchecks: Not installed
2026-01-29 15:29:43,549:INFO:             xgboost: Not installed
2026-01-29 15:29:43,549:INFO:            catboost: 1.2.8
2026-01-29 15:29:43,549:INFO:              kmodes: 0.12.2
2026-01-29 15:29:43,549:INFO:             mlxtend: 0.23.4
2026-01-29 15:29:43,549:INFO:       statsforecast: 1.5.0
2026-01-29 15:29:43,549:INFO:        tune_sklearn: Not installed
2026-01-29 15:29:43,549:INFO:                 ray: Not installed
2026-01-29 15:29:43,549:INFO:            hyperopt: 0.2.7
2026-01-29 15:29:43,549:INFO:              optuna: 4.6.0
2026-01-29 15:29:43,549:INFO:               skopt: 0.10.2
2026-01-29 15:29:43,549:INFO:              mlflow: 3.8.1
2026-01-29 15:29:43,549:INFO:              gradio: 6.3.0
2026-01-29 15:29:43,549:INFO:             fastapi: 0.128.0
2026-01-29 15:29:43,549:INFO:             uvicorn: 0.40.0
2026-01-29 15:29:43,549:INFO:              m2cgen: 0.10.0
2026-01-29 15:29:43,549:INFO:           evidently: 0.4.40
2026-01-29 15:29:43,549:INFO:               fugue: 0.8.7
2026-01-29 15:29:43,549:INFO:           streamlit: Not installed
2026-01-29 15:29:43,549:INFO:             prophet: Not installed
2026-01-29 15:29:43,549:INFO:None
2026-01-29 15:29:43,549:INFO:Set up data.
2026-01-29 15:29:43,754:INFO:Set up folding strategy.
2026-01-29 15:29:43,754:INFO:Set up train/test split.
2026-01-29 15:29:43,990:INFO:Set up index.
2026-01-29 15:29:43,993:INFO:Assigning column types.
2026-01-29 15:29:44,136:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-29 15:29:44,174:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 15:29:44,175:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:29:44,200:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:29:44,200:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:29:44,238:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 15:29:44,239:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:29:44,263:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:29:44,264:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:29:44,265:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-29 15:29:44,304:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:29:44,327:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:29:44,327:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:29:44,359:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:29:44,395:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:29:44,395:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:29:44,396:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-29 15:29:44,471:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:29:44,472:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:29:44,530:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:29:44,530:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:29:44,545:INFO:Preparing preprocessing pipeline...
2026-01-29 15:29:44,564:INFO:Set up simple imputation.
2026-01-29 15:29:44,564:INFO:Set up column transformation.
2026-01-29 15:29:44,564:INFO:Set up feature normalization.
2026-01-29 15:29:46,181:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\numpy\core\_methods.py:176: RuntimeWarning: overflow encountered in multiply

2026-01-29 15:29:47,054:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\preprocessing\_data.py:3408: RuntimeWarning: overflow encountered in power

2026-01-29 15:29:47,057:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\numpy\core\_methods.py:152: RuntimeWarning: overflow encountered in reduce

2026-01-29 15:32:51,925:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\306957030.py:15: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-29 15:33:59,293:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\1040826916.py:15: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-29 15:34:57,609:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\4055341079.py:18: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-29 15:34:59,879:INFO:PyCaret ClassificationExperiment
2026-01-29 15:34:59,879:INFO:Logging name: clf-default-name
2026-01-29 15:34:59,879:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-29 15:34:59,879:INFO:version 3.3.2
2026-01-29 15:34:59,879:INFO:Initializing setup()
2026-01-29 15:34:59,879:INFO:self.USI: 732d
2026-01-29 15:34:59,879:INFO:self._variable_keys: {'X_test', 'fold_groups_param', 'pipeline', 'fix_imbalance', 'exp_name_log', 'data', 'y_test', 'seed', 'fold_shuffle_param', 'n_jobs_param', 'is_multiclass', 'gpu_n_jobs_param', 'memory', 'log_plots_param', 'logging_param', 'idx', 'y', 'target_param', 'fold_generator', 'y_train', 'gpu_param', 'USI', 'exp_id', '_available_plots', 'X', 'X_train', 'html_param', '_ml_usecase'}
2026-01-29 15:34:59,879:INFO:Checking environment
2026-01-29 15:34:59,879:INFO:python_version: 3.11.11
2026-01-29 15:34:59,879:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-29 15:34:59,879:INFO:machine: AMD64
2026-01-29 15:34:59,879:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-29 15:34:59,879:INFO:Memory: svmem(total=34009374720, available=15858475008, percent=53.4, used=18150899712, free=15858475008)
2026-01-29 15:34:59,879:INFO:Physical Core: 12
2026-01-29 15:34:59,879:INFO:Logical Core: 16
2026-01-29 15:34:59,879:INFO:Checking libraries
2026-01-29 15:34:59,879:INFO:System:
2026-01-29 15:34:59,879:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-29 15:34:59,879:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-29 15:34:59,879:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-29 15:34:59,879:INFO:PyCaret required dependencies:
2026-01-29 15:34:59,879:INFO:                 pip: 25.0
2026-01-29 15:34:59,879:INFO:          setuptools: 75.8.0
2026-01-29 15:34:59,879:INFO:             pycaret: 3.3.2
2026-01-29 15:34:59,879:INFO:             IPython: 9.9.0
2026-01-29 15:34:59,879:INFO:          ipywidgets: 8.1.8
2026-01-29 15:34:59,879:INFO:                tqdm: 4.67.1
2026-01-29 15:34:59,879:INFO:               numpy: 1.26.4
2026-01-29 15:34:59,879:INFO:              pandas: 2.1.4
2026-01-29 15:34:59,879:INFO:              jinja2: 3.1.6
2026-01-29 15:34:59,879:INFO:               scipy: 1.11.4
2026-01-29 15:34:59,879:INFO:              joblib: 1.3.2
2026-01-29 15:34:59,879:INFO:             sklearn: 1.4.2
2026-01-29 15:34:59,879:INFO:                pyod: 2.0.6
2026-01-29 15:34:59,879:INFO:            imblearn: 0.14.1
2026-01-29 15:34:59,879:INFO:   category_encoders: 2.7.0
2026-01-29 15:34:59,879:INFO:            lightgbm: 4.6.0
2026-01-29 15:34:59,879:INFO:               numba: 0.62.1
2026-01-29 15:34:59,879:INFO:            requests: 2.32.3
2026-01-29 15:34:59,879:INFO:          matplotlib: 3.7.5
2026-01-29 15:34:59,879:INFO:          scikitplot: 0.3.7
2026-01-29 15:34:59,879:INFO:         yellowbrick: 1.5
2026-01-29 15:34:59,879:INFO:              plotly: 5.24.1
2026-01-29 15:34:59,879:INFO:    plotly-resampler: Not installed
2026-01-29 15:34:59,879:INFO:             kaleido: 1.2.0
2026-01-29 15:34:59,879:INFO:           schemdraw: 0.15
2026-01-29 15:34:59,879:INFO:         statsmodels: 0.14.6
2026-01-29 15:34:59,879:INFO:              sktime: 0.26.0
2026-01-29 15:34:59,879:INFO:               tbats: 1.1.3
2026-01-29 15:34:59,879:INFO:            pmdarima: 2.0.4
2026-01-29 15:34:59,879:INFO:              psutil: 7.2.1
2026-01-29 15:34:59,879:INFO:          markupsafe: 3.0.3
2026-01-29 15:34:59,879:INFO:             pickle5: Not installed
2026-01-29 15:34:59,879:INFO:         cloudpickle: 3.0.0
2026-01-29 15:34:59,879:INFO:         deprecation: 2.1.0
2026-01-29 15:34:59,879:INFO:              xxhash: 3.6.0
2026-01-29 15:34:59,879:INFO:           wurlitzer: Not installed
2026-01-29 15:34:59,879:INFO:PyCaret optional dependencies:
2026-01-29 15:34:59,879:INFO:                shap: 0.44.1
2026-01-29 15:34:59,879:INFO:           interpret: 0.7.3
2026-01-29 15:34:59,879:INFO:                umap: 0.5.7
2026-01-29 15:34:59,888:INFO:     ydata_profiling: 4.18.1
2026-01-29 15:34:59,888:INFO:  explainerdashboard: 0.5.1
2026-01-29 15:34:59,889:INFO:             autoviz: Not installed
2026-01-29 15:34:59,889:INFO:           fairlearn: 0.7.0
2026-01-29 15:34:59,890:INFO:          deepchecks: Not installed
2026-01-29 15:34:59,890:INFO:             xgboost: Not installed
2026-01-29 15:34:59,890:INFO:            catboost: 1.2.8
2026-01-29 15:34:59,890:INFO:              kmodes: 0.12.2
2026-01-29 15:34:59,890:INFO:             mlxtend: 0.23.4
2026-01-29 15:34:59,890:INFO:       statsforecast: 1.5.0
2026-01-29 15:34:59,890:INFO:        tune_sklearn: Not installed
2026-01-29 15:34:59,890:INFO:                 ray: Not installed
2026-01-29 15:34:59,890:INFO:            hyperopt: 0.2.7
2026-01-29 15:34:59,890:INFO:              optuna: 4.6.0
2026-01-29 15:34:59,890:INFO:               skopt: 0.10.2
2026-01-29 15:34:59,890:INFO:              mlflow: 3.8.1
2026-01-29 15:34:59,890:INFO:              gradio: 6.3.0
2026-01-29 15:34:59,890:INFO:             fastapi: 0.128.0
2026-01-29 15:34:59,890:INFO:             uvicorn: 0.40.0
2026-01-29 15:34:59,890:INFO:              m2cgen: 0.10.0
2026-01-29 15:34:59,890:INFO:           evidently: 0.4.40
2026-01-29 15:34:59,890:INFO:               fugue: 0.8.7
2026-01-29 15:34:59,890:INFO:           streamlit: Not installed
2026-01-29 15:34:59,890:INFO:             prophet: Not installed
2026-01-29 15:34:59,890:INFO:None
2026-01-29 15:34:59,890:INFO:Set up data.
2026-01-29 15:34:59,923:INFO:Set up folding strategy.
2026-01-29 15:34:59,923:INFO:Set up train/test split.
2026-01-29 15:35:00,060:INFO:Set up index.
2026-01-29 15:35:00,073:INFO:Assigning column types.
2026-01-29 15:35:00,090:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-29 15:35:00,140:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 15:35:00,140:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:35:00,180:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:35:00,180:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:35:00,227:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 15:35:00,228:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:35:00,257:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:35:00,258:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:35:00,259:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-29 15:35:00,303:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:35:00,329:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:35:00,329:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:35:00,373:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 15:35:00,396:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:35:00,396:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:35:00,396:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-29 15:35:00,468:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:35:00,468:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:35:00,529:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:35:00,529:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:35:00,529:INFO:Preparing preprocessing pipeline...
2026-01-29 15:35:00,546:INFO:Set up simple imputation.
2026-01-29 15:35:00,546:INFO:Set up feature normalization.
2026-01-29 15:35:00,642:INFO:Finished creating preprocessing pipeline.
2026-01-29 15:35:00,646:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-29 15:35:00,646:INFO:Creating final display dataframe.
2026-01-29 15:35:00,911:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape       (429278, 4)
4        Transformed data shape       (429278, 4)
5   Transformed train set shape       (343422, 4)
6    Transformed test set shape        (85856, 4)
7               Ignore features                58
8              Numeric features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                 5
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              732d
2026-01-29 15:35:00,956:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:35:00,956:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:35:01,023:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 15:35:01,023:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 15:35:01,023:INFO:setup() successfully completed in 1.17s...............
2026-01-29 15:35:01,023:INFO:Initializing compare_models()
2026-01-29 15:35:01,023:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-29 15:35:01,023:INFO:Checking exceptions
2026-01-29 15:35:01,057:INFO:Preparing display monitor
2026-01-29 15:35:01,089:INFO:Initializing Logistic Regression
2026-01-29 15:35:01,090:INFO:Total runtime is 1.8715858459472656e-05 minutes
2026-01-29 15:35:01,093:INFO:SubProcess create_model() called ==================================
2026-01-29 15:35:01,094:INFO:Initializing create_model()
2026-01-29 15:35:01,094:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:35:01,094:INFO:Checking exceptions
2026-01-29 15:35:01,094:INFO:Importing libraries
2026-01-29 15:35:01,095:INFO:Copying training dataset
2026-01-29 15:35:01,178:INFO:Defining folds
2026-01-29 15:35:01,178:INFO:Declaring metric variables
2026-01-29 15:35:01,181:INFO:Importing untrained model
2026-01-29 15:35:01,184:INFO:Logistic Regression Imported successfully
2026-01-29 15:35:01,191:INFO:Starting cross validation
2026-01-29 15:35:01,192:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:35:12,429:INFO:Calculating mean and std
2026-01-29 15:35:12,429:INFO:Creating metrics dataframe
2026-01-29 15:35:12,429:INFO:Uploading results into container
2026-01-29 15:35:12,429:INFO:Uploading model into container now
2026-01-29 15:35:12,429:INFO:_master_model_container: 1
2026-01-29 15:35:12,436:INFO:_display_container: 2
2026-01-29 15:35:12,436:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 15:35:12,436:INFO:create_model() successfully completed......................................
2026-01-29 15:35:12,639:INFO:SubProcess create_model() end ==================================
2026-01-29 15:35:12,639:INFO:Creating metrics dataframe
2026-01-29 15:35:12,643:INFO:Initializing K Neighbors Classifier
2026-01-29 15:35:12,643:INFO:Total runtime is 0.1925755222638448 minutes
2026-01-29 15:35:12,645:INFO:SubProcess create_model() called ==================================
2026-01-29 15:35:12,645:INFO:Initializing create_model()
2026-01-29 15:35:12,645:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:35:12,645:INFO:Checking exceptions
2026-01-29 15:35:12,645:INFO:Importing libraries
2026-01-29 15:35:12,646:INFO:Copying training dataset
2026-01-29 15:35:12,695:INFO:Defining folds
2026-01-29 15:35:12,706:INFO:Declaring metric variables
2026-01-29 15:35:12,708:INFO:Importing untrained model
2026-01-29 15:35:12,708:INFO:K Neighbors Classifier Imported successfully
2026-01-29 15:35:12,708:INFO:Starting cross validation
2026-01-29 15:35:12,708:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:52:50,271:INFO:Calculating mean and std
2026-01-29 15:52:50,273:INFO:Creating metrics dataframe
2026-01-29 15:52:50,276:INFO:Uploading results into container
2026-01-29 15:52:50,277:INFO:Uploading model into container now
2026-01-29 15:52:50,277:INFO:_master_model_container: 2
2026-01-29 15:52:50,278:INFO:_display_container: 2
2026-01-29 15:52:50,278:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2026-01-29 15:52:50,278:INFO:create_model() successfully completed......................................
2026-01-29 15:52:50,493:INFO:SubProcess create_model() end ==================================
2026-01-29 15:52:50,493:INFO:Creating metrics dataframe
2026-01-29 15:52:50,498:INFO:Initializing Naive Bayes
2026-01-29 15:52:50,498:INFO:Total runtime is 17.823485747973123 minutes
2026-01-29 15:52:50,501:INFO:SubProcess create_model() called ==================================
2026-01-29 15:52:50,502:INFO:Initializing create_model()
2026-01-29 15:52:50,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:52:50,502:INFO:Checking exceptions
2026-01-29 15:52:50,502:INFO:Importing libraries
2026-01-29 15:52:50,502:INFO:Copying training dataset
2026-01-29 15:52:50,576:INFO:Defining folds
2026-01-29 15:52:50,576:INFO:Declaring metric variables
2026-01-29 15:52:50,581:INFO:Importing untrained model
2026-01-29 15:52:50,581:INFO:Naive Bayes Imported successfully
2026-01-29 15:52:50,595:INFO:Starting cross validation
2026-01-29 15:52:50,596:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:52:52,044:INFO:Calculating mean and std
2026-01-29 15:52:52,047:INFO:Creating metrics dataframe
2026-01-29 15:52:52,052:INFO:Uploading results into container
2026-01-29 15:52:52,053:INFO:Uploading model into container now
2026-01-29 15:52:52,054:INFO:_master_model_container: 3
2026-01-29 15:52:52,056:INFO:_display_container: 2
2026-01-29 15:52:52,057:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-01-29 15:52:52,057:INFO:create_model() successfully completed......................................
2026-01-29 15:52:52,389:INFO:SubProcess create_model() end ==================================
2026-01-29 15:52:52,389:INFO:Creating metrics dataframe
2026-01-29 15:52:52,402:INFO:Initializing Decision Tree Classifier
2026-01-29 15:52:52,402:INFO:Total runtime is 17.855215458075204 minutes
2026-01-29 15:52:52,407:INFO:SubProcess create_model() called ==================================
2026-01-29 15:52:52,408:INFO:Initializing create_model()
2026-01-29 15:52:52,408:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:52:52,409:INFO:Checking exceptions
2026-01-29 15:52:52,409:INFO:Importing libraries
2026-01-29 15:52:52,409:INFO:Copying training dataset
2026-01-29 15:52:52,533:INFO:Defining folds
2026-01-29 15:52:52,533:INFO:Declaring metric variables
2026-01-29 15:52:52,537:INFO:Importing untrained model
2026-01-29 15:52:52,542:INFO:Decision Tree Classifier Imported successfully
2026-01-29 15:52:52,552:INFO:Starting cross validation
2026-01-29 15:52:52,554:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:52:57,251:INFO:Calculating mean and std
2026-01-29 15:52:57,251:INFO:Creating metrics dataframe
2026-01-29 15:52:57,251:INFO:Uploading results into container
2026-01-29 15:52:57,251:INFO:Uploading model into container now
2026-01-29 15:52:57,251:INFO:_master_model_container: 4
2026-01-29 15:52:57,251:INFO:_display_container: 2
2026-01-29 15:52:57,251:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 15:52:57,251:INFO:create_model() successfully completed......................................
2026-01-29 15:52:57,451:INFO:SubProcess create_model() end ==================================
2026-01-29 15:52:57,451:INFO:Creating metrics dataframe
2026-01-29 15:52:57,456:INFO:Initializing SVM - Linear Kernel
2026-01-29 15:52:57,456:INFO:Total runtime is 17.939451269308723 minutes
2026-01-29 15:52:57,459:INFO:SubProcess create_model() called ==================================
2026-01-29 15:52:57,459:INFO:Initializing create_model()
2026-01-29 15:52:57,459:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:52:57,460:INFO:Checking exceptions
2026-01-29 15:52:57,460:INFO:Importing libraries
2026-01-29 15:52:57,460:INFO:Copying training dataset
2026-01-29 15:52:57,538:INFO:Defining folds
2026-01-29 15:52:57,538:INFO:Declaring metric variables
2026-01-29 15:52:57,542:INFO:Importing untrained model
2026-01-29 15:52:57,546:INFO:SVM - Linear Kernel Imported successfully
2026-01-29 15:52:57,550:INFO:Starting cross validation
2026-01-29 15:52:57,550:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:53:05,859:INFO:Calculating mean and std
2026-01-29 15:53:05,860:INFO:Creating metrics dataframe
2026-01-29 15:53:05,862:INFO:Uploading results into container
2026-01-29 15:53:05,862:INFO:Uploading model into container now
2026-01-29 15:53:05,863:INFO:_master_model_container: 5
2026-01-29 15:53:05,863:INFO:_display_container: 2
2026-01-29 15:53:05,864:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2026-01-29 15:53:05,864:INFO:create_model() successfully completed......................................
2026-01-29 15:53:06,108:INFO:SubProcess create_model() end ==================================
2026-01-29 15:53:06,109:INFO:Creating metrics dataframe
2026-01-29 15:53:06,114:INFO:Initializing Ridge Classifier
2026-01-29 15:53:06,114:INFO:Total runtime is 18.083745956420895 minutes
2026-01-29 15:53:06,114:INFO:SubProcess create_model() called ==================================
2026-01-29 15:53:06,114:INFO:Initializing create_model()
2026-01-29 15:53:06,114:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:53:06,114:INFO:Checking exceptions
2026-01-29 15:53:06,114:INFO:Importing libraries
2026-01-29 15:53:06,114:INFO:Copying training dataset
2026-01-29 15:53:06,230:INFO:Defining folds
2026-01-29 15:53:06,230:INFO:Declaring metric variables
2026-01-29 15:53:06,235:INFO:Importing untrained model
2026-01-29 15:53:06,240:INFO:Ridge Classifier Imported successfully
2026-01-29 15:53:06,249:INFO:Starting cross validation
2026-01-29 15:53:06,251:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:53:14,237:INFO:Calculating mean and std
2026-01-29 15:53:14,239:INFO:Creating metrics dataframe
2026-01-29 15:53:14,242:INFO:Uploading results into container
2026-01-29 15:53:14,243:INFO:Uploading model into container now
2026-01-29 15:53:14,243:INFO:_master_model_container: 6
2026-01-29 15:53:14,243:INFO:_display_container: 2
2026-01-29 15:53:14,243:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2026-01-29 15:53:14,243:INFO:create_model() successfully completed......................................
2026-01-29 15:53:14,441:INFO:SubProcess create_model() end ==================================
2026-01-29 15:53:14,442:INFO:Creating metrics dataframe
2026-01-29 15:53:14,443:INFO:Initializing Random Forest Classifier
2026-01-29 15:53:14,443:INFO:Total runtime is 18.222563024361925 minutes
2026-01-29 15:53:14,443:INFO:SubProcess create_model() called ==================================
2026-01-29 15:53:14,443:INFO:Initializing create_model()
2026-01-29 15:53:14,443:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:53:14,443:INFO:Checking exceptions
2026-01-29 15:53:14,443:INFO:Importing libraries
2026-01-29 15:53:14,443:INFO:Copying training dataset
2026-01-29 15:53:14,516:INFO:Defining folds
2026-01-29 15:53:14,523:INFO:Declaring metric variables
2026-01-29 15:53:14,526:INFO:Importing untrained model
2026-01-29 15:53:14,526:INFO:Random Forest Classifier Imported successfully
2026-01-29 15:53:14,533:INFO:Starting cross validation
2026-01-29 15:53:14,533:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:53:24,811:INFO:Calculating mean and std
2026-01-29 15:53:24,811:INFO:Creating metrics dataframe
2026-01-29 15:53:24,811:INFO:Uploading results into container
2026-01-29 15:53:24,811:INFO:Uploading model into container now
2026-01-29 15:53:24,811:INFO:_master_model_container: 7
2026-01-29 15:53:24,811:INFO:_display_container: 2
2026-01-29 15:53:24,811:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 15:53:24,811:INFO:create_model() successfully completed......................................
2026-01-29 15:53:24,985:INFO:SubProcess create_model() end ==================================
2026-01-29 15:53:24,986:INFO:Creating metrics dataframe
2026-01-29 15:53:24,991:INFO:Initializing Quadratic Discriminant Analysis
2026-01-29 15:53:24,991:INFO:Total runtime is 18.3983648498853 minutes
2026-01-29 15:53:24,991:INFO:SubProcess create_model() called ==================================
2026-01-29 15:53:24,991:INFO:Initializing create_model()
2026-01-29 15:53:24,991:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:53:24,991:INFO:Checking exceptions
2026-01-29 15:53:24,991:INFO:Importing libraries
2026-01-29 15:53:24,991:INFO:Copying training dataset
2026-01-29 15:53:25,058:INFO:Defining folds
2026-01-29 15:53:25,059:INFO:Declaring metric variables
2026-01-29 15:53:25,061:INFO:Importing untrained model
2026-01-29 15:53:25,064:INFO:Quadratic Discriminant Analysis Imported successfully
2026-01-29 15:53:25,064:INFO:Starting cross validation
2026-01-29 15:53:25,064:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:53:25,727:INFO:Calculating mean and std
2026-01-29 15:53:25,728:INFO:Creating metrics dataframe
2026-01-29 15:53:25,730:INFO:Uploading results into container
2026-01-29 15:53:25,730:INFO:Uploading model into container now
2026-01-29 15:53:25,730:INFO:_master_model_container: 8
2026-01-29 15:53:25,732:INFO:_display_container: 2
2026-01-29 15:53:25,732:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2026-01-29 15:53:25,732:INFO:create_model() successfully completed......................................
2026-01-29 15:53:25,925:INFO:SubProcess create_model() end ==================================
2026-01-29 15:53:25,925:INFO:Creating metrics dataframe
2026-01-29 15:53:25,932:INFO:Initializing Ada Boost Classifier
2026-01-29 15:53:25,933:INFO:Total runtime is 18.414068611462906 minutes
2026-01-29 15:53:25,936:INFO:SubProcess create_model() called ==================================
2026-01-29 15:53:25,936:INFO:Initializing create_model()
2026-01-29 15:53:25,937:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:53:25,937:INFO:Checking exceptions
2026-01-29 15:53:25,937:INFO:Importing libraries
2026-01-29 15:53:25,937:INFO:Copying training dataset
2026-01-29 15:53:26,012:INFO:Defining folds
2026-01-29 15:53:26,012:INFO:Declaring metric variables
2026-01-29 15:53:26,016:INFO:Importing untrained model
2026-01-29 15:53:26,020:INFO:Ada Boost Classifier Imported successfully
2026-01-29 15:53:26,028:INFO:Starting cross validation
2026-01-29 15:53:26,029:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:53:26,189:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-01-29 15:53:26,215:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-01-29 15:53:26,237:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-01-29 15:53:26,264:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-01-29 15:53:26,282:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2026-01-29 15:53:33,521:INFO:Calculating mean and std
2026-01-29 15:53:33,524:INFO:Creating metrics dataframe
2026-01-29 15:53:33,527:INFO:Uploading results into container
2026-01-29 15:53:33,528:INFO:Uploading model into container now
2026-01-29 15:53:33,528:INFO:_master_model_container: 9
2026-01-29 15:53:33,530:INFO:_display_container: 2
2026-01-29 15:53:33,531:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2026-01-29 15:53:33,531:INFO:create_model() successfully completed......................................
2026-01-29 15:53:33,725:INFO:SubProcess create_model() end ==================================
2026-01-29 15:53:33,725:INFO:Creating metrics dataframe
2026-01-29 15:53:33,733:INFO:Initializing Gradient Boosting Classifier
2026-01-29 15:53:33,733:INFO:Total runtime is 18.544077916940047 minutes
2026-01-29 15:53:33,737:INFO:SubProcess create_model() called ==================================
2026-01-29 15:53:33,738:INFO:Initializing create_model()
2026-01-29 15:53:33,738:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:53:33,738:INFO:Checking exceptions
2026-01-29 15:53:33,740:INFO:Importing libraries
2026-01-29 15:53:33,740:INFO:Copying training dataset
2026-01-29 15:53:33,822:INFO:Defining folds
2026-01-29 15:53:33,822:INFO:Declaring metric variables
2026-01-29 15:53:33,826:INFO:Importing untrained model
2026-01-29 15:53:33,830:INFO:Gradient Boosting Classifier Imported successfully
2026-01-29 15:53:33,835:INFO:Starting cross validation
2026-01-29 15:53:33,836:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:53:41,968:INFO:Calculating mean and std
2026-01-29 15:53:41,969:INFO:Creating metrics dataframe
2026-01-29 15:53:41,971:INFO:Uploading results into container
2026-01-29 15:53:41,972:INFO:Uploading model into container now
2026-01-29 15:53:41,972:INFO:_master_model_container: 10
2026-01-29 15:53:41,973:INFO:_display_container: 2
2026-01-29 15:53:41,973:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2026-01-29 15:53:41,973:INFO:create_model() successfully completed......................................
2026-01-29 15:53:42,168:INFO:SubProcess create_model() end ==================================
2026-01-29 15:53:42,168:INFO:Creating metrics dataframe
2026-01-29 15:53:42,175:INFO:Initializing Linear Discriminant Analysis
2026-01-29 15:53:42,176:INFO:Total runtime is 18.684785914421074 minutes
2026-01-29 15:53:42,178:INFO:SubProcess create_model() called ==================================
2026-01-29 15:53:42,178:INFO:Initializing create_model()
2026-01-29 15:53:42,178:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:53:42,178:INFO:Checking exceptions
2026-01-29 15:53:42,178:INFO:Importing libraries
2026-01-29 15:53:42,178:INFO:Copying training dataset
2026-01-29 15:53:42,247:INFO:Defining folds
2026-01-29 15:53:42,247:INFO:Declaring metric variables
2026-01-29 15:53:42,250:INFO:Importing untrained model
2026-01-29 15:53:42,250:INFO:Linear Discriminant Analysis Imported successfully
2026-01-29 15:53:42,260:INFO:Starting cross validation
2026-01-29 15:53:42,261:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:53:42,938:INFO:Calculating mean and std
2026-01-29 15:53:42,939:INFO:Creating metrics dataframe
2026-01-29 15:53:42,942:INFO:Uploading results into container
2026-01-29 15:53:42,942:INFO:Uploading model into container now
2026-01-29 15:53:42,943:INFO:_master_model_container: 11
2026-01-29 15:53:42,943:INFO:_display_container: 2
2026-01-29 15:53:42,943:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2026-01-29 15:53:42,943:INFO:create_model() successfully completed......................................
2026-01-29 15:53:43,137:INFO:SubProcess create_model() end ==================================
2026-01-29 15:53:43,138:INFO:Creating metrics dataframe
2026-01-29 15:53:43,145:INFO:Initializing Extra Trees Classifier
2026-01-29 15:53:43,146:INFO:Total runtime is 18.70095623334248 minutes
2026-01-29 15:53:43,149:INFO:SubProcess create_model() called ==================================
2026-01-29 15:53:43,149:INFO:Initializing create_model()
2026-01-29 15:53:43,149:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:53:43,149:INFO:Checking exceptions
2026-01-29 15:53:43,150:INFO:Importing libraries
2026-01-29 15:53:43,150:INFO:Copying training dataset
2026-01-29 15:53:43,242:INFO:Defining folds
2026-01-29 15:53:43,242:INFO:Declaring metric variables
2026-01-29 15:53:43,244:INFO:Importing untrained model
2026-01-29 15:53:43,244:INFO:Extra Trees Classifier Imported successfully
2026-01-29 15:53:43,256:INFO:Starting cross validation
2026-01-29 15:53:43,258:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:53:47,881:INFO:Calculating mean and std
2026-01-29 15:53:47,882:INFO:Creating metrics dataframe
2026-01-29 15:53:47,886:INFO:Uploading results into container
2026-01-29 15:53:47,887:INFO:Uploading model into container now
2026-01-29 15:53:47,887:INFO:_master_model_container: 12
2026-01-29 15:53:47,888:INFO:_display_container: 2
2026-01-29 15:53:47,889:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2026-01-29 15:53:47,889:INFO:create_model() successfully completed......................................
2026-01-29 15:53:48,126:INFO:SubProcess create_model() end ==================================
2026-01-29 15:53:48,126:INFO:Creating metrics dataframe
2026-01-29 15:53:48,135:INFO:Initializing Light Gradient Boosting Machine
2026-01-29 15:53:48,135:INFO:Total runtime is 18.78410774469375 minutes
2026-01-29 15:53:48,139:INFO:SubProcess create_model() called ==================================
2026-01-29 15:53:48,140:INFO:Initializing create_model()
2026-01-29 15:53:48,141:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:53:48,141:INFO:Checking exceptions
2026-01-29 15:53:48,141:INFO:Importing libraries
2026-01-29 15:53:48,141:INFO:Copying training dataset
2026-01-29 15:53:48,246:INFO:Defining folds
2026-01-29 15:53:48,246:INFO:Declaring metric variables
2026-01-29 15:53:48,250:INFO:Importing untrained model
2026-01-29 15:53:48,255:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-29 15:53:48,262:INFO:Starting cross validation
2026-01-29 15:53:48,263:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:53:50,367:INFO:Calculating mean and std
2026-01-29 15:53:50,368:INFO:Creating metrics dataframe
2026-01-29 15:53:50,371:INFO:Uploading results into container
2026-01-29 15:53:50,372:INFO:Uploading model into container now
2026-01-29 15:53:50,372:INFO:_master_model_container: 13
2026-01-29 15:53:50,373:INFO:_display_container: 2
2026-01-29 15:53:50,374:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-29 15:53:50,375:INFO:create_model() successfully completed......................................
2026-01-29 15:53:50,573:INFO:SubProcess create_model() end ==================================
2026-01-29 15:53:50,573:INFO:Creating metrics dataframe
2026-01-29 15:53:50,582:INFO:Initializing CatBoost Classifier
2026-01-29 15:53:50,582:INFO:Total runtime is 18.824895695845278 minutes
2026-01-29 15:53:50,582:INFO:SubProcess create_model() called ==================================
2026-01-29 15:53:50,582:INFO:Initializing create_model()
2026-01-29 15:53:50,582:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:53:50,582:INFO:Checking exceptions
2026-01-29 15:53:50,582:INFO:Importing libraries
2026-01-29 15:53:50,582:INFO:Copying training dataset
2026-01-29 15:53:50,668:INFO:Defining folds
2026-01-29 15:53:50,668:INFO:Declaring metric variables
2026-01-29 15:53:50,672:INFO:Importing untrained model
2026-01-29 15:53:50,675:INFO:CatBoost Classifier Imported successfully
2026-01-29 15:53:50,675:INFO:Starting cross validation
2026-01-29 15:53:50,675:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:54:46,154:INFO:Calculating mean and std
2026-01-29 15:54:46,158:INFO:Creating metrics dataframe
2026-01-29 15:54:46,158:INFO:Uploading results into container
2026-01-29 15:54:46,164:INFO:Uploading model into container now
2026-01-29 15:54:46,165:INFO:_master_model_container: 14
2026-01-29 15:54:46,165:INFO:_display_container: 2
2026-01-29 15:54:46,165:INFO:<catboost.core.CatBoostClassifier object at 0x0000024870CE2650>
2026-01-29 15:54:46,165:INFO:create_model() successfully completed......................................
2026-01-29 15:54:46,341:INFO:SubProcess create_model() end ==================================
2026-01-29 15:54:46,341:INFO:Creating metrics dataframe
2026-01-29 15:54:46,350:INFO:Initializing Dummy Classifier
2026-01-29 15:54:46,357:INFO:Total runtime is 19.754346024990074 minutes
2026-01-29 15:54:46,357:INFO:SubProcess create_model() called ==================================
2026-01-29 15:54:46,357:INFO:Initializing create_model()
2026-01-29 15:54:46,357:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024818D55690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:54:46,357:INFO:Checking exceptions
2026-01-29 15:54:46,357:INFO:Importing libraries
2026-01-29 15:54:46,357:INFO:Copying training dataset
2026-01-29 15:54:46,432:INFO:Defining folds
2026-01-29 15:54:46,432:INFO:Declaring metric variables
2026-01-29 15:54:46,436:INFO:Importing untrained model
2026-01-29 15:54:46,439:INFO:Dummy Classifier Imported successfully
2026-01-29 15:54:46,443:INFO:Starting cross validation
2026-01-29 15:54:46,443:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:54:46,724:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-01-29 15:54:46,745:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-01-29 15:54:46,757:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-01-29 15:54:46,776:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-01-29 15:54:46,808:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2026-01-29 15:54:47,025:INFO:Calculating mean and std
2026-01-29 15:54:47,025:INFO:Creating metrics dataframe
2026-01-29 15:54:47,025:INFO:Uploading results into container
2026-01-29 15:54:47,025:INFO:Uploading model into container now
2026-01-29 15:54:47,025:INFO:_master_model_container: 15
2026-01-29 15:54:47,025:INFO:_display_container: 2
2026-01-29 15:54:47,025:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2026-01-29 15:54:47,025:INFO:create_model() successfully completed......................................
2026-01-29 15:54:47,207:INFO:SubProcess create_model() end ==================================
2026-01-29 15:54:47,207:INFO:Creating metrics dataframe
2026-01-29 15:54:47,222:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-29 15:54:47,236:INFO:Initializing create_model()
2026-01-29 15:54:47,236:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:54:47,239:INFO:Checking exceptions
2026-01-29 15:54:47,240:INFO:Importing libraries
2026-01-29 15:54:47,240:INFO:Copying training dataset
2026-01-29 15:54:47,336:INFO:Defining folds
2026-01-29 15:54:47,337:INFO:Declaring metric variables
2026-01-29 15:54:47,337:INFO:Importing untrained model
2026-01-29 15:54:47,337:INFO:Declaring custom model
2026-01-29 15:54:47,337:INFO:Logistic Regression Imported successfully
2026-01-29 15:54:47,338:INFO:Cross validation set to False
2026-01-29 15:54:47,338:INFO:Fitting Model
2026-01-29 15:54:47,607:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 15:54:47,607:INFO:create_model() successfully completed......................................
2026-01-29 15:54:47,789:INFO:Initializing create_model()
2026-01-29 15:54:47,790:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:54:47,790:INFO:Checking exceptions
2026-01-29 15:54:47,791:INFO:Importing libraries
2026-01-29 15:54:47,791:INFO:Copying training dataset
2026-01-29 15:54:47,872:INFO:Defining folds
2026-01-29 15:54:47,872:INFO:Declaring metric variables
2026-01-29 15:54:47,872:INFO:Importing untrained model
2026-01-29 15:54:47,872:INFO:Declaring custom model
2026-01-29 15:54:47,872:INFO:Naive Bayes Imported successfully
2026-01-29 15:54:47,872:INFO:Cross validation set to False
2026-01-29 15:54:47,872:INFO:Fitting Model
2026-01-29 15:54:47,940:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-01-29 15:54:47,940:INFO:create_model() successfully completed......................................
2026-01-29 15:54:48,107:INFO:Initializing create_model()
2026-01-29 15:54:48,107:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:54:48,107:INFO:Checking exceptions
2026-01-29 15:54:48,118:INFO:Importing libraries
2026-01-29 15:54:48,118:INFO:Copying training dataset
2026-01-29 15:54:48,179:INFO:Defining folds
2026-01-29 15:54:48,179:INFO:Declaring metric variables
2026-01-29 15:54:48,180:INFO:Importing untrained model
2026-01-29 15:54:48,180:INFO:Declaring custom model
2026-01-29 15:54:48,180:INFO:Decision Tree Classifier Imported successfully
2026-01-29 15:54:48,180:INFO:Cross validation set to False
2026-01-29 15:54:48,180:INFO:Fitting Model
2026-01-29 15:54:48,241:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 15:54:48,241:INFO:create_model() successfully completed......................................
2026-01-29 15:54:48,425:INFO:_master_model_container: 15
2026-01-29 15:54:48,425:INFO:_display_container: 2
2026-01-29 15:54:48,425:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')]
2026-01-29 15:54:48,425:INFO:compare_models() successfully completed......................................
2026-01-29 15:54:48,425:INFO:Initializing tune_model()
2026-01-29 15:54:48,425:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 15:54:48,425:INFO:Checking exceptions
2026-01-29 15:54:48,475:INFO:Copying training dataset
2026-01-29 15:54:48,544:INFO:Checking base model
2026-01-29 15:54:48,544:INFO:Base model : Logistic Regression
2026-01-29 15:54:48,548:INFO:Declaring metric variables
2026-01-29 15:54:48,552:INFO:Defining Hyperparameters
2026-01-29 15:54:48,729:INFO:Tuning with n_jobs=-1
2026-01-29 15:54:48,729:INFO:Initializing RandomizedSearchCV
2026-01-29 15:54:52,415:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 5.682}
2026-01-29 15:54:52,415:INFO:Hyperparameter search completed
2026-01-29 15:54:52,415:INFO:SubProcess create_model() called ==================================
2026-01-29 15:54:52,415:INFO:Initializing create_model()
2026-01-29 15:54:52,415:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002480469E050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 5.682})
2026-01-29 15:54:52,415:INFO:Checking exceptions
2026-01-29 15:54:52,415:INFO:Importing libraries
2026-01-29 15:54:52,415:INFO:Copying training dataset
2026-01-29 15:54:52,490:INFO:Defining folds
2026-01-29 15:54:52,490:INFO:Declaring metric variables
2026-01-29 15:54:52,490:INFO:Importing untrained model
2026-01-29 15:54:52,490:INFO:Declaring custom model
2026-01-29 15:54:52,490:INFO:Logistic Regression Imported successfully
2026-01-29 15:54:52,505:INFO:Starting cross validation
2026-01-29 15:54:52,509:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:54:53,488:INFO:Calculating mean and std
2026-01-29 15:54:53,489:INFO:Creating metrics dataframe
2026-01-29 15:54:53,495:INFO:Finalizing model
2026-01-29 15:54:53,827:INFO:Uploading results into container
2026-01-29 15:54:53,828:INFO:Uploading model into container now
2026-01-29 15:54:53,829:INFO:_master_model_container: 16
2026-01-29 15:54:53,829:INFO:_display_container: 3
2026-01-29 15:54:53,830:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 15:54:53,830:INFO:create_model() successfully completed......................................
2026-01-29 15:54:54,012:INFO:SubProcess create_model() end ==================================
2026-01-29 15:54:54,012:INFO:choose_better activated
2026-01-29 15:54:54,015:INFO:SubProcess create_model() called ==================================
2026-01-29 15:54:54,016:INFO:Initializing create_model()
2026-01-29 15:54:54,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:54:54,016:INFO:Checking exceptions
2026-01-29 15:54:54,018:INFO:Importing libraries
2026-01-29 15:54:54,019:INFO:Copying training dataset
2026-01-29 15:54:54,074:INFO:Defining folds
2026-01-29 15:54:54,074:INFO:Declaring metric variables
2026-01-29 15:54:54,074:INFO:Importing untrained model
2026-01-29 15:54:54,074:INFO:Declaring custom model
2026-01-29 15:54:54,074:INFO:Logistic Regression Imported successfully
2026-01-29 15:54:54,074:INFO:Starting cross validation
2026-01-29 15:54:54,074:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:54:54,963:INFO:Calculating mean and std
2026-01-29 15:54:54,967:INFO:Creating metrics dataframe
2026-01-29 15:54:54,969:INFO:Finalizing model
2026-01-29 15:54:55,205:INFO:Uploading results into container
2026-01-29 15:54:55,206:INFO:Uploading model into container now
2026-01-29 15:54:55,206:INFO:_master_model_container: 17
2026-01-29 15:54:55,206:INFO:_display_container: 4
2026-01-29 15:54:55,207:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 15:54:55,207:INFO:create_model() successfully completed......................................
2026-01-29 15:54:55,422:INFO:SubProcess create_model() end ==================================
2026-01-29 15:54:55,423:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 15:54:55,423:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 15:54:55,423:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2026-01-29 15:54:55,423:INFO:choose_better completed
2026-01-29 15:54:55,424:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 15:54:55,429:INFO:_master_model_container: 17
2026-01-29 15:54:55,429:INFO:_display_container: 3
2026-01-29 15:54:55,429:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 15:54:55,429:INFO:tune_model() successfully completed......................................
2026-01-29 15:54:55,641:INFO:Initializing tune_model()
2026-01-29 15:54:55,641:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 15:54:55,641:INFO:Checking exceptions
2026-01-29 15:54:55,677:INFO:Copying training dataset
2026-01-29 15:54:55,754:INFO:Checking base model
2026-01-29 15:54:55,754:INFO:Base model : Naive Bayes
2026-01-29 15:54:55,758:INFO:Declaring metric variables
2026-01-29 15:54:55,762:INFO:Defining Hyperparameters
2026-01-29 15:54:55,983:INFO:Tuning with n_jobs=-1
2026-01-29 15:54:55,983:INFO:Initializing RandomizedSearchCV
2026-01-29 15:54:57,835:INFO:best_params: {'actual_estimator__var_smoothing': 2e-07}
2026-01-29 15:54:57,836:INFO:Hyperparameter search completed
2026-01-29 15:54:57,836:INFO:SubProcess create_model() called ==================================
2026-01-29 15:54:57,837:INFO:Initializing create_model()
2026-01-29 15:54:57,837:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024804682610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'var_smoothing': 2e-07})
2026-01-29 15:54:57,837:INFO:Checking exceptions
2026-01-29 15:54:57,838:INFO:Importing libraries
2026-01-29 15:54:57,838:INFO:Copying training dataset
2026-01-29 15:54:57,990:INFO:Defining folds
2026-01-29 15:54:57,990:INFO:Declaring metric variables
2026-01-29 15:54:57,995:INFO:Importing untrained model
2026-01-29 15:54:57,995:INFO:Declaring custom model
2026-01-29 15:54:58,000:INFO:Naive Bayes Imported successfully
2026-01-29 15:54:58,010:INFO:Starting cross validation
2026-01-29 15:54:58,011:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:54:58,780:INFO:Calculating mean and std
2026-01-29 15:54:58,780:INFO:Creating metrics dataframe
2026-01-29 15:54:58,790:INFO:Finalizing model
2026-01-29 15:54:58,883:INFO:Uploading results into container
2026-01-29 15:54:58,884:INFO:Uploading model into container now
2026-01-29 15:54:58,885:INFO:_master_model_container: 18
2026-01-29 15:54:58,885:INFO:_display_container: 4
2026-01-29 15:54:58,885:INFO:GaussianNB(priors=None, var_smoothing=2e-07)
2026-01-29 15:54:58,885:INFO:create_model() successfully completed......................................
2026-01-29 15:54:59,109:INFO:SubProcess create_model() end ==================================
2026-01-29 15:54:59,110:INFO:choose_better activated
2026-01-29 15:54:59,112:INFO:SubProcess create_model() called ==================================
2026-01-29 15:54:59,112:INFO:Initializing create_model()
2026-01-29 15:54:59,112:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:54:59,112:INFO:Checking exceptions
2026-01-29 15:54:59,114:INFO:Importing libraries
2026-01-29 15:54:59,114:INFO:Copying training dataset
2026-01-29 15:54:59,188:INFO:Defining folds
2026-01-29 15:54:59,188:INFO:Declaring metric variables
2026-01-29 15:54:59,188:INFO:Importing untrained model
2026-01-29 15:54:59,188:INFO:Declaring custom model
2026-01-29 15:54:59,189:INFO:Naive Bayes Imported successfully
2026-01-29 15:54:59,189:INFO:Starting cross validation
2026-01-29 15:54:59,190:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:54:59,915:INFO:Calculating mean and std
2026-01-29 15:54:59,916:INFO:Creating metrics dataframe
2026-01-29 15:54:59,918:INFO:Finalizing model
2026-01-29 15:54:59,995:INFO:Uploading results into container
2026-01-29 15:54:59,996:INFO:Uploading model into container now
2026-01-29 15:54:59,996:INFO:_master_model_container: 19
2026-01-29 15:54:59,996:INFO:_display_container: 5
2026-01-29 15:54:59,996:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-01-29 15:54:59,997:INFO:create_model() successfully completed......................................
2026-01-29 15:55:00,211:INFO:SubProcess create_model() end ==================================
2026-01-29 15:55:00,211:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for AUC is 0.5369
2026-01-29 15:55:00,212:INFO:GaussianNB(priors=None, var_smoothing=2e-07) result for AUC is 0.5369
2026-01-29 15:55:00,212:INFO:GaussianNB(priors=None, var_smoothing=1e-09) is best model
2026-01-29 15:55:00,212:INFO:choose_better completed
2026-01-29 15:55:00,212:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 15:55:00,223:INFO:_master_model_container: 19
2026-01-29 15:55:00,224:INFO:_display_container: 4
2026-01-29 15:55:00,224:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2026-01-29 15:55:00,224:INFO:tune_model() successfully completed......................................
2026-01-29 15:55:00,429:INFO:Initializing tune_model()
2026-01-29 15:55:00,430:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 15:55:00,430:INFO:Checking exceptions
2026-01-29 15:55:00,466:INFO:Copying training dataset
2026-01-29 15:55:00,543:INFO:Checking base model
2026-01-29 15:55:00,544:INFO:Base model : Decision Tree Classifier
2026-01-29 15:55:00,548:INFO:Declaring metric variables
2026-01-29 15:55:00,552:INFO:Defining Hyperparameters
2026-01-29 15:55:00,802:INFO:Tuning with n_jobs=-1
2026-01-29 15:55:00,802:INFO:Initializing RandomizedSearchCV
2026-01-29 15:55:02,562:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.0005, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 3, 'actual_estimator__criterion': 'gini'}
2026-01-29 15:55:02,563:INFO:Hyperparameter search completed
2026-01-29 15:55:02,564:INFO:SubProcess create_model() called ==================================
2026-01-29 15:55:02,564:INFO:Initializing create_model()
2026-01-29 15:55:02,565:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024870C3D290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0005, 'max_features': 1.0, 'max_depth': 3, 'criterion': 'gini'})
2026-01-29 15:55:02,566:INFO:Checking exceptions
2026-01-29 15:55:02,566:INFO:Importing libraries
2026-01-29 15:55:02,567:INFO:Copying training dataset
2026-01-29 15:55:02,706:INFO:Defining folds
2026-01-29 15:55:02,706:INFO:Declaring metric variables
2026-01-29 15:55:02,724:INFO:Importing untrained model
2026-01-29 15:55:02,724:INFO:Declaring custom model
2026-01-29 15:55:02,729:INFO:Decision Tree Classifier Imported successfully
2026-01-29 15:55:02,737:INFO:Starting cross validation
2026-01-29 15:55:02,738:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:55:03,450:INFO:Calculating mean and std
2026-01-29 15:55:03,452:INFO:Creating metrics dataframe
2026-01-29 15:55:03,458:INFO:Finalizing model
2026-01-29 15:55:03,607:INFO:Uploading results into container
2026-01-29 15:55:03,609:INFO:Uploading model into container now
2026-01-29 15:55:03,609:INFO:_master_model_container: 20
2026-01-29 15:55:03,609:INFO:_display_container: 5
2026-01-29 15:55:03,610:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 15:55:03,610:INFO:create_model() successfully completed......................................
2026-01-29 15:55:03,874:INFO:SubProcess create_model() end ==================================
2026-01-29 15:55:03,874:INFO:choose_better activated
2026-01-29 15:55:03,880:INFO:SubProcess create_model() called ==================================
2026-01-29 15:55:03,881:INFO:Initializing create_model()
2026-01-29 15:55:03,881:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 15:55:03,882:INFO:Checking exceptions
2026-01-29 15:55:03,884:INFO:Importing libraries
2026-01-29 15:55:03,884:INFO:Copying training dataset
2026-01-29 15:55:03,986:INFO:Defining folds
2026-01-29 15:55:03,986:INFO:Declaring metric variables
2026-01-29 15:55:03,986:INFO:Importing untrained model
2026-01-29 15:55:03,986:INFO:Declaring custom model
2026-01-29 15:55:03,986:INFO:Decision Tree Classifier Imported successfully
2026-01-29 15:55:03,987:INFO:Starting cross validation
2026-01-29 15:55:03,987:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 15:55:04,751:INFO:Calculating mean and std
2026-01-29 15:55:04,751:INFO:Creating metrics dataframe
2026-01-29 15:55:04,758:INFO:Finalizing model
2026-01-29 15:55:04,852:INFO:Uploading results into container
2026-01-29 15:55:04,853:INFO:Uploading model into container now
2026-01-29 15:55:04,853:INFO:_master_model_container: 21
2026-01-29 15:55:04,853:INFO:_display_container: 6
2026-01-29 15:55:04,854:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 15:55:04,854:INFO:create_model() successfully completed......................................
2026-01-29 15:55:05,120:INFO:SubProcess create_model() end ==================================
2026-01-29 15:55:05,122:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5369
2026-01-29 15:55:05,123:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5366
2026-01-29 15:55:05,124:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-29 15:55:05,124:INFO:choose_better completed
2026-01-29 15:55:05,125:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 15:55:05,142:INFO:_master_model_container: 21
2026-01-29 15:55:05,142:INFO:_display_container: 5
2026-01-29 15:55:05,144:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 15:55:05,144:INFO:tune_model() successfully completed......................................
2026-01-29 15:55:05,552:INFO:Initializing evaluate_model()
2026-01-29 15:55:05,555:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 15:55:05,613:INFO:Initializing plot_model()
2026-01-29 15:55:05,614:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:55:05,614:INFO:Checking exceptions
2026-01-29 15:55:05,661:INFO:Preloading libraries
2026-01-29 15:55:05,661:INFO:Copying training dataset
2026-01-29 15:55:05,661:INFO:Plot type: pipeline
2026-01-29 15:55:05,825:INFO:Visual Rendered Successfully
2026-01-29 15:55:06,016:INFO:plot_model() successfully completed......................................
2026-01-29 15:55:06,019:INFO:Initializing evaluate_model()
2026-01-29 15:55:06,019:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 15:55:06,050:INFO:Initializing plot_model()
2026-01-29 15:55:06,051:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:55:06,051:INFO:Checking exceptions
2026-01-29 15:55:06,082:INFO:Preloading libraries
2026-01-29 15:55:06,082:INFO:Copying training dataset
2026-01-29 15:55:06,082:INFO:Plot type: pipeline
2026-01-29 15:55:06,148:INFO:Visual Rendered Successfully
2026-01-29 15:55:06,324:INFO:plot_model() successfully completed......................................
2026-01-29 15:55:06,326:INFO:Initializing evaluate_model()
2026-01-29 15:55:06,326:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 15:55:06,370:INFO:Initializing plot_model()
2026-01-29 15:55:06,371:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:55:06,371:INFO:Checking exceptions
2026-01-29 15:55:06,408:INFO:Preloading libraries
2026-01-29 15:55:06,408:INFO:Copying training dataset
2026-01-29 15:55:06,408:INFO:Plot type: pipeline
2026-01-29 15:55:06,476:INFO:Visual Rendered Successfully
2026-01-29 15:55:06,656:INFO:plot_model() successfully completed......................................
2026-01-29 15:55:06,662:INFO:Initializing predict_model()
2026-01-29 15:55:06,662:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000248048BC720>)
2026-01-29 15:55:06,662:INFO:Checking exceptions
2026-01-29 15:55:06,662:INFO:Preloading libraries
2026-01-29 15:55:06,664:INFO:Set up data.
2026-01-29 15:55:06,673:INFO:Set up index.
2026-01-29 15:55:07,155:INFO:Initializing predict_model()
2026-01-29 15:55:07,155:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024810D7FC40>)
2026-01-29 15:55:07,155:INFO:Checking exceptions
2026-01-29 15:55:07,155:INFO:Preloading libraries
2026-01-29 15:55:07,158:INFO:Set up data.
2026-01-29 15:55:07,164:INFO:Set up index.
2026-01-29 15:55:07,640:INFO:Initializing predict_model()
2026-01-29 15:55:07,640:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000248048BC720>)
2026-01-29 15:55:07,640:INFO:Checking exceptions
2026-01-29 15:55:07,640:INFO:Preloading libraries
2026-01-29 15:55:07,640:INFO:Set up data.
2026-01-29 15:55:07,640:INFO:Set up index.
2026-01-29 15:55:08,108:INFO:Initializing plot_model()
2026-01-29 15:55:08,109:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-29 15:55:08,109:INFO:Checking exceptions
2026-01-29 15:55:08,132:INFO:Preloading libraries
2026-01-29 15:55:08,132:INFO:Copying training dataset
2026-01-29 15:55:08,132:INFO:Plot type: feature
2026-01-29 15:55:08,386:INFO:Visual Rendered Successfully
2026-01-29 15:55:08,561:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:15,782:INFO:Initializing plot_model()
2026-01-29 15:57:15,783:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=dimension, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:15,783:INFO:Checking exceptions
2026-01-29 15:57:15,812:INFO:Preloading libraries
2026-01-29 15:57:15,812:INFO:Copying training dataset
2026-01-29 15:57:15,812:INFO:Plot type: dimension
2026-01-29 15:57:15,933:INFO:Fitting StandardScaler()
2026-01-29 15:57:16,020:INFO:Fitting PCA()
2026-01-29 15:57:16,274:INFO:Fitting & Transforming Model
2026-01-29 15:57:16,291:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\yellowbrick\features\radviz.py:199: RuntimeWarning: invalid value encountered in divide

2026-01-29 15:57:21,111:INFO:Visual Rendered Successfully
2026-01-29 15:57:21,307:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:21,319:INFO:Initializing plot_model()
2026-01-29 15:57:21,319:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:21,319:INFO:Checking exceptions
2026-01-29 15:57:21,340:INFO:Preloading libraries
2026-01-29 15:57:21,340:INFO:Copying training dataset
2026-01-29 15:57:21,340:INFO:Plot type: pipeline
2026-01-29 15:57:21,393:INFO:Visual Rendered Successfully
2026-01-29 15:57:21,588:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:27,131:INFO:Initializing plot_model()
2026-01-29 15:57:27,132:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=calibration, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:27,132:INFO:Checking exceptions
2026-01-29 15:57:27,152:INFO:Preloading libraries
2026-01-29 15:57:27,152:INFO:Copying training dataset
2026-01-29 15:57:27,152:INFO:Plot type: calibration
2026-01-29 15:57:27,159:INFO:Scoring test/hold-out set
2026-01-29 15:57:27,297:INFO:Visual Rendered Successfully
2026-01-29 15:57:27,504:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:28,477:INFO:Initializing plot_model()
2026-01-29 15:57:28,477:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:28,477:INFO:Checking exceptions
2026-01-29 15:57:28,499:INFO:Preloading libraries
2026-01-29 15:57:28,499:INFO:Copying training dataset
2026-01-29 15:57:28,499:INFO:Plot type: pipeline
2026-01-29 15:57:28,547:INFO:Visual Rendered Successfully
2026-01-29 15:57:28,750:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:29,658:INFO:Initializing plot_model()
2026-01-29 15:57:29,658:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=calibration, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:29,659:INFO:Checking exceptions
2026-01-29 15:57:29,684:INFO:Preloading libraries
2026-01-29 15:57:29,684:INFO:Copying training dataset
2026-01-29 15:57:29,684:INFO:Plot type: calibration
2026-01-29 15:57:29,691:INFO:Scoring test/hold-out set
2026-01-29 15:57:29,825:INFO:Visual Rendered Successfully
2026-01-29 15:57:30,020:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:33,354:INFO:Initializing plot_model()
2026-01-29 15:57:33,356:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=dimension, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:33,356:INFO:Checking exceptions
2026-01-29 15:57:33,377:INFO:Preloading libraries
2026-01-29 15:57:33,377:INFO:Copying training dataset
2026-01-29 15:57:33,377:INFO:Plot type: dimension
2026-01-29 15:57:33,443:INFO:Fitting StandardScaler()
2026-01-29 15:57:33,513:INFO:Fitting PCA()
2026-01-29 15:57:33,756:INFO:Fitting & Transforming Model
2026-01-29 15:57:33,771:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\yellowbrick\features\radviz.py:199: RuntimeWarning: invalid value encountered in divide

2026-01-29 15:57:41,864:INFO:Visual Rendered Successfully
2026-01-29 15:57:42,103:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:42,136:INFO:Initializing plot_model()
2026-01-29 15:57:42,136:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=tree, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:42,136:INFO:Checking exceptions
2026-01-29 15:57:43,864:INFO:Initializing plot_model()
2026-01-29 15:57:43,864:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=learning, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:43,864:INFO:Checking exceptions
2026-01-29 15:57:43,884:INFO:Preloading libraries
2026-01-29 15:57:43,885:INFO:Copying training dataset
2026-01-29 15:57:43,885:INFO:Plot type: learning
2026-01-29 15:57:44,051:INFO:Fitting Model
2026-01-29 15:57:51,354:INFO:Visual Rendered Successfully
2026-01-29 15:57:51,565:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:51,615:INFO:Initializing plot_model()
2026-01-29 15:57:51,615:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=calibration, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:51,615:INFO:Checking exceptions
2026-01-29 15:57:51,646:INFO:Preloading libraries
2026-01-29 15:57:51,646:INFO:Copying training dataset
2026-01-29 15:57:51,646:INFO:Plot type: calibration
2026-01-29 15:57:51,655:INFO:Scoring test/hold-out set
2026-01-29 15:57:51,848:INFO:Visual Rendered Successfully
2026-01-29 15:57:52,080:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:53,370:INFO:Initializing plot_model()
2026-01-29 15:57:53,371:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:53,371:INFO:Checking exceptions
2026-01-29 15:57:53,391:INFO:Preloading libraries
2026-01-29 15:57:53,391:INFO:Copying training dataset
2026-01-29 15:57:53,391:INFO:Plot type: feature
2026-01-29 15:57:53,580:INFO:Visual Rendered Successfully
2026-01-29 15:57:53,778:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:55,745:INFO:Initializing plot_model()
2026-01-29 15:57:55,745:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature_all, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:55,745:INFO:Checking exceptions
2026-01-29 15:57:55,770:INFO:Preloading libraries
2026-01-29 15:57:55,770:INFO:Copying training dataset
2026-01-29 15:57:55,770:INFO:Plot type: feature_all
2026-01-29 15:57:56,029:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\matplotlib\_tight_bbox.py:67: RuntimeWarning: divide by zero encountered in scalar divide

2026-01-29 15:57:56,029:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\matplotlib\_tight_bbox.py:68: RuntimeWarning: divide by zero encountered in scalar divide

2026-01-29 15:57:56,029:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\matplotlib\patches.py:739: RuntimeWarning: invalid value encountered in scalar add

2026-01-29 15:57:56,029:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\matplotlib\transforms.py:2050: RuntimeWarning: invalid value encountered in scalar add

2026-01-29 15:57:56,046:INFO:Visual Rendered Successfully
2026-01-29 15:57:56,254:INFO:plot_model() successfully completed......................................
2026-01-29 15:57:59,486:INFO:Initializing plot_model()
2026-01-29 15:57:59,487:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=boundary, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:57:59,487:INFO:Checking exceptions
2026-01-29 15:57:59,514:INFO:Preloading libraries
2026-01-29 15:57:59,514:INFO:Copying training dataset
2026-01-29 15:57:59,514:INFO:Plot type: boundary
2026-01-29 15:57:59,620:INFO:Fitting StandardScaler()
2026-01-29 15:57:59,634:INFO:Fitting PCA()
2026-01-29 15:57:59,813:INFO:Fitting Model
2026-01-29 15:58:01,610:INFO:Visual Rendered Successfully
2026-01-29 15:58:01,860:INFO:plot_model() successfully completed......................................
2026-01-29 15:58:03,737:INFO:Initializing plot_model()
2026-01-29 15:58:03,738:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=gain, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:58:03,739:INFO:Checking exceptions
2026-01-29 15:58:03,761:INFO:Preloading libraries
2026-01-29 15:58:03,761:INFO:Copying training dataset
2026-01-29 15:58:03,761:INFO:Plot type: gain
2026-01-29 15:58:03,761:INFO:Generating predictions / predict_proba on X_test
2026-01-29 15:58:03,925:INFO:Visual Rendered Successfully
2026-01-29 15:58:04,113:INFO:plot_model() successfully completed......................................
2026-01-29 15:58:05,457:INFO:Initializing plot_model()
2026-01-29 15:58:05,457:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=tree, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:58:05,457:INFO:Checking exceptions
2026-01-29 15:58:06,613:INFO:Initializing plot_model()
2026-01-29 15:58:06,613:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=learning, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:58:06,613:INFO:Checking exceptions
2026-01-29 15:58:06,633:INFO:Preloading libraries
2026-01-29 15:58:06,633:INFO:Copying training dataset
2026-01-29 15:58:06,633:INFO:Plot type: learning
2026-01-29 15:58:06,829:INFO:Fitting Model
2026-01-29 15:58:13,907:INFO:Visual Rendered Successfully
2026-01-29 15:58:14,118:INFO:plot_model() successfully completed......................................
2026-01-29 15:58:14,128:INFO:Initializing plot_model()
2026-01-29 15:58:14,128:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=rfe, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:58:14,128:INFO:Checking exceptions
2026-01-29 15:58:14,166:INFO:Preloading libraries
2026-01-29 15:58:14,166:INFO:Copying training dataset
2026-01-29 15:58:14,166:INFO:Plot type: rfe
2026-01-29 15:58:14,382:INFO:Fitting Model
2026-01-29 15:58:19,436:INFO:Visual Rendered Successfully
2026-01-29 15:58:19,632:INFO:plot_model() successfully completed......................................
2026-01-29 15:58:33,959:INFO:Initializing plot_model()
2026-01-29 15:58:33,959:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=gain, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:58:33,959:INFO:Checking exceptions
2026-01-29 15:58:33,999:INFO:Preloading libraries
2026-01-29 15:58:34,000:INFO:Copying training dataset
2026-01-29 15:58:34,000:INFO:Plot type: gain
2026-01-29 15:58:34,000:INFO:Generating predictions / predict_proba on X_test
2026-01-29 15:58:34,216:INFO:Visual Rendered Successfully
2026-01-29 15:58:34,430:INFO:plot_model() successfully completed......................................
2026-01-29 15:58:36,177:INFO:Initializing plot_model()
2026-01-29 15:58:36,177:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=lift, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:58:36,177:INFO:Checking exceptions
2026-01-29 15:58:36,199:INFO:Preloading libraries
2026-01-29 15:58:36,199:INFO:Copying training dataset
2026-01-29 15:58:36,199:INFO:Plot type: lift
2026-01-29 15:58:36,199:INFO:Generating predictions / predict_proba on X_test
2026-01-29 15:58:36,361:INFO:Visual Rendered Successfully
2026-01-29 15:58:36,563:INFO:plot_model() successfully completed......................................
2026-01-29 15:58:55,094:INFO:Initializing plot_model()
2026-01-29 15:58:55,094:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=learning, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:58:55,094:INFO:Checking exceptions
2026-01-29 15:58:55,121:INFO:Preloading libraries
2026-01-29 15:58:55,121:INFO:Copying training dataset
2026-01-29 15:58:55,121:INFO:Plot type: learning
2026-01-29 15:58:55,330:INFO:Fitting Model
2026-01-29 15:58:56,460:INFO:Visual Rendered Successfully
2026-01-29 15:58:56,670:INFO:plot_model() successfully completed......................................
2026-01-29 15:59:04,839:INFO:Initializing plot_model()
2026-01-29 15:59:04,839:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F613050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), plot=learning, scale=1, save=False, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 15:59:04,839:INFO:Checking exceptions
2026-01-29 15:59:04,870:INFO:Preloading libraries
2026-01-29 15:59:04,870:INFO:Copying training dataset
2026-01-29 15:59:04,870:INFO:Plot type: learning
2026-01-29 15:59:05,056:INFO:Fitting Model
2026-01-29 15:59:06,092:INFO:Visual Rendered Successfully
2026-01-29 15:59:06,293:INFO:plot_model() successfully completed......................................
2026-01-29 16:03:10,077:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\1833453759.py:18: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-29 16:03:12,331:INFO:PyCaret ClassificationExperiment
2026-01-29 16:03:12,332:INFO:Logging name: clf-default-name
2026-01-29 16:03:12,332:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-29 16:03:12,332:INFO:version 3.3.2
2026-01-29 16:03:12,332:INFO:Initializing setup()
2026-01-29 16:03:12,332:INFO:self.USI: e0d6
2026-01-29 16:03:12,332:INFO:self._variable_keys: {'X_test', 'fold_groups_param', 'pipeline', 'fix_imbalance', 'exp_name_log', 'data', 'y_test', 'seed', 'fold_shuffle_param', 'n_jobs_param', 'is_multiclass', 'gpu_n_jobs_param', 'memory', 'log_plots_param', 'logging_param', 'idx', 'y', 'target_param', 'fold_generator', 'y_train', 'gpu_param', 'USI', 'exp_id', '_available_plots', 'X', 'X_train', 'html_param', '_ml_usecase'}
2026-01-29 16:03:12,332:INFO:Checking environment
2026-01-29 16:03:12,332:INFO:python_version: 3.11.11
2026-01-29 16:03:12,333:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-29 16:03:12,333:INFO:machine: AMD64
2026-01-29 16:03:12,334:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-29 16:03:12,334:INFO:Memory: svmem(total=34009374720, available=12534964224, percent=63.1, used=21474410496, free=12534964224)
2026-01-29 16:03:12,334:INFO:Physical Core: 12
2026-01-29 16:03:12,334:INFO:Logical Core: 16
2026-01-29 16:03:12,334:INFO:Checking libraries
2026-01-29 16:03:12,334:INFO:System:
2026-01-29 16:03:12,334:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-29 16:03:12,334:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-29 16:03:12,335:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-29 16:03:12,335:INFO:PyCaret required dependencies:
2026-01-29 16:03:12,335:INFO:                 pip: 25.0
2026-01-29 16:03:12,335:INFO:          setuptools: 75.8.0
2026-01-29 16:03:12,335:INFO:             pycaret: 3.3.2
2026-01-29 16:03:12,335:INFO:             IPython: 9.9.0
2026-01-29 16:03:12,335:INFO:          ipywidgets: 8.1.8
2026-01-29 16:03:12,335:INFO:                tqdm: 4.67.1
2026-01-29 16:03:12,335:INFO:               numpy: 1.26.4
2026-01-29 16:03:12,335:INFO:              pandas: 2.1.4
2026-01-29 16:03:12,335:INFO:              jinja2: 3.1.6
2026-01-29 16:03:12,335:INFO:               scipy: 1.11.4
2026-01-29 16:03:12,335:INFO:              joblib: 1.3.2
2026-01-29 16:03:12,335:INFO:             sklearn: 1.4.2
2026-01-29 16:03:12,335:INFO:                pyod: 2.0.6
2026-01-29 16:03:12,335:INFO:            imblearn: 0.14.1
2026-01-29 16:03:12,335:INFO:   category_encoders: 2.7.0
2026-01-29 16:03:12,335:INFO:            lightgbm: 4.6.0
2026-01-29 16:03:12,335:INFO:               numba: 0.62.1
2026-01-29 16:03:12,335:INFO:            requests: 2.32.3
2026-01-29 16:03:12,335:INFO:          matplotlib: 3.7.5
2026-01-29 16:03:12,336:INFO:          scikitplot: 0.3.7
2026-01-29 16:03:12,336:INFO:         yellowbrick: 1.5
2026-01-29 16:03:12,336:INFO:              plotly: 5.24.1
2026-01-29 16:03:12,336:INFO:    plotly-resampler: Not installed
2026-01-29 16:03:12,336:INFO:             kaleido: 1.2.0
2026-01-29 16:03:12,336:INFO:           schemdraw: 0.15
2026-01-29 16:03:12,336:INFO:         statsmodels: 0.14.6
2026-01-29 16:03:12,336:INFO:              sktime: 0.26.0
2026-01-29 16:03:12,336:INFO:               tbats: 1.1.3
2026-01-29 16:03:12,336:INFO:            pmdarima: 2.0.4
2026-01-29 16:03:12,336:INFO:              psutil: 7.2.1
2026-01-29 16:03:12,336:INFO:          markupsafe: 3.0.3
2026-01-29 16:03:12,336:INFO:             pickle5: Not installed
2026-01-29 16:03:12,336:INFO:         cloudpickle: 3.0.0
2026-01-29 16:03:12,336:INFO:         deprecation: 2.1.0
2026-01-29 16:03:12,336:INFO:              xxhash: 3.6.0
2026-01-29 16:03:12,336:INFO:           wurlitzer: Not installed
2026-01-29 16:03:12,336:INFO:PyCaret optional dependencies:
2026-01-29 16:03:12,336:INFO:                shap: 0.44.1
2026-01-29 16:03:12,337:INFO:           interpret: 0.7.3
2026-01-29 16:03:12,338:INFO:                umap: 0.5.7
2026-01-29 16:03:12,338:INFO:     ydata_profiling: 4.18.1
2026-01-29 16:03:12,339:INFO:  explainerdashboard: 0.5.1
2026-01-29 16:03:12,339:INFO:             autoviz: Not installed
2026-01-29 16:03:12,339:INFO:           fairlearn: 0.7.0
2026-01-29 16:03:12,339:INFO:          deepchecks: Not installed
2026-01-29 16:03:12,339:INFO:             xgboost: Not installed
2026-01-29 16:03:12,339:INFO:            catboost: 1.2.8
2026-01-29 16:03:12,339:INFO:              kmodes: 0.12.2
2026-01-29 16:03:12,339:INFO:             mlxtend: 0.23.4
2026-01-29 16:03:12,339:INFO:       statsforecast: 1.5.0
2026-01-29 16:03:12,339:INFO:        tune_sklearn: Not installed
2026-01-29 16:03:12,339:INFO:                 ray: Not installed
2026-01-29 16:03:12,341:INFO:            hyperopt: 0.2.7
2026-01-29 16:03:12,341:INFO:              optuna: 4.6.0
2026-01-29 16:03:12,341:INFO:               skopt: 0.10.2
2026-01-29 16:03:12,341:INFO:              mlflow: 3.8.1
2026-01-29 16:03:12,341:INFO:              gradio: 6.3.0
2026-01-29 16:03:12,341:INFO:             fastapi: 0.128.0
2026-01-29 16:03:12,341:INFO:             uvicorn: 0.40.0
2026-01-29 16:03:12,342:INFO:              m2cgen: 0.10.0
2026-01-29 16:03:12,342:INFO:           evidently: 0.4.40
2026-01-29 16:03:12,342:INFO:               fugue: 0.8.7
2026-01-29 16:03:12,342:INFO:           streamlit: Not installed
2026-01-29 16:03:12,342:INFO:             prophet: Not installed
2026-01-29 16:03:12,342:INFO:None
2026-01-29 16:03:12,342:INFO:Set up data.
2026-01-29 16:03:12,377:INFO:Set up folding strategy.
2026-01-29 16:03:12,377:INFO:Set up train/test split.
2026-01-29 16:03:12,487:INFO:Set up index.
2026-01-29 16:03:12,495:INFO:Assigning column types.
2026-01-29 16:03:12,512:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-29 16:03:12,546:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:03:12,546:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:03:12,564:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:03:12,564:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:03:12,585:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:03:12,585:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:03:12,613:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:03:12,613:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:03:12,614:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-29 16:03:12,634:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:03:12,653:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:03:12,653:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:03:12,684:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:03:12,703:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:03:12,709:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:03:12,709:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-29 16:03:12,753:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:03:12,753:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:03:12,803:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:03:12,803:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:03:12,808:INFO:Preparing preprocessing pipeline...
2026-01-29 16:03:12,815:INFO:Set up simple imputation.
2026-01-29 16:03:12,816:INFO:Set up feature normalization.
2026-01-29 16:03:12,902:INFO:Finished creating preprocessing pipeline.
2026-01-29 16:03:12,914:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-29 16:03:12,914:INFO:Creating final display dataframe.
2026-01-29 16:03:13,181:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape       (429278, 4)
4        Transformed data shape       (429278, 4)
5   Transformed train set shape       (343422, 4)
6    Transformed test set shape        (85856, 4)
7               Ignore features                58
8              Numeric features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                 5
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              e0d6
2026-01-29 16:03:13,230:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:03:13,230:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:03:13,287:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:03:13,289:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:03:13,291:INFO:setup() successfully completed in 0.97s...............
2026-01-29 16:03:13,291:INFO:Initializing compare_models()
2026-01-29 16:03:13,291:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002481F5FA790>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002481F5FA790>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-29 16:03:13,293:INFO:Checking exceptions
2026-01-29 16:03:13,333:INFO:Preparing display monitor
2026-01-29 16:03:13,354:INFO:Initializing Logistic Regression
2026-01-29 16:03:13,355:INFO:Total runtime is 7.474422454833985e-06 minutes
2026-01-29 16:03:13,360:INFO:SubProcess create_model() called ==================================
2026-01-29 16:03:13,360:INFO:Initializing create_model()
2026-01-29 16:03:13,360:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002481F5FA790>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002480EE11E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:03:13,360:INFO:Checking exceptions
2026-01-29 16:03:13,361:INFO:Importing libraries
2026-01-29 16:03:13,361:INFO:Copying training dataset
2026-01-29 16:03:13,481:INFO:Defining folds
2026-01-29 16:03:13,482:INFO:Declaring metric variables
2026-01-29 16:03:13,485:INFO:Importing untrained model
2026-01-29 16:03:13,489:INFO:Logistic Regression Imported successfully
2026-01-29 16:03:13,497:INFO:Starting cross validation
2026-01-29 16:03:13,498:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:03:14,246:INFO:Calculating mean and std
2026-01-29 16:03:14,247:INFO:Creating metrics dataframe
2026-01-29 16:03:14,249:INFO:Uploading results into container
2026-01-29 16:03:14,249:INFO:Uploading model into container now
2026-01-29 16:03:14,250:INFO:_master_model_container: 1
2026-01-29 16:03:14,250:INFO:_display_container: 2
2026-01-29 16:03:14,250:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:03:14,250:INFO:create_model() successfully completed......................................
2026-01-29 16:03:14,536:INFO:SubProcess create_model() end ==================================
2026-01-29 16:03:14,536:INFO:Creating metrics dataframe
2026-01-29 16:03:14,543:INFO:Initializing K Neighbors Classifier
2026-01-29 16:03:14,544:INFO:Total runtime is 0.019810458024342857 minutes
2026-01-29 16:03:14,547:INFO:SubProcess create_model() called ==================================
2026-01-29 16:03:14,548:INFO:Initializing create_model()
2026-01-29 16:03:14,548:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002481F5FA790>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002480EE11E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:03:14,548:INFO:Checking exceptions
2026-01-29 16:03:14,548:INFO:Importing libraries
2026-01-29 16:03:14,548:INFO:Copying training dataset
2026-01-29 16:03:14,649:INFO:Defining folds
2026-01-29 16:03:14,649:INFO:Declaring metric variables
2026-01-29 16:03:14,656:INFO:Importing untrained model
2026-01-29 16:03:14,660:INFO:K Neighbors Classifier Imported successfully
2026-01-29 16:03:14,666:INFO:Starting cross validation
2026-01-29 16:03:14,667:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:09:45,976:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\2961347337.py:18: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-29 16:09:47,884:INFO:PyCaret ClassificationExperiment
2026-01-29 16:09:47,884:INFO:Logging name: clf-default-name
2026-01-29 16:09:47,885:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-29 16:09:47,885:INFO:version 3.3.2
2026-01-29 16:09:47,885:INFO:Initializing setup()
2026-01-29 16:09:47,885:INFO:self.USI: a7a0
2026-01-29 16:09:47,885:INFO:self._variable_keys: {'X_test', 'fold_groups_param', 'pipeline', 'fix_imbalance', 'exp_name_log', 'data', 'y_test', 'seed', 'fold_shuffle_param', 'n_jobs_param', 'is_multiclass', 'gpu_n_jobs_param', 'memory', 'log_plots_param', 'logging_param', 'idx', 'y', 'target_param', 'fold_generator', 'y_train', 'gpu_param', 'USI', 'exp_id', '_available_plots', 'X', 'X_train', 'html_param', '_ml_usecase'}
2026-01-29 16:09:47,886:INFO:Checking environment
2026-01-29 16:09:47,886:INFO:python_version: 3.11.11
2026-01-29 16:09:47,887:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-29 16:09:47,887:INFO:machine: AMD64
2026-01-29 16:09:47,887:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-29 16:09:47,887:INFO:Memory: svmem(total=34009374720, available=15785549824, percent=53.6, used=18223824896, free=15785549824)
2026-01-29 16:09:47,887:INFO:Physical Core: 12
2026-01-29 16:09:47,887:INFO:Logical Core: 16
2026-01-29 16:09:47,887:INFO:Checking libraries
2026-01-29 16:09:47,887:INFO:System:
2026-01-29 16:09:47,887:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-29 16:09:47,887:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-29 16:09:47,887:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-29 16:09:47,887:INFO:PyCaret required dependencies:
2026-01-29 16:09:47,887:INFO:                 pip: 25.0
2026-01-29 16:09:47,888:INFO:          setuptools: 75.8.0
2026-01-29 16:09:47,888:INFO:             pycaret: 3.3.2
2026-01-29 16:09:47,888:INFO:             IPython: 9.9.0
2026-01-29 16:09:47,888:INFO:          ipywidgets: 8.1.8
2026-01-29 16:09:47,888:INFO:                tqdm: 4.67.1
2026-01-29 16:09:47,888:INFO:               numpy: 1.26.4
2026-01-29 16:09:47,888:INFO:              pandas: 2.1.4
2026-01-29 16:09:47,888:INFO:              jinja2: 3.1.6
2026-01-29 16:09:47,888:INFO:               scipy: 1.11.4
2026-01-29 16:09:47,888:INFO:              joblib: 1.3.2
2026-01-29 16:09:47,888:INFO:             sklearn: 1.4.2
2026-01-29 16:09:47,888:INFO:                pyod: 2.0.6
2026-01-29 16:09:47,888:INFO:            imblearn: 0.14.1
2026-01-29 16:09:47,888:INFO:   category_encoders: 2.7.0
2026-01-29 16:09:47,888:INFO:            lightgbm: 4.6.0
2026-01-29 16:09:47,888:INFO:               numba: 0.62.1
2026-01-29 16:09:47,888:INFO:            requests: 2.32.3
2026-01-29 16:09:47,888:INFO:          matplotlib: 3.7.5
2026-01-29 16:09:47,888:INFO:          scikitplot: 0.3.7
2026-01-29 16:09:47,888:INFO:         yellowbrick: 1.5
2026-01-29 16:09:47,888:INFO:              plotly: 5.24.1
2026-01-29 16:09:47,888:INFO:    plotly-resampler: Not installed
2026-01-29 16:09:47,888:INFO:             kaleido: 1.2.0
2026-01-29 16:09:47,888:INFO:           schemdraw: 0.15
2026-01-29 16:09:47,888:INFO:         statsmodels: 0.14.6
2026-01-29 16:09:47,888:INFO:              sktime: 0.26.0
2026-01-29 16:09:47,888:INFO:               tbats: 1.1.3
2026-01-29 16:09:47,888:INFO:            pmdarima: 2.0.4
2026-01-29 16:09:47,888:INFO:              psutil: 7.2.1
2026-01-29 16:09:47,888:INFO:          markupsafe: 3.0.3
2026-01-29 16:09:47,889:INFO:             pickle5: Not installed
2026-01-29 16:09:47,889:INFO:         cloudpickle: 3.0.0
2026-01-29 16:09:47,889:INFO:         deprecation: 2.1.0
2026-01-29 16:09:47,889:INFO:              xxhash: 3.6.0
2026-01-29 16:09:47,889:INFO:           wurlitzer: Not installed
2026-01-29 16:09:47,889:INFO:PyCaret optional dependencies:
2026-01-29 16:09:47,889:INFO:                shap: 0.44.1
2026-01-29 16:09:47,889:INFO:           interpret: 0.7.3
2026-01-29 16:09:47,889:INFO:                umap: 0.5.7
2026-01-29 16:09:47,889:INFO:     ydata_profiling: 4.18.1
2026-01-29 16:09:47,889:INFO:  explainerdashboard: 0.5.1
2026-01-29 16:09:47,889:INFO:             autoviz: Not installed
2026-01-29 16:09:47,889:INFO:           fairlearn: 0.7.0
2026-01-29 16:09:47,889:INFO:          deepchecks: Not installed
2026-01-29 16:09:47,890:INFO:             xgboost: Not installed
2026-01-29 16:09:47,890:INFO:            catboost: 1.2.8
2026-01-29 16:09:47,890:INFO:              kmodes: 0.12.2
2026-01-29 16:09:47,890:INFO:             mlxtend: 0.23.4
2026-01-29 16:09:47,890:INFO:       statsforecast: 1.5.0
2026-01-29 16:09:47,890:INFO:        tune_sklearn: Not installed
2026-01-29 16:09:47,890:INFO:                 ray: Not installed
2026-01-29 16:09:47,890:INFO:            hyperopt: 0.2.7
2026-01-29 16:09:47,890:INFO:              optuna: 4.6.0
2026-01-29 16:09:47,890:INFO:               skopt: 0.10.2
2026-01-29 16:09:47,890:INFO:              mlflow: 3.8.1
2026-01-29 16:09:47,890:INFO:              gradio: 6.3.0
2026-01-29 16:09:47,890:INFO:             fastapi: 0.128.0
2026-01-29 16:09:47,890:INFO:             uvicorn: 0.40.0
2026-01-29 16:09:47,891:INFO:              m2cgen: 0.10.0
2026-01-29 16:09:47,891:INFO:           evidently: 0.4.40
2026-01-29 16:09:47,891:INFO:               fugue: 0.8.7
2026-01-29 16:09:47,891:INFO:           streamlit: Not installed
2026-01-29 16:09:47,891:INFO:             prophet: Not installed
2026-01-29 16:09:47,891:INFO:None
2026-01-29 16:09:47,891:INFO:Set up data.
2026-01-29 16:09:47,923:INFO:Set up folding strategy.
2026-01-29 16:09:47,923:INFO:Set up train/test split.
2026-01-29 16:09:48,043:INFO:Set up index.
2026-01-29 16:09:48,043:INFO:Assigning column types.
2026-01-29 16:09:48,060:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-29 16:09:48,093:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:09:48,093:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:09:48,110:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:09:48,110:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:09:48,160:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:09:48,161:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:09:48,183:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:09:48,184:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:09:48,184:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-29 16:09:48,219:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:09:48,241:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:09:48,241:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:09:48,277:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:09:48,298:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:09:48,298:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:09:48,299:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-29 16:09:48,347:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:09:48,347:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:09:48,409:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:09:48,410:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:09:48,410:INFO:Preparing preprocessing pipeline...
2026-01-29 16:09:48,410:INFO:Set up simple imputation.
2026-01-29 16:09:48,410:INFO:Set up feature normalization.
2026-01-29 16:09:48,510:INFO:Finished creating preprocessing pipeline.
2026-01-29 16:09:48,510:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-29 16:09:48,510:INFO:Creating final display dataframe.
2026-01-29 16:09:48,710:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape       (429278, 4)
4        Transformed data shape       (429278, 4)
5   Transformed train set shape       (343422, 4)
6    Transformed test set shape        (85856, 4)
7               Ignore features                58
8              Numeric features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                 3
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              a7a0
2026-01-29 16:09:48,767:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:09:48,767:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:09:48,826:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:09:48,826:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:09:48,831:INFO:setup() successfully completed in 0.95s...............
2026-01-29 16:09:48,831:INFO:Initializing compare_models()
2026-01-29 16:09:48,831:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-29 16:09:48,831:INFO:Checking exceptions
2026-01-29 16:09:48,860:INFO:Preparing display monitor
2026-01-29 16:09:48,876:INFO:Initializing Logistic Regression
2026-01-29 16:09:48,876:INFO:Total runtime is 0.0 minutes
2026-01-29 16:09:48,878:INFO:SubProcess create_model() called ==================================
2026-01-29 16:09:48,879:INFO:Initializing create_model()
2026-01-29 16:09:48,879:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816D43CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:09:48,879:INFO:Checking exceptions
2026-01-29 16:09:48,879:INFO:Importing libraries
2026-01-29 16:09:48,879:INFO:Copying training dataset
2026-01-29 16:09:48,949:INFO:Defining folds
2026-01-29 16:09:48,950:INFO:Declaring metric variables
2026-01-29 16:09:48,952:INFO:Importing untrained model
2026-01-29 16:09:48,954:INFO:Logistic Regression Imported successfully
2026-01-29 16:09:48,959:INFO:Starting cross validation
2026-01-29 16:09:48,960:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:09:55,362:INFO:Calculating mean and std
2026-01-29 16:09:55,362:INFO:Creating metrics dataframe
2026-01-29 16:09:55,362:INFO:Uploading results into container
2026-01-29 16:09:55,362:INFO:Uploading model into container now
2026-01-29 16:09:55,366:INFO:_master_model_container: 1
2026-01-29 16:09:55,366:INFO:_display_container: 2
2026-01-29 16:09:55,367:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:09:55,368:INFO:create_model() successfully completed......................................
2026-01-29 16:09:55,680:INFO:SubProcess create_model() end ==================================
2026-01-29 16:09:55,680:INFO:Creating metrics dataframe
2026-01-29 16:09:55,686:INFO:Initializing Decision Tree Classifier
2026-01-29 16:09:55,686:INFO:Total runtime is 0.11348706881205241 minutes
2026-01-29 16:09:55,690:INFO:SubProcess create_model() called ==================================
2026-01-29 16:09:55,690:INFO:Initializing create_model()
2026-01-29 16:09:55,691:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816D43CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:09:55,691:INFO:Checking exceptions
2026-01-29 16:09:55,691:INFO:Importing libraries
2026-01-29 16:09:55,691:INFO:Copying training dataset
2026-01-29 16:09:55,760:INFO:Defining folds
2026-01-29 16:09:55,760:INFO:Declaring metric variables
2026-01-29 16:09:55,760:INFO:Importing untrained model
2026-01-29 16:09:55,777:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:09:55,777:INFO:Starting cross validation
2026-01-29 16:09:55,777:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:10:00,720:INFO:Calculating mean and std
2026-01-29 16:10:00,725:INFO:Creating metrics dataframe
2026-01-29 16:10:00,731:INFO:Uploading results into container
2026-01-29 16:10:00,731:INFO:Uploading model into container now
2026-01-29 16:10:00,733:INFO:_master_model_container: 2
2026-01-29 16:10:00,734:INFO:_display_container: 2
2026-01-29 16:10:00,735:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:10:00,735:INFO:create_model() successfully completed......................................
2026-01-29 16:10:00,943:INFO:SubProcess create_model() end ==================================
2026-01-29 16:10:00,943:INFO:Creating metrics dataframe
2026-01-29 16:10:00,943:INFO:Initializing Random Forest Classifier
2026-01-29 16:10:00,943:INFO:Total runtime is 0.2011061708132426 minutes
2026-01-29 16:10:00,951:INFO:SubProcess create_model() called ==================================
2026-01-29 16:10:00,951:INFO:Initializing create_model()
2026-01-29 16:10:00,951:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816D43CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:10:00,951:INFO:Checking exceptions
2026-01-29 16:10:00,951:INFO:Importing libraries
2026-01-29 16:10:00,951:INFO:Copying training dataset
2026-01-29 16:10:01,011:INFO:Defining folds
2026-01-29 16:10:01,011:INFO:Declaring metric variables
2026-01-29 16:10:01,011:INFO:Importing untrained model
2026-01-29 16:10:01,011:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:10:01,026:INFO:Starting cross validation
2026-01-29 16:10:01,027:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:10:08,114:INFO:Calculating mean and std
2026-01-29 16:10:08,114:INFO:Creating metrics dataframe
2026-01-29 16:10:08,114:INFO:Uploading results into container
2026-01-29 16:10:08,114:INFO:Uploading model into container now
2026-01-29 16:10:08,114:INFO:_master_model_container: 3
2026-01-29 16:10:08,114:INFO:_display_container: 2
2026-01-29 16:10:08,114:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:10:08,114:INFO:create_model() successfully completed......................................
2026-01-29 16:10:08,309:INFO:SubProcess create_model() end ==================================
2026-01-29 16:10:08,309:INFO:Creating metrics dataframe
2026-01-29 16:10:08,326:INFO:Initializing Light Gradient Boosting Machine
2026-01-29 16:10:08,326:INFO:Total runtime is 0.32416341304779056 minutes
2026-01-29 16:10:08,326:INFO:SubProcess create_model() called ==================================
2026-01-29 16:10:08,326:INFO:Initializing create_model()
2026-01-29 16:10:08,326:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816D43CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:10:08,326:INFO:Checking exceptions
2026-01-29 16:10:08,326:INFO:Importing libraries
2026-01-29 16:10:08,326:INFO:Copying training dataset
2026-01-29 16:10:08,403:INFO:Defining folds
2026-01-29 16:10:08,403:INFO:Declaring metric variables
2026-01-29 16:10:08,406:INFO:Importing untrained model
2026-01-29 16:10:08,410:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-29 16:10:08,411:INFO:Starting cross validation
2026-01-29 16:10:08,411:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:10:15,067:INFO:Calculating mean and std
2026-01-29 16:10:15,067:INFO:Creating metrics dataframe
2026-01-29 16:10:15,071:INFO:Uploading results into container
2026-01-29 16:10:15,071:INFO:Uploading model into container now
2026-01-29 16:10:15,071:INFO:_master_model_container: 4
2026-01-29 16:10:15,071:INFO:_display_container: 2
2026-01-29 16:10:15,073:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-29 16:10:15,073:INFO:create_model() successfully completed......................................
2026-01-29 16:10:15,276:INFO:SubProcess create_model() end ==================================
2026-01-29 16:10:15,276:INFO:Creating metrics dataframe
2026-01-29 16:10:15,279:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-29 16:10:15,289:INFO:Initializing create_model()
2026-01-29 16:10:15,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:10:15,289:INFO:Checking exceptions
2026-01-29 16:10:15,294:INFO:Importing libraries
2026-01-29 16:10:15,294:INFO:Copying training dataset
2026-01-29 16:10:15,359:INFO:Defining folds
2026-01-29 16:10:15,359:INFO:Declaring metric variables
2026-01-29 16:10:15,359:INFO:Importing untrained model
2026-01-29 16:10:15,359:INFO:Declaring custom model
2026-01-29 16:10:15,359:INFO:Logistic Regression Imported successfully
2026-01-29 16:10:15,359:INFO:Cross validation set to False
2026-01-29 16:10:15,359:INFO:Fitting Model
2026-01-29 16:10:15,576:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:10:15,576:INFO:create_model() successfully completed......................................
2026-01-29 16:10:15,776:INFO:Initializing create_model()
2026-01-29 16:10:15,776:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:10:15,776:INFO:Checking exceptions
2026-01-29 16:10:15,787:INFO:Importing libraries
2026-01-29 16:10:15,787:INFO:Copying training dataset
2026-01-29 16:10:15,843:INFO:Defining folds
2026-01-29 16:10:15,843:INFO:Declaring metric variables
2026-01-29 16:10:15,843:INFO:Importing untrained model
2026-01-29 16:10:15,843:INFO:Declaring custom model
2026-01-29 16:10:15,843:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:10:15,843:INFO:Cross validation set to False
2026-01-29 16:10:15,843:INFO:Fitting Model
2026-01-29 16:10:15,909:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:10:15,909:INFO:create_model() successfully completed......................................
2026-01-29 16:10:16,110:INFO:Initializing create_model()
2026-01-29 16:10:16,110:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:10:16,124:INFO:Checking exceptions
2026-01-29 16:10:16,126:INFO:Importing libraries
2026-01-29 16:10:16,126:INFO:Copying training dataset
2026-01-29 16:10:16,185:INFO:Defining folds
2026-01-29 16:10:16,185:INFO:Declaring metric variables
2026-01-29 16:10:16,185:INFO:Importing untrained model
2026-01-29 16:10:16,185:INFO:Declaring custom model
2026-01-29 16:10:16,186:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:10:16,186:INFO:Cross validation set to False
2026-01-29 16:10:16,186:INFO:Fitting Model
2026-01-29 16:10:17,494:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:10:17,494:INFO:create_model() successfully completed......................................
2026-01-29 16:10:17,719:INFO:_master_model_container: 4
2026-01-29 16:10:17,719:INFO:_display_container: 2
2026-01-29 16:10:17,719:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2026-01-29 16:10:17,719:INFO:compare_models() successfully completed......................................
2026-01-29 16:10:17,719:INFO:Initializing tune_model()
2026-01-29 16:10:17,719:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:10:17,719:INFO:Checking exceptions
2026-01-29 16:10:17,761:INFO:Copying training dataset
2026-01-29 16:10:17,826:INFO:Checking base model
2026-01-29 16:10:17,827:INFO:Base model : Logistic Regression
2026-01-29 16:10:17,831:INFO:Declaring metric variables
2026-01-29 16:10:17,833:INFO:Defining Hyperparameters
2026-01-29 16:10:18,043:INFO:Tuning with n_jobs=-1
2026-01-29 16:10:18,043:INFO:Initializing RandomizedSearchCV
2026-01-29 16:10:24,819:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 5.682}
2026-01-29 16:10:24,819:INFO:Hyperparameter search completed
2026-01-29 16:10:24,819:INFO:SubProcess create_model() called ==================================
2026-01-29 16:10:24,826:INFO:Initializing create_model()
2026-01-29 16:10:24,826:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816DC4BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 5.682})
2026-01-29 16:10:24,827:INFO:Checking exceptions
2026-01-29 16:10:24,827:INFO:Importing libraries
2026-01-29 16:10:24,827:INFO:Copying training dataset
2026-01-29 16:10:24,893:INFO:Defining folds
2026-01-29 16:10:24,893:INFO:Declaring metric variables
2026-01-29 16:10:24,893:INFO:Importing untrained model
2026-01-29 16:10:24,893:INFO:Declaring custom model
2026-01-29 16:10:24,893:INFO:Logistic Regression Imported successfully
2026-01-29 16:10:24,909:INFO:Starting cross validation
2026-01-29 16:10:24,909:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:10:25,795:INFO:Calculating mean and std
2026-01-29 16:10:25,795:INFO:Creating metrics dataframe
2026-01-29 16:10:25,809:INFO:Finalizing model
2026-01-29 16:10:26,120:INFO:Uploading results into container
2026-01-29 16:10:26,121:INFO:Uploading model into container now
2026-01-29 16:10:26,122:INFO:_master_model_container: 5
2026-01-29 16:10:26,122:INFO:_display_container: 3
2026-01-29 16:10:26,122:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:10:26,122:INFO:create_model() successfully completed......................................
2026-01-29 16:10:26,343:INFO:SubProcess create_model() end ==================================
2026-01-29 16:10:26,343:INFO:choose_better activated
2026-01-29 16:10:26,343:INFO:SubProcess create_model() called ==================================
2026-01-29 16:10:26,343:INFO:Initializing create_model()
2026-01-29 16:10:26,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:10:26,343:INFO:Checking exceptions
2026-01-29 16:10:26,343:INFO:Importing libraries
2026-01-29 16:10:26,343:INFO:Copying training dataset
2026-01-29 16:10:26,424:INFO:Defining folds
2026-01-29 16:10:26,426:INFO:Declaring metric variables
2026-01-29 16:10:26,426:INFO:Importing untrained model
2026-01-29 16:10:26,426:INFO:Declaring custom model
2026-01-29 16:10:26,426:INFO:Logistic Regression Imported successfully
2026-01-29 16:10:26,426:INFO:Starting cross validation
2026-01-29 16:10:26,426:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:10:27,222:INFO:Calculating mean and std
2026-01-29 16:10:27,224:INFO:Creating metrics dataframe
2026-01-29 16:10:27,226:INFO:Finalizing model
2026-01-29 16:10:27,446:INFO:Uploading results into container
2026-01-29 16:10:27,460:INFO:Uploading model into container now
2026-01-29 16:10:27,460:INFO:_master_model_container: 6
2026-01-29 16:10:27,460:INFO:_display_container: 4
2026-01-29 16:10:27,460:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:10:27,460:INFO:create_model() successfully completed......................................
2026-01-29 16:10:27,659:INFO:SubProcess create_model() end ==================================
2026-01-29 16:10:27,659:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 16:10:27,659:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 16:10:27,659:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2026-01-29 16:10:27,659:INFO:choose_better completed
2026-01-29 16:10:27,659:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:10:27,676:INFO:_master_model_container: 6
2026-01-29 16:10:27,676:INFO:_display_container: 3
2026-01-29 16:10:27,676:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:10:27,676:INFO:tune_model() successfully completed......................................
2026-01-29 16:10:27,876:INFO:Initializing tune_model()
2026-01-29 16:10:27,876:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:10:27,876:INFO:Checking exceptions
2026-01-29 16:10:27,919:INFO:Copying training dataset
2026-01-29 16:10:28,002:INFO:Checking base model
2026-01-29 16:10:28,003:INFO:Base model : Decision Tree Classifier
2026-01-29 16:10:28,008:INFO:Declaring metric variables
2026-01-29 16:10:28,012:INFO:Defining Hyperparameters
2026-01-29 16:10:28,209:INFO:Tuning with n_jobs=-1
2026-01-29 16:10:28,209:INFO:Initializing RandomizedSearchCV
2026-01-29 16:10:29,211:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.0005, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 3, 'actual_estimator__criterion': 'gini'}
2026-01-29 16:10:29,211:INFO:Hyperparameter search completed
2026-01-29 16:10:29,211:INFO:SubProcess create_model() called ==================================
2026-01-29 16:10:29,211:INFO:Initializing create_model()
2026-01-29 16:10:29,211:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024871ADDC10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0005, 'max_features': 1.0, 'max_depth': 3, 'criterion': 'gini'})
2026-01-29 16:10:29,211:INFO:Checking exceptions
2026-01-29 16:10:29,211:INFO:Importing libraries
2026-01-29 16:10:29,211:INFO:Copying training dataset
2026-01-29 16:10:29,276:INFO:Defining folds
2026-01-29 16:10:29,276:INFO:Declaring metric variables
2026-01-29 16:10:29,276:INFO:Importing untrained model
2026-01-29 16:10:29,276:INFO:Declaring custom model
2026-01-29 16:10:29,276:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:10:29,293:INFO:Starting cross validation
2026-01-29 16:10:29,293:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:10:29,963:INFO:Calculating mean and std
2026-01-29 16:10:29,963:INFO:Creating metrics dataframe
2026-01-29 16:10:29,963:INFO:Finalizing model
2026-01-29 16:10:30,026:INFO:Uploading results into container
2026-01-29 16:10:30,026:INFO:Uploading model into container now
2026-01-29 16:10:30,026:INFO:_master_model_container: 7
2026-01-29 16:10:30,026:INFO:_display_container: 4
2026-01-29 16:10:30,026:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:10:30,026:INFO:create_model() successfully completed......................................
2026-01-29 16:10:30,264:INFO:SubProcess create_model() end ==================================
2026-01-29 16:10:30,264:INFO:choose_better activated
2026-01-29 16:10:30,276:INFO:SubProcess create_model() called ==================================
2026-01-29 16:10:30,276:INFO:Initializing create_model()
2026-01-29 16:10:30,276:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:10:30,276:INFO:Checking exceptions
2026-01-29 16:10:30,276:INFO:Importing libraries
2026-01-29 16:10:30,276:INFO:Copying training dataset
2026-01-29 16:10:30,400:INFO:Defining folds
2026-01-29 16:10:30,400:INFO:Declaring metric variables
2026-01-29 16:10:30,400:INFO:Importing untrained model
2026-01-29 16:10:30,400:INFO:Declaring custom model
2026-01-29 16:10:30,400:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:10:30,400:INFO:Starting cross validation
2026-01-29 16:10:30,400:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:10:31,146:INFO:Calculating mean and std
2026-01-29 16:10:31,147:INFO:Creating metrics dataframe
2026-01-29 16:10:31,148:INFO:Finalizing model
2026-01-29 16:10:31,226:INFO:Uploading results into container
2026-01-29 16:10:31,226:INFO:Uploading model into container now
2026-01-29 16:10:31,226:INFO:_master_model_container: 8
2026-01-29 16:10:31,226:INFO:_display_container: 5
2026-01-29 16:10:31,226:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:10:31,226:INFO:create_model() successfully completed......................................
2026-01-29 16:10:31,493:INFO:SubProcess create_model() end ==================================
2026-01-29 16:10:31,493:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5369
2026-01-29 16:10:31,493:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5366
2026-01-29 16:10:31,493:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-29 16:10:31,493:INFO:choose_better completed
2026-01-29 16:10:31,493:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:10:31,503:INFO:_master_model_container: 8
2026-01-29 16:10:31,503:INFO:_display_container: 4
2026-01-29 16:10:31,503:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:10:31,503:INFO:tune_model() successfully completed......................................
2026-01-29 16:10:31,709:INFO:Initializing tune_model()
2026-01-29 16:10:31,709:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:10:31,709:INFO:Checking exceptions
2026-01-29 16:10:31,743:INFO:Copying training dataset
2026-01-29 16:10:31,816:INFO:Checking base model
2026-01-29 16:10:31,816:INFO:Base model : Random Forest Classifier
2026-01-29 16:10:31,819:INFO:Declaring metric variables
2026-01-29 16:10:31,823:INFO:Defining Hyperparameters
2026-01-29 16:10:32,043:INFO:Tuning with n_jobs=-1
2026-01-29 16:10:32,043:INFO:Initializing RandomizedSearchCV
2026-01-29 16:10:58,903:INFO:best_params: {'actual_estimator__n_estimators': 120, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-29 16:10:58,904:INFO:Hyperparameter search completed
2026-01-29 16:10:58,904:INFO:SubProcess create_model() called ==================================
2026-01-29 16:10:58,904:INFO:Initializing create_model()
2026-01-29 16:10:58,905:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024870A8CF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 120, 'min_samples_split': 5, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': True})
2026-01-29 16:10:58,906:INFO:Checking exceptions
2026-01-29 16:10:58,906:INFO:Importing libraries
2026-01-29 16:10:58,906:INFO:Copying training dataset
2026-01-29 16:10:58,978:INFO:Defining folds
2026-01-29 16:10:58,978:INFO:Declaring metric variables
2026-01-29 16:10:58,981:INFO:Importing untrained model
2026-01-29 16:10:58,981:INFO:Declaring custom model
2026-01-29 16:10:58,981:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:10:58,993:INFO:Starting cross validation
2026-01-29 16:10:58,994:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:11:01,930:INFO:Calculating mean and std
2026-01-29 16:11:01,930:INFO:Creating metrics dataframe
2026-01-29 16:11:01,930:INFO:Finalizing model
2026-01-29 16:11:03,712:INFO:Uploading results into container
2026-01-29 16:11:03,712:INFO:Uploading model into container now
2026-01-29 16:11:03,712:INFO:_master_model_container: 9
2026-01-29 16:11:03,712:INFO:_display_container: 5
2026-01-29 16:11:03,712:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=120, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:11:03,712:INFO:create_model() successfully completed......................................
2026-01-29 16:11:03,960:INFO:SubProcess create_model() end ==================================
2026-01-29 16:11:03,960:INFO:choose_better activated
2026-01-29 16:11:03,975:INFO:SubProcess create_model() called ==================================
2026-01-29 16:11:03,975:INFO:Initializing create_model()
2026-01-29 16:11:03,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:11:03,975:INFO:Checking exceptions
2026-01-29 16:11:03,975:INFO:Importing libraries
2026-01-29 16:11:03,975:INFO:Copying training dataset
2026-01-29 16:11:04,045:INFO:Defining folds
2026-01-29 16:11:04,045:INFO:Declaring metric variables
2026-01-29 16:11:04,045:INFO:Importing untrained model
2026-01-29 16:11:04,045:INFO:Declaring custom model
2026-01-29 16:11:04,045:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:11:04,045:INFO:Starting cross validation
2026-01-29 16:11:04,045:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:11:06,566:INFO:Calculating mean and std
2026-01-29 16:11:06,566:INFO:Creating metrics dataframe
2026-01-29 16:11:06,566:INFO:Finalizing model
2026-01-29 16:11:08,046:INFO:Uploading results into container
2026-01-29 16:11:08,046:INFO:Uploading model into container now
2026-01-29 16:11:08,046:INFO:_master_model_container: 10
2026-01-29 16:11:08,046:INFO:_display_container: 6
2026-01-29 16:11:08,046:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:11:08,046:INFO:create_model() successfully completed......................................
2026-01-29 16:11:08,258:INFO:SubProcess create_model() end ==================================
2026-01-29 16:11:08,258:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.5369
2026-01-29 16:11:08,258:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=120, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.5369
2026-01-29 16:11:08,258:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-29 16:11:08,258:INFO:choose_better completed
2026-01-29 16:11:08,258:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:11:08,272:INFO:_master_model_container: 10
2026-01-29 16:11:08,272:INFO:_display_container: 5
2026-01-29 16:11:08,272:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:11:08,274:INFO:tune_model() successfully completed......................................
2026-01-29 16:11:08,491:INFO:Initializing evaluate_model()
2026-01-29 16:11:08,491:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:11:08,531:INFO:Initializing plot_model()
2026-01-29 16:11:08,531:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:11:08,532:INFO:Checking exceptions
2026-01-29 16:11:08,561:INFO:Preloading libraries
2026-01-29 16:11:08,561:INFO:Copying training dataset
2026-01-29 16:11:08,561:INFO:Plot type: pipeline
2026-01-29 16:11:08,628:INFO:Visual Rendered Successfully
2026-01-29 16:11:08,862:INFO:plot_model() successfully completed......................................
2026-01-29 16:11:08,866:INFO:Initializing evaluate_model()
2026-01-29 16:11:08,867:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:11:08,917:INFO:Initializing plot_model()
2026-01-29 16:11:08,918:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:11:08,918:INFO:Checking exceptions
2026-01-29 16:11:08,964:INFO:Preloading libraries
2026-01-29 16:11:08,964:INFO:Copying training dataset
2026-01-29 16:11:08,964:INFO:Plot type: pipeline
2026-01-29 16:11:09,024:INFO:Visual Rendered Successfully
2026-01-29 16:11:09,224:INFO:plot_model() successfully completed......................................
2026-01-29 16:11:09,240:INFO:Initializing evaluate_model()
2026-01-29 16:11:09,242:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:11:09,283:INFO:Initializing plot_model()
2026-01-29 16:11:09,283:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:11:09,283:INFO:Checking exceptions
2026-01-29 16:11:09,328:INFO:Preloading libraries
2026-01-29 16:11:09,346:INFO:Copying training dataset
2026-01-29 16:11:09,346:INFO:Plot type: pipeline
2026-01-29 16:11:09,412:INFO:Visual Rendered Successfully
2026-01-29 16:11:09,627:INFO:plot_model() successfully completed......................................
2026-01-29 16:11:09,636:INFO:Initializing predict_model()
2026-01-29 16:11:09,636:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024871470B80>)
2026-01-29 16:11:09,637:INFO:Checking exceptions
2026-01-29 16:11:09,637:INFO:Preloading libraries
2026-01-29 16:11:09,638:INFO:Set up data.
2026-01-29 16:11:09,647:INFO:Set up index.
2026-01-29 16:11:10,159:INFO:Initializing predict_model()
2026-01-29 16:11:10,159:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002480475F6A0>)
2026-01-29 16:11:10,159:INFO:Checking exceptions
2026-01-29 16:11:10,159:INFO:Preloading libraries
2026-01-29 16:11:10,175:INFO:Set up data.
2026-01-29 16:11:10,177:INFO:Set up index.
2026-01-29 16:11:10,729:INFO:Initializing predict_model()
2026-01-29 16:11:10,729:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024871470680>)
2026-01-29 16:11:10,729:INFO:Checking exceptions
2026-01-29 16:11:10,729:INFO:Preloading libraries
2026-01-29 16:11:10,731:INFO:Set up data.
2026-01-29 16:11:10,740:INFO:Set up index.
2026-01-29 16:11:11,434:INFO:Initializing plot_model()
2026-01-29 16:11:11,434:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248171E9E90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-29 16:11:11,434:INFO:Checking exceptions
2026-01-29 16:11:11,460:INFO:Preloading libraries
2026-01-29 16:11:11,460:INFO:Copying training dataset
2026-01-29 16:11:11,460:INFO:Plot type: feature
2026-01-29 16:11:11,714:INFO:Visual Rendered Successfully
2026-01-29 16:11:11,931:INFO:plot_model() successfully completed......................................
2026-01-29 16:11:11,931:INFO:Initializing save_model()
2026-01-29 16:11:11,931:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=..\modelos\modelo_general, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-29 16:11:11,931:INFO:Adding model into prep_pipe
2026-01-29 16:13:57,407:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\1855575028.py:18: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-29 16:13:59,973:INFO:PyCaret ClassificationExperiment
2026-01-29 16:13:59,973:INFO:Logging name: clf-default-name
2026-01-29 16:13:59,986:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-29 16:13:59,986:INFO:version 3.3.2
2026-01-29 16:13:59,986:INFO:Initializing setup()
2026-01-29 16:13:59,986:INFO:self.USI: b0bf
2026-01-29 16:13:59,986:INFO:self._variable_keys: {'X_test', 'fold_groups_param', 'pipeline', 'fix_imbalance', 'exp_name_log', 'data', 'y_test', 'seed', 'fold_shuffle_param', 'n_jobs_param', 'is_multiclass', 'gpu_n_jobs_param', 'memory', 'log_plots_param', 'logging_param', 'idx', 'y', 'target_param', 'fold_generator', 'y_train', 'gpu_param', 'USI', 'exp_id', '_available_plots', 'X', 'X_train', 'html_param', '_ml_usecase'}
2026-01-29 16:13:59,988:INFO:Checking environment
2026-01-29 16:13:59,988:INFO:python_version: 3.11.11
2026-01-29 16:13:59,988:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-29 16:13:59,988:INFO:machine: AMD64
2026-01-29 16:13:59,988:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-29 16:13:59,988:INFO:Memory: svmem(total=34009374720, available=12933509120, percent=62.0, used=21075865600, free=12933509120)
2026-01-29 16:13:59,989:INFO:Physical Core: 12
2026-01-29 16:13:59,990:INFO:Logical Core: 16
2026-01-29 16:13:59,990:INFO:Checking libraries
2026-01-29 16:13:59,990:INFO:System:
2026-01-29 16:13:59,990:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-29 16:13:59,990:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-29 16:13:59,990:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-29 16:13:59,990:INFO:PyCaret required dependencies:
2026-01-29 16:13:59,990:INFO:                 pip: 25.0
2026-01-29 16:13:59,990:INFO:          setuptools: 75.8.0
2026-01-29 16:13:59,990:INFO:             pycaret: 3.3.2
2026-01-29 16:13:59,990:INFO:             IPython: 9.9.0
2026-01-29 16:13:59,990:INFO:          ipywidgets: 8.1.8
2026-01-29 16:13:59,990:INFO:                tqdm: 4.67.1
2026-01-29 16:13:59,990:INFO:               numpy: 1.26.4
2026-01-29 16:13:59,990:INFO:              pandas: 2.1.4
2026-01-29 16:13:59,990:INFO:              jinja2: 3.1.6
2026-01-29 16:13:59,990:INFO:               scipy: 1.11.4
2026-01-29 16:13:59,990:INFO:              joblib: 1.3.2
2026-01-29 16:13:59,990:INFO:             sklearn: 1.4.2
2026-01-29 16:13:59,990:INFO:                pyod: 2.0.6
2026-01-29 16:13:59,990:INFO:            imblearn: 0.14.1
2026-01-29 16:13:59,990:INFO:   category_encoders: 2.7.0
2026-01-29 16:13:59,990:INFO:            lightgbm: 4.6.0
2026-01-29 16:13:59,990:INFO:               numba: 0.62.1
2026-01-29 16:13:59,990:INFO:            requests: 2.32.3
2026-01-29 16:13:59,990:INFO:          matplotlib: 3.7.5
2026-01-29 16:13:59,990:INFO:          scikitplot: 0.3.7
2026-01-29 16:13:59,990:INFO:         yellowbrick: 1.5
2026-01-29 16:13:59,999:INFO:              plotly: 5.24.1
2026-01-29 16:13:59,999:INFO:    plotly-resampler: Not installed
2026-01-29 16:13:59,999:INFO:             kaleido: 1.2.0
2026-01-29 16:13:59,999:INFO:           schemdraw: 0.15
2026-01-29 16:13:59,999:INFO:         statsmodels: 0.14.6
2026-01-29 16:13:59,999:INFO:              sktime: 0.26.0
2026-01-29 16:13:59,999:INFO:               tbats: 1.1.3
2026-01-29 16:13:59,999:INFO:            pmdarima: 2.0.4
2026-01-29 16:13:59,999:INFO:              psutil: 7.2.1
2026-01-29 16:13:59,999:INFO:          markupsafe: 3.0.3
2026-01-29 16:13:59,999:INFO:             pickle5: Not installed
2026-01-29 16:14:00,005:INFO:         cloudpickle: 3.0.0
2026-01-29 16:14:00,005:INFO:         deprecation: 2.1.0
2026-01-29 16:14:00,006:INFO:              xxhash: 3.6.0
2026-01-29 16:14:00,006:INFO:           wurlitzer: Not installed
2026-01-29 16:14:00,006:INFO:PyCaret optional dependencies:
2026-01-29 16:14:00,006:INFO:                shap: 0.44.1
2026-01-29 16:14:00,007:INFO:           interpret: 0.7.3
2026-01-29 16:14:00,007:INFO:                umap: 0.5.7
2026-01-29 16:14:00,007:INFO:     ydata_profiling: 4.18.1
2026-01-29 16:14:00,007:INFO:  explainerdashboard: 0.5.1
2026-01-29 16:14:00,007:INFO:             autoviz: Not installed
2026-01-29 16:14:00,007:INFO:           fairlearn: 0.7.0
2026-01-29 16:14:00,007:INFO:          deepchecks: Not installed
2026-01-29 16:14:00,007:INFO:             xgboost: Not installed
2026-01-29 16:14:00,007:INFO:            catboost: 1.2.8
2026-01-29 16:14:00,007:INFO:              kmodes: 0.12.2
2026-01-29 16:14:00,007:INFO:             mlxtend: 0.23.4
2026-01-29 16:14:00,007:INFO:       statsforecast: 1.5.0
2026-01-29 16:14:00,007:INFO:        tune_sklearn: Not installed
2026-01-29 16:14:00,007:INFO:                 ray: Not installed
2026-01-29 16:14:00,007:INFO:            hyperopt: 0.2.7
2026-01-29 16:14:00,007:INFO:              optuna: 4.6.0
2026-01-29 16:14:00,007:INFO:               skopt: 0.10.2
2026-01-29 16:14:00,007:INFO:              mlflow: 3.8.1
2026-01-29 16:14:00,007:INFO:              gradio: 6.3.0
2026-01-29 16:14:00,007:INFO:             fastapi: 0.128.0
2026-01-29 16:14:00,007:INFO:             uvicorn: 0.40.0
2026-01-29 16:14:00,007:INFO:              m2cgen: 0.10.0
2026-01-29 16:14:00,007:INFO:           evidently: 0.4.40
2026-01-29 16:14:00,007:INFO:               fugue: 0.8.7
2026-01-29 16:14:00,015:INFO:           streamlit: Not installed
2026-01-29 16:14:00,015:INFO:             prophet: Not installed
2026-01-29 16:14:00,015:INFO:None
2026-01-29 16:14:00,015:INFO:Set up data.
2026-01-29 16:14:00,090:INFO:Set up folding strategy.
2026-01-29 16:14:00,090:INFO:Set up train/test split.
2026-01-29 16:14:00,474:INFO:Set up index.
2026-01-29 16:14:00,507:INFO:Assigning column types.
2026-01-29 16:14:00,586:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-29 16:14:00,686:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:14:00,689:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:14:00,741:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:14:00,741:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:14:00,824:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:14:00,824:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:14:00,873:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:14:00,873:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:14:00,874:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-29 16:14:00,940:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:14:00,973:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:14:00,987:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:14:01,040:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:14:01,090:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:14:01,090:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:14:01,090:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-29 16:14:01,191:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:14:01,191:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:14:01,290:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:14:01,290:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:14:01,290:INFO:Preparing preprocessing pipeline...
2026-01-29 16:14:01,308:INFO:Set up simple imputation.
2026-01-29 16:14:01,308:INFO:Set up feature normalization.
2026-01-29 16:14:01,456:INFO:Finished creating preprocessing pipeline.
2026-01-29 16:14:01,473:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-29 16:14:01,473:INFO:Creating final display dataframe.
2026-01-29 16:14:01,890:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape       (429278, 4)
4        Transformed data shape       (429278, 4)
5   Transformed train set shape       (343422, 4)
6    Transformed test set shape        (85856, 4)
7               Ignore features                58
8              Numeric features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                 3
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              b0bf
2026-01-29 16:14:01,973:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:14:01,973:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:14:02,073:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:14:02,073:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:14:02,073:INFO:setup() successfully completed in 2.1s...............
2026-01-29 16:14:02,073:INFO:Initializing compare_models()
2026-01-29 16:14:02,073:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-29 16:14:02,073:INFO:Checking exceptions
2026-01-29 16:14:02,128:INFO:Preparing display monitor
2026-01-29 16:14:02,166:INFO:Initializing Logistic Regression
2026-01-29 16:14:02,167:INFO:Total runtime is 1.7237663269042968e-05 minutes
2026-01-29 16:14:02,172:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:02,173:INFO:Initializing create_model()
2026-01-29 16:14:02,174:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002481729F910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:02,174:INFO:Checking exceptions
2026-01-29 16:14:02,174:INFO:Importing libraries
2026-01-29 16:14:02,174:INFO:Copying training dataset
2026-01-29 16:14:02,330:INFO:Defining folds
2026-01-29 16:14:02,330:INFO:Declaring metric variables
2026-01-29 16:14:02,340:INFO:Importing untrained model
2026-01-29 16:14:02,340:INFO:Logistic Regression Imported successfully
2026-01-29 16:14:02,359:INFO:Starting cross validation
2026-01-29 16:14:02,361:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:03,601:INFO:Calculating mean and std
2026-01-29 16:14:03,601:INFO:Creating metrics dataframe
2026-01-29 16:14:03,607:INFO:Uploading results into container
2026-01-29 16:14:03,609:INFO:Uploading model into container now
2026-01-29 16:14:03,610:INFO:_master_model_container: 1
2026-01-29 16:14:03,611:INFO:_display_container: 2
2026-01-29 16:14:03,611:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:14:03,612:INFO:create_model() successfully completed......................................
2026-01-29 16:14:03,947:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:03,947:INFO:Creating metrics dataframe
2026-01-29 16:14:03,957:INFO:Initializing Decision Tree Classifier
2026-01-29 16:14:03,957:INFO:Total runtime is 0.029845261573791505 minutes
2026-01-29 16:14:03,957:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:03,957:INFO:Initializing create_model()
2026-01-29 16:14:03,957:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002481729F910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:03,957:INFO:Checking exceptions
2026-01-29 16:14:03,957:INFO:Importing libraries
2026-01-29 16:14:03,957:INFO:Copying training dataset
2026-01-29 16:14:04,061:INFO:Defining folds
2026-01-29 16:14:04,061:INFO:Declaring metric variables
2026-01-29 16:14:04,070:INFO:Importing untrained model
2026-01-29 16:14:04,074:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:14:04,082:INFO:Starting cross validation
2026-01-29 16:14:04,083:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:04,760:INFO:Calculating mean and std
2026-01-29 16:14:04,760:INFO:Creating metrics dataframe
2026-01-29 16:14:04,760:INFO:Uploading results into container
2026-01-29 16:14:04,760:INFO:Uploading model into container now
2026-01-29 16:14:04,765:INFO:_master_model_container: 2
2026-01-29 16:14:04,765:INFO:_display_container: 2
2026-01-29 16:14:04,766:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:14:04,766:INFO:create_model() successfully completed......................................
2026-01-29 16:14:05,022:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:05,023:INFO:Creating metrics dataframe
2026-01-29 16:14:05,023:INFO:Initializing Random Forest Classifier
2026-01-29 16:14:05,023:INFO:Total runtime is 0.047616843382517496 minutes
2026-01-29 16:14:05,023:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:05,023:INFO:Initializing create_model()
2026-01-29 16:14:05,023:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002481729F910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:05,023:INFO:Checking exceptions
2026-01-29 16:14:05,023:INFO:Importing libraries
2026-01-29 16:14:05,023:INFO:Copying training dataset
2026-01-29 16:14:05,110:INFO:Defining folds
2026-01-29 16:14:05,111:INFO:Declaring metric variables
2026-01-29 16:14:05,114:INFO:Importing untrained model
2026-01-29 16:14:05,116:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:14:05,122:INFO:Starting cross validation
2026-01-29 16:14:05,123:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:10,285:INFO:Calculating mean and std
2026-01-29 16:14:10,289:INFO:Creating metrics dataframe
2026-01-29 16:14:10,290:INFO:Uploading results into container
2026-01-29 16:14:10,290:INFO:Uploading model into container now
2026-01-29 16:14:10,294:INFO:_master_model_container: 3
2026-01-29 16:14:10,294:INFO:_display_container: 2
2026-01-29 16:14:10,296:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:14:10,296:INFO:create_model() successfully completed......................................
2026-01-29 16:14:10,540:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:10,540:INFO:Creating metrics dataframe
2026-01-29 16:14:10,559:INFO:Initializing Light Gradient Boosting Machine
2026-01-29 16:14:10,560:INFO:Total runtime is 0.1398939530054728 minutes
2026-01-29 16:14:10,560:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:10,560:INFO:Initializing create_model()
2026-01-29 16:14:10,560:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002481729F910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:10,560:INFO:Checking exceptions
2026-01-29 16:14:10,560:INFO:Importing libraries
2026-01-29 16:14:10,560:INFO:Copying training dataset
2026-01-29 16:14:10,640:INFO:Defining folds
2026-01-29 16:14:10,640:INFO:Declaring metric variables
2026-01-29 16:14:10,640:INFO:Importing untrained model
2026-01-29 16:14:10,640:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-29 16:14:10,655:INFO:Starting cross validation
2026-01-29 16:14:10,657:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:12,436:INFO:Calculating mean and std
2026-01-29 16:14:12,440:INFO:Creating metrics dataframe
2026-01-29 16:14:12,442:INFO:Uploading results into container
2026-01-29 16:14:12,443:INFO:Uploading model into container now
2026-01-29 16:14:12,444:INFO:_master_model_container: 4
2026-01-29 16:14:12,444:INFO:_display_container: 2
2026-01-29 16:14:12,444:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-29 16:14:12,444:INFO:create_model() successfully completed......................................
2026-01-29 16:14:12,673:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:12,673:INFO:Creating metrics dataframe
2026-01-29 16:14:12,691:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-29 16:14:12,697:INFO:Initializing create_model()
2026-01-29 16:14:12,697:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:12,697:INFO:Checking exceptions
2026-01-29 16:14:12,697:INFO:Importing libraries
2026-01-29 16:14:12,697:INFO:Copying training dataset
2026-01-29 16:14:12,802:INFO:Defining folds
2026-01-29 16:14:12,802:INFO:Declaring metric variables
2026-01-29 16:14:12,802:INFO:Importing untrained model
2026-01-29 16:14:12,802:INFO:Declaring custom model
2026-01-29 16:14:12,802:INFO:Logistic Regression Imported successfully
2026-01-29 16:14:12,804:INFO:Cross validation set to False
2026-01-29 16:14:12,804:INFO:Fitting Model
2026-01-29 16:14:13,075:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:14:13,076:INFO:create_model() successfully completed......................................
2026-01-29 16:14:13,308:INFO:Initializing create_model()
2026-01-29 16:14:13,308:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:13,308:INFO:Checking exceptions
2026-01-29 16:14:13,308:INFO:Importing libraries
2026-01-29 16:14:13,313:INFO:Copying training dataset
2026-01-29 16:14:13,373:INFO:Defining folds
2026-01-29 16:14:13,373:INFO:Declaring metric variables
2026-01-29 16:14:13,373:INFO:Importing untrained model
2026-01-29 16:14:13,373:INFO:Declaring custom model
2026-01-29 16:14:13,373:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:14:13,373:INFO:Cross validation set to False
2026-01-29 16:14:13,373:INFO:Fitting Model
2026-01-29 16:14:13,455:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:14:13,455:INFO:create_model() successfully completed......................................
2026-01-29 16:14:13,687:INFO:Initializing create_model()
2026-01-29 16:14:13,687:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:13,687:INFO:Checking exceptions
2026-01-29 16:14:13,691:INFO:Importing libraries
2026-01-29 16:14:13,692:INFO:Copying training dataset
2026-01-29 16:14:13,755:INFO:Defining folds
2026-01-29 16:14:13,755:INFO:Declaring metric variables
2026-01-29 16:14:13,756:INFO:Importing untrained model
2026-01-29 16:14:13,756:INFO:Declaring custom model
2026-01-29 16:14:13,756:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:14:13,756:INFO:Cross validation set to False
2026-01-29 16:14:13,756:INFO:Fitting Model
2026-01-29 16:14:15,632:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:14:15,632:INFO:create_model() successfully completed......................................
2026-01-29 16:14:16,010:INFO:_master_model_container: 4
2026-01-29 16:14:16,010:INFO:_display_container: 2
2026-01-29 16:14:16,010:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2026-01-29 16:14:16,010:INFO:compare_models() successfully completed......................................
2026-01-29 16:14:16,010:INFO:Initializing tune_model()
2026-01-29 16:14:16,010:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:14:16,010:INFO:Checking exceptions
2026-01-29 16:14:16,062:INFO:Copying training dataset
2026-01-29 16:14:16,144:INFO:Checking base model
2026-01-29 16:14:16,145:INFO:Base model : Logistic Regression
2026-01-29 16:14:16,149:INFO:Declaring metric variables
2026-01-29 16:14:16,152:INFO:Defining Hyperparameters
2026-01-29 16:14:16,404:INFO:Tuning with n_jobs=-1
2026-01-29 16:14:16,404:INFO:Initializing RandomizedSearchCV
2026-01-29 16:14:19,085:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 5.682}
2026-01-29 16:14:19,085:INFO:Hyperparameter search completed
2026-01-29 16:14:19,085:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:19,088:INFO:Initializing create_model()
2026-01-29 16:14:19,088:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002481711D210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 5.682})
2026-01-29 16:14:19,088:INFO:Checking exceptions
2026-01-29 16:14:19,088:INFO:Importing libraries
2026-01-29 16:14:19,088:INFO:Copying training dataset
2026-01-29 16:14:19,189:INFO:Defining folds
2026-01-29 16:14:19,189:INFO:Declaring metric variables
2026-01-29 16:14:19,193:INFO:Importing untrained model
2026-01-29 16:14:19,193:INFO:Declaring custom model
2026-01-29 16:14:19,193:INFO:Logistic Regression Imported successfully
2026-01-29 16:14:19,205:INFO:Starting cross validation
2026-01-29 16:14:19,206:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:20,078:INFO:Calculating mean and std
2026-01-29 16:14:20,078:INFO:Creating metrics dataframe
2026-01-29 16:14:20,078:INFO:Finalizing model
2026-01-29 16:14:20,403:INFO:Uploading results into container
2026-01-29 16:14:20,414:INFO:Uploading model into container now
2026-01-29 16:14:20,414:INFO:_master_model_container: 5
2026-01-29 16:14:20,414:INFO:_display_container: 3
2026-01-29 16:14:20,414:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:14:20,414:INFO:create_model() successfully completed......................................
2026-01-29 16:14:20,655:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:20,655:INFO:choose_better activated
2026-01-29 16:14:20,655:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:20,655:INFO:Initializing create_model()
2026-01-29 16:14:20,655:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:20,655:INFO:Checking exceptions
2026-01-29 16:14:20,655:INFO:Importing libraries
2026-01-29 16:14:20,655:INFO:Copying training dataset
2026-01-29 16:14:20,725:INFO:Defining folds
2026-01-29 16:14:20,725:INFO:Declaring metric variables
2026-01-29 16:14:20,725:INFO:Importing untrained model
2026-01-29 16:14:20,725:INFO:Declaring custom model
2026-01-29 16:14:20,725:INFO:Logistic Regression Imported successfully
2026-01-29 16:14:20,725:INFO:Starting cross validation
2026-01-29 16:14:20,725:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:21,370:INFO:Calculating mean and std
2026-01-29 16:14:21,370:INFO:Creating metrics dataframe
2026-01-29 16:14:21,374:INFO:Finalizing model
2026-01-29 16:14:21,576:INFO:Uploading results into container
2026-01-29 16:14:21,576:INFO:Uploading model into container now
2026-01-29 16:14:21,576:INFO:_master_model_container: 6
2026-01-29 16:14:21,576:INFO:_display_container: 4
2026-01-29 16:14:21,576:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:14:21,576:INFO:create_model() successfully completed......................................
2026-01-29 16:14:21,774:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:21,774:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 16:14:21,774:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 16:14:21,774:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2026-01-29 16:14:21,774:INFO:choose_better completed
2026-01-29 16:14:21,774:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:14:21,792:INFO:_master_model_container: 6
2026-01-29 16:14:21,792:INFO:_display_container: 3
2026-01-29 16:14:21,792:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:14:21,792:INFO:tune_model() successfully completed......................................
2026-01-29 16:14:21,993:INFO:Initializing tune_model()
2026-01-29 16:14:21,993:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:14:21,993:INFO:Checking exceptions
2026-01-29 16:14:22,032:INFO:Copying training dataset
2026-01-29 16:14:22,078:INFO:Checking base model
2026-01-29 16:14:22,078:INFO:Base model : Decision Tree Classifier
2026-01-29 16:14:22,081:INFO:Declaring metric variables
2026-01-29 16:14:22,083:INFO:Defining Hyperparameters
2026-01-29 16:14:22,292:INFO:Tuning with n_jobs=-1
2026-01-29 16:14:22,292:INFO:Initializing RandomizedSearchCV
2026-01-29 16:14:23,116:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.0005, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 3, 'actual_estimator__criterion': 'gini'}
2026-01-29 16:14:23,116:INFO:Hyperparameter search completed
2026-01-29 16:14:23,116:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:23,116:INFO:Initializing create_model()
2026-01-29 16:14:23,116:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024870AE0C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0005, 'max_features': 1.0, 'max_depth': 3, 'criterion': 'gini'})
2026-01-29 16:14:23,116:INFO:Checking exceptions
2026-01-29 16:14:23,116:INFO:Importing libraries
2026-01-29 16:14:23,116:INFO:Copying training dataset
2026-01-29 16:14:23,173:INFO:Defining folds
2026-01-29 16:14:23,173:INFO:Declaring metric variables
2026-01-29 16:14:23,173:INFO:Importing untrained model
2026-01-29 16:14:23,173:INFO:Declaring custom model
2026-01-29 16:14:23,173:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:14:23,173:INFO:Starting cross validation
2026-01-29 16:14:23,173:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:23,652:INFO:Calculating mean and std
2026-01-29 16:14:23,652:INFO:Creating metrics dataframe
2026-01-29 16:14:23,659:INFO:Finalizing model
2026-01-29 16:14:23,722:INFO:Uploading results into container
2026-01-29 16:14:23,723:INFO:Uploading model into container now
2026-01-29 16:14:23,724:INFO:_master_model_container: 7
2026-01-29 16:14:23,724:INFO:_display_container: 4
2026-01-29 16:14:23,725:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:14:23,725:INFO:create_model() successfully completed......................................
2026-01-29 16:14:23,925:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:23,925:INFO:choose_better activated
2026-01-29 16:14:23,925:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:23,925:INFO:Initializing create_model()
2026-01-29 16:14:23,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:23,925:INFO:Checking exceptions
2026-01-29 16:14:23,925:INFO:Importing libraries
2026-01-29 16:14:23,925:INFO:Copying training dataset
2026-01-29 16:14:23,989:INFO:Defining folds
2026-01-29 16:14:23,989:INFO:Declaring metric variables
2026-01-29 16:14:23,989:INFO:Importing untrained model
2026-01-29 16:14:23,989:INFO:Declaring custom model
2026-01-29 16:14:23,989:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:14:23,989:INFO:Starting cross validation
2026-01-29 16:14:23,989:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:24,460:INFO:Calculating mean and std
2026-01-29 16:14:24,460:INFO:Creating metrics dataframe
2026-01-29 16:14:24,460:INFO:Finalizing model
2026-01-29 16:14:24,522:INFO:Uploading results into container
2026-01-29 16:14:24,525:INFO:Uploading model into container now
2026-01-29 16:14:24,525:INFO:_master_model_container: 8
2026-01-29 16:14:24,525:INFO:_display_container: 5
2026-01-29 16:14:24,525:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:14:24,525:INFO:create_model() successfully completed......................................
2026-01-29 16:14:24,738:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:24,738:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5369
2026-01-29 16:14:24,738:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5366
2026-01-29 16:14:24,738:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-29 16:14:24,738:INFO:choose_better completed
2026-01-29 16:14:24,738:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:14:24,738:INFO:_master_model_container: 8
2026-01-29 16:14:24,738:INFO:_display_container: 4
2026-01-29 16:14:24,738:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:14:24,738:INFO:tune_model() successfully completed......................................
2026-01-29 16:14:24,953:INFO:Initializing tune_model()
2026-01-29 16:14:24,953:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:14:24,953:INFO:Checking exceptions
2026-01-29 16:14:24,975:INFO:Copying training dataset
2026-01-29 16:14:25,028:INFO:Checking base model
2026-01-29 16:14:25,028:INFO:Base model : Random Forest Classifier
2026-01-29 16:14:25,030:INFO:Declaring metric variables
2026-01-29 16:14:25,032:INFO:Defining Hyperparameters
2026-01-29 16:14:25,240:INFO:Tuning with n_jobs=-1
2026-01-29 16:14:25,240:INFO:Initializing RandomizedSearchCV
2026-01-29 16:14:47,898:INFO:best_params: {'actual_estimator__n_estimators': 120, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-29 16:14:47,900:INFO:Hyperparameter search completed
2026-01-29 16:14:47,900:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:47,900:INFO:Initializing create_model()
2026-01-29 16:14:47,902:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002481B5D2C90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 120, 'min_samples_split': 5, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': True})
2026-01-29 16:14:47,902:INFO:Checking exceptions
2026-01-29 16:14:47,902:INFO:Importing libraries
2026-01-29 16:14:47,902:INFO:Copying training dataset
2026-01-29 16:14:47,975:INFO:Defining folds
2026-01-29 16:14:47,975:INFO:Declaring metric variables
2026-01-29 16:14:47,977:INFO:Importing untrained model
2026-01-29 16:14:47,977:INFO:Declaring custom model
2026-01-29 16:14:47,981:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:14:47,984:INFO:Starting cross validation
2026-01-29 16:14:47,987:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:50,600:INFO:Calculating mean and std
2026-01-29 16:14:50,600:INFO:Creating metrics dataframe
2026-01-29 16:14:50,606:INFO:Finalizing model
2026-01-29 16:14:52,198:INFO:Uploading results into container
2026-01-29 16:14:52,198:INFO:Uploading model into container now
2026-01-29 16:14:52,198:INFO:_master_model_container: 9
2026-01-29 16:14:52,198:INFO:_display_container: 5
2026-01-29 16:14:52,198:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=120, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:14:52,198:INFO:create_model() successfully completed......................................
2026-01-29 16:14:52,421:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:52,421:INFO:choose_better activated
2026-01-29 16:14:52,421:INFO:SubProcess create_model() called ==================================
2026-01-29 16:14:52,421:INFO:Initializing create_model()
2026-01-29 16:14:52,421:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:14:52,421:INFO:Checking exceptions
2026-01-29 16:14:52,421:INFO:Importing libraries
2026-01-29 16:14:52,421:INFO:Copying training dataset
2026-01-29 16:14:52,489:INFO:Defining folds
2026-01-29 16:14:52,489:INFO:Declaring metric variables
2026-01-29 16:14:52,489:INFO:Importing untrained model
2026-01-29 16:14:52,489:INFO:Declaring custom model
2026-01-29 16:14:52,489:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:14:52,489:INFO:Starting cross validation
2026-01-29 16:14:52,489:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:14:54,667:INFO:Calculating mean and std
2026-01-29 16:14:54,667:INFO:Creating metrics dataframe
2026-01-29 16:14:54,672:INFO:Finalizing model
2026-01-29 16:14:56,041:INFO:Uploading results into container
2026-01-29 16:14:56,043:INFO:Uploading model into container now
2026-01-29 16:14:56,043:INFO:_master_model_container: 10
2026-01-29 16:14:56,043:INFO:_display_container: 6
2026-01-29 16:14:56,043:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:14:56,043:INFO:create_model() successfully completed......................................
2026-01-29 16:14:56,258:INFO:SubProcess create_model() end ==================================
2026-01-29 16:14:56,269:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.5369
2026-01-29 16:14:56,269:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=120, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.5369
2026-01-29 16:14:56,269:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-29 16:14:56,269:INFO:choose_better completed
2026-01-29 16:14:56,269:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:14:56,273:INFO:_master_model_container: 10
2026-01-29 16:14:56,273:INFO:_display_container: 5
2026-01-29 16:14:56,273:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:14:56,273:INFO:tune_model() successfully completed......................................
2026-01-29 16:14:56,489:INFO:Initializing evaluate_model()
2026-01-29 16:14:56,489:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:14:56,528:INFO:Initializing plot_model()
2026-01-29 16:14:56,528:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:14:56,528:INFO:Checking exceptions
2026-01-29 16:14:56,556:INFO:Preloading libraries
2026-01-29 16:14:56,556:INFO:Copying training dataset
2026-01-29 16:14:56,556:INFO:Plot type: pipeline
2026-01-29 16:14:56,622:INFO:Visual Rendered Successfully
2026-01-29 16:14:56,822:INFO:plot_model() successfully completed......................................
2026-01-29 16:14:56,838:INFO:Initializing evaluate_model()
2026-01-29 16:14:56,838:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:14:56,889:INFO:Initializing plot_model()
2026-01-29 16:14:56,890:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:14:56,890:INFO:Checking exceptions
2026-01-29 16:14:56,929:INFO:Preloading libraries
2026-01-29 16:14:56,930:INFO:Copying training dataset
2026-01-29 16:14:56,930:INFO:Plot type: pipeline
2026-01-29 16:14:56,989:INFO:Visual Rendered Successfully
2026-01-29 16:14:57,205:INFO:plot_model() successfully completed......................................
2026-01-29 16:14:57,205:INFO:Initializing evaluate_model()
2026-01-29 16:14:57,205:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:14:57,241:INFO:Initializing plot_model()
2026-01-29 16:14:57,241:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:14:57,241:INFO:Checking exceptions
2026-01-29 16:14:57,292:INFO:Preloading libraries
2026-01-29 16:14:57,292:INFO:Copying training dataset
2026-01-29 16:14:57,292:INFO:Plot type: pipeline
2026-01-29 16:14:57,355:INFO:Visual Rendered Successfully
2026-01-29 16:14:57,574:INFO:plot_model() successfully completed......................................
2026-01-29 16:14:57,583:INFO:Initializing predict_model()
2026-01-29 16:14:57,583:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024810D7FE20>)
2026-01-29 16:14:57,583:INFO:Checking exceptions
2026-01-29 16:14:57,583:INFO:Preloading libraries
2026-01-29 16:14:57,585:INFO:Set up data.
2026-01-29 16:14:57,594:INFO:Set up index.
2026-01-29 16:14:58,122:INFO:Initializing predict_model()
2026-01-29 16:14:58,122:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002487E4E7BA0>)
2026-01-29 16:14:58,122:INFO:Checking exceptions
2026-01-29 16:14:58,122:INFO:Preloading libraries
2026-01-29 16:14:58,122:INFO:Set up data.
2026-01-29 16:14:58,122:INFO:Set up index.
2026-01-29 16:14:58,674:INFO:Initializing predict_model()
2026-01-29 16:14:58,674:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002487E426200>)
2026-01-29 16:14:58,674:INFO:Checking exceptions
2026-01-29 16:14:58,674:INFO:Preloading libraries
2026-01-29 16:14:58,674:INFO:Set up data.
2026-01-29 16:14:58,674:INFO:Set up index.
2026-01-29 16:14:59,338:INFO:Initializing plot_model()
2026-01-29 16:14:59,338:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D82D50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-29 16:14:59,340:INFO:Checking exceptions
2026-01-29 16:14:59,355:INFO:Preloading libraries
2026-01-29 16:14:59,355:INFO:Copying training dataset
2026-01-29 16:14:59,355:INFO:Plot type: feature
2026-01-29 16:14:59,608:INFO:Visual Rendered Successfully
2026-01-29 16:14:59,828:INFO:plot_model() successfully completed......................................
2026-01-29 16:14:59,828:INFO:Initializing save_model()
2026-01-29 16:14:59,828:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=..\datos\04. Modelos, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-29 16:14:59,828:INFO:Adding model into prep_pipe
2026-01-29 16:14:59,838:INFO:..\datos\04. Modelos.pkl saved in current working directory
2026-01-29 16:14:59,838:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(e...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=42,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2026-01-29 16:14:59,838:INFO:save_model() successfully completed......................................
2026-01-29 16:16:46,887:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\2531746454.py:18: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-29 16:16:48,804:INFO:PyCaret ClassificationExperiment
2026-01-29 16:16:48,804:INFO:Logging name: clf-default-name
2026-01-29 16:16:48,804:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-29 16:16:48,804:INFO:version 3.3.2
2026-01-29 16:16:48,804:INFO:Initializing setup()
2026-01-29 16:16:48,804:INFO:self.USI: 8fc6
2026-01-29 16:16:48,807:INFO:self._variable_keys: {'X_test', 'fold_groups_param', 'pipeline', 'fix_imbalance', 'exp_name_log', 'data', 'y_test', 'seed', 'fold_shuffle_param', 'n_jobs_param', 'is_multiclass', 'gpu_n_jobs_param', 'memory', 'log_plots_param', 'logging_param', 'idx', 'y', 'target_param', 'fold_generator', 'y_train', 'gpu_param', 'USI', 'exp_id', '_available_plots', 'X', 'X_train', 'html_param', '_ml_usecase'}
2026-01-29 16:16:48,807:INFO:Checking environment
2026-01-29 16:16:48,807:INFO:python_version: 3.11.11
2026-01-29 16:16:48,807:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-29 16:16:48,807:INFO:machine: AMD64
2026-01-29 16:16:48,807:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-29 16:16:48,807:INFO:Memory: svmem(total=34009374720, available=13133869056, percent=61.4, used=20875505664, free=13133869056)
2026-01-29 16:16:48,807:INFO:Physical Core: 12
2026-01-29 16:16:48,807:INFO:Logical Core: 16
2026-01-29 16:16:48,807:INFO:Checking libraries
2026-01-29 16:16:48,807:INFO:System:
2026-01-29 16:16:48,807:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-29 16:16:48,807:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-29 16:16:48,807:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-29 16:16:48,807:INFO:PyCaret required dependencies:
2026-01-29 16:16:48,807:INFO:                 pip: 25.0
2026-01-29 16:16:48,807:INFO:          setuptools: 75.8.0
2026-01-29 16:16:48,807:INFO:             pycaret: 3.3.2
2026-01-29 16:16:48,807:INFO:             IPython: 9.9.0
2026-01-29 16:16:48,807:INFO:          ipywidgets: 8.1.8
2026-01-29 16:16:48,807:INFO:                tqdm: 4.67.1
2026-01-29 16:16:48,807:INFO:               numpy: 1.26.4
2026-01-29 16:16:48,807:INFO:              pandas: 2.1.4
2026-01-29 16:16:48,807:INFO:              jinja2: 3.1.6
2026-01-29 16:16:48,807:INFO:               scipy: 1.11.4
2026-01-29 16:16:48,807:INFO:              joblib: 1.3.2
2026-01-29 16:16:48,807:INFO:             sklearn: 1.4.2
2026-01-29 16:16:48,807:INFO:                pyod: 2.0.6
2026-01-29 16:16:48,807:INFO:            imblearn: 0.14.1
2026-01-29 16:16:48,807:INFO:   category_encoders: 2.7.0
2026-01-29 16:16:48,807:INFO:            lightgbm: 4.6.0
2026-01-29 16:16:48,807:INFO:               numba: 0.62.1
2026-01-29 16:16:48,807:INFO:            requests: 2.32.3
2026-01-29 16:16:48,807:INFO:          matplotlib: 3.7.5
2026-01-29 16:16:48,807:INFO:          scikitplot: 0.3.7
2026-01-29 16:16:48,807:INFO:         yellowbrick: 1.5
2026-01-29 16:16:48,807:INFO:              plotly: 5.24.1
2026-01-29 16:16:48,807:INFO:    plotly-resampler: Not installed
2026-01-29 16:16:48,807:INFO:             kaleido: 1.2.0
2026-01-29 16:16:48,807:INFO:           schemdraw: 0.15
2026-01-29 16:16:48,807:INFO:         statsmodels: 0.14.6
2026-01-29 16:16:48,807:INFO:              sktime: 0.26.0
2026-01-29 16:16:48,807:INFO:               tbats: 1.1.3
2026-01-29 16:16:48,807:INFO:            pmdarima: 2.0.4
2026-01-29 16:16:48,807:INFO:              psutil: 7.2.1
2026-01-29 16:16:48,807:INFO:          markupsafe: 3.0.3
2026-01-29 16:16:48,807:INFO:             pickle5: Not installed
2026-01-29 16:16:48,807:INFO:         cloudpickle: 3.0.0
2026-01-29 16:16:48,807:INFO:         deprecation: 2.1.0
2026-01-29 16:16:48,807:INFO:              xxhash: 3.6.0
2026-01-29 16:16:48,807:INFO:           wurlitzer: Not installed
2026-01-29 16:16:48,807:INFO:PyCaret optional dependencies:
2026-01-29 16:16:48,807:INFO:                shap: 0.44.1
2026-01-29 16:16:48,807:INFO:           interpret: 0.7.3
2026-01-29 16:16:48,807:INFO:                umap: 0.5.7
2026-01-29 16:16:48,807:INFO:     ydata_profiling: 4.18.1
2026-01-29 16:16:48,807:INFO:  explainerdashboard: 0.5.1
2026-01-29 16:16:48,807:INFO:             autoviz: Not installed
2026-01-29 16:16:48,807:INFO:           fairlearn: 0.7.0
2026-01-29 16:16:48,807:INFO:          deepchecks: Not installed
2026-01-29 16:16:48,807:INFO:             xgboost: Not installed
2026-01-29 16:16:48,807:INFO:            catboost: 1.2.8
2026-01-29 16:16:48,807:INFO:              kmodes: 0.12.2
2026-01-29 16:16:48,807:INFO:             mlxtend: 0.23.4
2026-01-29 16:16:48,807:INFO:       statsforecast: 1.5.0
2026-01-29 16:16:48,807:INFO:        tune_sklearn: Not installed
2026-01-29 16:16:48,820:INFO:                 ray: Not installed
2026-01-29 16:16:48,820:INFO:            hyperopt: 0.2.7
2026-01-29 16:16:48,820:INFO:              optuna: 4.6.0
2026-01-29 16:16:48,820:INFO:               skopt: 0.10.2
2026-01-29 16:16:48,820:INFO:              mlflow: 3.8.1
2026-01-29 16:16:48,820:INFO:              gradio: 6.3.0
2026-01-29 16:16:48,820:INFO:             fastapi: 0.128.0
2026-01-29 16:16:48,820:INFO:             uvicorn: 0.40.0
2026-01-29 16:16:48,820:INFO:              m2cgen: 0.10.0
2026-01-29 16:16:48,820:INFO:           evidently: 0.4.40
2026-01-29 16:16:48,820:INFO:               fugue: 0.8.7
2026-01-29 16:16:48,820:INFO:           streamlit: Not installed
2026-01-29 16:16:48,820:INFO:             prophet: Not installed
2026-01-29 16:16:48,820:INFO:None
2026-01-29 16:16:48,820:INFO:Set up data.
2026-01-29 16:16:48,841:INFO:Set up folding strategy.
2026-01-29 16:16:48,841:INFO:Set up train/test split.
2026-01-29 16:16:48,939:INFO:Set up index.
2026-01-29 16:16:48,939:INFO:Assigning column types.
2026-01-29 16:16:48,970:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-29 16:16:48,986:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:16:48,986:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:16:49,017:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:16:49,017:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:16:49,040:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:16:49,040:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:16:49,070:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:16:49,070:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:16:49,070:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-29 16:16:49,117:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:16:49,135:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:16:49,135:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:16:49,172:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:16:49,188:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:16:49,188:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:16:49,188:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-29 16:16:49,240:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:16:49,240:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:16:49,286:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:16:49,286:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:16:49,286:INFO:Preparing preprocessing pipeline...
2026-01-29 16:16:49,286:INFO:Set up simple imputation.
2026-01-29 16:16:49,302:INFO:Set up feature normalization.
2026-01-29 16:16:49,388:INFO:Finished creating preprocessing pipeline.
2026-01-29 16:16:49,390:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-29 16:16:49,390:INFO:Creating final display dataframe.
2026-01-29 16:16:49,588:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape       (429278, 4)
4        Transformed data shape       (429278, 4)
5   Transformed train set shape       (343422, 4)
6    Transformed test set shape        (85856, 4)
7               Ignore features                58
8              Numeric features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                 3
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              8fc6
2026-01-29 16:16:49,636:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:16:49,636:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:16:49,673:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:16:49,673:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:16:49,673:INFO:setup() successfully completed in 0.88s...............
2026-01-29 16:16:49,673:INFO:Initializing compare_models()
2026-01-29 16:16:49,673:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-29 16:16:49,673:INFO:Checking exceptions
2026-01-29 16:16:49,710:INFO:Preparing display monitor
2026-01-29 16:16:49,738:INFO:Initializing Logistic Regression
2026-01-29 16:16:49,738:INFO:Total runtime is 0.0 minutes
2026-01-29 16:16:49,742:INFO:SubProcess create_model() called ==================================
2026-01-29 16:16:49,742:INFO:Initializing create_model()
2026-01-29 16:16:49,742:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816CE95D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:16:49,742:INFO:Checking exceptions
2026-01-29 16:16:49,744:INFO:Importing libraries
2026-01-29 16:16:49,744:INFO:Copying training dataset
2026-01-29 16:16:49,817:INFO:Defining folds
2026-01-29 16:16:49,817:INFO:Declaring metric variables
2026-01-29 16:16:49,820:INFO:Importing untrained model
2026-01-29 16:16:49,825:INFO:Logistic Regression Imported successfully
2026-01-29 16:16:49,825:INFO:Starting cross validation
2026-01-29 16:16:49,825:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:16:50,495:INFO:Calculating mean and std
2026-01-29 16:16:50,495:INFO:Creating metrics dataframe
2026-01-29 16:16:50,495:INFO:Uploading results into container
2026-01-29 16:16:50,495:INFO:Uploading model into container now
2026-01-29 16:16:50,495:INFO:_master_model_container: 1
2026-01-29 16:16:50,495:INFO:_display_container: 2
2026-01-29 16:16:50,495:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:16:50,495:INFO:create_model() successfully completed......................................
2026-01-29 16:16:50,712:INFO:SubProcess create_model() end ==================================
2026-01-29 16:16:50,712:INFO:Creating metrics dataframe
2026-01-29 16:16:50,723:INFO:Initializing Decision Tree Classifier
2026-01-29 16:16:50,723:INFO:Total runtime is 0.016418596108754475 minutes
2026-01-29 16:16:50,723:INFO:SubProcess create_model() called ==================================
2026-01-29 16:16:50,723:INFO:Initializing create_model()
2026-01-29 16:16:50,723:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816CE95D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:16:50,723:INFO:Checking exceptions
2026-01-29 16:16:50,723:INFO:Importing libraries
2026-01-29 16:16:50,723:INFO:Copying training dataset
2026-01-29 16:16:50,787:INFO:Defining folds
2026-01-29 16:16:50,788:INFO:Declaring metric variables
2026-01-29 16:16:50,791:INFO:Importing untrained model
2026-01-29 16:16:50,791:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:16:50,791:INFO:Starting cross validation
2026-01-29 16:16:50,791:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:16:51,325:INFO:Calculating mean and std
2026-01-29 16:16:51,326:INFO:Creating metrics dataframe
2026-01-29 16:16:51,327:INFO:Uploading results into container
2026-01-29 16:16:51,328:INFO:Uploading model into container now
2026-01-29 16:16:51,328:INFO:_master_model_container: 2
2026-01-29 16:16:51,328:INFO:_display_container: 2
2026-01-29 16:16:51,329:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:16:51,329:INFO:create_model() successfully completed......................................
2026-01-29 16:16:51,550:INFO:SubProcess create_model() end ==================================
2026-01-29 16:16:51,550:INFO:Creating metrics dataframe
2026-01-29 16:16:51,556:INFO:Initializing Random Forest Classifier
2026-01-29 16:16:51,556:INFO:Total runtime is 0.030309824148813884 minutes
2026-01-29 16:16:51,558:INFO:SubProcess create_model() called ==================================
2026-01-29 16:16:51,558:INFO:Initializing create_model()
2026-01-29 16:16:51,558:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816CE95D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:16:51,558:INFO:Checking exceptions
2026-01-29 16:16:51,558:INFO:Importing libraries
2026-01-29 16:16:51,558:INFO:Copying training dataset
2026-01-29 16:16:51,631:INFO:Defining folds
2026-01-29 16:16:51,631:INFO:Declaring metric variables
2026-01-29 16:16:51,635:INFO:Importing untrained model
2026-01-29 16:16:51,638:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:16:51,643:INFO:Starting cross validation
2026-01-29 16:16:51,643:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:16:54,095:INFO:Calculating mean and std
2026-01-29 16:16:54,095:INFO:Creating metrics dataframe
2026-01-29 16:16:54,102:INFO:Uploading results into container
2026-01-29 16:16:54,102:INFO:Uploading model into container now
2026-01-29 16:16:54,103:INFO:_master_model_container: 3
2026-01-29 16:16:54,103:INFO:_display_container: 2
2026-01-29 16:16:54,104:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:16:54,105:INFO:create_model() successfully completed......................................
2026-01-29 16:16:54,317:INFO:SubProcess create_model() end ==================================
2026-01-29 16:16:54,317:INFO:Creating metrics dataframe
2026-01-29 16:16:54,321:INFO:Initializing Light Gradient Boosting Machine
2026-01-29 16:16:54,321:INFO:Total runtime is 0.07638957500457763 minutes
2026-01-29 16:16:54,321:INFO:SubProcess create_model() called ==================================
2026-01-29 16:16:54,321:INFO:Initializing create_model()
2026-01-29 16:16:54,321:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816CE95D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:16:54,321:INFO:Checking exceptions
2026-01-29 16:16:54,321:INFO:Importing libraries
2026-01-29 16:16:54,321:INFO:Copying training dataset
2026-01-29 16:16:54,390:INFO:Defining folds
2026-01-29 16:16:54,390:INFO:Declaring metric variables
2026-01-29 16:16:54,407:INFO:Importing untrained model
2026-01-29 16:16:54,407:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-29 16:16:54,407:INFO:Starting cross validation
2026-01-29 16:16:54,407:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:16:55,803:INFO:Calculating mean and std
2026-01-29 16:16:55,807:INFO:Creating metrics dataframe
2026-01-29 16:16:55,812:INFO:Uploading results into container
2026-01-29 16:16:55,813:INFO:Uploading model into container now
2026-01-29 16:16:55,813:INFO:_master_model_container: 4
2026-01-29 16:16:55,813:INFO:_display_container: 2
2026-01-29 16:16:55,813:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-29 16:16:55,813:INFO:create_model() successfully completed......................................
2026-01-29 16:16:56,004:INFO:SubProcess create_model() end ==================================
2026-01-29 16:16:56,004:INFO:Creating metrics dataframe
2026-01-29 16:16:56,020:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-29 16:16:56,025:INFO:Initializing create_model()
2026-01-29 16:16:56,025:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:16:56,025:INFO:Checking exceptions
2026-01-29 16:16:56,025:INFO:Importing libraries
2026-01-29 16:16:56,025:INFO:Copying training dataset
2026-01-29 16:16:56,071:INFO:Defining folds
2026-01-29 16:16:56,071:INFO:Declaring metric variables
2026-01-29 16:16:56,071:INFO:Importing untrained model
2026-01-29 16:16:56,071:INFO:Declaring custom model
2026-01-29 16:16:56,071:INFO:Logistic Regression Imported successfully
2026-01-29 16:16:56,071:INFO:Cross validation set to False
2026-01-29 16:16:56,071:INFO:Fitting Model
2026-01-29 16:16:56,290:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:16:56,290:INFO:create_model() successfully completed......................................
2026-01-29 16:16:56,505:INFO:Initializing create_model()
2026-01-29 16:16:56,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:16:56,505:INFO:Checking exceptions
2026-01-29 16:16:56,511:INFO:Importing libraries
2026-01-29 16:16:56,512:INFO:Copying training dataset
2026-01-29 16:16:56,568:INFO:Defining folds
2026-01-29 16:16:56,568:INFO:Declaring metric variables
2026-01-29 16:16:56,568:INFO:Importing untrained model
2026-01-29 16:16:56,568:INFO:Declaring custom model
2026-01-29 16:16:56,568:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:16:56,569:INFO:Cross validation set to False
2026-01-29 16:16:56,569:INFO:Fitting Model
2026-01-29 16:16:56,621:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:16:56,621:INFO:create_model() successfully completed......................................
2026-01-29 16:16:56,841:INFO:Initializing create_model()
2026-01-29 16:16:56,841:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:16:56,841:INFO:Checking exceptions
2026-01-29 16:16:56,845:INFO:Importing libraries
2026-01-29 16:16:56,845:INFO:Copying training dataset
2026-01-29 16:16:56,920:INFO:Defining folds
2026-01-29 16:16:56,920:INFO:Declaring metric variables
2026-01-29 16:16:56,920:INFO:Importing untrained model
2026-01-29 16:16:56,920:INFO:Declaring custom model
2026-01-29 16:16:56,920:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:16:56,920:INFO:Cross validation set to False
2026-01-29 16:16:56,920:INFO:Fitting Model
2026-01-29 16:16:58,137:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:16:58,137:INFO:create_model() successfully completed......................................
2026-01-29 16:16:58,359:INFO:_master_model_container: 4
2026-01-29 16:16:58,359:INFO:_display_container: 2
2026-01-29 16:16:58,359:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2026-01-29 16:16:58,359:INFO:compare_models() successfully completed......................................
2026-01-29 16:16:58,371:INFO:Initializing tune_model()
2026-01-29 16:16:58,371:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:16:58,371:INFO:Checking exceptions
2026-01-29 16:16:58,409:INFO:Copying training dataset
2026-01-29 16:16:58,490:INFO:Checking base model
2026-01-29 16:16:58,491:INFO:Base model : Logistic Regression
2026-01-29 16:16:58,493:INFO:Declaring metric variables
2026-01-29 16:16:58,495:INFO:Defining Hyperparameters
2026-01-29 16:16:58,687:INFO:Tuning with n_jobs=-1
2026-01-29 16:16:58,687:INFO:Initializing RandomizedSearchCV
2026-01-29 16:17:00,322:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 5.682}
2026-01-29 16:17:00,322:INFO:Hyperparameter search completed
2026-01-29 16:17:00,322:INFO:SubProcess create_model() called ==================================
2026-01-29 16:17:00,322:INFO:Initializing create_model()
2026-01-29 16:17:00,322:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024871B10E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 5.682})
2026-01-29 16:17:00,322:INFO:Checking exceptions
2026-01-29 16:17:00,322:INFO:Importing libraries
2026-01-29 16:17:00,322:INFO:Copying training dataset
2026-01-29 16:17:00,387:INFO:Defining folds
2026-01-29 16:17:00,387:INFO:Declaring metric variables
2026-01-29 16:17:00,387:INFO:Importing untrained model
2026-01-29 16:17:00,387:INFO:Declaring custom model
2026-01-29 16:17:00,402:INFO:Logistic Regression Imported successfully
2026-01-29 16:17:00,407:INFO:Starting cross validation
2026-01-29 16:17:00,407:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:17:01,161:INFO:Calculating mean and std
2026-01-29 16:17:01,161:INFO:Creating metrics dataframe
2026-01-29 16:17:01,170:INFO:Finalizing model
2026-01-29 16:17:01,448:INFO:Uploading results into container
2026-01-29 16:17:01,448:INFO:Uploading model into container now
2026-01-29 16:17:01,448:INFO:_master_model_container: 5
2026-01-29 16:17:01,448:INFO:_display_container: 3
2026-01-29 16:17:01,448:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:17:01,448:INFO:create_model() successfully completed......................................
2026-01-29 16:17:01,654:INFO:SubProcess create_model() end ==================================
2026-01-29 16:17:01,654:INFO:choose_better activated
2026-01-29 16:17:01,654:INFO:SubProcess create_model() called ==================================
2026-01-29 16:17:01,654:INFO:Initializing create_model()
2026-01-29 16:17:01,654:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:17:01,654:INFO:Checking exceptions
2026-01-29 16:17:01,654:INFO:Importing libraries
2026-01-29 16:17:01,654:INFO:Copying training dataset
2026-01-29 16:17:01,721:INFO:Defining folds
2026-01-29 16:17:01,721:INFO:Declaring metric variables
2026-01-29 16:17:01,721:INFO:Importing untrained model
2026-01-29 16:17:01,721:INFO:Declaring custom model
2026-01-29 16:17:01,721:INFO:Logistic Regression Imported successfully
2026-01-29 16:17:01,721:INFO:Starting cross validation
2026-01-29 16:17:01,721:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:17:02,373:INFO:Calculating mean and std
2026-01-29 16:17:02,375:INFO:Creating metrics dataframe
2026-01-29 16:17:02,377:INFO:Finalizing model
2026-01-29 16:17:02,610:INFO:Uploading results into container
2026-01-29 16:17:02,610:INFO:Uploading model into container now
2026-01-29 16:17:02,610:INFO:_master_model_container: 6
2026-01-29 16:17:02,610:INFO:_display_container: 4
2026-01-29 16:17:02,610:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:17:02,610:INFO:create_model() successfully completed......................................
2026-01-29 16:17:02,820:INFO:SubProcess create_model() end ==================================
2026-01-29 16:17:02,820:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 16:17:02,820:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 16:17:02,820:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2026-01-29 16:17:02,820:INFO:choose_better completed
2026-01-29 16:17:02,820:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:17:02,825:INFO:_master_model_container: 6
2026-01-29 16:17:02,825:INFO:_display_container: 3
2026-01-29 16:17:02,825:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:17:02,825:INFO:tune_model() successfully completed......................................
2026-01-29 16:17:03,039:INFO:Initializing tune_model()
2026-01-29 16:17:03,039:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:17:03,040:INFO:Checking exceptions
2026-01-29 16:17:03,068:INFO:Copying training dataset
2026-01-29 16:17:03,129:INFO:Checking base model
2026-01-29 16:17:03,130:INFO:Base model : Decision Tree Classifier
2026-01-29 16:17:03,133:INFO:Declaring metric variables
2026-01-29 16:17:03,138:INFO:Defining Hyperparameters
2026-01-29 16:17:03,353:INFO:Tuning with n_jobs=-1
2026-01-29 16:17:03,353:INFO:Initializing RandomizedSearchCV
2026-01-29 16:17:04,328:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.0005, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 3, 'actual_estimator__criterion': 'gini'}
2026-01-29 16:17:04,328:INFO:Hyperparameter search completed
2026-01-29 16:17:04,328:INFO:SubProcess create_model() called ==================================
2026-01-29 16:17:04,328:INFO:Initializing create_model()
2026-01-29 16:17:04,328:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002487DF698D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0005, 'max_features': 1.0, 'max_depth': 3, 'criterion': 'gini'})
2026-01-29 16:17:04,328:INFO:Checking exceptions
2026-01-29 16:17:04,328:INFO:Importing libraries
2026-01-29 16:17:04,328:INFO:Copying training dataset
2026-01-29 16:17:04,387:INFO:Defining folds
2026-01-29 16:17:04,387:INFO:Declaring metric variables
2026-01-29 16:17:04,387:INFO:Importing untrained model
2026-01-29 16:17:04,387:INFO:Declaring custom model
2026-01-29 16:17:04,387:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:17:04,404:INFO:Starting cross validation
2026-01-29 16:17:04,404:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:17:04,946:INFO:Calculating mean and std
2026-01-29 16:17:04,948:INFO:Creating metrics dataframe
2026-01-29 16:17:04,954:INFO:Finalizing model
2026-01-29 16:17:05,030:INFO:Uploading results into container
2026-01-29 16:17:05,030:INFO:Uploading model into container now
2026-01-29 16:17:05,030:INFO:_master_model_container: 7
2026-01-29 16:17:05,030:INFO:_display_container: 4
2026-01-29 16:17:05,034:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:17:05,034:INFO:create_model() successfully completed......................................
2026-01-29 16:17:05,276:INFO:SubProcess create_model() end ==================================
2026-01-29 16:17:05,276:INFO:choose_better activated
2026-01-29 16:17:05,279:INFO:SubProcess create_model() called ==================================
2026-01-29 16:17:05,279:INFO:Initializing create_model()
2026-01-29 16:17:05,279:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:17:05,280:INFO:Checking exceptions
2026-01-29 16:17:05,281:INFO:Importing libraries
2026-01-29 16:17:05,282:INFO:Copying training dataset
2026-01-29 16:17:05,364:INFO:Defining folds
2026-01-29 16:17:05,364:INFO:Declaring metric variables
2026-01-29 16:17:05,365:INFO:Importing untrained model
2026-01-29 16:17:05,365:INFO:Declaring custom model
2026-01-29 16:17:05,365:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:17:05,365:INFO:Starting cross validation
2026-01-29 16:17:05,366:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:17:05,959:INFO:Calculating mean and std
2026-01-29 16:17:05,959:INFO:Creating metrics dataframe
2026-01-29 16:17:05,959:INFO:Finalizing model
2026-01-29 16:17:06,040:INFO:Uploading results into container
2026-01-29 16:17:06,040:INFO:Uploading model into container now
2026-01-29 16:17:06,040:INFO:_master_model_container: 8
2026-01-29 16:17:06,040:INFO:_display_container: 5
2026-01-29 16:17:06,040:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:17:06,040:INFO:create_model() successfully completed......................................
2026-01-29 16:17:06,270:INFO:SubProcess create_model() end ==================================
2026-01-29 16:17:06,270:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5369
2026-01-29 16:17:06,270:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5366
2026-01-29 16:17:06,270:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-29 16:17:06,270:INFO:choose_better completed
2026-01-29 16:17:06,270:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:17:06,287:INFO:_master_model_container: 8
2026-01-29 16:17:06,287:INFO:_display_container: 4
2026-01-29 16:17:06,287:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:17:06,287:INFO:tune_model() successfully completed......................................
2026-01-29 16:17:06,503:INFO:Initializing tune_model()
2026-01-29 16:17:06,503:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:17:06,503:INFO:Checking exceptions
2026-01-29 16:17:06,553:INFO:Copying training dataset
2026-01-29 16:17:06,620:INFO:Checking base model
2026-01-29 16:17:06,620:INFO:Base model : Random Forest Classifier
2026-01-29 16:17:06,626:INFO:Declaring metric variables
2026-01-29 16:17:06,630:INFO:Defining Hyperparameters
2026-01-29 16:17:06,869:INFO:Tuning with n_jobs=-1
2026-01-29 16:17:06,869:INFO:Initializing RandomizedSearchCV
2026-01-29 16:17:34,874:INFO:best_params: {'actual_estimator__n_estimators': 120, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-29 16:17:34,874:INFO:Hyperparameter search completed
2026-01-29 16:17:34,874:INFO:SubProcess create_model() called ==================================
2026-01-29 16:17:34,874:INFO:Initializing create_model()
2026-01-29 16:17:34,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024827B0F5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 120, 'min_samples_split': 5, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': True})
2026-01-29 16:17:34,874:INFO:Checking exceptions
2026-01-29 16:17:34,874:INFO:Importing libraries
2026-01-29 16:17:34,874:INFO:Copying training dataset
2026-01-29 16:17:34,953:INFO:Defining folds
2026-01-29 16:17:34,953:INFO:Declaring metric variables
2026-01-29 16:17:34,956:INFO:Importing untrained model
2026-01-29 16:17:34,956:INFO:Declaring custom model
2026-01-29 16:17:34,956:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:17:34,971:INFO:Starting cross validation
2026-01-29 16:17:34,972:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:17:38,064:INFO:Calculating mean and std
2026-01-29 16:17:38,064:INFO:Creating metrics dataframe
2026-01-29 16:17:38,073:INFO:Finalizing model
2026-01-29 16:17:39,755:INFO:Uploading results into container
2026-01-29 16:17:39,756:INFO:Uploading model into container now
2026-01-29 16:17:39,756:INFO:_master_model_container: 9
2026-01-29 16:17:39,756:INFO:_display_container: 5
2026-01-29 16:17:39,756:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=120, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:17:39,756:INFO:create_model() successfully completed......................................
2026-01-29 16:17:39,984:INFO:SubProcess create_model() end ==================================
2026-01-29 16:17:39,984:INFO:choose_better activated
2026-01-29 16:17:39,984:INFO:SubProcess create_model() called ==================================
2026-01-29 16:17:39,984:INFO:Initializing create_model()
2026-01-29 16:17:39,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:17:39,984:INFO:Checking exceptions
2026-01-29 16:17:39,984:INFO:Importing libraries
2026-01-29 16:17:39,984:INFO:Copying training dataset
2026-01-29 16:17:40,053:INFO:Defining folds
2026-01-29 16:17:40,053:INFO:Declaring metric variables
2026-01-29 16:17:40,053:INFO:Importing untrained model
2026-01-29 16:17:40,053:INFO:Declaring custom model
2026-01-29 16:17:40,053:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:17:40,053:INFO:Starting cross validation
2026-01-29 16:17:40,053:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:17:42,552:INFO:Calculating mean and std
2026-01-29 16:17:42,552:INFO:Creating metrics dataframe
2026-01-29 16:17:42,558:INFO:Finalizing model
2026-01-29 16:17:43,833:INFO:Uploading results into container
2026-01-29 16:17:43,833:INFO:Uploading model into container now
2026-01-29 16:17:43,833:INFO:_master_model_container: 10
2026-01-29 16:17:43,833:INFO:_display_container: 6
2026-01-29 16:17:43,833:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:17:43,833:INFO:create_model() successfully completed......................................
2026-01-29 16:17:44,038:INFO:SubProcess create_model() end ==================================
2026-01-29 16:17:44,038:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.5369
2026-01-29 16:17:44,038:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=120, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.5369
2026-01-29 16:17:44,038:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-29 16:17:44,038:INFO:choose_better completed
2026-01-29 16:17:44,038:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:17:44,053:INFO:_master_model_container: 10
2026-01-29 16:17:44,053:INFO:_display_container: 5
2026-01-29 16:17:44,053:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:17:44,053:INFO:tune_model() successfully completed......................................
2026-01-29 16:17:44,254:INFO:Initializing evaluate_model()
2026-01-29 16:17:44,254:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:17:44,294:INFO:Initializing plot_model()
2026-01-29 16:17:44,294:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:17:44,295:INFO:Checking exceptions
2026-01-29 16:17:44,321:INFO:Preloading libraries
2026-01-29 16:17:44,321:INFO:Copying training dataset
2026-01-29 16:17:44,321:INFO:Plot type: pipeline
2026-01-29 16:17:44,371:INFO:Visual Rendered Successfully
2026-01-29 16:17:44,572:INFO:plot_model() successfully completed......................................
2026-01-29 16:17:44,572:INFO:Initializing evaluate_model()
2026-01-29 16:17:44,585:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:17:44,617:INFO:Initializing plot_model()
2026-01-29 16:17:44,617:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:17:44,617:INFO:Checking exceptions
2026-01-29 16:17:44,657:INFO:Preloading libraries
2026-01-29 16:17:44,658:INFO:Copying training dataset
2026-01-29 16:17:44,658:INFO:Plot type: pipeline
2026-01-29 16:17:44,750:INFO:Visual Rendered Successfully
2026-01-29 16:17:44,955:INFO:plot_model() successfully completed......................................
2026-01-29 16:17:44,955:INFO:Initializing evaluate_model()
2026-01-29 16:17:44,955:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:17:44,995:INFO:Initializing plot_model()
2026-01-29 16:17:44,995:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:17:44,995:INFO:Checking exceptions
2026-01-29 16:17:45,038:INFO:Preloading libraries
2026-01-29 16:17:45,038:INFO:Copying training dataset
2026-01-29 16:17:45,038:INFO:Plot type: pipeline
2026-01-29 16:17:45,101:INFO:Visual Rendered Successfully
2026-01-29 16:17:45,301:INFO:plot_model() successfully completed......................................
2026-01-29 16:17:45,312:INFO:Initializing predict_model()
2026-01-29 16:17:45,312:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002481E4E31A0>)
2026-01-29 16:17:45,312:INFO:Checking exceptions
2026-01-29 16:17:45,312:INFO:Preloading libraries
2026-01-29 16:17:45,314:INFO:Set up data.
2026-01-29 16:17:45,320:INFO:Set up index.
2026-01-29 16:17:45,803:INFO:Initializing predict_model()
2026-01-29 16:17:45,803:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000248172B4720>)
2026-01-29 16:17:45,803:INFO:Checking exceptions
2026-01-29 16:17:45,803:INFO:Preloading libraries
2026-01-29 16:17:45,803:INFO:Set up data.
2026-01-29 16:17:45,819:INFO:Set up index.
2026-01-29 16:17:46,305:INFO:Initializing predict_model()
2026-01-29 16:17:46,305:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002480F570EA0>)
2026-01-29 16:17:46,305:INFO:Checking exceptions
2026-01-29 16:17:46,305:INFO:Preloading libraries
2026-01-29 16:17:46,305:INFO:Set up data.
2026-01-29 16:17:46,305:INFO:Set up index.
2026-01-29 16:17:47,093:INFO:Initializing plot_model()
2026-01-29 16:17:47,093:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002480F68C810>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-29 16:17:47,093:INFO:Checking exceptions
2026-01-29 16:17:47,156:INFO:Preloading libraries
2026-01-29 16:17:47,156:INFO:Copying training dataset
2026-01-29 16:17:47,156:INFO:Plot type: feature
2026-01-29 16:17:47,476:INFO:Visual Rendered Successfully
2026-01-29 16:17:47,725:INFO:plot_model() successfully completed......................................
2026-01-29 16:17:47,725:INFO:Initializing save_model()
2026-01-29 16:17:47,725:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=..\datos\04. Modelos, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-29 16:17:47,725:INFO:Adding model into prep_pipe
2026-01-29 16:17:47,740:INFO:..\datos\04. Modelos.pkl saved in current working directory
2026-01-29 16:17:47,741:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(e...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=42,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2026-01-29 16:17:47,741:INFO:save_model() successfully completed......................................
2026-01-29 16:19:05,735:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26224\1878984716.py:18: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-29 16:19:07,449:INFO:PyCaret ClassificationExperiment
2026-01-29 16:19:07,449:INFO:Logging name: clf-default-name
2026-01-29 16:19:07,449:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-29 16:19:07,449:INFO:version 3.3.2
2026-01-29 16:19:07,451:INFO:Initializing setup()
2026-01-29 16:19:07,451:INFO:self.USI: e4f4
2026-01-29 16:19:07,451:INFO:self._variable_keys: {'X_test', 'fold_groups_param', 'pipeline', 'fix_imbalance', 'exp_name_log', 'data', 'y_test', 'seed', 'fold_shuffle_param', 'n_jobs_param', 'is_multiclass', 'gpu_n_jobs_param', 'memory', 'log_plots_param', 'logging_param', 'idx', 'y', 'target_param', 'fold_generator', 'y_train', 'gpu_param', 'USI', 'exp_id', '_available_plots', 'X', 'X_train', 'html_param', '_ml_usecase'}
2026-01-29 16:19:07,451:INFO:Checking environment
2026-01-29 16:19:07,451:INFO:python_version: 3.11.11
2026-01-29 16:19:07,451:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-29 16:19:07,451:INFO:machine: AMD64
2026-01-29 16:19:07,451:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-29 16:19:07,451:INFO:Memory: svmem(total=34009374720, available=13444653056, percent=60.5, used=20564721664, free=13444653056)
2026-01-29 16:19:07,451:INFO:Physical Core: 12
2026-01-29 16:19:07,452:INFO:Logical Core: 16
2026-01-29 16:19:07,452:INFO:Checking libraries
2026-01-29 16:19:07,452:INFO:System:
2026-01-29 16:19:07,452:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-29 16:19:07,452:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-29 16:19:07,452:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-29 16:19:07,452:INFO:PyCaret required dependencies:
2026-01-29 16:19:07,452:INFO:                 pip: 25.0
2026-01-29 16:19:07,452:INFO:          setuptools: 75.8.0
2026-01-29 16:19:07,452:INFO:             pycaret: 3.3.2
2026-01-29 16:19:07,452:INFO:             IPython: 9.9.0
2026-01-29 16:19:07,452:INFO:          ipywidgets: 8.1.8
2026-01-29 16:19:07,452:INFO:                tqdm: 4.67.1
2026-01-29 16:19:07,452:INFO:               numpy: 1.26.4
2026-01-29 16:19:07,452:INFO:              pandas: 2.1.4
2026-01-29 16:19:07,452:INFO:              jinja2: 3.1.6
2026-01-29 16:19:07,452:INFO:               scipy: 1.11.4
2026-01-29 16:19:07,452:INFO:              joblib: 1.3.2
2026-01-29 16:19:07,452:INFO:             sklearn: 1.4.2
2026-01-29 16:19:07,452:INFO:                pyod: 2.0.6
2026-01-29 16:19:07,452:INFO:            imblearn: 0.14.1
2026-01-29 16:19:07,452:INFO:   category_encoders: 2.7.0
2026-01-29 16:19:07,452:INFO:            lightgbm: 4.6.0
2026-01-29 16:19:07,452:INFO:               numba: 0.62.1
2026-01-29 16:19:07,452:INFO:            requests: 2.32.3
2026-01-29 16:19:07,452:INFO:          matplotlib: 3.7.5
2026-01-29 16:19:07,452:INFO:          scikitplot: 0.3.7
2026-01-29 16:19:07,452:INFO:         yellowbrick: 1.5
2026-01-29 16:19:07,452:INFO:              plotly: 5.24.1
2026-01-29 16:19:07,452:INFO:    plotly-resampler: Not installed
2026-01-29 16:19:07,452:INFO:             kaleido: 1.2.0
2026-01-29 16:19:07,452:INFO:           schemdraw: 0.15
2026-01-29 16:19:07,452:INFO:         statsmodels: 0.14.6
2026-01-29 16:19:07,452:INFO:              sktime: 0.26.0
2026-01-29 16:19:07,452:INFO:               tbats: 1.1.3
2026-01-29 16:19:07,452:INFO:            pmdarima: 2.0.4
2026-01-29 16:19:07,452:INFO:              psutil: 7.2.1
2026-01-29 16:19:07,452:INFO:          markupsafe: 3.0.3
2026-01-29 16:19:07,452:INFO:             pickle5: Not installed
2026-01-29 16:19:07,452:INFO:         cloudpickle: 3.0.0
2026-01-29 16:19:07,452:INFO:         deprecation: 2.1.0
2026-01-29 16:19:07,452:INFO:              xxhash: 3.6.0
2026-01-29 16:19:07,452:INFO:           wurlitzer: Not installed
2026-01-29 16:19:07,452:INFO:PyCaret optional dependencies:
2026-01-29 16:19:07,452:INFO:                shap: 0.44.1
2026-01-29 16:19:07,452:INFO:           interpret: 0.7.3
2026-01-29 16:19:07,452:INFO:                umap: 0.5.7
2026-01-29 16:19:07,452:INFO:     ydata_profiling: 4.18.1
2026-01-29 16:19:07,452:INFO:  explainerdashboard: 0.5.1
2026-01-29 16:19:07,452:INFO:             autoviz: Not installed
2026-01-29 16:19:07,452:INFO:           fairlearn: 0.7.0
2026-01-29 16:19:07,452:INFO:          deepchecks: Not installed
2026-01-29 16:19:07,452:INFO:             xgboost: Not installed
2026-01-29 16:19:07,452:INFO:            catboost: 1.2.8
2026-01-29 16:19:07,452:INFO:              kmodes: 0.12.2
2026-01-29 16:19:07,452:INFO:             mlxtend: 0.23.4
2026-01-29 16:19:07,452:INFO:       statsforecast: 1.5.0
2026-01-29 16:19:07,452:INFO:        tune_sklearn: Not installed
2026-01-29 16:19:07,452:INFO:                 ray: Not installed
2026-01-29 16:19:07,452:INFO:            hyperopt: 0.2.7
2026-01-29 16:19:07,452:INFO:              optuna: 4.6.0
2026-01-29 16:19:07,452:INFO:               skopt: 0.10.2
2026-01-29 16:19:07,452:INFO:              mlflow: 3.8.1
2026-01-29 16:19:07,452:INFO:              gradio: 6.3.0
2026-01-29 16:19:07,452:INFO:             fastapi: 0.128.0
2026-01-29 16:19:07,452:INFO:             uvicorn: 0.40.0
2026-01-29 16:19:07,452:INFO:              m2cgen: 0.10.0
2026-01-29 16:19:07,452:INFO:           evidently: 0.4.40
2026-01-29 16:19:07,452:INFO:               fugue: 0.8.7
2026-01-29 16:19:07,452:INFO:           streamlit: Not installed
2026-01-29 16:19:07,452:INFO:             prophet: Not installed
2026-01-29 16:19:07,452:INFO:None
2026-01-29 16:19:07,452:INFO:Set up data.
2026-01-29 16:19:07,485:INFO:Set up folding strategy.
2026-01-29 16:19:07,485:INFO:Set up train/test split.
2026-01-29 16:19:07,585:INFO:Set up index.
2026-01-29 16:19:07,585:INFO:Assigning column types.
2026-01-29 16:19:07,602:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-29 16:19:07,635:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:19:07,635:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:19:07,656:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:19:07,656:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:19:07,684:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-29 16:19:07,685:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:19:07,702:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:19:07,702:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:19:07,702:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-29 16:19:07,719:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:19:07,735:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:19:07,735:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:19:07,769:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-29 16:19:07,785:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:19:07,785:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:19:07,785:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-29 16:19:07,835:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:19:07,835:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:19:07,885:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:19:07,885:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:19:07,885:INFO:Preparing preprocessing pipeline...
2026-01-29 16:19:07,895:INFO:Set up simple imputation.
2026-01-29 16:19:07,895:INFO:Set up feature normalization.
2026-01-29 16:19:07,971:INFO:Finished creating preprocessing pipeline.
2026-01-29 16:19:07,971:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-29 16:19:07,971:INFO:Creating final display dataframe.
2026-01-29 16:19:08,186:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape       (429278, 4)
4        Transformed data shape       (429278, 4)
5   Transformed train set shape       (343422, 4)
6    Transformed test set shape        (85856, 4)
7               Ignore features                58
8              Numeric features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            zscore
15               Fold Generator   StratifiedKFold
16                  Fold Number                 3
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              e4f4
2026-01-29 16:19:08,236:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:19:08,236:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:19:08,285:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-29 16:19:08,286:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-29 16:19:08,287:INFO:setup() successfully completed in 0.85s...............
2026-01-29 16:19:08,287:INFO:Initializing compare_models()
2026-01-29 16:19:08,287:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-29 16:19:08,287:INFO:Checking exceptions
2026-01-29 16:19:08,302:INFO:Preparing display monitor
2026-01-29 16:19:08,330:INFO:Initializing Logistic Regression
2026-01-29 16:19:08,330:INFO:Total runtime is 6.67572021484375e-06 minutes
2026-01-29 16:19:08,332:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:08,333:INFO:Initializing create_model()
2026-01-29 16:19:08,333:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002480E442290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:08,333:INFO:Checking exceptions
2026-01-29 16:19:08,333:INFO:Importing libraries
2026-01-29 16:19:08,333:INFO:Copying training dataset
2026-01-29 16:19:08,417:INFO:Defining folds
2026-01-29 16:19:08,417:INFO:Declaring metric variables
2026-01-29 16:19:08,420:INFO:Importing untrained model
2026-01-29 16:19:08,422:INFO:Logistic Regression Imported successfully
2026-01-29 16:19:08,427:INFO:Starting cross validation
2026-01-29 16:19:08,428:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:08,980:INFO:Calculating mean and std
2026-01-29 16:19:08,980:INFO:Creating metrics dataframe
2026-01-29 16:19:08,980:INFO:Uploading results into container
2026-01-29 16:19:08,980:INFO:Uploading model into container now
2026-01-29 16:19:08,984:INFO:_master_model_container: 1
2026-01-29 16:19:08,984:INFO:_display_container: 2
2026-01-29 16:19:08,984:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:19:08,984:INFO:create_model() successfully completed......................................
2026-01-29 16:19:09,185:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:09,185:INFO:Creating metrics dataframe
2026-01-29 16:19:09,185:INFO:Initializing Decision Tree Classifier
2026-01-29 16:19:09,185:INFO:Total runtime is 0.014251784483591715 minutes
2026-01-29 16:19:09,185:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:09,185:INFO:Initializing create_model()
2026-01-29 16:19:09,185:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002480E442290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:09,185:INFO:Checking exceptions
2026-01-29 16:19:09,185:INFO:Importing libraries
2026-01-29 16:19:09,185:INFO:Copying training dataset
2026-01-29 16:19:09,238:INFO:Defining folds
2026-01-29 16:19:09,251:INFO:Declaring metric variables
2026-01-29 16:19:09,253:INFO:Importing untrained model
2026-01-29 16:19:09,253:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:19:09,253:INFO:Starting cross validation
2026-01-29 16:19:09,253:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:09,718:INFO:Calculating mean and std
2026-01-29 16:19:09,719:INFO:Creating metrics dataframe
2026-01-29 16:19:09,719:INFO:Uploading results into container
2026-01-29 16:19:09,719:INFO:Uploading model into container now
2026-01-29 16:19:09,719:INFO:_master_model_container: 2
2026-01-29 16:19:09,723:INFO:_display_container: 2
2026-01-29 16:19:09,724:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:19:09,724:INFO:create_model() successfully completed......................................
2026-01-29 16:19:09,919:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:09,919:INFO:Creating metrics dataframe
2026-01-29 16:19:09,919:INFO:Initializing Random Forest Classifier
2026-01-29 16:19:09,919:INFO:Total runtime is 0.02647436459859212 minutes
2026-01-29 16:19:09,934:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:09,935:INFO:Initializing create_model()
2026-01-29 16:19:09,935:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002480E442290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:09,935:INFO:Checking exceptions
2026-01-29 16:19:09,935:INFO:Importing libraries
2026-01-29 16:19:09,935:INFO:Copying training dataset
2026-01-29 16:19:09,987:INFO:Defining folds
2026-01-29 16:19:09,987:INFO:Declaring metric variables
2026-01-29 16:19:09,987:INFO:Importing untrained model
2026-01-29 16:19:09,987:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:19:09,987:INFO:Starting cross validation
2026-01-29 16:19:09,987:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:12,204:INFO:Calculating mean and std
2026-01-29 16:19:12,204:INFO:Creating metrics dataframe
2026-01-29 16:19:12,217:INFO:Uploading results into container
2026-01-29 16:19:12,219:INFO:Uploading model into container now
2026-01-29 16:19:12,220:INFO:_master_model_container: 3
2026-01-29 16:19:12,220:INFO:_display_container: 2
2026-01-29 16:19:12,220:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:19:12,220:INFO:create_model() successfully completed......................................
2026-01-29 16:19:12,419:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:12,419:INFO:Creating metrics dataframe
2026-01-29 16:19:12,419:INFO:Initializing Light Gradient Boosting Machine
2026-01-29 16:19:12,419:INFO:Total runtime is 0.0681542714436849 minutes
2026-01-29 16:19:12,419:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:12,435:INFO:Initializing create_model()
2026-01-29 16:19:12,435:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002480E442290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:12,435:INFO:Checking exceptions
2026-01-29 16:19:12,435:INFO:Importing libraries
2026-01-29 16:19:12,435:INFO:Copying training dataset
2026-01-29 16:19:12,486:INFO:Defining folds
2026-01-29 16:19:12,486:INFO:Declaring metric variables
2026-01-29 16:19:12,486:INFO:Importing untrained model
2026-01-29 16:19:12,486:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-29 16:19:12,486:INFO:Starting cross validation
2026-01-29 16:19:12,502:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:13,632:INFO:Calculating mean and std
2026-01-29 16:19:13,632:INFO:Creating metrics dataframe
2026-01-29 16:19:13,632:INFO:Uploading results into container
2026-01-29 16:19:13,632:INFO:Uploading model into container now
2026-01-29 16:19:13,632:INFO:_master_model_container: 4
2026-01-29 16:19:13,632:INFO:_display_container: 2
2026-01-29 16:19:13,636:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-29 16:19:13,636:INFO:create_model() successfully completed......................................
2026-01-29 16:19:13,839:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:13,839:INFO:Creating metrics dataframe
2026-01-29 16:19:13,845:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-29 16:19:13,854:INFO:Initializing create_model()
2026-01-29 16:19:13,854:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:13,854:INFO:Checking exceptions
2026-01-29 16:19:13,854:INFO:Importing libraries
2026-01-29 16:19:13,854:INFO:Copying training dataset
2026-01-29 16:19:13,920:INFO:Defining folds
2026-01-29 16:19:13,920:INFO:Declaring metric variables
2026-01-29 16:19:13,920:INFO:Importing untrained model
2026-01-29 16:19:13,920:INFO:Declaring custom model
2026-01-29 16:19:13,921:INFO:Logistic Regression Imported successfully
2026-01-29 16:19:13,921:INFO:Cross validation set to False
2026-01-29 16:19:13,921:INFO:Fitting Model
2026-01-29 16:19:14,117:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:19:14,117:INFO:create_model() successfully completed......................................
2026-01-29 16:19:14,333:INFO:Initializing create_model()
2026-01-29 16:19:14,333:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:14,333:INFO:Checking exceptions
2026-01-29 16:19:14,345:INFO:Importing libraries
2026-01-29 16:19:14,345:INFO:Copying training dataset
2026-01-29 16:19:14,402:INFO:Defining folds
2026-01-29 16:19:14,402:INFO:Declaring metric variables
2026-01-29 16:19:14,402:INFO:Importing untrained model
2026-01-29 16:19:14,402:INFO:Declaring custom model
2026-01-29 16:19:14,402:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:19:14,402:INFO:Cross validation set to False
2026-01-29 16:19:14,402:INFO:Fitting Model
2026-01-29 16:19:14,469:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:19:14,469:INFO:create_model() successfully completed......................................
2026-01-29 16:19:14,671:INFO:Initializing create_model()
2026-01-29 16:19:14,671:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:14,671:INFO:Checking exceptions
2026-01-29 16:19:14,676:INFO:Importing libraries
2026-01-29 16:19:14,676:INFO:Copying training dataset
2026-01-29 16:19:14,735:INFO:Defining folds
2026-01-29 16:19:14,735:INFO:Declaring metric variables
2026-01-29 16:19:14,735:INFO:Importing untrained model
2026-01-29 16:19:14,735:INFO:Declaring custom model
2026-01-29 16:19:14,735:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:19:14,735:INFO:Cross validation set to False
2026-01-29 16:19:14,735:INFO:Fitting Model
2026-01-29 16:19:15,867:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:19:15,867:INFO:create_model() successfully completed......................................
2026-01-29 16:19:16,086:INFO:_master_model_container: 4
2026-01-29 16:19:16,086:INFO:_display_container: 2
2026-01-29 16:19:16,086:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)]
2026-01-29 16:19:16,086:INFO:compare_models() successfully completed......................................
2026-01-29 16:19:16,086:INFO:Initializing tune_model()
2026-01-29 16:19:16,086:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:19:16,086:INFO:Checking exceptions
2026-01-29 16:19:16,134:INFO:Copying training dataset
2026-01-29 16:19:16,196:INFO:Checking base model
2026-01-29 16:19:16,196:INFO:Base model : Logistic Regression
2026-01-29 16:19:16,199:INFO:Declaring metric variables
2026-01-29 16:19:16,201:INFO:Defining Hyperparameters
2026-01-29 16:19:16,418:INFO:Tuning with n_jobs=-1
2026-01-29 16:19:16,418:INFO:Initializing RandomizedSearchCV
2026-01-29 16:19:17,823:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 5.682}
2026-01-29 16:19:17,823:INFO:Hyperparameter search completed
2026-01-29 16:19:17,823:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:17,823:INFO:Initializing create_model()
2026-01-29 16:19:17,823:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816DB8910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 5.682})
2026-01-29 16:19:17,823:INFO:Checking exceptions
2026-01-29 16:19:17,823:INFO:Importing libraries
2026-01-29 16:19:17,823:INFO:Copying training dataset
2026-01-29 16:19:17,886:INFO:Defining folds
2026-01-29 16:19:17,886:INFO:Declaring metric variables
2026-01-29 16:19:17,886:INFO:Importing untrained model
2026-01-29 16:19:17,886:INFO:Declaring custom model
2026-01-29 16:19:17,886:INFO:Logistic Regression Imported successfully
2026-01-29 16:19:17,901:INFO:Starting cross validation
2026-01-29 16:19:17,901:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:18,608:INFO:Calculating mean and std
2026-01-29 16:19:18,608:INFO:Creating metrics dataframe
2026-01-29 16:19:18,608:INFO:Finalizing model
2026-01-29 16:19:18,909:INFO:Uploading results into container
2026-01-29 16:19:18,911:INFO:Uploading model into container now
2026-01-29 16:19:18,911:INFO:_master_model_container: 5
2026-01-29 16:19:18,911:INFO:_display_container: 3
2026-01-29 16:19:18,911:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:19:18,911:INFO:create_model() successfully completed......................................
2026-01-29 16:19:19,120:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:19,120:INFO:choose_better activated
2026-01-29 16:19:19,120:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:19,120:INFO:Initializing create_model()
2026-01-29 16:19:19,120:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:19,120:INFO:Checking exceptions
2026-01-29 16:19:19,120:INFO:Importing libraries
2026-01-29 16:19:19,120:INFO:Copying training dataset
2026-01-29 16:19:19,185:INFO:Defining folds
2026-01-29 16:19:19,185:INFO:Declaring metric variables
2026-01-29 16:19:19,185:INFO:Importing untrained model
2026-01-29 16:19:19,185:INFO:Declaring custom model
2026-01-29 16:19:19,185:INFO:Logistic Regression Imported successfully
2026-01-29 16:19:19,189:INFO:Starting cross validation
2026-01-29 16:19:19,189:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:19,920:INFO:Calculating mean and std
2026-01-29 16:19:19,920:INFO:Creating metrics dataframe
2026-01-29 16:19:19,920:INFO:Finalizing model
2026-01-29 16:19:20,154:INFO:Uploading results into container
2026-01-29 16:19:20,154:INFO:Uploading model into container now
2026-01-29 16:19:20,154:INFO:_master_model_container: 6
2026-01-29 16:19:20,154:INFO:_display_container: 4
2026-01-29 16:19:20,154:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:19:20,154:INFO:create_model() successfully completed......................................
2026-01-29 16:19:20,371:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:20,371:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 16:19:20,371:INFO:LogisticRegression(C=5.682, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.5369
2026-01-29 16:19:20,371:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2026-01-29 16:19:20,371:INFO:choose_better completed
2026-01-29 16:19:20,371:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:19:20,371:INFO:_master_model_container: 6
2026-01-29 16:19:20,371:INFO:_display_container: 3
2026-01-29 16:19:20,371:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-29 16:19:20,371:INFO:tune_model() successfully completed......................................
2026-01-29 16:19:20,592:INFO:Initializing tune_model()
2026-01-29 16:19:20,592:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:19:20,592:INFO:Checking exceptions
2026-01-29 16:19:20,619:INFO:Copying training dataset
2026-01-29 16:19:20,690:INFO:Checking base model
2026-01-29 16:19:20,692:INFO:Base model : Decision Tree Classifier
2026-01-29 16:19:20,694:INFO:Declaring metric variables
2026-01-29 16:19:20,697:INFO:Defining Hyperparameters
2026-01-29 16:19:20,903:INFO:Tuning with n_jobs=-1
2026-01-29 16:19:20,903:INFO:Initializing RandomizedSearchCV
2026-01-29 16:19:21,772:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.0005, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 3, 'actual_estimator__criterion': 'gini'}
2026-01-29 16:19:21,772:INFO:Hyperparameter search completed
2026-01-29 16:19:21,772:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:21,772:INFO:Initializing create_model()
2026-01-29 16:19:21,772:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002487E3F3ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0005, 'max_features': 1.0, 'max_depth': 3, 'criterion': 'gini'})
2026-01-29 16:19:21,772:INFO:Checking exceptions
2026-01-29 16:19:21,772:INFO:Importing libraries
2026-01-29 16:19:21,772:INFO:Copying training dataset
2026-01-29 16:19:21,834:INFO:Defining folds
2026-01-29 16:19:21,834:INFO:Declaring metric variables
2026-01-29 16:19:21,834:INFO:Importing untrained model
2026-01-29 16:19:21,834:INFO:Declaring custom model
2026-01-29 16:19:21,834:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:19:21,834:INFO:Starting cross validation
2026-01-29 16:19:21,834:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:22,491:INFO:Calculating mean and std
2026-01-29 16:19:22,491:INFO:Creating metrics dataframe
2026-01-29 16:19:22,501:INFO:Finalizing model
2026-01-29 16:19:22,568:INFO:Uploading results into container
2026-01-29 16:19:22,568:INFO:Uploading model into container now
2026-01-29 16:19:22,568:INFO:_master_model_container: 7
2026-01-29 16:19:22,568:INFO:_display_container: 4
2026-01-29 16:19:22,568:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:19:22,568:INFO:create_model() successfully completed......................................
2026-01-29 16:19:22,817:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:22,818:INFO:choose_better activated
2026-01-29 16:19:22,821:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:22,822:INFO:Initializing create_model()
2026-01-29 16:19:22,822:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:22,822:INFO:Checking exceptions
2026-01-29 16:19:22,822:INFO:Importing libraries
2026-01-29 16:19:22,822:INFO:Copying training dataset
2026-01-29 16:19:22,894:INFO:Defining folds
2026-01-29 16:19:22,894:INFO:Declaring metric variables
2026-01-29 16:19:22,894:INFO:Importing untrained model
2026-01-29 16:19:22,894:INFO:Declaring custom model
2026-01-29 16:19:22,896:INFO:Decision Tree Classifier Imported successfully
2026-01-29 16:19:22,896:INFO:Starting cross validation
2026-01-29 16:19:22,896:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:23,496:INFO:Calculating mean and std
2026-01-29 16:19:23,496:INFO:Creating metrics dataframe
2026-01-29 16:19:23,500:INFO:Finalizing model
2026-01-29 16:19:23,563:INFO:Uploading results into container
2026-01-29 16:19:23,570:INFO:Uploading model into container now
2026-01-29 16:19:23,570:INFO:_master_model_container: 8
2026-01-29 16:19:23,570:INFO:_display_container: 5
2026-01-29 16:19:23,570:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:19:23,570:INFO:create_model() successfully completed......................................
2026-01-29 16:19:23,786:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:23,786:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5369
2026-01-29 16:19:23,786:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=3, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0005, min_samples_leaf=3,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.5366
2026-01-29 16:19:23,786:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-29 16:19:23,786:INFO:choose_better completed
2026-01-29 16:19:23,786:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:19:23,801:INFO:_master_model_container: 8
2026-01-29 16:19:23,802:INFO:_display_container: 4
2026-01-29 16:19:23,802:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-29 16:19:23,802:INFO:tune_model() successfully completed......................................
2026-01-29 16:19:24,019:INFO:Initializing tune_model()
2026-01-29 16:19:24,019:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-29 16:19:24,019:INFO:Checking exceptions
2026-01-29 16:19:24,054:INFO:Copying training dataset
2026-01-29 16:19:24,109:INFO:Checking base model
2026-01-29 16:19:24,109:INFO:Base model : Random Forest Classifier
2026-01-29 16:19:24,112:INFO:Declaring metric variables
2026-01-29 16:19:24,115:INFO:Defining Hyperparameters
2026-01-29 16:19:24,335:INFO:Tuning with n_jobs=-1
2026-01-29 16:19:24,335:INFO:Initializing RandomizedSearchCV
2026-01-29 16:19:48,174:INFO:best_params: {'actual_estimator__n_estimators': 120, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-29 16:19:48,174:INFO:Hyperparameter search completed
2026-01-29 16:19:48,174:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:48,174:INFO:Initializing create_model()
2026-01-29 16:19:48,174:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024816D828D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 120, 'min_samples_split': 5, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': True})
2026-01-29 16:19:48,174:INFO:Checking exceptions
2026-01-29 16:19:48,174:INFO:Importing libraries
2026-01-29 16:19:48,174:INFO:Copying training dataset
2026-01-29 16:19:48,289:INFO:Defining folds
2026-01-29 16:19:48,289:INFO:Declaring metric variables
2026-01-29 16:19:48,292:INFO:Importing untrained model
2026-01-29 16:19:48,292:INFO:Declaring custom model
2026-01-29 16:19:48,297:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:19:48,306:INFO:Starting cross validation
2026-01-29 16:19:48,306:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:51,069:INFO:Calculating mean and std
2026-01-29 16:19:51,069:INFO:Creating metrics dataframe
2026-01-29 16:19:51,069:INFO:Finalizing model
2026-01-29 16:19:52,812:INFO:Uploading results into container
2026-01-29 16:19:52,812:INFO:Uploading model into container now
2026-01-29 16:19:52,812:INFO:_master_model_container: 9
2026-01-29 16:19:52,812:INFO:_display_container: 5
2026-01-29 16:19:52,812:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=120, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:19:52,812:INFO:create_model() successfully completed......................................
2026-01-29 16:19:53,037:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:53,037:INFO:choose_better activated
2026-01-29 16:19:53,037:INFO:SubProcess create_model() called ==================================
2026-01-29 16:19:53,037:INFO:Initializing create_model()
2026-01-29 16:19:53,037:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-29 16:19:53,037:INFO:Checking exceptions
2026-01-29 16:19:53,037:INFO:Importing libraries
2026-01-29 16:19:53,037:INFO:Copying training dataset
2026-01-29 16:19:53,102:INFO:Defining folds
2026-01-29 16:19:53,102:INFO:Declaring metric variables
2026-01-29 16:19:53,102:INFO:Importing untrained model
2026-01-29 16:19:53,102:INFO:Declaring custom model
2026-01-29 16:19:53,102:INFO:Random Forest Classifier Imported successfully
2026-01-29 16:19:53,102:INFO:Starting cross validation
2026-01-29 16:19:53,102:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-29 16:19:55,455:INFO:Calculating mean and std
2026-01-29 16:19:55,455:INFO:Creating metrics dataframe
2026-01-29 16:19:55,455:INFO:Finalizing model
2026-01-29 16:19:56,823:INFO:Uploading results into container
2026-01-29 16:19:56,823:INFO:Uploading model into container now
2026-01-29 16:19:56,823:INFO:_master_model_container: 10
2026-01-29 16:19:56,823:INFO:_display_container: 6
2026-01-29 16:19:56,823:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:19:56,823:INFO:create_model() successfully completed......................................
2026-01-29 16:19:57,035:INFO:SubProcess create_model() end ==================================
2026-01-29 16:19:57,035:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.5369
2026-01-29 16:19:57,035:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=120, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.5369
2026-01-29 16:19:57,035:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-29 16:19:57,035:INFO:choose_better completed
2026-01-29 16:19:57,035:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-29 16:19:57,051:INFO:_master_model_container: 10
2026-01-29 16:19:57,051:INFO:_display_container: 5
2026-01-29 16:19:57,051:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-29 16:19:57,051:INFO:tune_model() successfully completed......................................
2026-01-29 16:19:57,302:INFO:Initializing evaluate_model()
2026-01-29 16:19:57,302:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:19:57,338:INFO:Initializing plot_model()
2026-01-29 16:19:57,339:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:19:57,339:INFO:Checking exceptions
2026-01-29 16:19:57,371:INFO:Preloading libraries
2026-01-29 16:19:57,371:INFO:Copying training dataset
2026-01-29 16:19:57,371:INFO:Plot type: pipeline
2026-01-29 16:19:57,435:INFO:Visual Rendered Successfully
2026-01-29 16:19:57,701:INFO:plot_model() successfully completed......................................
2026-01-29 16:19:57,701:INFO:Initializing evaluate_model()
2026-01-29 16:19:57,701:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:19:57,754:INFO:Initializing plot_model()
2026-01-29 16:19:57,754:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:19:57,754:INFO:Checking exceptions
2026-01-29 16:19:57,786:INFO:Preloading libraries
2026-01-29 16:19:57,786:INFO:Copying training dataset
2026-01-29 16:19:57,786:INFO:Plot type: pipeline
2026-01-29 16:19:57,895:INFO:Visual Rendered Successfully
2026-01-29 16:19:58,118:INFO:plot_model() successfully completed......................................
2026-01-29 16:19:58,126:INFO:Initializing evaluate_model()
2026-01-29 16:19:58,127:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2026-01-29 16:19:58,162:INFO:Initializing plot_model()
2026-01-29 16:19:58,163:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 16:19:58,163:INFO:Checking exceptions
2026-01-29 16:19:58,239:INFO:Preloading libraries
2026-01-29 16:19:58,239:INFO:Copying training dataset
2026-01-29 16:19:58,239:INFO:Plot type: pipeline
2026-01-29 16:19:58,325:INFO:Visual Rendered Successfully
2026-01-29 16:19:58,540:INFO:plot_model() successfully completed......................................
2026-01-29 16:19:58,551:INFO:Initializing predict_model()
2026-01-29 16:19:58,552:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000248488BA8E0>)
2026-01-29 16:19:58,552:INFO:Checking exceptions
2026-01-29 16:19:58,552:INFO:Preloading libraries
2026-01-29 16:19:58,553:INFO:Set up data.
2026-01-29 16:19:58,564:INFO:Set up index.
2026-01-29 16:19:59,152:INFO:Initializing predict_model()
2026-01-29 16:19:59,152:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002480F572AC0>)
2026-01-29 16:19:59,152:INFO:Checking exceptions
2026-01-29 16:19:59,152:INFO:Preloading libraries
2026-01-29 16:19:59,154:INFO:Set up data.
2026-01-29 16:19:59,154:INFO:Set up index.
2026-01-29 16:19:59,685:INFO:Initializing predict_model()
2026-01-29 16:19:59,685:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002487FF34220>)
2026-01-29 16:19:59,685:INFO:Checking exceptions
2026-01-29 16:19:59,685:INFO:Preloading libraries
2026-01-29 16:19:59,685:INFO:Set up data.
2026-01-29 16:19:59,685:INFO:Set up index.
2026-01-29 16:20:00,418:INFO:Initializing plot_model()
2026-01-29 16:20:00,419:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-29 16:20:00,419:INFO:Checking exceptions
2026-01-29 16:20:00,442:INFO:Preloading libraries
2026-01-29 16:20:00,442:INFO:Copying training dataset
2026-01-29 16:20:00,442:INFO:Plot type: feature
2026-01-29 16:20:00,728:INFO:Visual Rendered Successfully
2026-01-29 16:20:00,970:INFO:plot_model() successfully completed......................................
2026-01-29 16:20:00,973:INFO:Initializing save_model()
2026-01-29 16:20:00,973:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=..\datos\04. Modelos, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-29 16:20:00,973:INFO:Adding model into prep_pipe
2026-01-29 16:20:00,973:INFO:..\datos\04. Modelos.pkl saved in current working directory
2026-01-29 16:20:00,988:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'num_asistencias_acum',
                                             'num_solicitudes_acum'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(e...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=42,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2026-01-29 16:20:00,988:INFO:save_model() successfully completed......................................
2026-01-29 17:15:41,175:INFO:Initializing plot_model()
2026-01-29 17:15:41,178:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024816D447D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=rfe, scale=1, save=False, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2026-01-29 17:15:41,179:INFO:Checking exceptions
2026-01-29 17:15:41,218:INFO:Preloading libraries
2026-01-29 17:15:41,219:INFO:Copying training dataset
2026-01-29 17:15:41,219:INFO:Plot type: rfe
2026-01-29 17:15:41,446:INFO:Fitting Model
2026-01-29 17:15:44,103:INFO:Visual Rendered Successfully
2026-01-29 17:15:44,349:INFO:plot_model() successfully completed......................................
2026-01-30 08:51:44,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-30 08:51:44,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-30 08:51:44,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-30 08:51:44,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2026-01-30 08:57:28,953:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\417549131.py:20: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(ruta_dataset, sep=";")

2026-01-30 08:57:31,166:INFO:PyCaret ClassificationExperiment
2026-01-30 08:57:31,166:INFO:Logging name: clf-default-name
2026-01-30 08:57:31,166:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-30 08:57:31,166:INFO:version 3.3.2
2026-01-30 08:57:31,168:INFO:Initializing setup()
2026-01-30 08:57:31,168:INFO:self.USI: 0660
2026-01-30 08:57:31,168:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'n_jobs_param', 'data', 'X', 'idx', 'y_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'USI', 'target_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'y_train', 'X_test', 'seed', 'gpu_param', 'gpu_n_jobs_param', 'y', 'logging_param', 'pipeline', 'fold_generator', 'exp_id'}
2026-01-30 08:57:31,170:INFO:Checking environment
2026-01-30 08:57:31,170:INFO:python_version: 3.11.11
2026-01-30 08:57:31,170:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-30 08:57:31,170:INFO:machine: AMD64
2026-01-30 08:57:31,170:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-30 08:57:31,170:INFO:Memory: svmem(total=34009374720, available=16781463552, percent=50.7, used=17227911168, free=16781463552)
2026-01-30 08:57:31,170:INFO:Physical Core: 12
2026-01-30 08:57:31,170:INFO:Logical Core: 16
2026-01-30 08:57:31,170:INFO:Checking libraries
2026-01-30 08:57:31,170:INFO:System:
2026-01-30 08:57:31,170:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-30 08:57:31,172:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-30 08:57:31,173:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-30 08:57:31,173:INFO:PyCaret required dependencies:
2026-01-30 08:57:32,242:INFO:                 pip: 25.0
2026-01-30 08:57:32,243:INFO:          setuptools: 75.8.0
2026-01-30 08:57:32,243:INFO:             pycaret: 3.3.2
2026-01-30 08:57:32,243:INFO:             IPython: 9.9.0
2026-01-30 08:57:32,243:INFO:          ipywidgets: 8.1.8
2026-01-30 08:57:32,243:INFO:                tqdm: 4.67.1
2026-01-30 08:57:32,243:INFO:               numpy: 1.26.4
2026-01-30 08:57:32,243:INFO:              pandas: 2.1.4
2026-01-30 08:57:32,243:INFO:              jinja2: 3.1.6
2026-01-30 08:57:32,243:INFO:               scipy: 1.11.4
2026-01-30 08:57:32,243:INFO:              joblib: 1.3.2
2026-01-30 08:57:32,243:INFO:             sklearn: 1.4.2
2026-01-30 08:57:32,243:INFO:                pyod: 2.0.6
2026-01-30 08:57:32,243:INFO:            imblearn: 0.14.1
2026-01-30 08:57:32,243:INFO:   category_encoders: 2.7.0
2026-01-30 08:57:32,243:INFO:            lightgbm: 4.6.0
2026-01-30 08:57:32,243:INFO:               numba: 0.62.1
2026-01-30 08:57:32,243:INFO:            requests: 2.32.3
2026-01-30 08:57:32,243:INFO:          matplotlib: 3.7.5
2026-01-30 08:57:32,243:INFO:          scikitplot: 0.3.7
2026-01-30 08:57:32,243:INFO:         yellowbrick: 1.5
2026-01-30 08:57:32,243:INFO:              plotly: 5.24.1
2026-01-30 08:57:32,243:INFO:    plotly-resampler: Not installed
2026-01-30 08:57:32,243:INFO:             kaleido: 1.2.0
2026-01-30 08:57:32,243:INFO:           schemdraw: 0.15
2026-01-30 08:57:32,243:INFO:         statsmodels: 0.14.6
2026-01-30 08:57:32,243:INFO:              sktime: 0.26.0
2026-01-30 08:57:32,243:INFO:               tbats: 1.1.3
2026-01-30 08:57:32,243:INFO:            pmdarima: 2.0.4
2026-01-30 08:57:32,244:INFO:              psutil: 7.2.1
2026-01-30 08:57:32,244:INFO:          markupsafe: 3.0.3
2026-01-30 08:57:32,244:INFO:             pickle5: Not installed
2026-01-30 08:57:32,244:INFO:         cloudpickle: 3.0.0
2026-01-30 08:57:32,244:INFO:         deprecation: 2.1.0
2026-01-30 08:57:32,244:INFO:              xxhash: 3.6.0
2026-01-30 08:57:32,244:INFO:           wurlitzer: Not installed
2026-01-30 08:57:32,244:INFO:PyCaret optional dependencies:
2026-01-30 08:57:39,269:INFO:                shap: 0.44.1
2026-01-30 08:57:39,269:INFO:           interpret: 0.7.3
2026-01-30 08:57:39,269:INFO:                umap: 0.5.7
2026-01-30 08:57:39,269:INFO:     ydata_profiling: 4.18.1
2026-01-30 08:57:39,270:INFO:  explainerdashboard: 0.5.1
2026-01-30 08:57:39,270:INFO:             autoviz: Not installed
2026-01-30 08:57:39,270:INFO:           fairlearn: 0.7.0
2026-01-30 08:57:39,270:INFO:          deepchecks: Not installed
2026-01-30 08:57:39,270:INFO:             xgboost: Not installed
2026-01-30 08:57:39,271:INFO:            catboost: 1.2.8
2026-01-30 08:57:39,271:INFO:              kmodes: 0.12.2
2026-01-30 08:57:39,271:INFO:             mlxtend: 0.23.4
2026-01-30 08:57:39,271:INFO:       statsforecast: 1.5.0
2026-01-30 08:57:39,271:INFO:        tune_sklearn: Not installed
2026-01-30 08:57:39,271:INFO:                 ray: Not installed
2026-01-30 08:57:39,271:INFO:            hyperopt: 0.2.7
2026-01-30 08:57:39,271:INFO:              optuna: 4.6.0
2026-01-30 08:57:39,271:INFO:               skopt: 0.10.2
2026-01-30 08:57:39,271:INFO:              mlflow: 3.8.1
2026-01-30 08:57:39,271:INFO:              gradio: 6.3.0
2026-01-30 08:57:39,271:INFO:             fastapi: 0.128.0
2026-01-30 08:57:39,271:INFO:             uvicorn: 0.40.0
2026-01-30 08:57:39,271:INFO:              m2cgen: 0.10.0
2026-01-30 08:57:39,271:INFO:           evidently: 0.4.40
2026-01-30 08:57:39,271:INFO:               fugue: 0.8.7
2026-01-30 08:57:39,271:INFO:           streamlit: Not installed
2026-01-30 08:57:39,271:INFO:             prophet: Not installed
2026-01-30 08:57:39,272:INFO:None
2026-01-30 08:57:39,272:INFO:Set up data.
2026-01-30 08:57:39,402:INFO:Set up folding strategy.
2026-01-30 08:57:39,402:INFO:Set up train/test split.
2026-01-30 08:57:39,626:INFO:Set up index.
2026-01-30 08:57:39,646:INFO:Assigning column types.
2026-01-30 08:57:39,787:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-30 08:57:39,824:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 08:57:39,827:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 08:57:40,010:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 08:57:40,010:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 08:57:40,239:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 08:57:40,240:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 08:57:40,272:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 08:57:40,274:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 08:57:40,274:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-30 08:57:40,314:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 08:57:40,324:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 08:57:40,324:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 08:57:40,374:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 08:57:40,404:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 08:57:40,404:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 08:57:40,405:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-30 08:57:40,475:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 08:57:40,475:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 08:57:40,540:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 08:57:40,540:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 08:57:40,540:INFO:Preparing preprocessing pipeline...
2026-01-30 08:57:40,577:INFO:Set up simple imputation.
2026-01-30 08:57:40,577:INFO:Set up feature normalization.
2026-01-30 08:57:41,019:INFO:Finished creating preprocessing pipeline.
2026-01-30 08:57:41,024:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'MINIMUMPAYMENTPAYED',
                                             'PAID_PERCENT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'YEARPERSONBIRTHDATE',
                                             'PL_SI...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-30 08:57:41,024:INFO:Creating final display dataframe.
2026-01-30 08:57:42,491:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape      (429278, 20)
4        Transformed data shape      (429278, 20)
5   Transformed train set shape      (300494, 20)
6    Transformed test set shape      (128784, 20)
7              Numeric features                15
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                 3
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              0660
2026-01-30 08:57:42,560:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 08:57:42,561:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 08:57:42,624:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 08:57:42,624:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 08:57:42,624:INFO:setup() successfully completed in 11.47s...............
2026-01-30 08:57:42,624:INFO:Initializing compare_models()
2026-01-30 08:57:42,624:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-30 08:57:42,624:INFO:Checking exceptions
2026-01-30 08:57:42,741:INFO:Preparing display monitor
2026-01-30 08:57:42,761:INFO:Initializing Logistic Regression
2026-01-30 08:57:42,762:INFO:Total runtime is 1.6895929972330728e-05 minutes
2026-01-30 08:57:42,762:INFO:SubProcess create_model() called ==================================
2026-01-30 08:57:42,762:INFO:Initializing create_model()
2026-01-30 08:57:42,762:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C28A7710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 08:57:42,763:INFO:Checking exceptions
2026-01-30 08:57:42,763:INFO:Importing libraries
2026-01-30 08:57:42,763:INFO:Copying training dataset
2026-01-30 08:57:42,958:INFO:Defining folds
2026-01-30 08:57:42,958:INFO:Declaring metric variables
2026-01-30 08:57:42,958:INFO:Importing untrained model
2026-01-30 08:57:42,959:INFO:Logistic Regression Imported successfully
2026-01-30 08:57:42,959:INFO:Starting cross validation
2026-01-30 08:57:42,960:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 08:57:50,916:INFO:Calculating mean and std
2026-01-30 08:57:50,916:INFO:Creating metrics dataframe
2026-01-30 08:57:50,924:INFO:Uploading results into container
2026-01-30 08:57:50,924:INFO:Uploading model into container now
2026-01-30 08:57:50,925:INFO:_master_model_container: 1
2026-01-30 08:57:50,925:INFO:_display_container: 2
2026-01-30 08:57:50,925:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-30 08:57:50,925:INFO:create_model() successfully completed......................................
2026-01-30 08:57:51,042:INFO:SubProcess create_model() end ==================================
2026-01-30 08:57:51,042:INFO:Creating metrics dataframe
2026-01-30 08:57:51,042:INFO:Initializing Decision Tree Classifier
2026-01-30 08:57:51,042:INFO:Total runtime is 0.1380051891009013 minutes
2026-01-30 08:57:51,042:INFO:SubProcess create_model() called ==================================
2026-01-30 08:57:51,042:INFO:Initializing create_model()
2026-01-30 08:57:51,042:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C28A7710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 08:57:51,042:INFO:Checking exceptions
2026-01-30 08:57:51,042:INFO:Importing libraries
2026-01-30 08:57:51,042:INFO:Copying training dataset
2026-01-30 08:57:51,173:INFO:Defining folds
2026-01-30 08:57:51,173:INFO:Declaring metric variables
2026-01-30 08:57:51,173:INFO:Importing untrained model
2026-01-30 08:57:51,173:INFO:Decision Tree Classifier Imported successfully
2026-01-30 08:57:51,173:INFO:Starting cross validation
2026-01-30 08:57:51,173:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 08:57:57,063:INFO:Calculating mean and std
2026-01-30 08:57:57,063:INFO:Creating metrics dataframe
2026-01-30 08:57:57,063:INFO:Uploading results into container
2026-01-30 08:57:57,067:INFO:Uploading model into container now
2026-01-30 08:57:57,067:INFO:_master_model_container: 2
2026-01-30 08:57:57,067:INFO:_display_container: 2
2026-01-30 08:57:57,067:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 08:57:57,067:INFO:create_model() successfully completed......................................
2026-01-30 08:57:57,173:INFO:SubProcess create_model() end ==================================
2026-01-30 08:57:57,173:INFO:Creating metrics dataframe
2026-01-30 08:57:57,188:INFO:Initializing Random Forest Classifier
2026-01-30 08:57:57,188:INFO:Total runtime is 0.2404475728670756 minutes
2026-01-30 08:57:57,188:INFO:SubProcess create_model() called ==================================
2026-01-30 08:57:57,189:INFO:Initializing create_model()
2026-01-30 08:57:57,189:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C28A7710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 08:57:57,189:INFO:Checking exceptions
2026-01-30 08:57:57,189:INFO:Importing libraries
2026-01-30 08:57:57,189:INFO:Copying training dataset
2026-01-30 08:57:57,319:INFO:Defining folds
2026-01-30 08:57:57,319:INFO:Declaring metric variables
2026-01-30 08:57:57,319:INFO:Importing untrained model
2026-01-30 08:57:57,319:INFO:Random Forest Classifier Imported successfully
2026-01-30 08:57:57,321:INFO:Starting cross validation
2026-01-30 08:57:57,321:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 08:58:09,085:INFO:Calculating mean and std
2026-01-30 08:58:09,089:INFO:Creating metrics dataframe
2026-01-30 08:58:09,091:INFO:Uploading results into container
2026-01-30 08:58:09,092:INFO:Uploading model into container now
2026-01-30 08:58:09,092:INFO:_master_model_container: 3
2026-01-30 08:58:09,092:INFO:_display_container: 2
2026-01-30 08:58:09,093:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 08:58:09,093:INFO:create_model() successfully completed......................................
2026-01-30 08:58:09,209:INFO:SubProcess create_model() end ==================================
2026-01-30 08:58:09,209:INFO:Creating metrics dataframe
2026-01-30 08:58:09,223:INFO:Initializing Light Gradient Boosting Machine
2026-01-30 08:58:09,223:INFO:Total runtime is 0.44102354447046915 minutes
2026-01-30 08:58:09,223:INFO:SubProcess create_model() called ==================================
2026-01-30 08:58:09,223:INFO:Initializing create_model()
2026-01-30 08:58:09,223:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C28A7710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 08:58:09,223:INFO:Checking exceptions
2026-01-30 08:58:09,223:INFO:Importing libraries
2026-01-30 08:58:09,223:INFO:Copying training dataset
2026-01-30 08:58:09,367:INFO:Defining folds
2026-01-30 08:58:09,367:INFO:Declaring metric variables
2026-01-30 08:58:09,367:INFO:Importing untrained model
2026-01-30 08:58:09,367:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 08:58:09,367:INFO:Starting cross validation
2026-01-30 08:58:09,367:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 08:58:17,273:INFO:Calculating mean and std
2026-01-30 08:58:17,273:INFO:Creating metrics dataframe
2026-01-30 08:58:17,273:INFO:Uploading results into container
2026-01-30 08:58:17,273:INFO:Uploading model into container now
2026-01-30 08:58:17,273:INFO:_master_model_container: 4
2026-01-30 08:58:17,273:INFO:_display_container: 2
2026-01-30 08:58:17,273:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 08:58:17,273:INFO:create_model() successfully completed......................................
2026-01-30 08:58:17,402:INFO:SubProcess create_model() end ==================================
2026-01-30 08:58:17,403:INFO:Creating metrics dataframe
2026-01-30 08:58:17,406:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-30 08:58:17,406:INFO:Initializing create_model()
2026-01-30 08:58:17,406:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 08:58:17,406:INFO:Checking exceptions
2026-01-30 08:58:17,406:INFO:Importing libraries
2026-01-30 08:58:17,406:INFO:Copying training dataset
2026-01-30 08:58:17,740:INFO:Defining folds
2026-01-30 08:58:17,740:INFO:Declaring metric variables
2026-01-30 08:58:17,740:INFO:Importing untrained model
2026-01-30 08:58:17,740:INFO:Declaring custom model
2026-01-30 08:58:17,740:INFO:Random Forest Classifier Imported successfully
2026-01-30 08:58:17,740:INFO:Cross validation set to False
2026-01-30 08:58:17,740:INFO:Fitting Model
2026-01-30 08:58:22,099:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 08:58:22,099:INFO:create_model() successfully completed......................................
2026-01-30 08:58:22,232:INFO:Initializing create_model()
2026-01-30 08:58:22,233:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 08:58:22,233:INFO:Checking exceptions
2026-01-30 08:58:22,234:INFO:Importing libraries
2026-01-30 08:58:22,234:INFO:Copying training dataset
2026-01-30 08:58:22,473:INFO:Defining folds
2026-01-30 08:58:22,473:INFO:Declaring metric variables
2026-01-30 08:58:22,473:INFO:Importing untrained model
2026-01-30 08:58:22,473:INFO:Declaring custom model
2026-01-30 08:58:22,473:INFO:Decision Tree Classifier Imported successfully
2026-01-30 08:58:22,473:INFO:Cross validation set to False
2026-01-30 08:58:22,473:INFO:Fitting Model
2026-01-30 08:58:23,772:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 08:58:23,772:INFO:create_model() successfully completed......................................
2026-01-30 08:58:23,906:INFO:Initializing create_model()
2026-01-30 08:58:23,906:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 08:58:23,906:INFO:Checking exceptions
2026-01-30 08:58:23,906:INFO:Importing libraries
2026-01-30 08:58:23,906:INFO:Copying training dataset
2026-01-30 08:58:24,072:INFO:Defining folds
2026-01-30 08:58:24,072:INFO:Declaring metric variables
2026-01-30 08:58:24,072:INFO:Importing untrained model
2026-01-30 08:58:24,072:INFO:Declaring custom model
2026-01-30 08:58:24,072:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 08:58:24,072:INFO:Cross validation set to False
2026-01-30 08:58:24,072:INFO:Fitting Model
2026-01-30 08:58:24,608:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 08:58:24,649:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009199 seconds.
2026-01-30 08:58:24,649:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 08:58:24,649:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 08:58:24,649:INFO:[LightGBM] [Info] Total Bins 1967
2026-01-30 08:58:24,649:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 19
2026-01-30 08:58:24,652:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 08:58:24,652:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 08:58:25,160:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 08:58:25,160:INFO:create_model() successfully completed......................................
2026-01-30 08:58:25,322:INFO:_master_model_container: 4
2026-01-30 08:58:25,322:INFO:_display_container: 2
2026-01-30 08:58:25,322:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)]
2026-01-30 08:58:25,322:INFO:compare_models() successfully completed......................................
2026-01-30 08:58:25,322:INFO:Initializing tune_model()
2026-01-30 08:58:25,322:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 08:58:25,322:INFO:Checking exceptions
2026-01-30 08:58:25,390:INFO:Copying training dataset
2026-01-30 08:58:25,514:INFO:Checking base model
2026-01-30 08:58:25,514:INFO:Base model : Random Forest Classifier
2026-01-30 08:58:25,515:INFO:Declaring metric variables
2026-01-30 08:58:25,516:INFO:Defining Hyperparameters
2026-01-30 08:58:25,643:INFO:Tuning with n_jobs=-1
2026-01-30 08:58:25,643:INFO:Initializing RandomizedSearchCV
2026-01-30 08:59:43,741:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-30 08:59:43,741:INFO:Hyperparameter search completed
2026-01-30 08:59:43,741:INFO:SubProcess create_model() called ==================================
2026-01-30 08:59:43,741:INFO:Initializing create_model()
2026-01-30 08:59:43,741:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A06D69FCD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': True})
2026-01-30 08:59:43,741:INFO:Checking exceptions
2026-01-30 08:59:43,741:INFO:Importing libraries
2026-01-30 08:59:43,741:INFO:Copying training dataset
2026-01-30 08:59:43,999:INFO:Defining folds
2026-01-30 08:59:43,999:INFO:Declaring metric variables
2026-01-30 08:59:43,999:INFO:Importing untrained model
2026-01-30 08:59:43,999:INFO:Declaring custom model
2026-01-30 08:59:44,004:INFO:Random Forest Classifier Imported successfully
2026-01-30 08:59:44,004:INFO:Starting cross validation
2026-01-30 08:59:44,006:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:00:04,177:INFO:Calculating mean and std
2026-01-30 09:00:04,177:INFO:Creating metrics dataframe
2026-01-30 09:00:04,190:INFO:Finalizing model
2026-01-30 09:00:16,415:INFO:Uploading results into container
2026-01-30 09:00:16,423:INFO:Uploading model into container now
2026-01-30 09:00:16,430:INFO:_master_model_container: 5
2026-01-30 09:00:16,431:INFO:_display_container: 3
2026-01-30 09:00:16,441:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:00:16,447:INFO:create_model() successfully completed......................................
2026-01-30 09:00:16,716:INFO:SubProcess create_model() end ==================================
2026-01-30 09:00:16,717:INFO:choose_better activated
2026-01-30 09:00:16,718:INFO:SubProcess create_model() called ==================================
2026-01-30 09:00:16,719:INFO:Initializing create_model()
2026-01-30 09:00:16,719:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:00:16,719:INFO:Checking exceptions
2026-01-30 09:00:16,721:INFO:Importing libraries
2026-01-30 09:00:16,721:INFO:Copying training dataset
2026-01-30 09:00:17,238:INFO:Defining folds
2026-01-30 09:00:17,238:INFO:Declaring metric variables
2026-01-30 09:00:17,239:INFO:Importing untrained model
2026-01-30 09:00:17,239:INFO:Declaring custom model
2026-01-30 09:00:17,240:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:00:17,241:INFO:Starting cross validation
2026-01-30 09:00:17,242:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:00:34,584:INFO:Calculating mean and std
2026-01-30 09:00:34,586:INFO:Creating metrics dataframe
2026-01-30 09:00:34,590:INFO:Finalizing model
2026-01-30 09:00:44,903:INFO:Uploading results into container
2026-01-30 09:00:44,905:INFO:Uploading model into container now
2026-01-30 09:00:44,905:INFO:_master_model_container: 6
2026-01-30 09:00:44,906:INFO:_display_container: 4
2026-01-30 09:00:44,907:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:00:44,907:INFO:create_model() successfully completed......................................
2026-01-30 09:00:45,137:INFO:SubProcess create_model() end ==================================
2026-01-30 09:00:45,138:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9993
2026-01-30 09:00:45,139:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9934
2026-01-30 09:00:45,140:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-30 09:00:45,140:INFO:choose_better completed
2026-01-30 09:00:45,140:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 09:00:45,145:INFO:_master_model_container: 6
2026-01-30 09:00:45,145:INFO:_display_container: 3
2026-01-30 09:00:45,145:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:00:45,146:INFO:tune_model() successfully completed......................................
2026-01-30 09:00:45,376:INFO:Initializing tune_model()
2026-01-30 09:00:45,376:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:00:45,377:INFO:Checking exceptions
2026-01-30 09:00:45,557:INFO:Copying training dataset
2026-01-30 09:00:45,883:INFO:Checking base model
2026-01-30 09:00:45,884:INFO:Base model : Decision Tree Classifier
2026-01-30 09:00:45,885:INFO:Declaring metric variables
2026-01-30 09:00:45,885:INFO:Defining Hyperparameters
2026-01-30 09:00:46,106:INFO:Tuning with n_jobs=-1
2026-01-30 09:00:46,106:INFO:Initializing RandomizedSearchCV
2026-01-30 09:00:57,353:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 15, 'actual_estimator__criterion': 'gini'}
2026-01-30 09:00:57,354:INFO:Hyperparameter search completed
2026-01-30 09:00:57,355:INFO:SubProcess create_model() called ==================================
2026-01-30 09:00:57,358:INFO:Initializing create_model()
2026-01-30 09:00:57,358:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A06E84A250>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 2, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 15, 'criterion': 'gini'})
2026-01-30 09:00:57,358:INFO:Checking exceptions
2026-01-30 09:00:57,359:INFO:Importing libraries
2026-01-30 09:00:57,359:INFO:Copying training dataset
2026-01-30 09:00:57,809:INFO:Defining folds
2026-01-30 09:00:57,810:INFO:Declaring metric variables
2026-01-30 09:00:57,810:INFO:Importing untrained model
2026-01-30 09:00:57,810:INFO:Declaring custom model
2026-01-30 09:00:57,811:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:00:57,811:INFO:Starting cross validation
2026-01-30 09:00:57,812:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:01:00,281:INFO:Calculating mean and std
2026-01-30 09:01:00,285:INFO:Creating metrics dataframe
2026-01-30 09:01:00,289:INFO:Finalizing model
2026-01-30 09:01:01,773:INFO:Uploading results into container
2026-01-30 09:01:01,774:INFO:Uploading model into container now
2026-01-30 09:01:01,775:INFO:_master_model_container: 7
2026-01-30 09:01:01,775:INFO:_display_container: 4
2026-01-30 09:01:01,776:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:01:01,776:INFO:create_model() successfully completed......................................
2026-01-30 09:01:01,993:INFO:SubProcess create_model() end ==================================
2026-01-30 09:01:01,993:INFO:choose_better activated
2026-01-30 09:01:01,995:INFO:SubProcess create_model() called ==================================
2026-01-30 09:01:01,995:INFO:Initializing create_model()
2026-01-30 09:01:01,995:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:01:01,997:INFO:Checking exceptions
2026-01-30 09:01:01,997:INFO:Importing libraries
2026-01-30 09:01:01,998:INFO:Copying training dataset
2026-01-30 09:01:02,388:INFO:Defining folds
2026-01-30 09:01:02,388:INFO:Declaring metric variables
2026-01-30 09:01:02,388:INFO:Importing untrained model
2026-01-30 09:01:02,389:INFO:Declaring custom model
2026-01-30 09:01:02,389:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:01:02,390:INFO:Starting cross validation
2026-01-30 09:01:02,391:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:01:04,980:INFO:Calculating mean and std
2026-01-30 09:01:04,981:INFO:Creating metrics dataframe
2026-01-30 09:01:04,983:INFO:Finalizing model
2026-01-30 09:01:07,011:INFO:Uploading results into container
2026-01-30 09:01:07,011:INFO:Uploading model into container now
2026-01-30 09:01:07,013:INFO:_master_model_container: 8
2026-01-30 09:01:07,013:INFO:_display_container: 5
2026-01-30 09:01:07,013:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:01:07,013:INFO:create_model() successfully completed......................................
2026-01-30 09:01:07,193:INFO:SubProcess create_model() end ==================================
2026-01-30 09:01:07,194:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9988
2026-01-30 09:01:07,194:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9876
2026-01-30 09:01:07,194:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-30 09:01:07,194:INFO:choose_better completed
2026-01-30 09:01:07,195:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 09:01:07,198:INFO:_master_model_container: 8
2026-01-30 09:01:07,198:INFO:_display_container: 4
2026-01-30 09:01:07,199:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:01:07,199:INFO:tune_model() successfully completed......................................
2026-01-30 09:01:07,369:INFO:Initializing tune_model()
2026-01-30 09:01:07,369:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:01:07,369:INFO:Checking exceptions
2026-01-30 09:01:07,510:INFO:Copying training dataset
2026-01-30 09:01:07,765:INFO:Checking base model
2026-01-30 09:01:07,766:INFO:Base model : Light Gradient Boosting Machine
2026-01-30 09:01:07,767:INFO:Declaring metric variables
2026-01-30 09:01:07,767:INFO:Defining Hyperparameters
2026-01-30 09:01:07,955:INFO:Tuning with n_jobs=-1
2026-01-30 09:01:07,956:INFO:Initializing RandomizedSearchCV
2026-01-30 09:02:50,262:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2026-01-30 09:02:50,264:INFO:Hyperparameter search completed
2026-01-30 09:02:50,264:INFO:SubProcess create_model() called ==================================
2026-01-30 09:02:50,267:INFO:Initializing create_model()
2026-01-30 09:02:50,267:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A06E54AC90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2026-01-30 09:02:50,267:INFO:Checking exceptions
2026-01-30 09:02:50,267:INFO:Importing libraries
2026-01-30 09:02:50,267:INFO:Copying training dataset
2026-01-30 09:02:50,798:INFO:Defining folds
2026-01-30 09:02:50,798:INFO:Declaring metric variables
2026-01-30 09:02:50,799:INFO:Importing untrained model
2026-01-30 09:02:50,799:INFO:Declaring custom model
2026-01-30 09:02:50,800:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:02:50,802:INFO:Starting cross validation
2026-01-30 09:02:50,804:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:03:17,057:INFO:Calculating mean and std
2026-01-30 09:03:17,059:INFO:Creating metrics dataframe
2026-01-30 09:03:17,062:INFO:Finalizing model
2026-01-30 09:03:17,824:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 09:03:17,824:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 09:03:17,824:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 09:03:18,485:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 09:03:18,486:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 09:03:18,487:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 09:03:18,493:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 09:03:18,661:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036028 seconds.
2026-01-30 09:03:18,661:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:03:18,661:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:03:18,662:INFO:[LightGBM] [Info] Total Bins 1967
2026-01-30 09:03:18,664:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 19
2026-01-30 09:03:18,676:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 09:03:18,676:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 09:03:25,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-01-30 09:03:25,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-01-30 09:03:25,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-01-30 09:03:26,769:INFO:Uploading results into container
2026-01-30 09:03:26,770:INFO:Uploading model into container now
2026-01-30 09:03:26,772:INFO:_master_model_container: 9
2026-01-30 09:03:26,773:INFO:_display_container: 5
2026-01-30 09:03:26,775:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:03:26,776:INFO:create_model() successfully completed......................................
2026-01-30 09:03:27,057:INFO:SubProcess create_model() end ==================================
2026-01-30 09:03:27,059:INFO:choose_better activated
2026-01-30 09:03:27,059:INFO:SubProcess create_model() called ==================================
2026-01-30 09:03:27,060:INFO:Initializing create_model()
2026-01-30 09:03:27,060:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:03:27,060:INFO:Checking exceptions
2026-01-30 09:03:27,062:INFO:Importing libraries
2026-01-30 09:03:27,062:INFO:Copying training dataset
2026-01-30 09:03:27,520:INFO:Defining folds
2026-01-30 09:03:27,520:INFO:Declaring metric variables
2026-01-30 09:03:27,520:INFO:Importing untrained model
2026-01-30 09:03:27,521:INFO:Declaring custom model
2026-01-30 09:03:27,523:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:03:27,523:INFO:Starting cross validation
2026-01-30 09:03:27,524:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:03:38,369:INFO:Calculating mean and std
2026-01-30 09:03:38,370:INFO:Creating metrics dataframe
2026-01-30 09:03:38,374:INFO:Finalizing model
2026-01-30 09:03:39,810:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 09:03:39,905:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023140 seconds.
2026-01-30 09:03:39,906:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:03:39,906:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:03:39,906:INFO:[LightGBM] [Info] Total Bins 1967
2026-01-30 09:03:39,908:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 19
2026-01-30 09:03:39,912:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 09:03:39,912:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 09:03:42,586:INFO:Uploading results into container
2026-01-30 09:03:42,587:INFO:Uploading model into container now
2026-01-30 09:03:42,588:INFO:_master_model_container: 10
2026-01-30 09:03:42,588:INFO:_display_container: 6
2026-01-30 09:03:42,590:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:03:42,590:INFO:create_model() successfully completed......................................
2026-01-30 09:03:42,843:INFO:SubProcess create_model() end ==================================
2026-01-30 09:03:42,846:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9966
2026-01-30 09:03:42,848:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9992
2026-01-30 09:03:42,849:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2026-01-30 09:03:42,849:INFO:choose_better completed
2026-01-30 09:03:42,856:INFO:_master_model_container: 10
2026-01-30 09:03:42,856:INFO:_display_container: 5
2026-01-30 09:03:42,858:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:03:42,858:INFO:tune_model() successfully completed......................................
2026-01-30 09:03:43,109:INFO:Initializing predict_model()
2026-01-30 09:03:43,110:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A01562A5C0>)
2026-01-30 09:03:43,110:INFO:Checking exceptions
2026-01-30 09:03:43,110:INFO:Preloading libraries
2026-01-30 09:03:43,110:INFO:Set up data.
2026-01-30 09:03:43,233:INFO:Set up index.
2026-01-30 09:03:46,032:INFO:Initializing predict_model()
2026-01-30 09:03:46,033:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A01562A5C0>)
2026-01-30 09:03:46,033:INFO:Checking exceptions
2026-01-30 09:03:46,033:INFO:Preloading libraries
2026-01-30 09:03:46,034:INFO:Set up data.
2026-01-30 09:03:46,102:INFO:Set up index.
2026-01-30 09:03:47,218:INFO:Initializing predict_model()
2026-01-30 09:03:47,218:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A03C546160>)
2026-01-30 09:03:47,219:INFO:Checking exceptions
2026-01-30 09:03:47,219:INFO:Preloading libraries
2026-01-30 09:03:47,219:INFO:Set up data.
2026-01-30 09:03:47,269:INFO:Set up index.
2026-01-30 09:03:49,802:INFO:Initializing plot_model()
2026-01-30 09:03:49,803:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 09:03:49,803:INFO:Checking exceptions
2026-01-30 09:03:50,212:INFO:Preloading libraries
2026-01-30 09:03:50,346:INFO:Copying training dataset
2026-01-30 09:03:50,346:INFO:Plot type: feature
2026-01-30 09:03:50,346:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 09:03:51,430:INFO:Visual Rendered Successfully
2026-01-30 09:03:51,639:INFO:plot_model() successfully completed......................................
2026-01-30 09:03:51,652:INFO:Initializing plot_model()
2026-01-30 09:03:51,652:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C515750>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature_all, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 09:03:51,652:INFO:Checking exceptions
2026-01-30 09:03:52,050:INFO:Preloading libraries
2026-01-30 09:03:52,174:INFO:Copying training dataset
2026-01-30 09:03:52,174:INFO:Plot type: feature_all
2026-01-30 09:03:52,636:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 09:03:53,616:INFO:Visual Rendered Successfully
2026-01-30 09:03:53,861:INFO:plot_model() successfully completed......................................
2026-01-30 09:03:53,888:INFO:Initializing save_model()
2026-01-30 09:03:53,889:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), model_name=..\datos\04. Modelos\modelo_final_explicable, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'MINIMUMPAYMENTPAYED',
                                             'PAID_PERCENT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'YEARPERSONBIRTHDATE',
                                             'PL_SI...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-30 09:03:53,889:INFO:Adding model into prep_pipe
2026-01-30 09:03:54,285:INFO:..\datos\04. Modelos\modelo_final_explicable.pkl saved in current working directory
2026-01-30 09:03:54,294:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'MINIMUMPAYMENTPAYED',
                                             'PAID_PERCENT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'YEARPERSONBIRTHDATE',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges_...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=42, verbose=0,
                                        warm_start=False))],
         verbose=False)
2026-01-30 09:03:54,294:INFO:save_model() successfully completed......................................
2026-01-30 09:11:22,347:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\2920816646.py:20: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-30 09:11:24,345:INFO:PyCaret ClassificationExperiment
2026-01-30 09:11:24,345:INFO:Logging name: clf-default-name
2026-01-30 09:11:24,345:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-30 09:11:24,345:INFO:version 3.3.2
2026-01-30 09:11:24,345:INFO:Initializing setup()
2026-01-30 09:11:24,345:INFO:self.USI: 3c14
2026-01-30 09:11:24,345:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'n_jobs_param', 'data', 'X', 'idx', 'y_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'USI', 'target_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'y_train', 'X_test', 'seed', 'gpu_param', 'gpu_n_jobs_param', 'y', 'logging_param', 'pipeline', 'fold_generator', 'exp_id'}
2026-01-30 09:11:24,345:INFO:Checking environment
2026-01-30 09:11:24,345:INFO:python_version: 3.11.11
2026-01-30 09:11:24,345:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-30 09:11:24,345:INFO:machine: AMD64
2026-01-30 09:11:24,345:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-30 09:11:24,345:INFO:Memory: svmem(total=34009374720, available=16202559488, percent=52.4, used=17806815232, free=16202559488)
2026-01-30 09:11:24,345:INFO:Physical Core: 12
2026-01-30 09:11:24,345:INFO:Logical Core: 16
2026-01-30 09:11:24,345:INFO:Checking libraries
2026-01-30 09:11:24,345:INFO:System:
2026-01-30 09:11:24,345:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-30 09:11:24,345:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-30 09:11:24,345:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-30 09:11:24,345:INFO:PyCaret required dependencies:
2026-01-30 09:11:24,345:INFO:                 pip: 25.0
2026-01-30 09:11:24,345:INFO:          setuptools: 75.8.0
2026-01-30 09:11:24,345:INFO:             pycaret: 3.3.2
2026-01-30 09:11:24,345:INFO:             IPython: 9.9.0
2026-01-30 09:11:24,345:INFO:          ipywidgets: 8.1.8
2026-01-30 09:11:24,345:INFO:                tqdm: 4.67.1
2026-01-30 09:11:24,345:INFO:               numpy: 1.26.4
2026-01-30 09:11:24,345:INFO:              pandas: 2.1.4
2026-01-30 09:11:24,345:INFO:              jinja2: 3.1.6
2026-01-30 09:11:24,345:INFO:               scipy: 1.11.4
2026-01-30 09:11:24,345:INFO:              joblib: 1.3.2
2026-01-30 09:11:24,345:INFO:             sklearn: 1.4.2
2026-01-30 09:11:24,345:INFO:                pyod: 2.0.6
2026-01-30 09:11:24,345:INFO:            imblearn: 0.14.1
2026-01-30 09:11:24,345:INFO:   category_encoders: 2.7.0
2026-01-30 09:11:24,345:INFO:            lightgbm: 4.6.0
2026-01-30 09:11:24,345:INFO:               numba: 0.62.1
2026-01-30 09:11:24,345:INFO:            requests: 2.32.3
2026-01-30 09:11:24,345:INFO:          matplotlib: 3.7.5
2026-01-30 09:11:24,345:INFO:          scikitplot: 0.3.7
2026-01-30 09:11:24,345:INFO:         yellowbrick: 1.5
2026-01-30 09:11:24,345:INFO:              plotly: 5.24.1
2026-01-30 09:11:24,345:INFO:    plotly-resampler: Not installed
2026-01-30 09:11:24,345:INFO:             kaleido: 1.2.0
2026-01-30 09:11:24,345:INFO:           schemdraw: 0.15
2026-01-30 09:11:24,345:INFO:         statsmodels: 0.14.6
2026-01-30 09:11:24,345:INFO:              sktime: 0.26.0
2026-01-30 09:11:24,345:INFO:               tbats: 1.1.3
2026-01-30 09:11:24,345:INFO:            pmdarima: 2.0.4
2026-01-30 09:11:24,345:INFO:              psutil: 7.2.1
2026-01-30 09:11:24,345:INFO:          markupsafe: 3.0.3
2026-01-30 09:11:24,345:INFO:             pickle5: Not installed
2026-01-30 09:11:24,345:INFO:         cloudpickle: 3.0.0
2026-01-30 09:11:24,345:INFO:         deprecation: 2.1.0
2026-01-30 09:11:24,345:INFO:              xxhash: 3.6.0
2026-01-30 09:11:24,345:INFO:           wurlitzer: Not installed
2026-01-30 09:11:24,345:INFO:PyCaret optional dependencies:
2026-01-30 09:11:24,345:INFO:                shap: 0.44.1
2026-01-30 09:11:24,345:INFO:           interpret: 0.7.3
2026-01-30 09:11:24,345:INFO:                umap: 0.5.7
2026-01-30 09:11:24,345:INFO:     ydata_profiling: 4.18.1
2026-01-30 09:11:24,345:INFO:  explainerdashboard: 0.5.1
2026-01-30 09:11:24,345:INFO:             autoviz: Not installed
2026-01-30 09:11:24,345:INFO:           fairlearn: 0.7.0
2026-01-30 09:11:24,345:INFO:          deepchecks: Not installed
2026-01-30 09:11:24,345:INFO:             xgboost: Not installed
2026-01-30 09:11:24,345:INFO:            catboost: 1.2.8
2026-01-30 09:11:24,345:INFO:              kmodes: 0.12.2
2026-01-30 09:11:24,345:INFO:             mlxtend: 0.23.4
2026-01-30 09:11:24,345:INFO:       statsforecast: 1.5.0
2026-01-30 09:11:24,345:INFO:        tune_sklearn: Not installed
2026-01-30 09:11:24,345:INFO:                 ray: Not installed
2026-01-30 09:11:24,345:INFO:            hyperopt: 0.2.7
2026-01-30 09:11:24,345:INFO:              optuna: 4.6.0
2026-01-30 09:11:24,345:INFO:               skopt: 0.10.2
2026-01-30 09:11:24,345:INFO:              mlflow: 3.8.1
2026-01-30 09:11:24,345:INFO:              gradio: 6.3.0
2026-01-30 09:11:24,345:INFO:             fastapi: 0.128.0
2026-01-30 09:11:24,345:INFO:             uvicorn: 0.40.0
2026-01-30 09:11:24,345:INFO:              m2cgen: 0.10.0
2026-01-30 09:11:24,345:INFO:           evidently: 0.4.40
2026-01-30 09:11:24,345:INFO:               fugue: 0.8.7
2026-01-30 09:11:24,345:INFO:           streamlit: Not installed
2026-01-30 09:11:24,345:INFO:             prophet: Not installed
2026-01-30 09:11:24,345:INFO:None
2026-01-30 09:11:24,345:INFO:Set up data.
2026-01-30 09:11:24,448:INFO:Set up folding strategy.
2026-01-30 09:11:24,449:INFO:Set up train/test split.
2026-01-30 09:11:24,608:INFO:Set up index.
2026-01-30 09:11:24,618:INFO:Assigning column types.
2026-01-30 09:11:24,717:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-30 09:11:24,743:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 09:11:24,744:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:11:24,761:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:11:24,761:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:11:24,787:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 09:11:24,788:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:11:24,795:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:11:24,795:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:11:24,795:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-30 09:11:24,828:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:11:24,846:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:11:24,847:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:11:24,862:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:11:24,886:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:11:24,886:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:11:24,886:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-30 09:11:24,928:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:11:24,928:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:11:24,965:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:11:24,965:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:11:24,965:INFO:Preparing preprocessing pipeline...
2026-01-30 09:11:24,987:INFO:Set up simple imputation.
2026-01-30 09:11:24,987:INFO:Set up feature normalization.
2026-01-30 09:11:25,195:INFO:Finished creating preprocessing pipeline.
2026-01-30 09:11:25,195:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'MINIMUMPAYMENTPAYED',
                                             'PAID_PERCENT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'YEARPERSONBIRTHDATE',
                                             'PL_SI...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-30 09:11:25,195:INFO:Creating final display dataframe.
2026-01-30 09:11:25,584:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape      (429278, 20)
4        Transformed data shape      (429278, 20)
5   Transformed train set shape      (300494, 20)
6    Transformed test set shape      (128784, 20)
7              Numeric features                15
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                 3
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              3c14
2026-01-30 09:11:25,618:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:11:25,618:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:11:25,668:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:11:25,668:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:11:25,670:INFO:setup() successfully completed in 1.33s...............
2026-01-30 09:11:25,670:INFO:Initializing compare_models()
2026-01-30 09:11:25,670:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-30 09:11:25,670:INFO:Checking exceptions
2026-01-30 09:11:25,762:INFO:Preparing display monitor
2026-01-30 09:11:25,762:INFO:Initializing Logistic Regression
2026-01-30 09:11:25,762:INFO:Total runtime is 0.0 minutes
2026-01-30 09:11:25,762:INFO:SubProcess create_model() called ==================================
2026-01-30 09:11:25,762:INFO:Initializing create_model()
2026-01-30 09:11:25,762:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03DDCEE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:11:25,762:INFO:Checking exceptions
2026-01-30 09:11:25,762:INFO:Importing libraries
2026-01-30 09:11:25,762:INFO:Copying training dataset
2026-01-30 09:11:25,930:INFO:Defining folds
2026-01-30 09:11:25,930:INFO:Declaring metric variables
2026-01-30 09:11:25,930:INFO:Importing untrained model
2026-01-30 09:11:25,930:INFO:Logistic Regression Imported successfully
2026-01-30 09:11:25,930:INFO:Starting cross validation
2026-01-30 09:11:25,930:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:11:33,531:INFO:Calculating mean and std
2026-01-30 09:11:33,531:INFO:Creating metrics dataframe
2026-01-30 09:11:33,531:INFO:Uploading results into container
2026-01-30 09:11:33,531:INFO:Uploading model into container now
2026-01-30 09:11:33,531:INFO:_master_model_container: 1
2026-01-30 09:11:33,531:INFO:_display_container: 2
2026-01-30 09:11:33,531:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-30 09:11:33,531:INFO:create_model() successfully completed......................................
2026-01-30 09:11:33,645:INFO:SubProcess create_model() end ==================================
2026-01-30 09:11:33,645:INFO:Creating metrics dataframe
2026-01-30 09:11:33,645:INFO:Initializing Decision Tree Classifier
2026-01-30 09:11:33,645:INFO:Total runtime is 0.13138734499613444 minutes
2026-01-30 09:11:33,645:INFO:SubProcess create_model() called ==================================
2026-01-30 09:11:33,645:INFO:Initializing create_model()
2026-01-30 09:11:33,645:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03DDCEE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:11:33,645:INFO:Checking exceptions
2026-01-30 09:11:33,645:INFO:Importing libraries
2026-01-30 09:11:33,645:INFO:Copying training dataset
2026-01-30 09:11:33,778:INFO:Defining folds
2026-01-30 09:11:33,778:INFO:Declaring metric variables
2026-01-30 09:11:33,778:INFO:Importing untrained model
2026-01-30 09:11:33,778:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:11:33,778:INFO:Starting cross validation
2026-01-30 09:11:33,778:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:11:38,720:INFO:Calculating mean and std
2026-01-30 09:11:38,720:INFO:Creating metrics dataframe
2026-01-30 09:11:38,720:INFO:Uploading results into container
2026-01-30 09:11:38,720:INFO:Uploading model into container now
2026-01-30 09:11:38,720:INFO:_master_model_container: 2
2026-01-30 09:11:38,727:INFO:_display_container: 2
2026-01-30 09:11:38,727:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:11:38,727:INFO:create_model() successfully completed......................................
2026-01-30 09:11:38,845:INFO:SubProcess create_model() end ==================================
2026-01-30 09:11:38,845:INFO:Creating metrics dataframe
2026-01-30 09:11:38,845:INFO:Initializing Random Forest Classifier
2026-01-30 09:11:38,845:INFO:Total runtime is 0.21805393298467002 minutes
2026-01-30 09:11:38,845:INFO:SubProcess create_model() called ==================================
2026-01-30 09:11:38,845:INFO:Initializing create_model()
2026-01-30 09:11:38,845:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03DDCEE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:11:38,845:INFO:Checking exceptions
2026-01-30 09:11:38,845:INFO:Importing libraries
2026-01-30 09:11:38,845:INFO:Copying training dataset
2026-01-30 09:11:38,978:INFO:Defining folds
2026-01-30 09:11:38,978:INFO:Declaring metric variables
2026-01-30 09:11:38,978:INFO:Importing untrained model
2026-01-30 09:11:38,978:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:11:38,978:INFO:Starting cross validation
2026-01-30 09:11:38,978:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:11:50,912:INFO:Calculating mean and std
2026-01-30 09:11:50,912:INFO:Creating metrics dataframe
2026-01-30 09:11:50,912:INFO:Uploading results into container
2026-01-30 09:11:50,912:INFO:Uploading model into container now
2026-01-30 09:11:50,912:INFO:_master_model_container: 3
2026-01-30 09:11:50,912:INFO:_display_container: 2
2026-01-30 09:11:50,912:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:11:50,912:INFO:create_model() successfully completed......................................
2026-01-30 09:11:51,031:INFO:SubProcess create_model() end ==================================
2026-01-30 09:11:51,031:INFO:Creating metrics dataframe
2026-01-30 09:11:51,031:INFO:Initializing Light Gradient Boosting Machine
2026-01-30 09:11:51,031:INFO:Total runtime is 0.42115186452865605 minutes
2026-01-30 09:11:51,044:INFO:SubProcess create_model() called ==================================
2026-01-30 09:11:51,044:INFO:Initializing create_model()
2026-01-30 09:11:51,044:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03DDCEE90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:11:51,044:INFO:Checking exceptions
2026-01-30 09:11:51,044:INFO:Importing libraries
2026-01-30 09:11:51,044:INFO:Copying training dataset
2026-01-30 09:11:51,178:INFO:Defining folds
2026-01-30 09:11:51,178:INFO:Declaring metric variables
2026-01-30 09:11:51,178:INFO:Importing untrained model
2026-01-30 09:11:51,178:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:11:51,178:INFO:Starting cross validation
2026-01-30 09:11:51,178:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:11:57,631:INFO:Calculating mean and std
2026-01-30 09:11:57,631:INFO:Creating metrics dataframe
2026-01-30 09:11:57,631:INFO:Uploading results into container
2026-01-30 09:11:57,631:INFO:Uploading model into container now
2026-01-30 09:11:57,631:INFO:_master_model_container: 4
2026-01-30 09:11:57,631:INFO:_display_container: 2
2026-01-30 09:11:57,631:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:11:57,631:INFO:create_model() successfully completed......................................
2026-01-30 09:11:57,744:INFO:SubProcess create_model() end ==================================
2026-01-30 09:11:57,744:INFO:Creating metrics dataframe
2026-01-30 09:11:57,760:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-30 09:11:57,761:INFO:Initializing create_model()
2026-01-30 09:11:57,761:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:11:57,761:INFO:Checking exceptions
2026-01-30 09:11:57,761:INFO:Importing libraries
2026-01-30 09:11:57,761:INFO:Copying training dataset
2026-01-30 09:11:57,894:INFO:Defining folds
2026-01-30 09:11:57,894:INFO:Declaring metric variables
2026-01-30 09:11:57,894:INFO:Importing untrained model
2026-01-30 09:11:57,894:INFO:Declaring custom model
2026-01-30 09:11:57,894:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:11:57,894:INFO:Cross validation set to False
2026-01-30 09:11:57,894:INFO:Fitting Model
2026-01-30 09:12:02,813:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:12:02,813:INFO:create_model() successfully completed......................................
2026-01-30 09:12:02,962:INFO:Initializing create_model()
2026-01-30 09:12:02,962:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:12:02,962:INFO:Checking exceptions
2026-01-30 09:12:02,962:INFO:Importing libraries
2026-01-30 09:12:02,962:INFO:Copying training dataset
2026-01-30 09:12:03,153:INFO:Defining folds
2026-01-30 09:12:03,153:INFO:Declaring metric variables
2026-01-30 09:12:03,153:INFO:Importing untrained model
2026-01-30 09:12:03,154:INFO:Declaring custom model
2026-01-30 09:12:03,154:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:12:03,155:INFO:Cross validation set to False
2026-01-30 09:12:03,155:INFO:Fitting Model
2026-01-30 09:12:04,494:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:12:04,494:INFO:create_model() successfully completed......................................
2026-01-30 09:12:04,695:INFO:Initializing create_model()
2026-01-30 09:12:04,695:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:12:04,695:INFO:Checking exceptions
2026-01-30 09:12:04,697:INFO:Importing libraries
2026-01-30 09:12:04,697:INFO:Copying training dataset
2026-01-30 09:12:04,881:INFO:Defining folds
2026-01-30 09:12:04,881:INFO:Declaring metric variables
2026-01-30 09:12:04,881:INFO:Importing untrained model
2026-01-30 09:12:04,881:INFO:Declaring custom model
2026-01-30 09:12:04,881:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:12:04,881:INFO:Cross validation set to False
2026-01-30 09:12:04,881:INFO:Fitting Model
2026-01-30 09:12:05,484:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 09:12:05,517:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007788 seconds.
2026-01-30 09:12:05,517:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:12:05,519:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:12:05,519:INFO:[LightGBM] [Info] Total Bins 1967
2026-01-30 09:12:05,519:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 19
2026-01-30 09:12:05,521:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 09:12:05,521:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 09:12:06,065:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:12:06,065:INFO:create_model() successfully completed......................................
2026-01-30 09:12:06,237:INFO:_master_model_container: 4
2026-01-30 09:12:06,237:INFO:_display_container: 2
2026-01-30 09:12:06,237:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)]
2026-01-30 09:12:06,237:INFO:compare_models() successfully completed......................................
2026-01-30 09:12:06,244:INFO:Initializing tune_model()
2026-01-30 09:12:06,244:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:12:06,244:INFO:Checking exceptions
2026-01-30 09:12:06,327:INFO:Copying training dataset
2026-01-30 09:12:06,461:INFO:Checking base model
2026-01-30 09:12:06,461:INFO:Base model : Random Forest Classifier
2026-01-30 09:12:06,461:INFO:Declaring metric variables
2026-01-30 09:12:06,461:INFO:Defining Hyperparameters
2026-01-30 09:12:06,611:INFO:Tuning with n_jobs=-1
2026-01-30 09:12:06,611:INFO:Initializing RandomizedSearchCV
2026-01-30 09:13:29,731:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-30 09:13:29,732:INFO:Hyperparameter search completed
2026-01-30 09:13:29,733:INFO:SubProcess create_model() called ==================================
2026-01-30 09:13:29,736:INFO:Initializing create_model()
2026-01-30 09:13:29,736:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A06E702090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': True})
2026-01-30 09:13:29,736:INFO:Checking exceptions
2026-01-30 09:13:29,736:INFO:Importing libraries
2026-01-30 09:13:29,736:INFO:Copying training dataset
2026-01-30 09:13:29,945:INFO:Defining folds
2026-01-30 09:13:29,945:INFO:Declaring metric variables
2026-01-30 09:13:29,945:INFO:Importing untrained model
2026-01-30 09:13:29,945:INFO:Declaring custom model
2026-01-30 09:13:29,945:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:13:29,945:INFO:Starting cross validation
2026-01-30 09:13:29,945:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:13:46,361:INFO:Calculating mean and std
2026-01-30 09:13:46,362:INFO:Creating metrics dataframe
2026-01-30 09:13:46,364:INFO:Finalizing model
2026-01-30 09:13:54,279:INFO:Uploading results into container
2026-01-30 09:13:54,279:INFO:Uploading model into container now
2026-01-30 09:13:54,279:INFO:_master_model_container: 5
2026-01-30 09:13:54,279:INFO:_display_container: 3
2026-01-30 09:13:54,279:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:13:54,279:INFO:create_model() successfully completed......................................
2026-01-30 09:13:54,410:INFO:SubProcess create_model() end ==================================
2026-01-30 09:13:54,410:INFO:choose_better activated
2026-01-30 09:13:54,410:INFO:SubProcess create_model() called ==================================
2026-01-30 09:13:54,410:INFO:Initializing create_model()
2026-01-30 09:13:54,410:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:13:54,410:INFO:Checking exceptions
2026-01-30 09:13:54,410:INFO:Importing libraries
2026-01-30 09:13:54,410:INFO:Copying training dataset
2026-01-30 09:13:54,565:INFO:Defining folds
2026-01-30 09:13:54,565:INFO:Declaring metric variables
2026-01-30 09:13:54,565:INFO:Importing untrained model
2026-01-30 09:13:54,565:INFO:Declaring custom model
2026-01-30 09:13:54,565:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:13:54,566:INFO:Starting cross validation
2026-01-30 09:13:54,566:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:14:04,937:INFO:Calculating mean and std
2026-01-30 09:14:04,937:INFO:Creating metrics dataframe
2026-01-30 09:14:04,937:INFO:Finalizing model
2026-01-30 09:14:09,803:INFO:Uploading results into container
2026-01-30 09:14:09,804:INFO:Uploading model into container now
2026-01-30 09:14:09,805:INFO:_master_model_container: 6
2026-01-30 09:14:09,805:INFO:_display_container: 4
2026-01-30 09:14:09,806:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:14:09,806:INFO:create_model() successfully completed......................................
2026-01-30 09:14:09,944:INFO:SubProcess create_model() end ==================================
2026-01-30 09:14:09,945:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9993
2026-01-30 09:14:09,945:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9934
2026-01-30 09:14:09,946:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-30 09:14:09,946:INFO:choose_better completed
2026-01-30 09:14:09,946:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 09:14:09,948:INFO:_master_model_container: 6
2026-01-30 09:14:09,948:INFO:_display_container: 3
2026-01-30 09:14:09,949:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:14:09,949:INFO:tune_model() successfully completed......................................
2026-01-30 09:14:10,079:INFO:Initializing tune_model()
2026-01-30 09:14:10,079:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:14:10,079:INFO:Checking exceptions
2026-01-30 09:14:10,126:INFO:Copying training dataset
2026-01-30 09:14:10,254:INFO:Checking base model
2026-01-30 09:14:10,254:INFO:Base model : Decision Tree Classifier
2026-01-30 09:14:10,254:INFO:Declaring metric variables
2026-01-30 09:14:10,254:INFO:Defining Hyperparameters
2026-01-30 09:14:10,376:INFO:Tuning with n_jobs=-1
2026-01-30 09:14:10,376:INFO:Initializing RandomizedSearchCV
2026-01-30 09:14:15,029:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 15, 'actual_estimator__criterion': 'gini'}
2026-01-30 09:14:15,031:INFO:Hyperparameter search completed
2026-01-30 09:14:15,031:INFO:SubProcess create_model() called ==================================
2026-01-30 09:14:15,031:INFO:Initializing create_model()
2026-01-30 09:14:15,031:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A06E4C1350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 2, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 15, 'criterion': 'gini'})
2026-01-30 09:14:15,031:INFO:Checking exceptions
2026-01-30 09:14:15,031:INFO:Importing libraries
2026-01-30 09:14:15,031:INFO:Copying training dataset
2026-01-30 09:14:15,216:INFO:Defining folds
2026-01-30 09:14:15,216:INFO:Declaring metric variables
2026-01-30 09:14:15,217:INFO:Importing untrained model
2026-01-30 09:14:15,217:INFO:Declaring custom model
2026-01-30 09:14:15,218:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:14:15,218:INFO:Starting cross validation
2026-01-30 09:14:15,219:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:14:16,901:INFO:Calculating mean and std
2026-01-30 09:14:16,903:INFO:Creating metrics dataframe
2026-01-30 09:14:16,906:INFO:Finalizing model
2026-01-30 09:14:17,783:INFO:Uploading results into container
2026-01-30 09:14:17,784:INFO:Uploading model into container now
2026-01-30 09:14:17,784:INFO:_master_model_container: 7
2026-01-30 09:14:17,784:INFO:_display_container: 4
2026-01-30 09:14:17,785:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:14:17,785:INFO:create_model() successfully completed......................................
2026-01-30 09:14:17,909:INFO:SubProcess create_model() end ==================================
2026-01-30 09:14:17,915:INFO:choose_better activated
2026-01-30 09:14:17,915:INFO:SubProcess create_model() called ==================================
2026-01-30 09:14:17,915:INFO:Initializing create_model()
2026-01-30 09:14:17,915:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:14:17,915:INFO:Checking exceptions
2026-01-30 09:14:17,915:INFO:Importing libraries
2026-01-30 09:14:17,915:INFO:Copying training dataset
2026-01-30 09:14:18,064:INFO:Defining folds
2026-01-30 09:14:18,064:INFO:Declaring metric variables
2026-01-30 09:14:18,064:INFO:Importing untrained model
2026-01-30 09:14:18,064:INFO:Declaring custom model
2026-01-30 09:14:18,064:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:14:18,064:INFO:Starting cross validation
2026-01-30 09:14:18,075:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:14:20,164:INFO:Calculating mean and std
2026-01-30 09:14:20,165:INFO:Creating metrics dataframe
2026-01-30 09:14:20,166:INFO:Finalizing model
2026-01-30 09:14:21,429:INFO:Uploading results into container
2026-01-30 09:14:21,429:INFO:Uploading model into container now
2026-01-30 09:14:21,429:INFO:_master_model_container: 8
2026-01-30 09:14:21,429:INFO:_display_container: 5
2026-01-30 09:14:21,429:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:14:21,429:INFO:create_model() successfully completed......................................
2026-01-30 09:14:21,557:INFO:SubProcess create_model() end ==================================
2026-01-30 09:14:21,558:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9988
2026-01-30 09:14:21,559:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9876
2026-01-30 09:14:21,559:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-30 09:14:21,559:INFO:choose_better completed
2026-01-30 09:14:21,559:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 09:14:21,563:INFO:_master_model_container: 8
2026-01-30 09:14:21,563:INFO:_display_container: 4
2026-01-30 09:14:21,563:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:14:21,563:INFO:tune_model() successfully completed......................................
2026-01-30 09:14:21,684:INFO:Initializing tune_model()
2026-01-30 09:14:21,684:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:14:21,684:INFO:Checking exceptions
2026-01-30 09:14:21,747:INFO:Copying training dataset
2026-01-30 09:14:21,867:INFO:Checking base model
2026-01-30 09:14:21,868:INFO:Base model : Light Gradient Boosting Machine
2026-01-30 09:14:21,868:INFO:Declaring metric variables
2026-01-30 09:14:21,869:INFO:Defining Hyperparameters
2026-01-30 09:14:21,975:INFO:Tuning with n_jobs=-1
2026-01-30 09:14:21,975:INFO:Initializing RandomizedSearchCV
2026-01-30 09:14:53,219:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2026-01-30 09:14:53,219:INFO:Hyperparameter search completed
2026-01-30 09:14:53,225:INFO:SubProcess create_model() called ==================================
2026-01-30 09:14:53,226:INFO:Initializing create_model()
2026-01-30 09:14:53,226:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C8B3D810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2026-01-30 09:14:53,226:INFO:Checking exceptions
2026-01-30 09:14:53,226:INFO:Importing libraries
2026-01-30 09:14:53,227:INFO:Copying training dataset
2026-01-30 09:14:53,410:INFO:Defining folds
2026-01-30 09:14:53,410:INFO:Declaring metric variables
2026-01-30 09:14:53,410:INFO:Importing untrained model
2026-01-30 09:14:53,410:INFO:Declaring custom model
2026-01-30 09:14:53,410:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:14:53,410:INFO:Starting cross validation
2026-01-30 09:14:53,410:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:15:02,138:INFO:Calculating mean and std
2026-01-30 09:15:02,142:INFO:Creating metrics dataframe
2026-01-30 09:15:02,146:INFO:Finalizing model
2026-01-30 09:15:02,511:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 09:15:02,511:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 09:15:02,511:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 09:15:02,674:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 09:15:02,674:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 09:15:02,674:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 09:15:02,675:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 09:15:02,713:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006680 seconds.
2026-01-30 09:15:02,713:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:15:02,713:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:15:02,714:INFO:[LightGBM] [Info] Total Bins 1967
2026-01-30 09:15:02,715:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 19
2026-01-30 09:15:02,718:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 09:15:02,718:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 09:15:04,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-01-30 09:15:04,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-01-30 09:15:05,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-01-30 09:15:05,318:INFO:Uploading results into container
2026-01-30 09:15:05,319:INFO:Uploading model into container now
2026-01-30 09:15:05,320:INFO:_master_model_container: 9
2026-01-30 09:15:05,321:INFO:_display_container: 5
2026-01-30 09:15:05,322:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:15:05,323:INFO:create_model() successfully completed......................................
2026-01-30 09:15:05,510:INFO:SubProcess create_model() end ==================================
2026-01-30 09:15:05,510:INFO:choose_better activated
2026-01-30 09:15:05,510:INFO:SubProcess create_model() called ==================================
2026-01-30 09:15:05,510:INFO:Initializing create_model()
2026-01-30 09:15:05,510:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:15:05,510:INFO:Checking exceptions
2026-01-30 09:15:05,512:INFO:Importing libraries
2026-01-30 09:15:05,512:INFO:Copying training dataset
2026-01-30 09:15:05,698:INFO:Defining folds
2026-01-30 09:15:05,699:INFO:Declaring metric variables
2026-01-30 09:15:05,699:INFO:Importing untrained model
2026-01-30 09:15:05,699:INFO:Declaring custom model
2026-01-30 09:15:05,700:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:15:05,700:INFO:Starting cross validation
2026-01-30 09:15:05,700:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:15:10,180:INFO:Calculating mean and std
2026-01-30 09:15:10,180:INFO:Creating metrics dataframe
2026-01-30 09:15:10,182:INFO:Finalizing model
2026-01-30 09:15:10,714:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 09:15:10,746:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006799 seconds.
2026-01-30 09:15:10,746:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:15:10,746:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:15:10,746:INFO:[LightGBM] [Info] Total Bins 1967
2026-01-30 09:15:10,747:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 19
2026-01-30 09:15:10,749:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 09:15:10,749:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 09:15:11,521:INFO:Uploading results into container
2026-01-30 09:15:11,521:INFO:Uploading model into container now
2026-01-30 09:15:11,523:INFO:_master_model_container: 10
2026-01-30 09:15:11,523:INFO:_display_container: 6
2026-01-30 09:15:11,524:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:15:11,525:INFO:create_model() successfully completed......................................
2026-01-30 09:15:11,709:INFO:SubProcess create_model() end ==================================
2026-01-30 09:15:11,713:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9966
2026-01-30 09:15:11,713:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9992
2026-01-30 09:15:11,713:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2026-01-30 09:15:11,713:INFO:choose_better completed
2026-01-30 09:15:11,718:INFO:_master_model_container: 10
2026-01-30 09:15:11,718:INFO:_display_container: 5
2026-01-30 09:15:11,718:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:15:11,718:INFO:tune_model() successfully completed......................................
2026-01-30 09:15:11,893:INFO:Initializing predict_model()
2026-01-30 09:15:11,907:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A0D01FAF20>)
2026-01-30 09:15:11,907:INFO:Checking exceptions
2026-01-30 09:15:11,907:INFO:Preloading libraries
2026-01-30 09:15:11,907:INFO:Set up data.
2026-01-30 09:15:11,925:INFO:Set up index.
2026-01-30 09:15:12,810:INFO:Initializing predict_model()
2026-01-30 09:15:12,810:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A06E850F40>)
2026-01-30 09:15:12,810:INFO:Checking exceptions
2026-01-30 09:15:12,810:INFO:Preloading libraries
2026-01-30 09:15:12,811:INFO:Set up data.
2026-01-30 09:15:12,826:INFO:Set up index.
2026-01-30 09:15:13,291:INFO:Initializing predict_model()
2026-01-30 09:15:13,291:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A06E7DB100>)
2026-01-30 09:15:13,291:INFO:Checking exceptions
2026-01-30 09:15:13,291:INFO:Preloading libraries
2026-01-30 09:15:13,291:INFO:Set up data.
2026-01-30 09:15:13,327:INFO:Set up index.
2026-01-30 09:15:14,342:INFO:Initializing plot_model()
2026-01-30 09:15:14,342:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 09:15:14,342:INFO:Checking exceptions
2026-01-30 09:15:14,430:INFO:Preloading libraries
2026-01-30 09:15:14,463:INFO:Copying training dataset
2026-01-30 09:15:14,464:INFO:Plot type: feature
2026-01-30 09:15:14,464:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 09:15:14,709:INFO:Visual Rendered Successfully
2026-01-30 09:15:14,826:INFO:plot_model() successfully completed......................................
2026-01-30 09:15:14,847:INFO:Initializing plot_model()
2026-01-30 09:15:14,847:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C3A4050>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature_all, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 09:15:14,847:INFO:Checking exceptions
2026-01-30 09:15:14,925:INFO:Preloading libraries
2026-01-30 09:15:14,964:INFO:Copying training dataset
2026-01-30 09:15:14,964:INFO:Plot type: feature_all
2026-01-30 09:15:15,089:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 09:15:15,392:INFO:Visual Rendered Successfully
2026-01-30 09:15:15,511:INFO:plot_model() successfully completed......................................
2026-01-30 09:15:15,524:INFO:Initializing save_model()
2026-01-30 09:15:15,524:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), model_name=..\datos\04. Modelos\modelo_final_explicable, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'MINIMUMPAYMENTPAYED',
                                             'PAID_PERCENT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'YEARPERSONBIRTHDATE',
                                             'PL_SI...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-30 09:15:15,524:INFO:Adding model into prep_pipe
2026-01-30 09:15:15,641:INFO:..\datos\04. Modelos\modelo_final_explicable.pkl saved in current working directory
2026-01-30 09:15:15,646:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'MINIMUMPAYMENTPAYED',
                                             'PAID_PERCENT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'YEARPERSONBIRTHDATE',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges_...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=42, verbose=0,
                                        warm_start=False))],
         verbose=False)
2026-01-30 09:15:15,646:INFO:save_model() successfully completed......................................
2026-01-30 09:17:59,181:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\729519084.py:23: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-30 09:18:01,251:INFO:PyCaret ClassificationExperiment
2026-01-30 09:18:01,251:INFO:Logging name: clf-default-name
2026-01-30 09:18:01,252:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-30 09:18:01,252:INFO:version 3.3.2
2026-01-30 09:18:01,252:INFO:Initializing setup()
2026-01-30 09:18:01,252:INFO:self.USI: 66cd
2026-01-30 09:18:01,252:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'n_jobs_param', 'data', 'X', 'idx', 'y_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'USI', 'target_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'y_train', 'X_test', 'seed', 'gpu_param', 'gpu_n_jobs_param', 'y', 'logging_param', 'pipeline', 'fold_generator', 'exp_id'}
2026-01-30 09:18:01,252:INFO:Checking environment
2026-01-30 09:18:01,253:INFO:python_version: 3.11.11
2026-01-30 09:18:01,254:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-30 09:18:01,254:INFO:machine: AMD64
2026-01-30 09:18:01,254:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-30 09:18:01,254:INFO:Memory: svmem(total=34009374720, available=12782919680, percent=62.4, used=21226455040, free=12782919680)
2026-01-30 09:18:01,254:INFO:Physical Core: 12
2026-01-30 09:18:01,254:INFO:Logical Core: 16
2026-01-30 09:18:01,254:INFO:Checking libraries
2026-01-30 09:18:01,254:INFO:System:
2026-01-30 09:18:01,254:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-30 09:18:01,254:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-30 09:18:01,254:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-30 09:18:01,254:INFO:PyCaret required dependencies:
2026-01-30 09:18:01,254:INFO:                 pip: 25.0
2026-01-30 09:18:01,254:INFO:          setuptools: 75.8.0
2026-01-30 09:18:01,255:INFO:             pycaret: 3.3.2
2026-01-30 09:18:01,255:INFO:             IPython: 9.9.0
2026-01-30 09:18:01,255:INFO:          ipywidgets: 8.1.8
2026-01-30 09:18:01,255:INFO:                tqdm: 4.67.1
2026-01-30 09:18:01,255:INFO:               numpy: 1.26.4
2026-01-30 09:18:01,255:INFO:              pandas: 2.1.4
2026-01-30 09:18:01,255:INFO:              jinja2: 3.1.6
2026-01-30 09:18:01,255:INFO:               scipy: 1.11.4
2026-01-30 09:18:01,255:INFO:              joblib: 1.3.2
2026-01-30 09:18:01,255:INFO:             sklearn: 1.4.2
2026-01-30 09:18:01,255:INFO:                pyod: 2.0.6
2026-01-30 09:18:01,255:INFO:            imblearn: 0.14.1
2026-01-30 09:18:01,255:INFO:   category_encoders: 2.7.0
2026-01-30 09:18:01,255:INFO:            lightgbm: 4.6.0
2026-01-30 09:18:01,255:INFO:               numba: 0.62.1
2026-01-30 09:18:01,255:INFO:            requests: 2.32.3
2026-01-30 09:18:01,255:INFO:          matplotlib: 3.7.5
2026-01-30 09:18:01,255:INFO:          scikitplot: 0.3.7
2026-01-30 09:18:01,255:INFO:         yellowbrick: 1.5
2026-01-30 09:18:01,255:INFO:              plotly: 5.24.1
2026-01-30 09:18:01,255:INFO:    plotly-resampler: Not installed
2026-01-30 09:18:01,255:INFO:             kaleido: 1.2.0
2026-01-30 09:18:01,255:INFO:           schemdraw: 0.15
2026-01-30 09:18:01,255:INFO:         statsmodels: 0.14.6
2026-01-30 09:18:01,255:INFO:              sktime: 0.26.0
2026-01-30 09:18:01,255:INFO:               tbats: 1.1.3
2026-01-30 09:18:01,255:INFO:            pmdarima: 2.0.4
2026-01-30 09:18:01,255:INFO:              psutil: 7.2.1
2026-01-30 09:18:01,255:INFO:          markupsafe: 3.0.3
2026-01-30 09:18:01,255:INFO:             pickle5: Not installed
2026-01-30 09:18:01,255:INFO:         cloudpickle: 3.0.0
2026-01-30 09:18:01,256:INFO:         deprecation: 2.1.0
2026-01-30 09:18:01,256:INFO:              xxhash: 3.6.0
2026-01-30 09:18:01,256:INFO:           wurlitzer: Not installed
2026-01-30 09:18:01,256:INFO:PyCaret optional dependencies:
2026-01-30 09:18:01,256:INFO:                shap: 0.44.1
2026-01-30 09:18:01,257:INFO:           interpret: 0.7.3
2026-01-30 09:18:01,257:INFO:                umap: 0.5.7
2026-01-30 09:18:01,257:INFO:     ydata_profiling: 4.18.1
2026-01-30 09:18:01,257:INFO:  explainerdashboard: 0.5.1
2026-01-30 09:18:01,257:INFO:             autoviz: Not installed
2026-01-30 09:18:01,257:INFO:           fairlearn: 0.7.0
2026-01-30 09:18:01,257:INFO:          deepchecks: Not installed
2026-01-30 09:18:01,257:INFO:             xgboost: Not installed
2026-01-30 09:18:01,257:INFO:            catboost: 1.2.8
2026-01-30 09:18:01,257:INFO:              kmodes: 0.12.2
2026-01-30 09:18:01,257:INFO:             mlxtend: 0.23.4
2026-01-30 09:18:01,257:INFO:       statsforecast: 1.5.0
2026-01-30 09:18:01,257:INFO:        tune_sklearn: Not installed
2026-01-30 09:18:01,257:INFO:                 ray: Not installed
2026-01-30 09:18:01,257:INFO:            hyperopt: 0.2.7
2026-01-30 09:18:01,257:INFO:              optuna: 4.6.0
2026-01-30 09:18:01,257:INFO:               skopt: 0.10.2
2026-01-30 09:18:01,257:INFO:              mlflow: 3.8.1
2026-01-30 09:18:01,258:INFO:              gradio: 6.3.0
2026-01-30 09:18:01,259:INFO:             fastapi: 0.128.0
2026-01-30 09:18:01,259:INFO:             uvicorn: 0.40.0
2026-01-30 09:18:01,259:INFO:              m2cgen: 0.10.0
2026-01-30 09:18:01,259:INFO:           evidently: 0.4.40
2026-01-30 09:18:01,259:INFO:               fugue: 0.8.7
2026-01-30 09:18:01,259:INFO:           streamlit: Not installed
2026-01-30 09:18:01,259:INFO:             prophet: Not installed
2026-01-30 09:18:01,259:INFO:None
2026-01-30 09:18:01,260:INFO:Set up data.
2026-01-30 09:18:01,371:INFO:Set up folding strategy.
2026-01-30 09:18:01,371:INFO:Set up train/test split.
2026-01-30 09:18:01,551:INFO:Set up index.
2026-01-30 09:18:01,561:INFO:Assigning column types.
2026-01-30 09:18:01,666:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-30 09:18:01,696:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 09:18:01,697:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:18:01,709:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:18:01,709:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:18:01,741:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 09:18:01,742:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:18:01,758:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:18:01,758:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:18:01,758:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-30 09:18:01,773:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:18:01,802:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:18:01,802:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:18:01,831:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:18:01,848:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:18:01,848:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:18:01,849:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-30 09:18:01,893:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:18:01,893:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:18:01,937:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:18:01,937:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:18:01,938:INFO:Preparing preprocessing pipeline...
2026-01-30 09:18:01,957:INFO:Set up simple imputation.
2026-01-30 09:18:01,957:INFO:Set up feature normalization.
2026-01-30 09:18:02,188:INFO:Finished creating preprocessing pipeline.
2026-01-30 09:18:02,190:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'MINIMUMPAYMENTPAYED',
                                             'PAID_PERCENT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'YEARPERSONBIRTHDATE',
                                             'PL_SI...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-30 09:18:02,190:INFO:Creating final display dataframe.
2026-01-30 09:18:02,586:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape      (429278, 20)
4        Transformed data shape      (429278, 20)
5   Transformed train set shape      (300494, 20)
6    Transformed test set shape      (128784, 20)
7              Numeric features                15
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                 3
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              66cd
2026-01-30 09:18:02,630:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:18:02,630:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:18:02,678:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:18:02,678:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:18:02,680:INFO:setup() successfully completed in 1.44s...............
2026-01-30 09:18:02,680:INFO:Initializing compare_models()
2026-01-30 09:18:02,680:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-30 09:18:02,680:INFO:Checking exceptions
2026-01-30 09:18:02,793:INFO:Preparing display monitor
2026-01-30 09:18:02,793:INFO:Initializing Logistic Regression
2026-01-30 09:18:02,793:INFO:Total runtime is 0.0 minutes
2026-01-30 09:18:02,793:INFO:SubProcess create_model() called ==================================
2026-01-30 09:18:02,793:INFO:Initializing create_model()
2026-01-30 09:18:02,793:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C71A0490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:18:02,793:INFO:Checking exceptions
2026-01-30 09:18:02,793:INFO:Importing libraries
2026-01-30 09:18:02,793:INFO:Copying training dataset
2026-01-30 09:18:03,006:INFO:Defining folds
2026-01-30 09:18:03,006:INFO:Declaring metric variables
2026-01-30 09:18:03,006:INFO:Importing untrained model
2026-01-30 09:18:03,006:INFO:Logistic Regression Imported successfully
2026-01-30 09:18:03,006:INFO:Starting cross validation
2026-01-30 09:18:03,006:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:18:05,182:INFO:Calculating mean and std
2026-01-30 09:18:05,183:INFO:Creating metrics dataframe
2026-01-30 09:18:05,185:INFO:Uploading results into container
2026-01-30 09:18:05,185:INFO:Uploading model into container now
2026-01-30 09:18:05,186:INFO:_master_model_container: 1
2026-01-30 09:18:05,186:INFO:_display_container: 2
2026-01-30 09:18:05,187:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-30 09:18:05,187:INFO:create_model() successfully completed......................................
2026-01-30 09:18:05,389:INFO:SubProcess create_model() end ==================================
2026-01-30 09:18:05,389:INFO:Creating metrics dataframe
2026-01-30 09:18:05,389:INFO:Initializing Decision Tree Classifier
2026-01-30 09:18:05,389:INFO:Total runtime is 0.043268076578776044 minutes
2026-01-30 09:18:05,389:INFO:SubProcess create_model() called ==================================
2026-01-30 09:18:05,389:INFO:Initializing create_model()
2026-01-30 09:18:05,389:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C71A0490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:18:05,389:INFO:Checking exceptions
2026-01-30 09:18:05,389:INFO:Importing libraries
2026-01-30 09:18:05,389:INFO:Copying training dataset
2026-01-30 09:18:05,590:INFO:Defining folds
2026-01-30 09:18:05,606:INFO:Declaring metric variables
2026-01-30 09:18:05,606:INFO:Importing untrained model
2026-01-30 09:18:05,606:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:18:05,606:INFO:Starting cross validation
2026-01-30 09:18:05,608:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:18:07,669:INFO:Calculating mean and std
2026-01-30 09:18:07,672:INFO:Creating metrics dataframe
2026-01-30 09:18:07,676:INFO:Uploading results into container
2026-01-30 09:18:07,676:INFO:Uploading model into container now
2026-01-30 09:18:07,676:INFO:_master_model_container: 2
2026-01-30 09:18:07,676:INFO:_display_container: 2
2026-01-30 09:18:07,676:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:18:07,676:INFO:create_model() successfully completed......................................
2026-01-30 09:18:07,810:INFO:SubProcess create_model() end ==================================
2026-01-30 09:18:07,810:INFO:Creating metrics dataframe
2026-01-30 09:18:07,812:INFO:Initializing Random Forest Classifier
2026-01-30 09:18:07,812:INFO:Total runtime is 0.08364590803782146 minutes
2026-01-30 09:18:07,813:INFO:SubProcess create_model() called ==================================
2026-01-30 09:18:07,813:INFO:Initializing create_model()
2026-01-30 09:18:07,813:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C71A0490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:18:07,813:INFO:Checking exceptions
2026-01-30 09:18:07,813:INFO:Importing libraries
2026-01-30 09:18:07,813:INFO:Copying training dataset
2026-01-30 09:18:07,960:INFO:Defining folds
2026-01-30 09:18:07,960:INFO:Declaring metric variables
2026-01-30 09:18:07,960:INFO:Importing untrained model
2026-01-30 09:18:07,960:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:18:07,960:INFO:Starting cross validation
2026-01-30 09:18:07,960:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:18:17,590:INFO:Calculating mean and std
2026-01-30 09:18:17,593:INFO:Creating metrics dataframe
2026-01-30 09:18:17,596:INFO:Uploading results into container
2026-01-30 09:18:17,597:INFO:Uploading model into container now
2026-01-30 09:18:17,597:INFO:_master_model_container: 3
2026-01-30 09:18:17,599:INFO:_display_container: 2
2026-01-30 09:18:17,599:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:18:17,600:INFO:create_model() successfully completed......................................
2026-01-30 09:18:17,755:INFO:SubProcess create_model() end ==================================
2026-01-30 09:18:17,756:INFO:Creating metrics dataframe
2026-01-30 09:18:17,758:INFO:Initializing Light Gradient Boosting Machine
2026-01-30 09:18:17,758:INFO:Total runtime is 0.2494127074877421 minutes
2026-01-30 09:18:17,758:INFO:SubProcess create_model() called ==================================
2026-01-30 09:18:17,759:INFO:Initializing create_model()
2026-01-30 09:18:17,759:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C71A0490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:18:17,759:INFO:Checking exceptions
2026-01-30 09:18:17,759:INFO:Importing libraries
2026-01-30 09:18:17,759:INFO:Copying training dataset
2026-01-30 09:18:17,972:INFO:Defining folds
2026-01-30 09:18:17,972:INFO:Declaring metric variables
2026-01-30 09:18:17,972:INFO:Importing untrained model
2026-01-30 09:18:17,972:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:18:17,972:INFO:Starting cross validation
2026-01-30 09:18:17,972:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:18:20,815:INFO:Calculating mean and std
2026-01-30 09:18:20,815:INFO:Creating metrics dataframe
2026-01-30 09:18:20,815:INFO:Uploading results into container
2026-01-30 09:18:20,815:INFO:Uploading model into container now
2026-01-30 09:18:20,815:INFO:_master_model_container: 4
2026-01-30 09:18:20,815:INFO:_display_container: 2
2026-01-30 09:18:20,821:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:18:20,821:INFO:create_model() successfully completed......................................
2026-01-30 09:18:20,973:INFO:SubProcess create_model() end ==================================
2026-01-30 09:18:20,973:INFO:Creating metrics dataframe
2026-01-30 09:18:20,988:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-30 09:18:20,991:INFO:Initializing create_model()
2026-01-30 09:18:20,991:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:18:20,991:INFO:Checking exceptions
2026-01-30 09:18:20,992:INFO:Importing libraries
2026-01-30 09:18:20,992:INFO:Copying training dataset
2026-01-30 09:18:21,266:INFO:Defining folds
2026-01-30 09:18:21,267:INFO:Declaring metric variables
2026-01-30 09:18:21,267:INFO:Importing untrained model
2026-01-30 09:18:21,267:INFO:Declaring custom model
2026-01-30 09:18:21,268:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:18:21,268:INFO:Cross validation set to False
2026-01-30 09:18:21,268:INFO:Fitting Model
2026-01-30 09:18:25,677:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:18:25,677:INFO:create_model() successfully completed......................................
2026-01-30 09:18:25,809:INFO:Initializing create_model()
2026-01-30 09:18:25,809:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:18:25,809:INFO:Checking exceptions
2026-01-30 09:18:25,809:INFO:Importing libraries
2026-01-30 09:18:25,809:INFO:Copying training dataset
2026-01-30 09:18:25,956:INFO:Defining folds
2026-01-30 09:18:25,956:INFO:Declaring metric variables
2026-01-30 09:18:25,956:INFO:Importing untrained model
2026-01-30 09:18:25,956:INFO:Declaring custom model
2026-01-30 09:18:25,956:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:18:25,956:INFO:Cross validation set to False
2026-01-30 09:18:25,956:INFO:Fitting Model
2026-01-30 09:18:27,181:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:18:27,181:INFO:create_model() successfully completed......................................
2026-01-30 09:18:27,327:INFO:Initializing create_model()
2026-01-30 09:18:27,328:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:18:27,328:INFO:Checking exceptions
2026-01-30 09:18:27,328:INFO:Importing libraries
2026-01-30 09:18:27,328:INFO:Copying training dataset
2026-01-30 09:18:27,503:INFO:Defining folds
2026-01-30 09:18:27,504:INFO:Declaring metric variables
2026-01-30 09:18:27,504:INFO:Importing untrained model
2026-01-30 09:18:27,504:INFO:Declaring custom model
2026-01-30 09:18:27,506:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:18:27,506:INFO:Cross validation set to False
2026-01-30 09:18:27,506:INFO:Fitting Model
2026-01-30 09:18:28,026:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 09:18:28,059:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005837 seconds.
2026-01-30 09:18:28,059:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:18:28,059:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:18:28,059:INFO:[LightGBM] [Info] Total Bins 1967
2026-01-30 09:18:28,060:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 19
2026-01-30 09:18:28,062:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 09:18:28,062:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 09:18:28,556:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:18:28,557:INFO:create_model() successfully completed......................................
2026-01-30 09:18:28,731:INFO:_master_model_container: 4
2026-01-30 09:18:28,732:INFO:_display_container: 2
2026-01-30 09:18:28,733:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)]
2026-01-30 09:18:28,733:INFO:compare_models() successfully completed......................................
2026-01-30 09:18:28,739:INFO:Initializing tune_model()
2026-01-30 09:18:28,739:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:18:28,739:INFO:Checking exceptions
2026-01-30 09:18:28,808:INFO:Copying training dataset
2026-01-30 09:18:28,927:INFO:Checking base model
2026-01-30 09:18:28,927:INFO:Base model : Random Forest Classifier
2026-01-30 09:18:28,928:INFO:Declaring metric variables
2026-01-30 09:18:28,928:INFO:Defining Hyperparameters
2026-01-30 09:18:29,052:INFO:Tuning with n_jobs=-1
2026-01-30 09:18:29,053:INFO:Initializing RandomizedSearchCV
2026-01-30 09:19:42,892:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-30 09:19:42,893:INFO:Hyperparameter search completed
2026-01-30 09:19:42,893:INFO:SubProcess create_model() called ==================================
2026-01-30 09:19:42,893:INFO:Initializing create_model()
2026-01-30 09:19:42,893:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03CD1EED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': True})
2026-01-30 09:19:42,894:INFO:Checking exceptions
2026-01-30 09:19:42,894:INFO:Importing libraries
2026-01-30 09:19:42,894:INFO:Copying training dataset
2026-01-30 09:19:43,121:INFO:Defining folds
2026-01-30 09:19:43,121:INFO:Declaring metric variables
2026-01-30 09:19:43,121:INFO:Importing untrained model
2026-01-30 09:19:43,121:INFO:Declaring custom model
2026-01-30 09:19:43,121:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:19:43,121:INFO:Starting cross validation
2026-01-30 09:19:43,121:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:19:58,929:INFO:Calculating mean and std
2026-01-30 09:19:58,929:INFO:Creating metrics dataframe
2026-01-30 09:19:58,929:INFO:Finalizing model
2026-01-30 09:20:06,979:INFO:Uploading results into container
2026-01-30 09:20:06,986:INFO:Uploading model into container now
2026-01-30 09:20:06,986:INFO:_master_model_container: 5
2026-01-30 09:20:06,987:INFO:_display_container: 3
2026-01-30 09:20:06,987:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:20:06,988:INFO:create_model() successfully completed......................................
2026-01-30 09:20:07,152:INFO:SubProcess create_model() end ==================================
2026-01-30 09:20:07,152:INFO:choose_better activated
2026-01-30 09:20:07,153:INFO:SubProcess create_model() called ==================================
2026-01-30 09:20:07,154:INFO:Initializing create_model()
2026-01-30 09:20:07,154:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:20:07,154:INFO:Checking exceptions
2026-01-30 09:20:07,155:INFO:Importing libraries
2026-01-30 09:20:07,155:INFO:Copying training dataset
2026-01-30 09:20:07,358:INFO:Defining folds
2026-01-30 09:20:07,358:INFO:Declaring metric variables
2026-01-30 09:20:07,358:INFO:Importing untrained model
2026-01-30 09:20:07,358:INFO:Declaring custom model
2026-01-30 09:20:07,359:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:20:07,359:INFO:Starting cross validation
2026-01-30 09:20:07,360:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:20:17,307:INFO:Calculating mean and std
2026-01-30 09:20:17,308:INFO:Creating metrics dataframe
2026-01-30 09:20:17,310:INFO:Finalizing model
2026-01-30 09:20:22,027:INFO:Uploading results into container
2026-01-30 09:20:22,028:INFO:Uploading model into container now
2026-01-30 09:20:22,029:INFO:_master_model_container: 6
2026-01-30 09:20:22,029:INFO:_display_container: 4
2026-01-30 09:20:22,030:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:20:22,030:INFO:create_model() successfully completed......................................
2026-01-30 09:20:22,157:INFO:SubProcess create_model() end ==================================
2026-01-30 09:20:22,158:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9993
2026-01-30 09:20:22,158:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9934
2026-01-30 09:20:22,158:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-30 09:20:22,158:INFO:choose_better completed
2026-01-30 09:20:22,159:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 09:20:22,161:INFO:_master_model_container: 6
2026-01-30 09:20:22,161:INFO:_display_container: 3
2026-01-30 09:20:22,161:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:20:22,161:INFO:tune_model() successfully completed......................................
2026-01-30 09:20:22,282:INFO:Initializing tune_model()
2026-01-30 09:20:22,282:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:20:22,282:INFO:Checking exceptions
2026-01-30 09:20:22,338:INFO:Copying training dataset
2026-01-30 09:20:22,454:INFO:Checking base model
2026-01-30 09:20:22,454:INFO:Base model : Decision Tree Classifier
2026-01-30 09:20:22,454:INFO:Declaring metric variables
2026-01-30 09:20:22,454:INFO:Defining Hyperparameters
2026-01-30 09:20:22,585:INFO:Tuning with n_jobs=-1
2026-01-30 09:20:22,586:INFO:Initializing RandomizedSearchCV
2026-01-30 09:20:26,459:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 15, 'actual_estimator__criterion': 'gini'}
2026-01-30 09:20:26,460:INFO:Hyperparameter search completed
2026-01-30 09:20:26,461:INFO:SubProcess create_model() called ==================================
2026-01-30 09:20:26,461:INFO:Initializing create_model()
2026-01-30 09:20:26,462:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A06E849510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 2, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 15, 'criterion': 'gini'})
2026-01-30 09:20:26,462:INFO:Checking exceptions
2026-01-30 09:20:26,462:INFO:Importing libraries
2026-01-30 09:20:26,462:INFO:Copying training dataset
2026-01-30 09:20:26,742:INFO:Defining folds
2026-01-30 09:20:26,742:INFO:Declaring metric variables
2026-01-30 09:20:26,742:INFO:Importing untrained model
2026-01-30 09:20:26,742:INFO:Declaring custom model
2026-01-30 09:20:26,743:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:20:26,743:INFO:Starting cross validation
2026-01-30 09:20:26,744:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:20:28,331:INFO:Calculating mean and std
2026-01-30 09:20:28,333:INFO:Creating metrics dataframe
2026-01-30 09:20:28,334:INFO:Finalizing model
2026-01-30 09:20:29,310:INFO:Uploading results into container
2026-01-30 09:20:29,311:INFO:Uploading model into container now
2026-01-30 09:20:29,312:INFO:_master_model_container: 7
2026-01-30 09:20:29,312:INFO:_display_container: 4
2026-01-30 09:20:29,313:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:20:29,313:INFO:create_model() successfully completed......................................
2026-01-30 09:20:29,438:INFO:SubProcess create_model() end ==================================
2026-01-30 09:20:29,438:INFO:choose_better activated
2026-01-30 09:20:29,438:INFO:SubProcess create_model() called ==================================
2026-01-30 09:20:29,438:INFO:Initializing create_model()
2026-01-30 09:20:29,438:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:20:29,438:INFO:Checking exceptions
2026-01-30 09:20:29,438:INFO:Importing libraries
2026-01-30 09:20:29,438:INFO:Copying training dataset
2026-01-30 09:20:29,606:INFO:Defining folds
2026-01-30 09:20:29,606:INFO:Declaring metric variables
2026-01-30 09:20:29,606:INFO:Importing untrained model
2026-01-30 09:20:29,606:INFO:Declaring custom model
2026-01-30 09:20:29,606:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:20:29,606:INFO:Starting cross validation
2026-01-30 09:20:29,606:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:20:31,473:INFO:Calculating mean and std
2026-01-30 09:20:31,474:INFO:Creating metrics dataframe
2026-01-30 09:20:31,475:INFO:Finalizing model
2026-01-30 09:20:33,160:INFO:Uploading results into container
2026-01-30 09:20:33,160:INFO:Uploading model into container now
2026-01-30 09:20:33,160:INFO:_master_model_container: 8
2026-01-30 09:20:33,160:INFO:_display_container: 5
2026-01-30 09:20:33,160:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:20:33,160:INFO:create_model() successfully completed......................................
2026-01-30 09:20:33,298:INFO:SubProcess create_model() end ==================================
2026-01-30 09:20:33,299:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9988
2026-01-30 09:20:33,299:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9876
2026-01-30 09:20:33,299:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-30 09:20:33,299:INFO:choose_better completed
2026-01-30 09:20:33,299:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 09:20:33,301:INFO:_master_model_container: 8
2026-01-30 09:20:33,301:INFO:_display_container: 4
2026-01-30 09:20:33,302:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:20:33,302:INFO:tune_model() successfully completed......................................
2026-01-30 09:20:33,434:INFO:Initializing tune_model()
2026-01-30 09:20:33,434:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:20:33,434:INFO:Checking exceptions
2026-01-30 09:20:33,504:INFO:Copying training dataset
2026-01-30 09:20:33,646:INFO:Checking base model
2026-01-30 09:20:33,646:INFO:Base model : Light Gradient Boosting Machine
2026-01-30 09:20:33,648:INFO:Declaring metric variables
2026-01-30 09:20:33,648:INFO:Defining Hyperparameters
2026-01-30 09:20:33,824:INFO:Tuning with n_jobs=-1
2026-01-30 09:20:33,824:INFO:Initializing RandomizedSearchCV
2026-01-30 09:21:00,479:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2026-01-30 09:21:00,480:INFO:Hyperparameter search completed
2026-01-30 09:21:00,481:INFO:SubProcess create_model() called ==================================
2026-01-30 09:21:00,482:INFO:Initializing create_model()
2026-01-30 09:21:00,482:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A06E702410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2026-01-30 09:21:00,482:INFO:Checking exceptions
2026-01-30 09:21:00,482:INFO:Importing libraries
2026-01-30 09:21:00,482:INFO:Copying training dataset
2026-01-30 09:21:00,663:INFO:Defining folds
2026-01-30 09:21:00,663:INFO:Declaring metric variables
2026-01-30 09:21:00,664:INFO:Importing untrained model
2026-01-30 09:21:00,664:INFO:Declaring custom model
2026-01-30 09:21:00,665:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:21:00,665:INFO:Starting cross validation
2026-01-30 09:21:00,666:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:21:08,046:INFO:Calculating mean and std
2026-01-30 09:21:08,046:INFO:Creating metrics dataframe
2026-01-30 09:21:08,051:INFO:Finalizing model
2026-01-30 09:21:08,477:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 09:21:08,477:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 09:21:08,477:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 09:21:08,663:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 09:21:08,663:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 09:21:08,663:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 09:21:08,664:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 09:21:08,706:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010122 seconds.
2026-01-30 09:21:08,706:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:21:08,706:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:21:08,707:INFO:[LightGBM] [Info] Total Bins 1967
2026-01-30 09:21:08,707:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 19
2026-01-30 09:21:08,711:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 09:21:08,711:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 09:21:10,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-01-30 09:21:10,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-01-30 09:21:10,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-01-30 09:21:10,904:INFO:Uploading results into container
2026-01-30 09:21:10,906:INFO:Uploading model into container now
2026-01-30 09:21:10,907:INFO:_master_model_container: 9
2026-01-30 09:21:10,907:INFO:_display_container: 5
2026-01-30 09:21:10,908:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:21:10,908:INFO:create_model() successfully completed......................................
2026-01-30 09:21:11,083:INFO:SubProcess create_model() end ==================================
2026-01-30 09:21:11,083:INFO:choose_better activated
2026-01-30 09:21:11,084:INFO:SubProcess create_model() called ==================================
2026-01-30 09:21:11,085:INFO:Initializing create_model()
2026-01-30 09:21:11,085:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:21:11,085:INFO:Checking exceptions
2026-01-30 09:21:11,087:INFO:Importing libraries
2026-01-30 09:21:11,087:INFO:Copying training dataset
2026-01-30 09:21:11,256:INFO:Defining folds
2026-01-30 09:21:11,256:INFO:Declaring metric variables
2026-01-30 09:21:11,256:INFO:Importing untrained model
2026-01-30 09:21:11,256:INFO:Declaring custom model
2026-01-30 09:21:11,256:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:21:11,256:INFO:Starting cross validation
2026-01-30 09:21:11,256:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:21:14,773:INFO:Calculating mean and std
2026-01-30 09:21:14,773:INFO:Creating metrics dataframe
2026-01-30 09:21:14,773:INFO:Finalizing model
2026-01-30 09:21:15,382:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 09:21:15,426:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008562 seconds.
2026-01-30 09:21:15,426:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:21:15,426:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:21:15,427:INFO:[LightGBM] [Info] Total Bins 1967
2026-01-30 09:21:15,427:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 19
2026-01-30 09:21:15,430:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 09:21:15,430:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 09:21:16,072:INFO:Uploading results into container
2026-01-30 09:21:16,072:INFO:Uploading model into container now
2026-01-30 09:21:16,074:INFO:_master_model_container: 10
2026-01-30 09:21:16,074:INFO:_display_container: 6
2026-01-30 09:21:16,074:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:21:16,074:INFO:create_model() successfully completed......................................
2026-01-30 09:21:16,235:INFO:SubProcess create_model() end ==================================
2026-01-30 09:21:16,236:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9966
2026-01-30 09:21:16,237:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9992
2026-01-30 09:21:16,238:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2026-01-30 09:21:16,238:INFO:choose_better completed
2026-01-30 09:21:16,240:INFO:_master_model_container: 10
2026-01-30 09:21:16,240:INFO:_display_container: 5
2026-01-30 09:21:16,240:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:21:16,240:INFO:tune_model() successfully completed......................................
2026-01-30 09:21:16,381:INFO:Initializing predict_model()
2026-01-30 09:21:16,381:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A0C3C9E700>)
2026-01-30 09:21:16,381:INFO:Checking exceptions
2026-01-30 09:21:16,381:INFO:Preloading libraries
2026-01-30 09:21:16,381:INFO:Set up data.
2026-01-30 09:21:16,412:INFO:Set up index.
2026-01-30 09:21:17,339:INFO:Initializing predict_model()
2026-01-30 09:21:17,339:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A036A98220>)
2026-01-30 09:21:17,339:INFO:Checking exceptions
2026-01-30 09:21:17,339:INFO:Preloading libraries
2026-01-30 09:21:17,339:INFO:Set up data.
2026-01-30 09:21:17,383:INFO:Set up index.
2026-01-30 09:21:17,944:INFO:Initializing predict_model()
2026-01-30 09:21:17,945:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A036A98220>)
2026-01-30 09:21:17,945:INFO:Checking exceptions
2026-01-30 09:21:17,945:INFO:Preloading libraries
2026-01-30 09:21:17,945:INFO:Set up data.
2026-01-30 09:21:17,979:INFO:Set up index.
2026-01-30 09:21:19,008:INFO:Initializing plot_model()
2026-01-30 09:21:19,008:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 09:21:19,008:INFO:Checking exceptions
2026-01-30 09:21:19,103:INFO:Preloading libraries
2026-01-30 09:21:19,156:INFO:Copying training dataset
2026-01-30 09:21:19,156:INFO:Plot type: feature
2026-01-30 09:21:19,157:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 09:21:19,459:INFO:Visual Rendered Successfully
2026-01-30 09:21:19,591:INFO:plot_model() successfully completed......................................
2026-01-30 09:21:19,593:INFO:Initializing plot_model()
2026-01-30 09:21:19,593:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0D02C2990>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature_all, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 09:21:19,593:INFO:Checking exceptions
2026-01-30 09:21:19,693:INFO:Preloading libraries
2026-01-30 09:21:19,703:INFO:Copying training dataset
2026-01-30 09:21:19,719:INFO:Plot type: feature_all
2026-01-30 09:21:19,859:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 09:21:20,203:INFO:Visual Rendered Successfully
2026-01-30 09:21:20,342:INFO:plot_model() successfully completed......................................
2026-01-30 09:21:20,359:INFO:Initializing save_model()
2026-01-30 09:21:20,359:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), model_name=..\datos\04. Modelos\modelo_final_explicable, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'MINIMUMPAYMENTPAYED',
                                             'PAID_PERCENT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'YEARPERSONBIRTHDATE',
                                             'PL_SI...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-30 09:21:20,359:INFO:Adding model into prep_pipe
2026-01-30 09:21:20,438:INFO:..\datos\04. Modelos\modelo_final_explicable.pkl saved in current working directory
2026-01-30 09:21:20,443:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'MINIMUMPAYMENTPAYED',
                                             'PAID_PERCENT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'YEARPERSONBIRTHDATE',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges_...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=42, verbose=0,
                                        warm_start=False))],
         verbose=False)
2026-01-30 09:21:20,443:INFO:save_model() successfully completed......................................
2026-01-30 09:28:58,546:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\472289403.py:23: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-30 09:29:00,567:INFO:PyCaret ClassificationExperiment
2026-01-30 09:29:00,567:INFO:Logging name: clf-default-name
2026-01-30 09:29:00,567:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-30 09:29:00,567:INFO:version 3.3.2
2026-01-30 09:29:00,567:INFO:Initializing setup()
2026-01-30 09:29:00,567:INFO:self.USI: 8d13
2026-01-30 09:29:00,567:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'n_jobs_param', 'data', 'X', 'idx', 'y_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'USI', 'target_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'y_train', 'X_test', 'seed', 'gpu_param', 'gpu_n_jobs_param', 'y', 'logging_param', 'pipeline', 'fold_generator', 'exp_id'}
2026-01-30 09:29:00,567:INFO:Checking environment
2026-01-30 09:29:00,567:INFO:python_version: 3.11.11
2026-01-30 09:29:00,567:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-30 09:29:00,567:INFO:machine: AMD64
2026-01-30 09:29:00,567:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-30 09:29:00,567:INFO:Memory: svmem(total=34009374720, available=16086147072, percent=52.7, used=17923227648, free=16086147072)
2026-01-30 09:29:00,567:INFO:Physical Core: 12
2026-01-30 09:29:00,567:INFO:Logical Core: 16
2026-01-30 09:29:00,567:INFO:Checking libraries
2026-01-30 09:29:00,567:INFO:System:
2026-01-30 09:29:00,567:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-30 09:29:00,567:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-30 09:29:00,567:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-30 09:29:00,567:INFO:PyCaret required dependencies:
2026-01-30 09:29:00,567:INFO:                 pip: 25.0
2026-01-30 09:29:00,567:INFO:          setuptools: 75.8.0
2026-01-30 09:29:00,567:INFO:             pycaret: 3.3.2
2026-01-30 09:29:00,567:INFO:             IPython: 9.9.0
2026-01-30 09:29:00,567:INFO:          ipywidgets: 8.1.8
2026-01-30 09:29:00,567:INFO:                tqdm: 4.67.1
2026-01-30 09:29:00,567:INFO:               numpy: 1.26.4
2026-01-30 09:29:00,567:INFO:              pandas: 2.1.4
2026-01-30 09:29:00,567:INFO:              jinja2: 3.1.6
2026-01-30 09:29:00,567:INFO:               scipy: 1.11.4
2026-01-30 09:29:00,567:INFO:              joblib: 1.3.2
2026-01-30 09:29:00,567:INFO:             sklearn: 1.4.2
2026-01-30 09:29:00,567:INFO:                pyod: 2.0.6
2026-01-30 09:29:00,567:INFO:            imblearn: 0.14.1
2026-01-30 09:29:00,567:INFO:   category_encoders: 2.7.0
2026-01-30 09:29:00,567:INFO:            lightgbm: 4.6.0
2026-01-30 09:29:00,567:INFO:               numba: 0.62.1
2026-01-30 09:29:00,567:INFO:            requests: 2.32.3
2026-01-30 09:29:00,567:INFO:          matplotlib: 3.7.5
2026-01-30 09:29:00,567:INFO:          scikitplot: 0.3.7
2026-01-30 09:29:00,567:INFO:         yellowbrick: 1.5
2026-01-30 09:29:00,567:INFO:              plotly: 5.24.1
2026-01-30 09:29:00,567:INFO:    plotly-resampler: Not installed
2026-01-30 09:29:00,567:INFO:             kaleido: 1.2.0
2026-01-30 09:29:00,567:INFO:           schemdraw: 0.15
2026-01-30 09:29:00,567:INFO:         statsmodels: 0.14.6
2026-01-30 09:29:00,567:INFO:              sktime: 0.26.0
2026-01-30 09:29:00,567:INFO:               tbats: 1.1.3
2026-01-30 09:29:00,567:INFO:            pmdarima: 2.0.4
2026-01-30 09:29:00,567:INFO:              psutil: 7.2.1
2026-01-30 09:29:00,567:INFO:          markupsafe: 3.0.3
2026-01-30 09:29:00,567:INFO:             pickle5: Not installed
2026-01-30 09:29:00,567:INFO:         cloudpickle: 3.0.0
2026-01-30 09:29:00,567:INFO:         deprecation: 2.1.0
2026-01-30 09:29:00,567:INFO:              xxhash: 3.6.0
2026-01-30 09:29:00,567:INFO:           wurlitzer: Not installed
2026-01-30 09:29:00,567:INFO:PyCaret optional dependencies:
2026-01-30 09:29:00,567:INFO:                shap: 0.44.1
2026-01-30 09:29:00,567:INFO:           interpret: 0.7.3
2026-01-30 09:29:00,567:INFO:                umap: 0.5.7
2026-01-30 09:29:00,567:INFO:     ydata_profiling: 4.18.1
2026-01-30 09:29:00,567:INFO:  explainerdashboard: 0.5.1
2026-01-30 09:29:00,567:INFO:             autoviz: Not installed
2026-01-30 09:29:00,567:INFO:           fairlearn: 0.7.0
2026-01-30 09:29:00,567:INFO:          deepchecks: Not installed
2026-01-30 09:29:00,567:INFO:             xgboost: Not installed
2026-01-30 09:29:00,567:INFO:            catboost: 1.2.8
2026-01-30 09:29:00,567:INFO:              kmodes: 0.12.2
2026-01-30 09:29:00,567:INFO:             mlxtend: 0.23.4
2026-01-30 09:29:00,567:INFO:       statsforecast: 1.5.0
2026-01-30 09:29:00,567:INFO:        tune_sklearn: Not installed
2026-01-30 09:29:00,567:INFO:                 ray: Not installed
2026-01-30 09:29:00,567:INFO:            hyperopt: 0.2.7
2026-01-30 09:29:00,567:INFO:              optuna: 4.6.0
2026-01-30 09:29:00,567:INFO:               skopt: 0.10.2
2026-01-30 09:29:00,567:INFO:              mlflow: 3.8.1
2026-01-30 09:29:00,567:INFO:              gradio: 6.3.0
2026-01-30 09:29:00,567:INFO:             fastapi: 0.128.0
2026-01-30 09:29:00,567:INFO:             uvicorn: 0.40.0
2026-01-30 09:29:00,567:INFO:              m2cgen: 0.10.0
2026-01-30 09:29:00,567:INFO:           evidently: 0.4.40
2026-01-30 09:29:00,567:INFO:               fugue: 0.8.7
2026-01-30 09:29:00,567:INFO:           streamlit: Not installed
2026-01-30 09:29:00,567:INFO:             prophet: Not installed
2026-01-30 09:29:00,567:INFO:None
2026-01-30 09:29:00,567:INFO:Set up data.
2026-01-30 09:29:00,667:INFO:Set up folding strategy.
2026-01-30 09:29:00,667:INFO:Set up train/test split.
2026-01-30 09:29:00,835:INFO:Set up index.
2026-01-30 09:29:00,847:INFO:Assigning column types.
2026-01-30 09:29:00,935:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-30 09:29:00,963:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 09:29:00,963:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:29:00,983:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:29:00,983:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:29:01,012:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 09:29:01,013:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:29:01,029:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:29:01,030:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:29:01,030:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-30 09:29:01,046:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:29:01,063:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:29:01,063:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:29:01,098:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:29:01,113:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:29:01,113:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:29:01,113:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-30 09:29:01,147:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:29:01,147:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:29:01,195:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:29:01,196:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:29:01,197:INFO:Preparing preprocessing pipeline...
2026-01-30 09:29:01,213:INFO:Set up simple imputation.
2026-01-30 09:29:01,213:INFO:Set up feature normalization.
2026-01-30 09:29:01,436:INFO:Finished creating preprocessing pipeline.
2026-01-30 09:29:01,436:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'MINIMUMPAYMENTPAYED',
                                             'PAID_PERCENT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'YEARPERSONBIRTHDATE',
                                             'PL_SI...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-30 09:29:01,436:INFO:Creating final display dataframe.
2026-01-30 09:29:01,813:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape      (429278, 20)
4        Transformed data shape      (429278, 20)
5   Transformed train set shape      (300494, 20)
6    Transformed test set shape      (128784, 20)
7              Numeric features                15
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                 3
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              8d13
2026-01-30 09:29:01,863:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:29:01,863:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:29:01,897:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:29:01,897:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:29:01,897:INFO:setup() successfully completed in 1.35s...............
2026-01-30 09:29:01,897:INFO:Initializing compare_models()
2026-01-30 09:29:01,897:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-30 09:29:01,897:INFO:Checking exceptions
2026-01-30 09:29:01,980:INFO:Preparing display monitor
2026-01-30 09:29:01,980:INFO:Initializing Logistic Regression
2026-01-30 09:29:01,980:INFO:Total runtime is 0.0 minutes
2026-01-30 09:29:01,980:INFO:SubProcess create_model() called ==================================
2026-01-30 09:29:01,980:INFO:Initializing create_model()
2026-01-30 09:29:01,980:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03C347350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:29:01,980:INFO:Checking exceptions
2026-01-30 09:29:01,980:INFO:Importing libraries
2026-01-30 09:29:01,980:INFO:Copying training dataset
2026-01-30 09:29:02,133:INFO:Defining folds
2026-01-30 09:29:02,134:INFO:Declaring metric variables
2026-01-30 09:29:02,134:INFO:Importing untrained model
2026-01-30 09:29:02,135:INFO:Logistic Regression Imported successfully
2026-01-30 09:29:02,135:INFO:Starting cross validation
2026-01-30 09:29:02,135:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:29:14,299:INFO:Calculating mean and std
2026-01-30 09:29:14,303:INFO:Creating metrics dataframe
2026-01-30 09:29:14,307:INFO:Uploading results into container
2026-01-30 09:29:14,310:INFO:Uploading model into container now
2026-01-30 09:29:14,310:INFO:_master_model_container: 1
2026-01-30 09:29:14,310:INFO:_display_container: 2
2026-01-30 09:29:14,310:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-30 09:29:14,313:INFO:create_model() successfully completed......................................
2026-01-30 09:29:14,481:INFO:SubProcess create_model() end ==================================
2026-01-30 09:29:14,482:INFO:Creating metrics dataframe
2026-01-30 09:29:14,485:INFO:Initializing Decision Tree Classifier
2026-01-30 09:29:14,485:INFO:Total runtime is 0.20842784643173218 minutes
2026-01-30 09:29:14,485:INFO:SubProcess create_model() called ==================================
2026-01-30 09:29:14,485:INFO:Initializing create_model()
2026-01-30 09:29:14,485:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03C347350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:29:14,485:INFO:Checking exceptions
2026-01-30 09:29:14,485:INFO:Importing libraries
2026-01-30 09:29:14,485:INFO:Copying training dataset
2026-01-30 09:29:14,682:INFO:Defining folds
2026-01-30 09:29:14,682:INFO:Declaring metric variables
2026-01-30 09:29:14,682:INFO:Importing untrained model
2026-01-30 09:29:14,682:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:29:14,682:INFO:Starting cross validation
2026-01-30 09:29:14,682:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:29:20,812:INFO:Calculating mean and std
2026-01-30 09:29:20,813:INFO:Creating metrics dataframe
2026-01-30 09:29:20,815:INFO:Uploading results into container
2026-01-30 09:29:20,815:INFO:Uploading model into container now
2026-01-30 09:29:20,816:INFO:_master_model_container: 2
2026-01-30 09:29:20,816:INFO:_display_container: 2
2026-01-30 09:29:20,817:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:29:20,817:INFO:create_model() successfully completed......................................
2026-01-30 09:29:20,970:INFO:SubProcess create_model() end ==================================
2026-01-30 09:29:20,970:INFO:Creating metrics dataframe
2026-01-30 09:29:20,970:INFO:Initializing Random Forest Classifier
2026-01-30 09:29:20,970:INFO:Total runtime is 0.3165002743403117 minutes
2026-01-30 09:29:20,970:INFO:SubProcess create_model() called ==================================
2026-01-30 09:29:20,970:INFO:Initializing create_model()
2026-01-30 09:29:20,970:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03C347350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:29:20,970:INFO:Checking exceptions
2026-01-30 09:29:20,970:INFO:Importing libraries
2026-01-30 09:29:20,970:INFO:Copying training dataset
2026-01-30 09:29:21,143:INFO:Defining folds
2026-01-30 09:29:21,145:INFO:Declaring metric variables
2026-01-30 09:29:21,147:INFO:Importing untrained model
2026-01-30 09:29:21,147:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:29:21,148:INFO:Starting cross validation
2026-01-30 09:29:21,149:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:29:34,164:INFO:Calculating mean and std
2026-01-30 09:29:34,166:INFO:Creating metrics dataframe
2026-01-30 09:29:34,167:INFO:Uploading results into container
2026-01-30 09:29:34,167:INFO:Uploading model into container now
2026-01-30 09:29:34,167:INFO:_master_model_container: 3
2026-01-30 09:29:34,167:INFO:_display_container: 2
2026-01-30 09:29:34,167:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:29:34,167:INFO:create_model() successfully completed......................................
2026-01-30 09:29:34,305:INFO:SubProcess create_model() end ==================================
2026-01-30 09:29:34,305:INFO:Creating metrics dataframe
2026-01-30 09:29:34,306:INFO:Initializing Light Gradient Boosting Machine
2026-01-30 09:29:34,306:INFO:Total runtime is 0.5387771089871725 minutes
2026-01-30 09:29:34,307:INFO:SubProcess create_model() called ==================================
2026-01-30 09:29:34,307:INFO:Initializing create_model()
2026-01-30 09:29:34,307:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03C347350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:29:34,307:INFO:Checking exceptions
2026-01-30 09:29:34,307:INFO:Importing libraries
2026-01-30 09:29:34,307:INFO:Copying training dataset
2026-01-30 09:29:34,446:INFO:Defining folds
2026-01-30 09:29:34,446:INFO:Declaring metric variables
2026-01-30 09:29:34,446:INFO:Importing untrained model
2026-01-30 09:29:34,446:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:29:34,446:INFO:Starting cross validation
2026-01-30 09:29:34,446:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:29:41,909:INFO:Calculating mean and std
2026-01-30 09:29:41,915:INFO:Creating metrics dataframe
2026-01-30 09:29:41,917:INFO:Uploading results into container
2026-01-30 09:29:41,917:INFO:Uploading model into container now
2026-01-30 09:29:41,919:INFO:_master_model_container: 4
2026-01-30 09:29:41,919:INFO:_display_container: 2
2026-01-30 09:29:41,919:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:29:41,919:INFO:create_model() successfully completed......................................
2026-01-30 09:29:42,029:INFO:SubProcess create_model() end ==================================
2026-01-30 09:29:42,029:INFO:Creating metrics dataframe
2026-01-30 09:29:42,044:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-30 09:29:42,046:INFO:Initializing create_model()
2026-01-30 09:29:42,046:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:29:42,046:INFO:Checking exceptions
2026-01-30 09:29:42,046:INFO:Importing libraries
2026-01-30 09:29:42,046:INFO:Copying training dataset
2026-01-30 09:29:42,188:INFO:Defining folds
2026-01-30 09:29:42,188:INFO:Declaring metric variables
2026-01-30 09:29:42,188:INFO:Importing untrained model
2026-01-30 09:29:42,188:INFO:Declaring custom model
2026-01-30 09:29:42,189:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:29:42,189:INFO:Cross validation set to False
2026-01-30 09:29:42,189:INFO:Fitting Model
2026-01-30 09:29:47,099:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:29:47,099:INFO:create_model() successfully completed......................................
2026-01-30 09:29:47,234:INFO:Initializing create_model()
2026-01-30 09:29:47,234:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:29:47,235:INFO:Checking exceptions
2026-01-30 09:29:47,235:INFO:Importing libraries
2026-01-30 09:29:47,235:INFO:Copying training dataset
2026-01-30 09:29:47,374:INFO:Defining folds
2026-01-30 09:29:47,375:INFO:Declaring metric variables
2026-01-30 09:29:47,375:INFO:Importing untrained model
2026-01-30 09:29:47,375:INFO:Declaring custom model
2026-01-30 09:29:47,375:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:29:47,376:INFO:Cross validation set to False
2026-01-30 09:29:47,376:INFO:Fitting Model
2026-01-30 09:29:48,542:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:29:48,542:INFO:create_model() successfully completed......................................
2026-01-30 09:29:48,669:INFO:Initializing create_model()
2026-01-30 09:29:48,669:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:29:48,669:INFO:Checking exceptions
2026-01-30 09:29:48,670:INFO:Importing libraries
2026-01-30 09:29:48,670:INFO:Copying training dataset
2026-01-30 09:29:48,814:INFO:Defining folds
2026-01-30 09:29:48,814:INFO:Declaring metric variables
2026-01-30 09:29:48,814:INFO:Importing untrained model
2026-01-30 09:29:48,815:INFO:Declaring custom model
2026-01-30 09:29:48,815:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:29:48,816:INFO:Cross validation set to False
2026-01-30 09:29:48,816:INFO:Fitting Model
2026-01-30 09:29:49,304:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 09:29:49,346:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007317 seconds.
2026-01-30 09:29:49,347:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:29:49,347:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:29:49,347:INFO:[LightGBM] [Info] Total Bins 1967
2026-01-30 09:29:49,348:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 19
2026-01-30 09:29:49,350:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 09:29:49,350:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 09:29:49,879:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:29:49,879:INFO:create_model() successfully completed......................................
2026-01-30 09:29:50,064:INFO:_master_model_container: 4
2026-01-30 09:29:50,064:INFO:_display_container: 2
2026-01-30 09:29:50,066:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)]
2026-01-30 09:29:50,066:INFO:compare_models() successfully completed......................................
2026-01-30 09:29:50,072:INFO:Initializing tune_model()
2026-01-30 09:29:50,072:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:29:50,073:INFO:Checking exceptions
2026-01-30 09:29:50,136:INFO:Copying training dataset
2026-01-30 09:29:50,228:INFO:Checking base model
2026-01-30 09:29:50,229:INFO:Base model : Random Forest Classifier
2026-01-30 09:29:50,229:INFO:Declaring metric variables
2026-01-30 09:29:50,229:INFO:Defining Hyperparameters
2026-01-30 09:29:50,362:INFO:Tuning with n_jobs=-1
2026-01-30 09:29:50,362:INFO:Initializing RandomizedSearchCV
2026-01-30 09:31:11,486:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-30 09:31:11,486:INFO:Hyperparameter search completed
2026-01-30 09:31:11,486:INFO:SubProcess create_model() called ==================================
2026-01-30 09:31:11,486:INFO:Initializing create_model()
2026-01-30 09:31:11,486:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03C3BF610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': True})
2026-01-30 09:31:11,486:INFO:Checking exceptions
2026-01-30 09:31:11,486:INFO:Importing libraries
2026-01-30 09:31:11,486:INFO:Copying training dataset
2026-01-30 09:31:11,714:INFO:Defining folds
2026-01-30 09:31:11,714:INFO:Declaring metric variables
2026-01-30 09:31:11,714:INFO:Importing untrained model
2026-01-30 09:31:11,714:INFO:Declaring custom model
2026-01-30 09:31:11,714:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:31:11,714:INFO:Starting cross validation
2026-01-30 09:31:11,724:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:31:29,109:INFO:Calculating mean and std
2026-01-30 09:31:29,111:INFO:Creating metrics dataframe
2026-01-30 09:31:29,113:INFO:Finalizing model
2026-01-30 09:31:37,745:INFO:Uploading results into container
2026-01-30 09:31:37,746:INFO:Uploading model into container now
2026-01-30 09:31:37,747:INFO:_master_model_container: 5
2026-01-30 09:31:37,747:INFO:_display_container: 3
2026-01-30 09:31:37,748:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:31:37,748:INFO:create_model() successfully completed......................................
2026-01-30 09:31:37,896:INFO:SubProcess create_model() end ==================================
2026-01-30 09:31:37,897:INFO:choose_better activated
2026-01-30 09:31:37,897:INFO:SubProcess create_model() called ==================================
2026-01-30 09:31:37,897:INFO:Initializing create_model()
2026-01-30 09:31:37,897:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:31:37,897:INFO:Checking exceptions
2026-01-30 09:31:37,898:INFO:Importing libraries
2026-01-30 09:31:37,898:INFO:Copying training dataset
2026-01-30 09:31:38,045:INFO:Defining folds
2026-01-30 09:31:38,045:INFO:Declaring metric variables
2026-01-30 09:31:38,045:INFO:Importing untrained model
2026-01-30 09:31:38,045:INFO:Declaring custom model
2026-01-30 09:31:38,045:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:31:38,045:INFO:Starting cross validation
2026-01-30 09:31:38,045:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:31:49,414:INFO:Calculating mean and std
2026-01-30 09:31:49,414:INFO:Creating metrics dataframe
2026-01-30 09:31:49,416:INFO:Finalizing model
2026-01-30 09:31:55,199:INFO:Uploading results into container
2026-01-30 09:31:55,200:INFO:Uploading model into container now
2026-01-30 09:31:55,200:INFO:_master_model_container: 6
2026-01-30 09:31:55,201:INFO:_display_container: 4
2026-01-30 09:31:55,201:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:31:55,201:INFO:create_model() successfully completed......................................
2026-01-30 09:31:55,358:INFO:SubProcess create_model() end ==================================
2026-01-30 09:31:55,359:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9993
2026-01-30 09:31:55,360:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9934
2026-01-30 09:31:55,360:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-30 09:31:55,360:INFO:choose_better completed
2026-01-30 09:31:55,361:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 09:31:55,364:INFO:_master_model_container: 6
2026-01-30 09:31:55,365:INFO:_display_container: 3
2026-01-30 09:31:55,365:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:31:55,365:INFO:tune_model() successfully completed......................................
2026-01-30 09:31:55,520:INFO:Initializing tune_model()
2026-01-30 09:31:55,520:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:31:55,520:INFO:Checking exceptions
2026-01-30 09:31:55,603:INFO:Copying training dataset
2026-01-30 09:31:55,799:INFO:Checking base model
2026-01-30 09:31:55,800:INFO:Base model : Decision Tree Classifier
2026-01-30 09:31:55,801:INFO:Declaring metric variables
2026-01-30 09:31:55,801:INFO:Defining Hyperparameters
2026-01-30 09:31:56,002:INFO:Tuning with n_jobs=-1
2026-01-30 09:31:56,003:INFO:Initializing RandomizedSearchCV
2026-01-30 09:32:00,866:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 15, 'actual_estimator__criterion': 'gini'}
2026-01-30 09:32:00,866:INFO:Hyperparameter search completed
2026-01-30 09:32:00,866:INFO:SubProcess create_model() called ==================================
2026-01-30 09:32:00,866:INFO:Initializing create_model()
2026-01-30 09:32:00,866:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A07F31BF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 2, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 15, 'criterion': 'gini'})
2026-01-30 09:32:00,866:INFO:Checking exceptions
2026-01-30 09:32:00,866:INFO:Importing libraries
2026-01-30 09:32:00,866:INFO:Copying training dataset
2026-01-30 09:32:01,028:INFO:Defining folds
2026-01-30 09:32:01,028:INFO:Declaring metric variables
2026-01-30 09:32:01,028:INFO:Importing untrained model
2026-01-30 09:32:01,028:INFO:Declaring custom model
2026-01-30 09:32:01,028:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:32:01,028:INFO:Starting cross validation
2026-01-30 09:32:01,028:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:32:02,673:INFO:Calculating mean and std
2026-01-30 09:32:02,676:INFO:Creating metrics dataframe
2026-01-30 09:32:02,677:INFO:Finalizing model
2026-01-30 09:32:03,544:INFO:Uploading results into container
2026-01-30 09:32:03,545:INFO:Uploading model into container now
2026-01-30 09:32:03,546:INFO:_master_model_container: 7
2026-01-30 09:32:03,546:INFO:_display_container: 4
2026-01-30 09:32:03,547:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:32:03,547:INFO:create_model() successfully completed......................................
2026-01-30 09:32:03,660:INFO:SubProcess create_model() end ==================================
2026-01-30 09:32:03,660:INFO:choose_better activated
2026-01-30 09:32:03,660:INFO:SubProcess create_model() called ==================================
2026-01-30 09:32:03,660:INFO:Initializing create_model()
2026-01-30 09:32:03,660:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:32:03,660:INFO:Checking exceptions
2026-01-30 09:32:03,660:INFO:Importing libraries
2026-01-30 09:32:03,660:INFO:Copying training dataset
2026-01-30 09:32:03,815:INFO:Defining folds
2026-01-30 09:32:03,815:INFO:Declaring metric variables
2026-01-30 09:32:03,816:INFO:Importing untrained model
2026-01-30 09:32:03,816:INFO:Declaring custom model
2026-01-30 09:32:03,816:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:32:03,816:INFO:Starting cross validation
2026-01-30 09:32:03,817:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:32:05,785:INFO:Calculating mean and std
2026-01-30 09:32:05,785:INFO:Creating metrics dataframe
2026-01-30 09:32:05,785:INFO:Finalizing model
2026-01-30 09:32:07,076:INFO:Uploading results into container
2026-01-30 09:32:07,077:INFO:Uploading model into container now
2026-01-30 09:32:07,077:INFO:_master_model_container: 8
2026-01-30 09:32:07,077:INFO:_display_container: 5
2026-01-30 09:32:07,077:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:32:07,077:INFO:create_model() successfully completed......................................
2026-01-30 09:32:07,200:INFO:SubProcess create_model() end ==================================
2026-01-30 09:32:07,200:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9988
2026-01-30 09:32:07,202:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9876
2026-01-30 09:32:07,202:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-30 09:32:07,202:INFO:choose_better completed
2026-01-30 09:32:07,202:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 09:32:07,204:INFO:_master_model_container: 8
2026-01-30 09:32:07,204:INFO:_display_container: 4
2026-01-30 09:32:07,204:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:32:07,204:INFO:tune_model() successfully completed......................................
2026-01-30 09:32:07,327:INFO:Initializing tune_model()
2026-01-30 09:32:07,327:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:32:07,327:INFO:Checking exceptions
2026-01-30 09:32:07,382:INFO:Copying training dataset
2026-01-30 09:32:07,485:INFO:Checking base model
2026-01-30 09:32:07,485:INFO:Base model : Light Gradient Boosting Machine
2026-01-30 09:32:07,486:INFO:Declaring metric variables
2026-01-30 09:32:07,486:INFO:Defining Hyperparameters
2026-01-30 09:32:07,615:INFO:Tuning with n_jobs=-1
2026-01-30 09:32:07,615:INFO:Initializing RandomizedSearchCV
2026-01-30 09:32:38,676:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2026-01-30 09:32:38,677:INFO:Hyperparameter search completed
2026-01-30 09:32:38,677:INFO:SubProcess create_model() called ==================================
2026-01-30 09:32:38,679:INFO:Initializing create_model()
2026-01-30 09:32:38,679:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C3C17F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2026-01-30 09:32:38,679:INFO:Checking exceptions
2026-01-30 09:32:38,679:INFO:Importing libraries
2026-01-30 09:32:38,680:INFO:Copying training dataset
2026-01-30 09:32:38,860:INFO:Defining folds
2026-01-30 09:32:38,860:INFO:Declaring metric variables
2026-01-30 09:32:38,860:INFO:Importing untrained model
2026-01-30 09:32:38,860:INFO:Declaring custom model
2026-01-30 09:32:38,875:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:32:38,876:INFO:Starting cross validation
2026-01-30 09:32:38,876:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:32:47,399:INFO:Calculating mean and std
2026-01-30 09:32:47,402:INFO:Creating metrics dataframe
2026-01-30 09:32:47,405:INFO:Finalizing model
2026-01-30 09:32:47,786:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 09:32:47,786:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 09:32:47,786:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 09:32:47,932:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 09:32:47,932:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 09:32:47,932:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 09:32:47,934:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 09:32:47,964:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008276 seconds.
2026-01-30 09:32:47,964:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:32:47,964:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:32:47,967:INFO:[LightGBM] [Info] Total Bins 1967
2026-01-30 09:32:47,967:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 19
2026-01-30 09:32:47,971:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 09:32:47,971:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 09:32:50,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-01-30 09:32:50,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-01-30 09:32:50,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2026-01-30 09:32:50,728:INFO:Uploading results into container
2026-01-30 09:32:50,730:INFO:Uploading model into container now
2026-01-30 09:32:50,730:INFO:_master_model_container: 9
2026-01-30 09:32:50,730:INFO:_display_container: 5
2026-01-30 09:32:50,732:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:32:50,732:INFO:create_model() successfully completed......................................
2026-01-30 09:32:50,926:INFO:SubProcess create_model() end ==================================
2026-01-30 09:32:50,926:INFO:choose_better activated
2026-01-30 09:32:50,926:INFO:SubProcess create_model() called ==================================
2026-01-30 09:32:50,926:INFO:Initializing create_model()
2026-01-30 09:32:50,926:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:32:50,926:INFO:Checking exceptions
2026-01-30 09:32:50,926:INFO:Importing libraries
2026-01-30 09:32:50,926:INFO:Copying training dataset
2026-01-30 09:32:51,093:INFO:Defining folds
2026-01-30 09:32:51,093:INFO:Declaring metric variables
2026-01-30 09:32:51,093:INFO:Importing untrained model
2026-01-30 09:32:51,093:INFO:Declaring custom model
2026-01-30 09:32:51,093:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:32:51,093:INFO:Starting cross validation
2026-01-30 09:32:51,093:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:32:55,122:INFO:Calculating mean and std
2026-01-30 09:32:55,123:INFO:Creating metrics dataframe
2026-01-30 09:32:55,127:INFO:Finalizing model
2026-01-30 09:32:55,712:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 09:32:55,751:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008999 seconds.
2026-01-30 09:32:55,751:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:32:55,751:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:32:55,751:INFO:[LightGBM] [Info] Total Bins 1967
2026-01-30 09:32:55,752:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 19
2026-01-30 09:32:55,754:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 09:32:55,755:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 09:32:56,615:INFO:Uploading results into container
2026-01-30 09:32:56,616:INFO:Uploading model into container now
2026-01-30 09:32:56,617:INFO:_master_model_container: 10
2026-01-30 09:32:56,617:INFO:_display_container: 6
2026-01-30 09:32:56,618:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:32:56,618:INFO:create_model() successfully completed......................................
2026-01-30 09:32:56,806:INFO:SubProcess create_model() end ==================================
2026-01-30 09:32:56,807:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9966
2026-01-30 09:32:56,807:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9992
2026-01-30 09:32:56,808:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2026-01-30 09:32:56,808:INFO:choose_better completed
2026-01-30 09:32:56,812:INFO:_master_model_container: 10
2026-01-30 09:32:56,812:INFO:_display_container: 5
2026-01-30 09:32:56,813:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:32:56,813:INFO:tune_model() successfully completed......................................
2026-01-30 09:32:56,962:INFO:Initializing predict_model()
2026-01-30 09:32:56,963:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A069E44EA0>)
2026-01-30 09:32:56,963:INFO:Checking exceptions
2026-01-30 09:32:56,963:INFO:Preloading libraries
2026-01-30 09:32:56,963:INFO:Set up data.
2026-01-30 09:32:56,998:INFO:Set up index.
2026-01-30 09:32:57,876:INFO:Initializing predict_model()
2026-01-30 09:32:57,876:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A069E44EA0>)
2026-01-30 09:32:57,876:INFO:Checking exceptions
2026-01-30 09:32:57,876:INFO:Preloading libraries
2026-01-30 09:32:57,876:INFO:Set up data.
2026-01-30 09:32:57,895:INFO:Set up index.
2026-01-30 09:32:58,359:INFO:Initializing predict_model()
2026-01-30 09:32:58,359:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A069E44EA0>)
2026-01-30 09:32:58,359:INFO:Checking exceptions
2026-01-30 09:32:58,359:INFO:Preloading libraries
2026-01-30 09:32:58,359:INFO:Set up data.
2026-01-30 09:32:58,396:INFO:Set up index.
2026-01-30 09:32:59,410:INFO:Initializing plot_model()
2026-01-30 09:32:59,410:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 09:32:59,410:INFO:Checking exceptions
2026-01-30 09:32:59,493:INFO:Preloading libraries
2026-01-30 09:32:59,526:INFO:Copying training dataset
2026-01-30 09:32:59,526:INFO:Plot type: feature
2026-01-30 09:32:59,526:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 09:32:59,776:INFO:Visual Rendered Successfully
2026-01-30 09:32:59,908:INFO:plot_model() successfully completed......................................
2026-01-30 09:32:59,909:INFO:Initializing plot_model()
2026-01-30 09:32:59,909:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0371E4790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature_all, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 09:32:59,910:INFO:Checking exceptions
2026-01-30 09:33:00,004:INFO:Preloading libraries
2026-01-30 09:33:00,026:INFO:Copying training dataset
2026-01-30 09:33:00,026:INFO:Plot type: feature_all
2026-01-30 09:33:00,143:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 09:33:00,426:INFO:Visual Rendered Successfully
2026-01-30 09:33:00,543:INFO:plot_model() successfully completed......................................
2026-01-30 09:33:00,561:INFO:Initializing save_model()
2026-01-30 09:33:00,561:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), model_name=..\datos\04. Modelos\modelo_final_explicable, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'MINIMUMPAYMENTPAYED',
                                             'PAID_PERCENT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'YEARPERSONBIRTHDATE',
                                             'PL_SI...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-30 09:33:00,561:INFO:Adding model into prep_pipe
2026-01-30 09:33:00,627:INFO:..\datos\04. Modelos\modelo_final_explicable.pkl saved in current working directory
2026-01-30 09:33:00,631:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['desmatriculado',
                                             'NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'MINIMUMPAYMENTPAYED',
                                             'PAID_PERCENT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'YEARPERSONBIRTHDATE',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges_...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=42, verbose=0,
                                        warm_start=False))],
         verbose=False)
2026-01-30 09:33:00,631:INFO:save_model() successfully completed......................................
2026-01-30 09:39:02,378:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\1844400550.py:23: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-30 09:39:04,349:INFO:PyCaret ClassificationExperiment
2026-01-30 09:39:04,349:INFO:Logging name: clf-default-name
2026-01-30 09:39:04,349:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-30 09:39:04,349:INFO:version 3.3.2
2026-01-30 09:39:04,349:INFO:Initializing setup()
2026-01-30 09:39:04,353:INFO:self.USI: a68c
2026-01-30 09:39:04,353:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'n_jobs_param', 'data', 'X', 'idx', 'y_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'USI', 'target_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'y_train', 'X_test', 'seed', 'gpu_param', 'gpu_n_jobs_param', 'y', 'logging_param', 'pipeline', 'fold_generator', 'exp_id'}
2026-01-30 09:39:04,353:INFO:Checking environment
2026-01-30 09:39:04,354:INFO:python_version: 3.11.11
2026-01-30 09:39:04,355:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-30 09:39:04,355:INFO:machine: AMD64
2026-01-30 09:39:04,355:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-30 09:39:04,355:INFO:Memory: svmem(total=34009374720, available=15912980480, percent=53.2, used=18096394240, free=15912980480)
2026-01-30 09:39:04,356:INFO:Physical Core: 12
2026-01-30 09:39:04,356:INFO:Logical Core: 16
2026-01-30 09:39:04,356:INFO:Checking libraries
2026-01-30 09:39:04,356:INFO:System:
2026-01-30 09:39:04,356:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-30 09:39:04,357:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-30 09:39:04,357:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-30 09:39:04,357:INFO:PyCaret required dependencies:
2026-01-30 09:39:04,357:INFO:                 pip: 25.0
2026-01-30 09:39:04,357:INFO:          setuptools: 75.8.0
2026-01-30 09:39:04,357:INFO:             pycaret: 3.3.2
2026-01-30 09:39:04,357:INFO:             IPython: 9.9.0
2026-01-30 09:39:04,357:INFO:          ipywidgets: 8.1.8
2026-01-30 09:39:04,357:INFO:                tqdm: 4.67.1
2026-01-30 09:39:04,357:INFO:               numpy: 1.26.4
2026-01-30 09:39:04,357:INFO:              pandas: 2.1.4
2026-01-30 09:39:04,357:INFO:              jinja2: 3.1.6
2026-01-30 09:39:04,357:INFO:               scipy: 1.11.4
2026-01-30 09:39:04,357:INFO:              joblib: 1.3.2
2026-01-30 09:39:04,357:INFO:             sklearn: 1.4.2
2026-01-30 09:39:04,357:INFO:                pyod: 2.0.6
2026-01-30 09:39:04,358:INFO:            imblearn: 0.14.1
2026-01-30 09:39:04,358:INFO:   category_encoders: 2.7.0
2026-01-30 09:39:04,358:INFO:            lightgbm: 4.6.0
2026-01-30 09:39:04,358:INFO:               numba: 0.62.1
2026-01-30 09:39:04,358:INFO:            requests: 2.32.3
2026-01-30 09:39:04,358:INFO:          matplotlib: 3.7.5
2026-01-30 09:39:04,358:INFO:          scikitplot: 0.3.7
2026-01-30 09:39:04,358:INFO:         yellowbrick: 1.5
2026-01-30 09:39:04,358:INFO:              plotly: 5.24.1
2026-01-30 09:39:04,358:INFO:    plotly-resampler: Not installed
2026-01-30 09:39:04,358:INFO:             kaleido: 1.2.0
2026-01-30 09:39:04,358:INFO:           schemdraw: 0.15
2026-01-30 09:39:04,358:INFO:         statsmodels: 0.14.6
2026-01-30 09:39:04,358:INFO:              sktime: 0.26.0
2026-01-30 09:39:04,358:INFO:               tbats: 1.1.3
2026-01-30 09:39:04,358:INFO:            pmdarima: 2.0.4
2026-01-30 09:39:04,358:INFO:              psutil: 7.2.1
2026-01-30 09:39:04,358:INFO:          markupsafe: 3.0.3
2026-01-30 09:39:04,358:INFO:             pickle5: Not installed
2026-01-30 09:39:04,358:INFO:         cloudpickle: 3.0.0
2026-01-30 09:39:04,358:INFO:         deprecation: 2.1.0
2026-01-30 09:39:04,358:INFO:              xxhash: 3.6.0
2026-01-30 09:39:04,358:INFO:           wurlitzer: Not installed
2026-01-30 09:39:04,358:INFO:PyCaret optional dependencies:
2026-01-30 09:39:04,358:INFO:                shap: 0.44.1
2026-01-30 09:39:04,358:INFO:           interpret: 0.7.3
2026-01-30 09:39:04,358:INFO:                umap: 0.5.7
2026-01-30 09:39:04,358:INFO:     ydata_profiling: 4.18.1
2026-01-30 09:39:04,358:INFO:  explainerdashboard: 0.5.1
2026-01-30 09:39:04,358:INFO:             autoviz: Not installed
2026-01-30 09:39:04,358:INFO:           fairlearn: 0.7.0
2026-01-30 09:39:04,358:INFO:          deepchecks: Not installed
2026-01-30 09:39:04,358:INFO:             xgboost: Not installed
2026-01-30 09:39:04,358:INFO:            catboost: 1.2.8
2026-01-30 09:39:04,358:INFO:              kmodes: 0.12.2
2026-01-30 09:39:04,358:INFO:             mlxtend: 0.23.4
2026-01-30 09:39:04,358:INFO:       statsforecast: 1.5.0
2026-01-30 09:39:04,358:INFO:        tune_sklearn: Not installed
2026-01-30 09:39:04,358:INFO:                 ray: Not installed
2026-01-30 09:39:04,358:INFO:            hyperopt: 0.2.7
2026-01-30 09:39:04,358:INFO:              optuna: 4.6.0
2026-01-30 09:39:04,358:INFO:               skopt: 0.10.2
2026-01-30 09:39:04,358:INFO:              mlflow: 3.8.1
2026-01-30 09:39:04,358:INFO:              gradio: 6.3.0
2026-01-30 09:39:04,358:INFO:             fastapi: 0.128.0
2026-01-30 09:39:04,358:INFO:             uvicorn: 0.40.0
2026-01-30 09:39:04,358:INFO:              m2cgen: 0.10.0
2026-01-30 09:39:04,358:INFO:           evidently: 0.4.40
2026-01-30 09:39:04,358:INFO:               fugue: 0.8.7
2026-01-30 09:39:04,358:INFO:           streamlit: Not installed
2026-01-30 09:39:04,358:INFO:             prophet: Not installed
2026-01-30 09:39:04,358:INFO:None
2026-01-30 09:39:04,358:INFO:Set up data.
2026-01-30 09:39:04,474:INFO:Set up folding strategy.
2026-01-30 09:39:04,474:INFO:Set up train/test split.
2026-01-30 09:39:04,661:INFO:Set up index.
2026-01-30 09:39:04,673:INFO:Assigning column types.
2026-01-30 09:39:04,778:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-30 09:39:04,811:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 09:39:04,811:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:39:04,827:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:39:04,827:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:39:04,839:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 09:39:04,839:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:39:04,861:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:39:04,861:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:39:04,870:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-30 09:39:04,894:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:39:04,911:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:39:04,911:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:39:04,937:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:39:04,954:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:39:04,954:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:39:04,955:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-30 09:39:04,994:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:39:04,994:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:39:05,037:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:39:05,037:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:39:05,039:INFO:Preparing preprocessing pipeline...
2026-01-30 09:39:05,058:INFO:Set up simple imputation.
2026-01-30 09:39:05,059:INFO:Set up feature normalization.
2026-01-30 09:39:05,507:INFO:Finished creating preprocessing pipeline.
2026-01-30 09:39:05,507:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'PAID_AMOUNT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdina...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-30 09:39:05,507:INFO:Creating final display dataframe.
2026-01-30 09:39:06,610:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape      (429278, 22)
4        Transformed data shape      (429278, 22)
5   Transformed train set shape      (300494, 22)
6    Transformed test set shape      (128784, 22)
7              Numeric features                18
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                 3
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              a68c
2026-01-30 09:39:06,638:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:39:06,638:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:39:06,690:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:39:06,690:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:39:06,690:INFO:setup() successfully completed in 2.35s...............
2026-01-30 09:39:06,690:INFO:Initializing compare_models()
2026-01-30 09:39:06,690:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-30 09:39:06,690:INFO:Checking exceptions
2026-01-30 09:39:06,791:INFO:Preparing display monitor
2026-01-30 09:39:06,791:INFO:Initializing Logistic Regression
2026-01-30 09:39:06,791:INFO:Total runtime is 0.0 minutes
2026-01-30 09:39:06,791:INFO:SubProcess create_model() called ==================================
2026-01-30 09:39:06,791:INFO:Initializing create_model()
2026-01-30 09:39:06,791:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C9F29550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:39:06,791:INFO:Checking exceptions
2026-01-30 09:39:06,791:INFO:Importing libraries
2026-01-30 09:39:06,791:INFO:Copying training dataset
2026-01-30 09:39:06,925:INFO:Defining folds
2026-01-30 09:39:06,925:INFO:Declaring metric variables
2026-01-30 09:39:06,925:INFO:Importing untrained model
2026-01-30 09:39:06,925:INFO:Logistic Regression Imported successfully
2026-01-30 09:39:06,925:INFO:Starting cross validation
2026-01-30 09:39:06,925:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:39:14,419:INFO:Calculating mean and std
2026-01-30 09:39:14,420:INFO:Creating metrics dataframe
2026-01-30 09:39:14,421:INFO:Uploading results into container
2026-01-30 09:39:14,421:INFO:Uploading model into container now
2026-01-30 09:39:14,421:INFO:_master_model_container: 1
2026-01-30 09:39:14,421:INFO:_display_container: 2
2026-01-30 09:39:14,425:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-30 09:39:14,425:INFO:create_model() successfully completed......................................
2026-01-30 09:39:14,541:INFO:SubProcess create_model() end ==================================
2026-01-30 09:39:14,541:INFO:Creating metrics dataframe
2026-01-30 09:39:14,541:INFO:Initializing Decision Tree Classifier
2026-01-30 09:39:14,541:INFO:Total runtime is 0.12916266918182373 minutes
2026-01-30 09:39:14,541:INFO:SubProcess create_model() called ==================================
2026-01-30 09:39:14,541:INFO:Initializing create_model()
2026-01-30 09:39:14,541:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C9F29550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:39:14,541:INFO:Checking exceptions
2026-01-30 09:39:14,541:INFO:Importing libraries
2026-01-30 09:39:14,541:INFO:Copying training dataset
2026-01-30 09:39:14,671:INFO:Defining folds
2026-01-30 09:39:14,671:INFO:Declaring metric variables
2026-01-30 09:39:14,671:INFO:Importing untrained model
2026-01-30 09:39:14,671:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:39:14,671:INFO:Starting cross validation
2026-01-30 09:39:14,671:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:39:20,653:INFO:Calculating mean and std
2026-01-30 09:39:20,655:INFO:Creating metrics dataframe
2026-01-30 09:39:20,659:INFO:Uploading results into container
2026-01-30 09:39:20,659:INFO:Uploading model into container now
2026-01-30 09:39:20,661:INFO:_master_model_container: 2
2026-01-30 09:39:20,661:INFO:_display_container: 2
2026-01-30 09:39:20,661:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:39:20,661:INFO:create_model() successfully completed......................................
2026-01-30 09:39:20,771:INFO:SubProcess create_model() end ==================================
2026-01-30 09:39:20,771:INFO:Creating metrics dataframe
2026-01-30 09:39:20,771:INFO:Initializing Random Forest Classifier
2026-01-30 09:39:20,771:INFO:Total runtime is 0.23299130996068318 minutes
2026-01-30 09:39:20,771:INFO:SubProcess create_model() called ==================================
2026-01-30 09:39:20,771:INFO:Initializing create_model()
2026-01-30 09:39:20,771:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C9F29550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:39:20,771:INFO:Checking exceptions
2026-01-30 09:39:20,771:INFO:Importing libraries
2026-01-30 09:39:20,771:INFO:Copying training dataset
2026-01-30 09:39:20,904:INFO:Defining folds
2026-01-30 09:39:20,904:INFO:Declaring metric variables
2026-01-30 09:39:20,904:INFO:Importing untrained model
2026-01-30 09:39:20,904:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:39:20,904:INFO:Starting cross validation
2026-01-30 09:39:20,904:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:39:37,903:INFO:Calculating mean and std
2026-01-30 09:39:37,904:INFO:Creating metrics dataframe
2026-01-30 09:39:37,904:INFO:Uploading results into container
2026-01-30 09:39:37,904:INFO:Uploading model into container now
2026-01-30 09:39:37,904:INFO:_master_model_container: 3
2026-01-30 09:39:37,904:INFO:_display_container: 2
2026-01-30 09:39:37,904:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:39:37,904:INFO:create_model() successfully completed......................................
2026-01-30 09:39:38,021:INFO:SubProcess create_model() end ==================================
2026-01-30 09:39:38,021:INFO:Creating metrics dataframe
2026-01-30 09:39:38,021:INFO:Initializing Light Gradient Boosting Machine
2026-01-30 09:39:38,021:INFO:Total runtime is 0.5204903920491537 minutes
2026-01-30 09:39:38,021:INFO:SubProcess create_model() called ==================================
2026-01-30 09:39:38,021:INFO:Initializing create_model()
2026-01-30 09:39:38,021:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C9F29550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:39:38,021:INFO:Checking exceptions
2026-01-30 09:39:38,021:INFO:Importing libraries
2026-01-30 09:39:38,021:INFO:Copying training dataset
2026-01-30 09:39:38,171:INFO:Defining folds
2026-01-30 09:39:38,171:INFO:Declaring metric variables
2026-01-30 09:39:38,171:INFO:Importing untrained model
2026-01-30 09:39:38,171:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:39:38,171:INFO:Starting cross validation
2026-01-30 09:39:38,171:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:39:45,503:INFO:Calculating mean and std
2026-01-30 09:39:45,504:INFO:Creating metrics dataframe
2026-01-30 09:39:45,504:INFO:Uploading results into container
2026-01-30 09:39:45,504:INFO:Uploading model into container now
2026-01-30 09:39:45,504:INFO:_master_model_container: 4
2026-01-30 09:39:45,504:INFO:_display_container: 2
2026-01-30 09:39:45,504:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:39:45,504:INFO:create_model() successfully completed......................................
2026-01-30 09:39:45,624:INFO:SubProcess create_model() end ==================================
2026-01-30 09:39:45,624:INFO:Creating metrics dataframe
2026-01-30 09:39:45,624:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-30 09:39:45,624:INFO:Initializing create_model()
2026-01-30 09:39:45,624:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:39:45,624:INFO:Checking exceptions
2026-01-30 09:39:45,624:INFO:Importing libraries
2026-01-30 09:39:45,624:INFO:Copying training dataset
2026-01-30 09:39:45,771:INFO:Defining folds
2026-01-30 09:39:45,771:INFO:Declaring metric variables
2026-01-30 09:39:45,771:INFO:Importing untrained model
2026-01-30 09:39:45,771:INFO:Declaring custom model
2026-01-30 09:39:45,771:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:39:45,771:INFO:Cross validation set to False
2026-01-30 09:39:45,771:INFO:Fitting Model
2026-01-30 09:39:52,757:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:39:52,757:INFO:create_model() successfully completed......................................
2026-01-30 09:39:52,871:INFO:Initializing create_model()
2026-01-30 09:39:52,871:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:39:52,871:INFO:Checking exceptions
2026-01-30 09:39:52,871:INFO:Importing libraries
2026-01-30 09:39:52,871:INFO:Copying training dataset
2026-01-30 09:39:53,023:INFO:Defining folds
2026-01-30 09:39:53,023:INFO:Declaring metric variables
2026-01-30 09:39:53,023:INFO:Importing untrained model
2026-01-30 09:39:53,023:INFO:Declaring custom model
2026-01-30 09:39:53,023:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:39:53,023:INFO:Cross validation set to False
2026-01-30 09:39:53,023:INFO:Fitting Model
2026-01-30 09:39:53,651:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 09:39:53,699:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008173 seconds.
2026-01-30 09:39:53,699:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:39:53,699:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:39:53,701:INFO:[LightGBM] [Info] Total Bins 3112
2026-01-30 09:39:53,701:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 21
2026-01-30 09:39:53,704:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 09:39:53,704:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 09:39:54,537:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:39:54,537:INFO:create_model() successfully completed......................................
2026-01-30 09:39:54,704:INFO:Initializing create_model()
2026-01-30 09:39:54,719:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:39:54,720:INFO:Checking exceptions
2026-01-30 09:39:54,720:INFO:Importing libraries
2026-01-30 09:39:54,720:INFO:Copying training dataset
2026-01-30 09:39:54,889:INFO:Defining folds
2026-01-30 09:39:54,889:INFO:Declaring metric variables
2026-01-30 09:39:54,889:INFO:Importing untrained model
2026-01-30 09:39:54,889:INFO:Declaring custom model
2026-01-30 09:39:54,889:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:39:54,889:INFO:Cross validation set to False
2026-01-30 09:39:54,889:INFO:Fitting Model
2026-01-30 09:39:57,713:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:39:57,713:INFO:create_model() successfully completed......................................
2026-01-30 09:39:57,843:INFO:_master_model_container: 4
2026-01-30 09:39:57,844:INFO:_display_container: 2
2026-01-30 09:39:57,844:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')]
2026-01-30 09:39:57,844:INFO:compare_models() successfully completed......................................
2026-01-30 09:39:57,861:INFO:Initializing tune_model()
2026-01-30 09:39:57,861:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:39:57,861:INFO:Checking exceptions
2026-01-30 09:39:57,916:INFO:Copying training dataset
2026-01-30 09:39:58,022:INFO:Checking base model
2026-01-30 09:39:58,023:INFO:Base model : Random Forest Classifier
2026-01-30 09:39:58,023:INFO:Declaring metric variables
2026-01-30 09:39:58,024:INFO:Defining Hyperparameters
2026-01-30 09:39:58,141:INFO:Tuning with n_jobs=-1
2026-01-30 09:39:58,142:INFO:Initializing RandomizedSearchCV
2026-01-30 09:42:15,983:INFO:best_params: {'actual_estimator__n_estimators': 120, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-30 09:42:15,986:INFO:Hyperparameter search completed
2026-01-30 09:42:15,986:INFO:SubProcess create_model() called ==================================
2026-01-30 09:42:15,986:INFO:Initializing create_model()
2026-01-30 09:42:15,986:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A06A301290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 120, 'min_samples_split': 5, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': True})
2026-01-30 09:42:15,986:INFO:Checking exceptions
2026-01-30 09:42:15,986:INFO:Importing libraries
2026-01-30 09:42:15,986:INFO:Copying training dataset
2026-01-30 09:42:16,220:INFO:Defining folds
2026-01-30 09:42:16,220:INFO:Declaring metric variables
2026-01-30 09:42:16,220:INFO:Importing untrained model
2026-01-30 09:42:16,220:INFO:Declaring custom model
2026-01-30 09:42:16,220:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:42:16,220:INFO:Starting cross validation
2026-01-30 09:42:16,220:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:42:30,870:INFO:Calculating mean and std
2026-01-30 09:42:30,870:INFO:Creating metrics dataframe
2026-01-30 09:42:30,874:INFO:Finalizing model
2026-01-30 09:42:37,952:INFO:Uploading results into container
2026-01-30 09:42:37,952:INFO:Uploading model into container now
2026-01-30 09:42:37,952:INFO:_master_model_container: 5
2026-01-30 09:42:37,966:INFO:_display_container: 3
2026-01-30 09:42:37,966:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=120, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:42:37,966:INFO:create_model() successfully completed......................................
2026-01-30 09:42:38,118:INFO:SubProcess create_model() end ==================================
2026-01-30 09:42:38,118:INFO:choose_better activated
2026-01-30 09:42:38,118:INFO:SubProcess create_model() called ==================================
2026-01-30 09:42:38,118:INFO:Initializing create_model()
2026-01-30 09:42:38,118:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:42:38,118:INFO:Checking exceptions
2026-01-30 09:42:38,118:INFO:Importing libraries
2026-01-30 09:42:38,118:INFO:Copying training dataset
2026-01-30 09:42:38,285:INFO:Defining folds
2026-01-30 09:42:38,285:INFO:Declaring metric variables
2026-01-30 09:42:38,285:INFO:Importing untrained model
2026-01-30 09:42:38,285:INFO:Declaring custom model
2026-01-30 09:42:38,285:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:42:38,285:INFO:Starting cross validation
2026-01-30 09:42:38,285:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:42:56,385:INFO:Calculating mean and std
2026-01-30 09:42:56,385:INFO:Creating metrics dataframe
2026-01-30 09:42:56,385:INFO:Finalizing model
2026-01-30 09:43:04,851:INFO:Uploading results into container
2026-01-30 09:43:04,852:INFO:Uploading model into container now
2026-01-30 09:43:04,853:INFO:_master_model_container: 6
2026-01-30 09:43:04,853:INFO:_display_container: 4
2026-01-30 09:43:04,853:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:43:04,853:INFO:create_model() successfully completed......................................
2026-01-30 09:43:04,970:INFO:SubProcess create_model() end ==================================
2026-01-30 09:43:04,970:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.998
2026-01-30 09:43:04,970:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=120, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9879
2026-01-30 09:43:04,970:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-30 09:43:04,970:INFO:choose_better completed
2026-01-30 09:43:04,970:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 09:43:04,985:INFO:_master_model_container: 6
2026-01-30 09:43:04,985:INFO:_display_container: 3
2026-01-30 09:43:04,985:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:43:04,985:INFO:tune_model() successfully completed......................................
2026-01-30 09:43:05,107:INFO:Initializing tune_model()
2026-01-30 09:43:05,107:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:43:05,107:INFO:Checking exceptions
2026-01-30 09:43:05,151:INFO:Copying training dataset
2026-01-30 09:43:05,262:INFO:Checking base model
2026-01-30 09:43:05,262:INFO:Base model : Light Gradient Boosting Machine
2026-01-30 09:43:05,262:INFO:Declaring metric variables
2026-01-30 09:43:05,262:INFO:Defining Hyperparameters
2026-01-30 09:43:05,368:INFO:Tuning with n_jobs=-1
2026-01-30 09:43:05,368:INFO:Initializing RandomizedSearchCV
2026-01-30 09:43:43,827:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2026-01-30 09:43:43,828:INFO:Hyperparameter search completed
2026-01-30 09:43:43,830:INFO:SubProcess create_model() called ==================================
2026-01-30 09:43:43,832:INFO:Initializing create_model()
2026-01-30 09:43:43,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C28A16D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2026-01-30 09:43:43,833:INFO:Checking exceptions
2026-01-30 09:43:43,833:INFO:Importing libraries
2026-01-30 09:43:43,833:INFO:Copying training dataset
2026-01-30 09:43:44,105:INFO:Defining folds
2026-01-30 09:43:44,105:INFO:Declaring metric variables
2026-01-30 09:43:44,105:INFO:Importing untrained model
2026-01-30 09:43:44,105:INFO:Declaring custom model
2026-01-30 09:43:44,107:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:43:44,108:INFO:Starting cross validation
2026-01-30 09:43:44,109:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:43:53,442:INFO:Calculating mean and std
2026-01-30 09:43:53,442:INFO:Creating metrics dataframe
2026-01-30 09:43:53,442:INFO:Finalizing model
2026-01-30 09:43:54,017:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 09:43:54,017:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 09:43:54,017:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 09:43:54,196:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 09:43:54,196:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 09:43:54,196:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 09:43:54,197:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 09:43:54,255:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009683 seconds.
2026-01-30 09:43:54,255:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:43:54,255:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:43:54,256:INFO:[LightGBM] [Info] Total Bins 3112
2026-01-30 09:43:54,257:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 21
2026-01-30 09:43:54,261:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 09:43:54,261:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 09:43:57,221:INFO:Uploading results into container
2026-01-30 09:43:57,223:INFO:Uploading model into container now
2026-01-30 09:43:57,223:INFO:_master_model_container: 7
2026-01-30 09:43:57,223:INFO:_display_container: 4
2026-01-30 09:43:57,225:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:43:57,225:INFO:create_model() successfully completed......................................
2026-01-30 09:43:57,411:INFO:SubProcess create_model() end ==================================
2026-01-30 09:43:57,411:INFO:choose_better activated
2026-01-30 09:43:57,411:INFO:SubProcess create_model() called ==================================
2026-01-30 09:43:57,412:INFO:Initializing create_model()
2026-01-30 09:43:57,412:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:43:57,412:INFO:Checking exceptions
2026-01-30 09:43:57,413:INFO:Importing libraries
2026-01-30 09:43:57,413:INFO:Copying training dataset
2026-01-30 09:43:57,600:INFO:Defining folds
2026-01-30 09:43:57,600:INFO:Declaring metric variables
2026-01-30 09:43:57,600:INFO:Importing untrained model
2026-01-30 09:43:57,600:INFO:Declaring custom model
2026-01-30 09:43:57,600:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:43:57,600:INFO:Starting cross validation
2026-01-30 09:43:57,600:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:44:01,906:INFO:Calculating mean and std
2026-01-30 09:44:01,906:INFO:Creating metrics dataframe
2026-01-30 09:44:01,906:INFO:Finalizing model
2026-01-30 09:44:02,554:INFO:[LightGBM] [Info] Number of positive: 116896, number of negative: 183598
2026-01-30 09:44:02,607:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008181 seconds.
2026-01-30 09:44:02,607:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:44:02,607:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:44:02,607:INFO:[LightGBM] [Info] Total Bins 3112
2026-01-30 09:44:02,609:INFO:[LightGBM] [Info] Number of data points in the train set: 300494, number of used features: 21
2026-01-30 09:44:02,612:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389013 -> initscore=-0.451464
2026-01-30 09:44:02,612:INFO:[LightGBM] [Info] Start training from score -0.451464
2026-01-30 09:44:03,503:INFO:Uploading results into container
2026-01-30 09:44:03,504:INFO:Uploading model into container now
2026-01-30 09:44:03,505:INFO:_master_model_container: 8
2026-01-30 09:44:03,505:INFO:_display_container: 5
2026-01-30 09:44:03,506:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:44:03,506:INFO:create_model() successfully completed......................................
2026-01-30 09:44:03,700:INFO:SubProcess create_model() end ==================================
2026-01-30 09:44:03,700:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9936
2026-01-30 09:44:03,700:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9981
2026-01-30 09:44:03,700:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2026-01-30 09:44:03,700:INFO:choose_better completed
2026-01-30 09:44:03,700:INFO:_master_model_container: 8
2026-01-30 09:44:03,700:INFO:_display_container: 4
2026-01-30 09:44:03,700:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:44:03,700:INFO:tune_model() successfully completed......................................
2026-01-30 09:44:03,833:INFO:Initializing tune_model()
2026-01-30 09:44:03,833:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:44:03,833:INFO:Checking exceptions
2026-01-30 09:44:03,907:INFO:Copying training dataset
2026-01-30 09:44:04,017:INFO:Checking base model
2026-01-30 09:44:04,017:INFO:Base model : Decision Tree Classifier
2026-01-30 09:44:04,017:INFO:Declaring metric variables
2026-01-30 09:44:04,017:INFO:Defining Hyperparameters
2026-01-30 09:44:04,134:INFO:Tuning with n_jobs=-1
2026-01-30 09:44:04,134:INFO:Initializing RandomizedSearchCV
2026-01-30 09:44:10,874:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 15, 'actual_estimator__criterion': 'gini'}
2026-01-30 09:44:10,874:INFO:Hyperparameter search completed
2026-01-30 09:44:10,874:INFO:SubProcess create_model() called ==================================
2026-01-30 09:44:10,874:INFO:Initializing create_model()
2026-01-30 09:44:10,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A06E646BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 2, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 15, 'criterion': 'gini'})
2026-01-30 09:44:10,874:INFO:Checking exceptions
2026-01-30 09:44:10,874:INFO:Importing libraries
2026-01-30 09:44:10,874:INFO:Copying training dataset
2026-01-30 09:44:11,083:INFO:Defining folds
2026-01-30 09:44:11,083:INFO:Declaring metric variables
2026-01-30 09:44:11,083:INFO:Importing untrained model
2026-01-30 09:44:11,083:INFO:Declaring custom model
2026-01-30 09:44:11,083:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:44:11,083:INFO:Starting cross validation
2026-01-30 09:44:11,083:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:44:13,487:INFO:Calculating mean and std
2026-01-30 09:44:13,489:INFO:Creating metrics dataframe
2026-01-30 09:44:13,494:INFO:Finalizing model
2026-01-30 09:44:15,064:INFO:Uploading results into container
2026-01-30 09:44:15,065:INFO:Uploading model into container now
2026-01-30 09:44:15,065:INFO:_master_model_container: 9
2026-01-30 09:44:15,065:INFO:_display_container: 5
2026-01-30 09:44:15,065:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:44:15,066:INFO:create_model() successfully completed......................................
2026-01-30 09:44:15,192:INFO:SubProcess create_model() end ==================================
2026-01-30 09:44:15,192:INFO:choose_better activated
2026-01-30 09:44:15,192:INFO:SubProcess create_model() called ==================================
2026-01-30 09:44:15,193:INFO:Initializing create_model()
2026-01-30 09:44:15,193:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:44:15,193:INFO:Checking exceptions
2026-01-30 09:44:15,193:INFO:Importing libraries
2026-01-30 09:44:15,194:INFO:Copying training dataset
2026-01-30 09:44:15,367:INFO:Defining folds
2026-01-30 09:44:15,367:INFO:Declaring metric variables
2026-01-30 09:44:15,367:INFO:Importing untrained model
2026-01-30 09:44:15,367:INFO:Declaring custom model
2026-01-30 09:44:15,367:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:44:15,367:INFO:Starting cross validation
2026-01-30 09:44:15,367:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:44:18,821:INFO:Calculating mean and std
2026-01-30 09:44:18,821:INFO:Creating metrics dataframe
2026-01-30 09:44:18,822:INFO:Finalizing model
2026-01-30 09:44:21,655:INFO:Uploading results into container
2026-01-30 09:44:21,655:INFO:Uploading model into container now
2026-01-30 09:44:21,666:INFO:_master_model_container: 10
2026-01-30 09:44:21,666:INFO:_display_container: 6
2026-01-30 09:44:21,666:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:44:21,666:INFO:create_model() successfully completed......................................
2026-01-30 09:44:21,807:INFO:SubProcess create_model() end ==================================
2026-01-30 09:44:21,807:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9856
2026-01-30 09:44:21,808:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9831
2026-01-30 09:44:21,808:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-30 09:44:21,808:INFO:choose_better completed
2026-01-30 09:44:21,808:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 09:44:21,810:INFO:_master_model_container: 10
2026-01-30 09:44:21,811:INFO:_display_container: 5
2026-01-30 09:44:21,811:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:44:21,811:INFO:tune_model() successfully completed......................................
2026-01-30 09:44:21,967:INFO:Initializing predict_model()
2026-01-30 09:44:21,967:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A03C5465C0>)
2026-01-30 09:44:21,968:INFO:Checking exceptions
2026-01-30 09:44:21,968:INFO:Preloading libraries
2026-01-30 09:44:21,968:INFO:Set up data.
2026-01-30 09:44:22,007:INFO:Set up index.
2026-01-30 09:44:23,289:INFO:Initializing predict_model()
2026-01-30 09:44:23,289:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A0C3C9E700>)
2026-01-30 09:44:23,289:INFO:Checking exceptions
2026-01-30 09:44:23,289:INFO:Preloading libraries
2026-01-30 09:44:23,289:INFO:Set up data.
2026-01-30 09:44:23,333:INFO:Set up index.
2026-01-30 09:44:24,423:INFO:Initializing predict_model()
2026-01-30 09:44:24,423:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A03C5465C0>)
2026-01-30 09:44:24,423:INFO:Checking exceptions
2026-01-30 09:44:24,423:INFO:Preloading libraries
2026-01-30 09:44:24,423:INFO:Set up data.
2026-01-30 09:44:24,460:INFO:Set up index.
2026-01-30 09:44:24,955:INFO:Initializing plot_model()
2026-01-30 09:44:24,961:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 09:44:24,961:INFO:Checking exceptions
2026-01-30 09:44:25,057:INFO:Preloading libraries
2026-01-30 09:44:25,136:INFO:Copying training dataset
2026-01-30 09:44:25,136:INFO:Plot type: feature
2026-01-30 09:44:25,136:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 09:44:25,418:INFO:Visual Rendered Successfully
2026-01-30 09:44:25,538:INFO:plot_model() successfully completed......................................
2026-01-30 09:44:25,549:INFO:Initializing plot_model()
2026-01-30 09:44:25,549:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C387150>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature_all, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 09:44:25,549:INFO:Checking exceptions
2026-01-30 09:44:25,633:INFO:Preloading libraries
2026-01-30 09:44:25,700:INFO:Copying training dataset
2026-01-30 09:44:25,700:INFO:Plot type: feature_all
2026-01-30 09:44:25,850:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 09:44:26,189:INFO:Visual Rendered Successfully
2026-01-30 09:44:26,307:INFO:plot_model() successfully completed......................................
2026-01-30 09:44:26,323:INFO:Initializing save_model()
2026-01-30 09:44:26,323:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), model_name=..\datos\04. Modelos\modelo_final_explicable, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'PAID_AMOUNT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdina...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-30 09:44:26,323:INFO:Adding model into prep_pipe
2026-01-30 09:44:26,426:INFO:..\datos\04. Modelos\modelo_final_explicable.pkl saved in current working directory
2026-01-30 09:44:26,429:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'PAID_AMOUNT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdinario_def__c',
                                             'CU_precioAplicado_def__c',
                                             'PO...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=42, verbose=0,
                                        warm_start=False))],
         verbose=False)
2026-01-30 09:44:26,429:INFO:save_model() successfully completed......................................
2026-01-30 09:54:19,796:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\3560701889.py:20: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-30 09:54:21,875:INFO:PyCaret ClassificationExperiment
2026-01-30 09:54:21,890:INFO:Logging name: clf-default-name
2026-01-30 09:54:21,890:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-30 09:54:21,890:INFO:version 3.3.2
2026-01-30 09:54:21,891:INFO:Initializing setup()
2026-01-30 09:54:21,891:INFO:self.USI: 0e4f
2026-01-30 09:54:21,891:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'n_jobs_param', 'data', 'X', 'idx', 'y_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'USI', 'target_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'y_train', 'X_test', 'seed', 'gpu_param', 'gpu_n_jobs_param', 'y', 'logging_param', 'pipeline', 'fold_generator', 'exp_id'}
2026-01-30 09:54:21,891:INFO:Checking environment
2026-01-30 09:54:21,892:INFO:python_version: 3.11.11
2026-01-30 09:54:21,892:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-30 09:54:21,892:INFO:machine: AMD64
2026-01-30 09:54:21,893:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-30 09:54:21,893:INFO:Memory: svmem(total=34009374720, available=15314989056, percent=55.0, used=18694385664, free=15314989056)
2026-01-30 09:54:21,893:INFO:Physical Core: 12
2026-01-30 09:54:21,893:INFO:Logical Core: 16
2026-01-30 09:54:21,894:INFO:Checking libraries
2026-01-30 09:54:21,894:INFO:System:
2026-01-30 09:54:21,894:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-30 09:54:21,894:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-30 09:54:21,894:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-30 09:54:21,894:INFO:PyCaret required dependencies:
2026-01-30 09:54:21,894:INFO:                 pip: 25.0
2026-01-30 09:54:21,894:INFO:          setuptools: 75.8.0
2026-01-30 09:54:21,894:INFO:             pycaret: 3.3.2
2026-01-30 09:54:21,894:INFO:             IPython: 9.9.0
2026-01-30 09:54:21,894:INFO:          ipywidgets: 8.1.8
2026-01-30 09:54:21,894:INFO:                tqdm: 4.67.1
2026-01-30 09:54:21,894:INFO:               numpy: 1.26.4
2026-01-30 09:54:21,894:INFO:              pandas: 2.1.4
2026-01-30 09:54:21,894:INFO:              jinja2: 3.1.6
2026-01-30 09:54:21,894:INFO:               scipy: 1.11.4
2026-01-30 09:54:21,894:INFO:              joblib: 1.3.2
2026-01-30 09:54:21,894:INFO:             sklearn: 1.4.2
2026-01-30 09:54:21,894:INFO:                pyod: 2.0.6
2026-01-30 09:54:21,894:INFO:            imblearn: 0.14.1
2026-01-30 09:54:21,894:INFO:   category_encoders: 2.7.0
2026-01-30 09:54:21,894:INFO:            lightgbm: 4.6.0
2026-01-30 09:54:21,894:INFO:               numba: 0.62.1
2026-01-30 09:54:21,894:INFO:            requests: 2.32.3
2026-01-30 09:54:21,894:INFO:          matplotlib: 3.7.5
2026-01-30 09:54:21,894:INFO:          scikitplot: 0.3.7
2026-01-30 09:54:21,894:INFO:         yellowbrick: 1.5
2026-01-30 09:54:21,894:INFO:              plotly: 5.24.1
2026-01-30 09:54:21,894:INFO:    plotly-resampler: Not installed
2026-01-30 09:54:21,894:INFO:             kaleido: 1.2.0
2026-01-30 09:54:21,894:INFO:           schemdraw: 0.15
2026-01-30 09:54:21,894:INFO:         statsmodels: 0.14.6
2026-01-30 09:54:21,894:INFO:              sktime: 0.26.0
2026-01-30 09:54:21,894:INFO:               tbats: 1.1.3
2026-01-30 09:54:21,894:INFO:            pmdarima: 2.0.4
2026-01-30 09:54:21,894:INFO:              psutil: 7.2.1
2026-01-30 09:54:21,894:INFO:          markupsafe: 3.0.3
2026-01-30 09:54:21,894:INFO:             pickle5: Not installed
2026-01-30 09:54:21,894:INFO:         cloudpickle: 3.0.0
2026-01-30 09:54:21,894:INFO:         deprecation: 2.1.0
2026-01-30 09:54:21,894:INFO:              xxhash: 3.6.0
2026-01-30 09:54:21,894:INFO:           wurlitzer: Not installed
2026-01-30 09:54:21,894:INFO:PyCaret optional dependencies:
2026-01-30 09:54:21,894:INFO:                shap: 0.44.1
2026-01-30 09:54:21,894:INFO:           interpret: 0.7.3
2026-01-30 09:54:21,894:INFO:                umap: 0.5.7
2026-01-30 09:54:21,894:INFO:     ydata_profiling: 4.18.1
2026-01-30 09:54:21,894:INFO:  explainerdashboard: 0.5.1
2026-01-30 09:54:21,894:INFO:             autoviz: Not installed
2026-01-30 09:54:21,894:INFO:           fairlearn: 0.7.0
2026-01-30 09:54:21,894:INFO:          deepchecks: Not installed
2026-01-30 09:54:21,894:INFO:             xgboost: Not installed
2026-01-30 09:54:21,894:INFO:            catboost: 1.2.8
2026-01-30 09:54:21,894:INFO:              kmodes: 0.12.2
2026-01-30 09:54:21,894:INFO:             mlxtend: 0.23.4
2026-01-30 09:54:21,894:INFO:       statsforecast: 1.5.0
2026-01-30 09:54:21,894:INFO:        tune_sklearn: Not installed
2026-01-30 09:54:21,894:INFO:                 ray: Not installed
2026-01-30 09:54:21,894:INFO:            hyperopt: 0.2.7
2026-01-30 09:54:21,894:INFO:              optuna: 4.6.0
2026-01-30 09:54:21,894:INFO:               skopt: 0.10.2
2026-01-30 09:54:21,894:INFO:              mlflow: 3.8.1
2026-01-30 09:54:21,894:INFO:              gradio: 6.3.0
2026-01-30 09:54:21,894:INFO:             fastapi: 0.128.0
2026-01-30 09:54:21,894:INFO:             uvicorn: 0.40.0
2026-01-30 09:54:21,894:INFO:              m2cgen: 0.10.0
2026-01-30 09:54:21,894:INFO:           evidently: 0.4.40
2026-01-30 09:54:21,894:INFO:               fugue: 0.8.7
2026-01-30 09:54:21,894:INFO:           streamlit: Not installed
2026-01-30 09:54:21,894:INFO:             prophet: Not installed
2026-01-30 09:54:21,894:INFO:None
2026-01-30 09:54:21,894:INFO:Set up data.
2026-01-30 09:54:22,054:INFO:Set up folding strategy.
2026-01-30 09:54:22,054:INFO:Set up train/test split.
2026-01-30 09:54:22,275:INFO:Set up index.
2026-01-30 09:54:22,291:INFO:Assigning column types.
2026-01-30 09:54:22,456:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-30 09:54:22,486:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 09:54:22,487:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:54:22,506:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:54:22,506:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:54:22,536:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 09:54:22,537:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:54:22,556:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:54:22,557:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:54:22,558:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-30 09:54:22,584:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:54:22,610:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:54:22,610:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:54:22,644:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 09:54:22,658:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:54:22,658:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:54:22,658:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-30 09:54:22,708:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:54:22,708:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:54:22,758:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:54:22,758:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:54:22,758:INFO:Preparing preprocessing pipeline...
2026-01-30 09:54:22,791:INFO:Set up simple imputation.
2026-01-30 09:54:22,791:INFO:Set up feature normalization.
2026-01-30 09:54:23,696:INFO:Finished creating preprocessing pipeline.
2026-01-30 09:54:23,707:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'PAID_AMOUNT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdina...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-30 09:54:23,708:INFO:Creating final display dataframe.
2026-01-30 09:54:25,695:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape      (482669, 28)
4        Transformed data shape      (482669, 28)
5   Transformed train set shape      (337868, 28)
6    Transformed test set shape      (144801, 28)
7              Numeric features                24
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                 3
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              0e4f
2026-01-30 09:54:25,761:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:54:25,761:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:54:25,828:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 09:54:25,828:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 09:54:25,828:INFO:setup() successfully completed in 3.95s...............
2026-01-30 09:54:25,828:INFO:Initializing compare_models()
2026-01-30 09:54:25,828:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-30 09:54:25,828:INFO:Checking exceptions
2026-01-30 09:54:25,975:INFO:Preparing display monitor
2026-01-30 09:54:25,991:INFO:Initializing Logistic Regression
2026-01-30 09:54:25,991:INFO:Total runtime is 0.0 minutes
2026-01-30 09:54:25,991:INFO:SubProcess create_model() called ==================================
2026-01-30 09:54:25,991:INFO:Initializing create_model()
2026-01-30 09:54:25,991:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0D02B07D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:54:25,991:INFO:Checking exceptions
2026-01-30 09:54:25,991:INFO:Importing libraries
2026-01-30 09:54:25,991:INFO:Copying training dataset
2026-01-30 09:54:26,227:INFO:Defining folds
2026-01-30 09:54:26,227:INFO:Declaring metric variables
2026-01-30 09:54:26,227:INFO:Importing untrained model
2026-01-30 09:54:26,227:INFO:Logistic Regression Imported successfully
2026-01-30 09:54:26,227:INFO:Starting cross validation
2026-01-30 09:54:26,227:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:54:36,429:INFO:Calculating mean and std
2026-01-30 09:54:36,429:INFO:Creating metrics dataframe
2026-01-30 09:54:36,429:INFO:Uploading results into container
2026-01-30 09:54:36,429:INFO:Uploading model into container now
2026-01-30 09:54:36,429:INFO:_master_model_container: 1
2026-01-30 09:54:36,429:INFO:_display_container: 2
2026-01-30 09:54:36,429:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-30 09:54:36,429:INFO:create_model() successfully completed......................................
2026-01-30 09:54:36,558:INFO:SubProcess create_model() end ==================================
2026-01-30 09:54:36,573:INFO:Creating metrics dataframe
2026-01-30 09:54:36,575:INFO:Initializing Decision Tree Classifier
2026-01-30 09:54:36,575:INFO:Total runtime is 0.17639289697011312 minutes
2026-01-30 09:54:36,575:INFO:SubProcess create_model() called ==================================
2026-01-30 09:54:36,575:INFO:Initializing create_model()
2026-01-30 09:54:36,575:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0D02B07D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:54:36,575:INFO:Checking exceptions
2026-01-30 09:54:36,575:INFO:Importing libraries
2026-01-30 09:54:36,575:INFO:Copying training dataset
2026-01-30 09:54:36,774:INFO:Defining folds
2026-01-30 09:54:36,774:INFO:Declaring metric variables
2026-01-30 09:54:36,774:INFO:Importing untrained model
2026-01-30 09:54:36,774:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:54:36,774:INFO:Starting cross validation
2026-01-30 09:54:36,774:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:54:45,395:INFO:Calculating mean and std
2026-01-30 09:54:45,395:INFO:Creating metrics dataframe
2026-01-30 09:54:45,395:INFO:Uploading results into container
2026-01-30 09:54:45,395:INFO:Uploading model into container now
2026-01-30 09:54:45,395:INFO:_master_model_container: 2
2026-01-30 09:54:45,395:INFO:_display_container: 2
2026-01-30 09:54:45,395:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:54:45,395:INFO:create_model() successfully completed......................................
2026-01-30 09:54:45,524:INFO:SubProcess create_model() end ==================================
2026-01-30 09:54:45,524:INFO:Creating metrics dataframe
2026-01-30 09:54:45,524:INFO:Initializing Random Forest Classifier
2026-01-30 09:54:45,524:INFO:Total runtime is 0.3255495190620422 minutes
2026-01-30 09:54:45,524:INFO:SubProcess create_model() called ==================================
2026-01-30 09:54:45,524:INFO:Initializing create_model()
2026-01-30 09:54:45,524:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0D02B07D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:54:45,524:INFO:Checking exceptions
2026-01-30 09:54:45,524:INFO:Importing libraries
2026-01-30 09:54:45,524:INFO:Copying training dataset
2026-01-30 09:54:45,724:INFO:Defining folds
2026-01-30 09:54:45,724:INFO:Declaring metric variables
2026-01-30 09:54:45,725:INFO:Importing untrained model
2026-01-30 09:54:45,725:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:54:45,725:INFO:Starting cross validation
2026-01-30 09:54:45,725:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:55:10,669:INFO:Calculating mean and std
2026-01-30 09:55:10,669:INFO:Creating metrics dataframe
2026-01-30 09:55:10,673:INFO:Uploading results into container
2026-01-30 09:55:10,674:INFO:Uploading model into container now
2026-01-30 09:55:10,674:INFO:_master_model_container: 3
2026-01-30 09:55:10,674:INFO:_display_container: 2
2026-01-30 09:55:10,674:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:55:10,674:INFO:create_model() successfully completed......................................
2026-01-30 09:55:10,807:INFO:SubProcess create_model() end ==================================
2026-01-30 09:55:10,807:INFO:Creating metrics dataframe
2026-01-30 09:55:10,807:INFO:Initializing Light Gradient Boosting Machine
2026-01-30 09:55:10,807:INFO:Total runtime is 0.7469383398691813 minutes
2026-01-30 09:55:10,807:INFO:SubProcess create_model() called ==================================
2026-01-30 09:55:10,807:INFO:Initializing create_model()
2026-01-30 09:55:10,807:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0D02B07D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:55:10,807:INFO:Checking exceptions
2026-01-30 09:55:10,807:INFO:Importing libraries
2026-01-30 09:55:10,807:INFO:Copying training dataset
2026-01-30 09:55:11,091:INFO:Defining folds
2026-01-30 09:55:11,091:INFO:Declaring metric variables
2026-01-30 09:55:11,091:INFO:Importing untrained model
2026-01-30 09:55:11,091:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:55:11,091:INFO:Starting cross validation
2026-01-30 09:55:11,091:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:55:20,519:INFO:Calculating mean and std
2026-01-30 09:55:20,523:INFO:Creating metrics dataframe
2026-01-30 09:55:20,524:INFO:Uploading results into container
2026-01-30 09:55:20,524:INFO:Uploading model into container now
2026-01-30 09:55:20,524:INFO:_master_model_container: 4
2026-01-30 09:55:20,524:INFO:_display_container: 2
2026-01-30 09:55:20,524:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:55:20,524:INFO:create_model() successfully completed......................................
2026-01-30 09:55:20,652:INFO:SubProcess create_model() end ==================================
2026-01-30 09:55:20,652:INFO:Creating metrics dataframe
2026-01-30 09:55:20,656:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-30 09:55:20,657:INFO:Initializing create_model()
2026-01-30 09:55:20,657:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:55:20,658:INFO:Checking exceptions
2026-01-30 09:55:20,658:INFO:Importing libraries
2026-01-30 09:55:20,658:INFO:Copying training dataset
2026-01-30 09:55:20,841:INFO:Defining folds
2026-01-30 09:55:20,841:INFO:Declaring metric variables
2026-01-30 09:55:20,841:INFO:Importing untrained model
2026-01-30 09:55:20,841:INFO:Declaring custom model
2026-01-30 09:55:20,841:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:55:20,841:INFO:Cross validation set to False
2026-01-30 09:55:20,841:INFO:Fitting Model
2026-01-30 09:55:30,974:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:55:30,974:INFO:create_model() successfully completed......................................
2026-01-30 09:55:31,112:INFO:Initializing create_model()
2026-01-30 09:55:31,112:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:55:31,112:INFO:Checking exceptions
2026-01-30 09:55:31,112:INFO:Importing libraries
2026-01-30 09:55:31,112:INFO:Copying training dataset
2026-01-30 09:55:31,307:INFO:Defining folds
2026-01-30 09:55:31,307:INFO:Declaring metric variables
2026-01-30 09:55:31,307:INFO:Importing untrained model
2026-01-30 09:55:31,307:INFO:Declaring custom model
2026-01-30 09:55:31,323:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 09:55:31,323:INFO:Cross validation set to False
2026-01-30 09:55:31,323:INFO:Fitting Model
2026-01-30 09:55:32,242:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 09:55:32,304:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014178 seconds.
2026-01-30 09:55:32,304:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 09:55:32,304:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 09:55:32,306:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 09:55:32,307:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 09:55:32,309:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 09:55:32,309:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 09:55:33,474:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 09:55:33,474:INFO:create_model() successfully completed......................................
2026-01-30 09:55:33,674:INFO:Initializing create_model()
2026-01-30 09:55:33,674:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:55:33,674:INFO:Checking exceptions
2026-01-30 09:55:33,674:INFO:Importing libraries
2026-01-30 09:55:33,674:INFO:Copying training dataset
2026-01-30 09:55:33,974:INFO:Defining folds
2026-01-30 09:55:33,989:INFO:Declaring metric variables
2026-01-30 09:55:33,989:INFO:Importing untrained model
2026-01-30 09:55:33,989:INFO:Declaring custom model
2026-01-30 09:55:33,989:INFO:Decision Tree Classifier Imported successfully
2026-01-30 09:55:33,990:INFO:Cross validation set to False
2026-01-30 09:55:33,990:INFO:Fitting Model
2026-01-30 09:55:36,774:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 09:55:36,774:INFO:create_model() successfully completed......................................
2026-01-30 09:55:36,909:INFO:_master_model_container: 4
2026-01-30 09:55:36,909:INFO:_display_container: 2
2026-01-30 09:55:36,909:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')]
2026-01-30 09:55:36,909:INFO:compare_models() successfully completed......................................
2026-01-30 09:55:36,909:INFO:Initializing tune_model()
2026-01-30 09:55:36,909:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:55:36,909:INFO:Checking exceptions
2026-01-30 09:55:36,990:INFO:Copying training dataset
2026-01-30 09:55:37,109:INFO:Checking base model
2026-01-30 09:55:37,109:INFO:Base model : Random Forest Classifier
2026-01-30 09:55:37,109:INFO:Declaring metric variables
2026-01-30 09:55:37,109:INFO:Defining Hyperparameters
2026-01-30 09:55:37,226:INFO:Tuning with n_jobs=-1
2026-01-30 09:55:37,226:INFO:Initializing RandomizedSearchCV
2026-01-30 09:58:27,555:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-30 09:58:27,558:INFO:Hyperparameter search completed
2026-01-30 09:58:27,558:INFO:SubProcess create_model() called ==================================
2026-01-30 09:58:27,560:INFO:Initializing create_model()
2026-01-30 09:58:27,560:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A06E675E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': True})
2026-01-30 09:58:27,560:INFO:Checking exceptions
2026-01-30 09:58:27,560:INFO:Importing libraries
2026-01-30 09:58:27,561:INFO:Copying training dataset
2026-01-30 09:58:27,988:INFO:Defining folds
2026-01-30 09:58:27,988:INFO:Declaring metric variables
2026-01-30 09:58:27,988:INFO:Importing untrained model
2026-01-30 09:58:27,988:INFO:Declaring custom model
2026-01-30 09:58:27,988:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:58:27,988:INFO:Starting cross validation
2026-01-30 09:58:27,988:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:59:01,021:INFO:Calculating mean and std
2026-01-30 09:59:01,024:INFO:Creating metrics dataframe
2026-01-30 09:59:01,027:INFO:Finalizing model
2026-01-30 09:59:17,913:INFO:Uploading results into container
2026-01-30 09:59:17,914:INFO:Uploading model into container now
2026-01-30 09:59:17,915:INFO:_master_model_container: 5
2026-01-30 09:59:17,916:INFO:_display_container: 3
2026-01-30 09:59:17,917:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:59:17,917:INFO:create_model() successfully completed......................................
2026-01-30 09:59:18,082:INFO:SubProcess create_model() end ==================================
2026-01-30 09:59:18,082:INFO:choose_better activated
2026-01-30 09:59:18,082:INFO:SubProcess create_model() called ==================================
2026-01-30 09:59:18,084:INFO:Initializing create_model()
2026-01-30 09:59:18,084:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 09:59:18,084:INFO:Checking exceptions
2026-01-30 09:59:18,085:INFO:Importing libraries
2026-01-30 09:59:18,085:INFO:Copying training dataset
2026-01-30 09:59:18,469:INFO:Defining folds
2026-01-30 09:59:18,469:INFO:Declaring metric variables
2026-01-30 09:59:18,469:INFO:Importing untrained model
2026-01-30 09:59:18,469:INFO:Declaring custom model
2026-01-30 09:59:18,470:INFO:Random Forest Classifier Imported successfully
2026-01-30 09:59:18,470:INFO:Starting cross validation
2026-01-30 09:59:18,472:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 09:59:40,639:INFO:Calculating mean and std
2026-01-30 09:59:40,640:INFO:Creating metrics dataframe
2026-01-30 09:59:40,642:INFO:Finalizing model
2026-01-30 09:59:51,731:INFO:Uploading results into container
2026-01-30 09:59:51,732:INFO:Uploading model into container now
2026-01-30 09:59:51,732:INFO:_master_model_container: 6
2026-01-30 09:59:51,733:INFO:_display_container: 4
2026-01-30 09:59:51,733:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:59:51,733:INFO:create_model() successfully completed......................................
2026-01-30 09:59:51,899:INFO:SubProcess create_model() end ==================================
2026-01-30 09:59:51,900:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9985
2026-01-30 09:59:51,901:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9894
2026-01-30 09:59:51,901:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-30 09:59:51,901:INFO:choose_better completed
2026-01-30 09:59:51,902:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 09:59:51,905:INFO:_master_model_container: 6
2026-01-30 09:59:51,906:INFO:_display_container: 3
2026-01-30 09:59:51,906:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 09:59:51,907:INFO:tune_model() successfully completed......................................
2026-01-30 09:59:52,068:INFO:Initializing tune_model()
2026-01-30 09:59:52,068:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 09:59:52,068:INFO:Checking exceptions
2026-01-30 09:59:52,189:INFO:Copying training dataset
2026-01-30 09:59:52,385:INFO:Checking base model
2026-01-30 09:59:52,385:INFO:Base model : Light Gradient Boosting Machine
2026-01-30 09:59:52,386:INFO:Declaring metric variables
2026-01-30 09:59:52,387:INFO:Defining Hyperparameters
2026-01-30 09:59:52,564:INFO:Tuning with n_jobs=-1
2026-01-30 09:59:52,565:INFO:Initializing RandomizedSearchCV
2026-01-30 10:00:39,556:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2026-01-30 10:00:39,558:INFO:Hyperparameter search completed
2026-01-30 10:00:39,558:INFO:SubProcess create_model() called ==================================
2026-01-30 10:00:39,559:INFO:Initializing create_model()
2026-01-30 10:00:39,559:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A074FCD0D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2026-01-30 10:00:39,560:INFO:Checking exceptions
2026-01-30 10:00:39,560:INFO:Importing libraries
2026-01-30 10:00:39,560:INFO:Copying training dataset
2026-01-30 10:00:39,882:INFO:Defining folds
2026-01-30 10:00:39,883:INFO:Declaring metric variables
2026-01-30 10:00:39,883:INFO:Importing untrained model
2026-01-30 10:00:39,883:INFO:Declaring custom model
2026-01-30 10:00:39,885:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:00:39,885:INFO:Starting cross validation
2026-01-30 10:00:39,886:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:00:51,413:INFO:Calculating mean and std
2026-01-30 10:00:51,414:INFO:Creating metrics dataframe
2026-01-30 10:00:51,416:INFO:Finalizing model
2026-01-30 10:00:52,223:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 10:00:52,223:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 10:00:52,223:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 10:00:52,437:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 10:00:52,438:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 10:00:52,438:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 10:00:52,438:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 10:00:52,502:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014042 seconds.
2026-01-30 10:00:52,502:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 10:00:52,502:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 10:00:52,502:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 10:00:52,504:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 10:00:52,509:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 10:00:52,510:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 10:00:56,832:INFO:Uploading results into container
2026-01-30 10:00:56,833:INFO:Uploading model into container now
2026-01-30 10:00:56,834:INFO:_master_model_container: 7
2026-01-30 10:00:56,835:INFO:_display_container: 4
2026-01-30 10:00:56,836:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:00:56,836:INFO:create_model() successfully completed......................................
2026-01-30 10:00:57,036:INFO:SubProcess create_model() end ==================================
2026-01-30 10:00:57,036:INFO:choose_better activated
2026-01-30 10:00:57,036:INFO:SubProcess create_model() called ==================================
2026-01-30 10:00:57,038:INFO:Initializing create_model()
2026-01-30 10:00:57,038:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:00:57,038:INFO:Checking exceptions
2026-01-30 10:00:57,039:INFO:Importing libraries
2026-01-30 10:00:57,040:INFO:Copying training dataset
2026-01-30 10:00:57,289:INFO:Defining folds
2026-01-30 10:00:57,289:INFO:Declaring metric variables
2026-01-30 10:00:57,289:INFO:Importing untrained model
2026-01-30 10:00:57,289:INFO:Declaring custom model
2026-01-30 10:00:57,290:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:00:57,290:INFO:Starting cross validation
2026-01-30 10:00:57,291:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:01:02,991:INFO:Calculating mean and std
2026-01-30 10:01:02,991:INFO:Creating metrics dataframe
2026-01-30 10:01:02,992:INFO:Finalizing model
2026-01-30 10:01:03,951:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 10:01:04,011:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016510 seconds.
2026-01-30 10:01:04,011:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 10:01:04,011:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 10:01:04,012:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 10:01:04,012:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 10:01:04,015:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 10:01:04,015:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 10:01:05,325:INFO:Uploading results into container
2026-01-30 10:01:05,326:INFO:Uploading model into container now
2026-01-30 10:01:05,327:INFO:_master_model_container: 8
2026-01-30 10:01:05,327:INFO:_display_container: 5
2026-01-30 10:01:05,328:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:01:05,328:INFO:create_model() successfully completed......................................
2026-01-30 10:01:05,528:INFO:SubProcess create_model() end ==================================
2026-01-30 10:01:05,529:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9945
2026-01-30 10:01:05,530:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9987
2026-01-30 10:01:05,531:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2026-01-30 10:01:05,531:INFO:choose_better completed
2026-01-30 10:01:05,534:INFO:_master_model_container: 8
2026-01-30 10:01:05,534:INFO:_display_container: 4
2026-01-30 10:01:05,535:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:01:05,535:INFO:tune_model() successfully completed......................................
2026-01-30 10:01:05,691:INFO:Initializing tune_model()
2026-01-30 10:01:05,692:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 10:01:05,692:INFO:Checking exceptions
2026-01-30 10:01:05,781:INFO:Copying training dataset
2026-01-30 10:01:05,953:INFO:Checking base model
2026-01-30 10:01:05,953:INFO:Base model : Decision Tree Classifier
2026-01-30 10:01:05,954:INFO:Declaring metric variables
2026-01-30 10:01:05,955:INFO:Defining Hyperparameters
2026-01-30 10:01:06,090:INFO:Tuning with n_jobs=-1
2026-01-30 10:01:06,090:INFO:Initializing RandomizedSearchCV
2026-01-30 10:01:15,556:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 15, 'actual_estimator__criterion': 'gini'}
2026-01-30 10:01:15,557:INFO:Hyperparameter search completed
2026-01-30 10:01:15,558:INFO:SubProcess create_model() called ==================================
2026-01-30 10:01:15,559:INFO:Initializing create_model()
2026-01-30 10:01:15,559:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C295D9D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 2, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 15, 'criterion': 'gini'})
2026-01-30 10:01:15,559:INFO:Checking exceptions
2026-01-30 10:01:15,559:INFO:Importing libraries
2026-01-30 10:01:15,560:INFO:Copying training dataset
2026-01-30 10:01:15,784:INFO:Defining folds
2026-01-30 10:01:15,785:INFO:Declaring metric variables
2026-01-30 10:01:15,785:INFO:Importing untrained model
2026-01-30 10:01:15,785:INFO:Declaring custom model
2026-01-30 10:01:15,786:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:01:15,786:INFO:Starting cross validation
2026-01-30 10:01:15,788:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:01:18,941:INFO:Calculating mean and std
2026-01-30 10:01:18,943:INFO:Creating metrics dataframe
2026-01-30 10:01:18,945:INFO:Finalizing model
2026-01-30 10:01:21,310:INFO:Uploading results into container
2026-01-30 10:01:21,312:INFO:Uploading model into container now
2026-01-30 10:01:21,312:INFO:_master_model_container: 9
2026-01-30 10:01:21,312:INFO:_display_container: 5
2026-01-30 10:01:21,313:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:01:21,313:INFO:create_model() successfully completed......................................
2026-01-30 10:01:21,461:INFO:SubProcess create_model() end ==================================
2026-01-30 10:01:21,461:INFO:choose_better activated
2026-01-30 10:01:21,461:INFO:SubProcess create_model() called ==================================
2026-01-30 10:01:21,462:INFO:Initializing create_model()
2026-01-30 10:01:21,462:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:01:21,462:INFO:Checking exceptions
2026-01-30 10:01:21,462:INFO:Importing libraries
2026-01-30 10:01:21,462:INFO:Copying training dataset
2026-01-30 10:01:21,673:INFO:Defining folds
2026-01-30 10:01:21,673:INFO:Declaring metric variables
2026-01-30 10:01:21,673:INFO:Importing untrained model
2026-01-30 10:01:21,674:INFO:Declaring custom model
2026-01-30 10:01:21,674:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:01:21,674:INFO:Starting cross validation
2026-01-30 10:01:21,675:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:01:26,057:INFO:Calculating mean and std
2026-01-30 10:01:26,058:INFO:Creating metrics dataframe
2026-01-30 10:01:26,061:INFO:Finalizing model
2026-01-30 10:01:29,406:INFO:Uploading results into container
2026-01-30 10:01:29,406:INFO:Uploading model into container now
2026-01-30 10:01:29,407:INFO:_master_model_container: 10
2026-01-30 10:01:29,407:INFO:_display_container: 6
2026-01-30 10:01:29,407:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:01:29,407:INFO:create_model() successfully completed......................................
2026-01-30 10:01:29,553:INFO:SubProcess create_model() end ==================================
2026-01-30 10:01:29,553:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.989
2026-01-30 10:01:29,554:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9826
2026-01-30 10:01:29,554:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-30 10:01:29,554:INFO:choose_better completed
2026-01-30 10:01:29,554:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 10:01:29,556:INFO:_master_model_container: 10
2026-01-30 10:01:29,557:INFO:_display_container: 5
2026-01-30 10:01:29,557:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:01:29,557:INFO:tune_model() successfully completed......................................
2026-01-30 10:01:29,709:INFO:Initializing predict_model()
2026-01-30 10:01:29,710:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0CCB7A590>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A069E44EA0>)
2026-01-30 10:01:29,710:INFO:Checking exceptions
2026-01-30 10:01:29,710:INFO:Preloading libraries
2026-01-30 10:01:29,710:INFO:Set up data.
2026-01-30 10:01:29,736:INFO:Set up index.
2026-01-30 10:01:30,158:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\utils\generic.py:585: UserWarning: Traceback (most recent call last):
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\utils\generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\utils\generic.py", line 583, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.


2026-01-30 10:01:30,181:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.

2026-01-30 10:02:49,008:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\1960418326.py:20: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-30 10:02:51,284:INFO:PyCaret ClassificationExperiment
2026-01-30 10:02:51,284:INFO:Logging name: clf-default-name
2026-01-30 10:02:51,284:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-30 10:02:51,284:INFO:version 3.3.2
2026-01-30 10:02:51,284:INFO:Initializing setup()
2026-01-30 10:02:51,284:INFO:self.USI: 60e5
2026-01-30 10:02:51,284:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'n_jobs_param', 'data', 'X', 'idx', 'y_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'USI', 'target_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'y_train', 'X_test', 'seed', 'gpu_param', 'gpu_n_jobs_param', 'y', 'logging_param', 'pipeline', 'fold_generator', 'exp_id'}
2026-01-30 10:02:51,284:INFO:Checking environment
2026-01-30 10:02:51,284:INFO:python_version: 3.11.11
2026-01-30 10:02:51,284:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-30 10:02:51,284:INFO:machine: AMD64
2026-01-30 10:02:51,284:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-30 10:02:51,285:INFO:Memory: svmem(total=34009374720, available=12001648640, percent=64.7, used=22007726080, free=12001648640)
2026-01-30 10:02:51,286:INFO:Physical Core: 12
2026-01-30 10:02:51,286:INFO:Logical Core: 16
2026-01-30 10:02:51,286:INFO:Checking libraries
2026-01-30 10:02:51,286:INFO:System:
2026-01-30 10:02:51,286:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-30 10:02:51,286:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-30 10:02:51,286:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-30 10:02:51,286:INFO:PyCaret required dependencies:
2026-01-30 10:02:51,286:INFO:                 pip: 25.0
2026-01-30 10:02:51,286:INFO:          setuptools: 75.8.0
2026-01-30 10:02:51,286:INFO:             pycaret: 3.3.2
2026-01-30 10:02:51,286:INFO:             IPython: 9.9.0
2026-01-30 10:02:51,286:INFO:          ipywidgets: 8.1.8
2026-01-30 10:02:51,286:INFO:                tqdm: 4.67.1
2026-01-30 10:02:51,286:INFO:               numpy: 1.26.4
2026-01-30 10:02:51,286:INFO:              pandas: 2.1.4
2026-01-30 10:02:51,286:INFO:              jinja2: 3.1.6
2026-01-30 10:02:51,286:INFO:               scipy: 1.11.4
2026-01-30 10:02:51,286:INFO:              joblib: 1.3.2
2026-01-30 10:02:51,286:INFO:             sklearn: 1.4.2
2026-01-30 10:02:51,286:INFO:                pyod: 2.0.6
2026-01-30 10:02:51,286:INFO:            imblearn: 0.14.1
2026-01-30 10:02:51,286:INFO:   category_encoders: 2.7.0
2026-01-30 10:02:51,286:INFO:            lightgbm: 4.6.0
2026-01-30 10:02:51,286:INFO:               numba: 0.62.1
2026-01-30 10:02:51,287:INFO:            requests: 2.32.3
2026-01-30 10:02:51,287:INFO:          matplotlib: 3.7.5
2026-01-30 10:02:51,287:INFO:          scikitplot: 0.3.7
2026-01-30 10:02:51,287:INFO:         yellowbrick: 1.5
2026-01-30 10:02:51,287:INFO:              plotly: 5.24.1
2026-01-30 10:02:51,287:INFO:    plotly-resampler: Not installed
2026-01-30 10:02:51,287:INFO:             kaleido: 1.2.0
2026-01-30 10:02:51,287:INFO:           schemdraw: 0.15
2026-01-30 10:02:51,287:INFO:         statsmodels: 0.14.6
2026-01-30 10:02:51,287:INFO:              sktime: 0.26.0
2026-01-30 10:02:51,287:INFO:               tbats: 1.1.3
2026-01-30 10:02:51,287:INFO:            pmdarima: 2.0.4
2026-01-30 10:02:51,287:INFO:              psutil: 7.2.1
2026-01-30 10:02:51,287:INFO:          markupsafe: 3.0.3
2026-01-30 10:02:51,287:INFO:             pickle5: Not installed
2026-01-30 10:02:51,287:INFO:         cloudpickle: 3.0.0
2026-01-30 10:02:51,287:INFO:         deprecation: 2.1.0
2026-01-30 10:02:51,287:INFO:              xxhash: 3.6.0
2026-01-30 10:02:51,287:INFO:           wurlitzer: Not installed
2026-01-30 10:02:51,287:INFO:PyCaret optional dependencies:
2026-01-30 10:02:51,287:INFO:                shap: 0.44.1
2026-01-30 10:02:51,287:INFO:           interpret: 0.7.3
2026-01-30 10:02:51,287:INFO:                umap: 0.5.7
2026-01-30 10:02:51,289:INFO:     ydata_profiling: 4.18.1
2026-01-30 10:02:51,289:INFO:  explainerdashboard: 0.5.1
2026-01-30 10:02:51,289:INFO:             autoviz: Not installed
2026-01-30 10:02:51,289:INFO:           fairlearn: 0.7.0
2026-01-30 10:02:51,289:INFO:          deepchecks: Not installed
2026-01-30 10:02:51,290:INFO:             xgboost: Not installed
2026-01-30 10:02:51,291:INFO:            catboost: 1.2.8
2026-01-30 10:02:51,291:INFO:              kmodes: 0.12.2
2026-01-30 10:02:51,292:INFO:             mlxtend: 0.23.4
2026-01-30 10:02:51,292:INFO:       statsforecast: 1.5.0
2026-01-30 10:02:51,293:INFO:        tune_sklearn: Not installed
2026-01-30 10:02:51,293:INFO:                 ray: Not installed
2026-01-30 10:02:51,293:INFO:            hyperopt: 0.2.7
2026-01-30 10:02:51,294:INFO:              optuna: 4.6.0
2026-01-30 10:02:51,294:INFO:               skopt: 0.10.2
2026-01-30 10:02:51,294:INFO:              mlflow: 3.8.1
2026-01-30 10:02:51,294:INFO:              gradio: 6.3.0
2026-01-30 10:02:51,294:INFO:             fastapi: 0.128.0
2026-01-30 10:02:51,294:INFO:             uvicorn: 0.40.0
2026-01-30 10:02:51,294:INFO:              m2cgen: 0.10.0
2026-01-30 10:02:51,294:INFO:           evidently: 0.4.40
2026-01-30 10:02:51,294:INFO:               fugue: 0.8.7
2026-01-30 10:02:51,294:INFO:           streamlit: Not installed
2026-01-30 10:02:51,294:INFO:             prophet: Not installed
2026-01-30 10:02:51,294:INFO:None
2026-01-30 10:02:51,294:INFO:Set up data.
2026-01-30 10:02:51,447:INFO:Set up folding strategy.
2026-01-30 10:02:51,447:INFO:Set up train/test split.
2026-01-30 10:02:51,692:INFO:Set up index.
2026-01-30 10:02:51,703:INFO:Assigning column types.
2026-01-30 10:02:51,857:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-30 10:02:51,885:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 10:02:51,885:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:02:51,903:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:02:51,904:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:02:51,934:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 10:02:51,934:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:02:51,954:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:02:51,954:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:02:51,955:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-30 10:02:51,985:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:02:52,002:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:02:52,002:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:02:52,032:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:02:52,050:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:02:52,050:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:02:52,051:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-30 10:02:52,097:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:02:52,098:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:02:52,145:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:02:52,145:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:02:52,147:INFO:Preparing preprocessing pipeline...
2026-01-30 10:02:52,177:INFO:Set up simple imputation.
2026-01-30 10:02:52,177:INFO:Set up feature normalization.
2026-01-30 10:02:52,502:INFO:Finished creating preprocessing pipeline.
2026-01-30 10:02:52,505:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'PAID_AMOUNT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdina...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-30 10:02:52,505:INFO:Creating final display dataframe.
2026-01-30 10:02:53,362:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape      (482669, 28)
4        Transformed data shape      (482669, 28)
5   Transformed train set shape      (337868, 28)
6    Transformed test set shape      (144801, 28)
7              Numeric features                24
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                 3
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              60e5
2026-01-30 10:02:53,434:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:02:53,434:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:02:53,506:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:02:53,508:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:02:53,510:INFO:setup() successfully completed in 2.23s...............
2026-01-30 10:02:53,510:INFO:Initializing compare_models()
2026-01-30 10:02:53,510:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-30 10:02:53,510:INFO:Checking exceptions
2026-01-30 10:02:53,680:INFO:Preparing display monitor
2026-01-30 10:02:53,685:INFO:Initializing Logistic Regression
2026-01-30 10:02:53,685:INFO:Total runtime is 0.0 minutes
2026-01-30 10:02:53,685:INFO:SubProcess create_model() called ==================================
2026-01-30 10:02:53,686:INFO:Initializing create_model()
2026-01-30 10:02:53,686:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03C57F050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:02:53,686:INFO:Checking exceptions
2026-01-30 10:02:53,686:INFO:Importing libraries
2026-01-30 10:02:53,686:INFO:Copying training dataset
2026-01-30 10:02:53,946:INFO:Defining folds
2026-01-30 10:02:53,946:INFO:Declaring metric variables
2026-01-30 10:02:53,946:INFO:Importing untrained model
2026-01-30 10:02:53,947:INFO:Logistic Regression Imported successfully
2026-01-30 10:02:53,947:INFO:Starting cross validation
2026-01-30 10:02:53,947:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:02:58,109:INFO:Calculating mean and std
2026-01-30 10:02:58,114:INFO:Creating metrics dataframe
2026-01-30 10:02:58,118:INFO:Uploading results into container
2026-01-30 10:02:58,120:INFO:Uploading model into container now
2026-01-30 10:02:58,123:INFO:_master_model_container: 1
2026-01-30 10:02:58,124:INFO:_display_container: 2
2026-01-30 10:02:58,126:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-30 10:02:58,127:INFO:create_model() successfully completed......................................
2026-01-30 10:02:58,286:INFO:SubProcess create_model() end ==================================
2026-01-30 10:02:58,286:INFO:Creating metrics dataframe
2026-01-30 10:02:58,289:INFO:Initializing Decision Tree Classifier
2026-01-30 10:02:58,290:INFO:Total runtime is 0.07675575415293376 minutes
2026-01-30 10:02:58,291:INFO:SubProcess create_model() called ==================================
2026-01-30 10:02:58,291:INFO:Initializing create_model()
2026-01-30 10:02:58,292:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03C57F050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:02:58,292:INFO:Checking exceptions
2026-01-30 10:02:58,292:INFO:Importing libraries
2026-01-30 10:02:58,292:INFO:Copying training dataset
2026-01-30 10:02:58,630:INFO:Defining folds
2026-01-30 10:02:58,630:INFO:Declaring metric variables
2026-01-30 10:02:58,631:INFO:Importing untrained model
2026-01-30 10:02:58,631:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:02:58,632:INFO:Starting cross validation
2026-01-30 10:02:58,633:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:03:02,845:INFO:Calculating mean and std
2026-01-30 10:03:02,846:INFO:Creating metrics dataframe
2026-01-30 10:03:02,848:INFO:Uploading results into container
2026-01-30 10:03:02,848:INFO:Uploading model into container now
2026-01-30 10:03:02,849:INFO:_master_model_container: 2
2026-01-30 10:03:02,849:INFO:_display_container: 2
2026-01-30 10:03:02,850:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:03:02,850:INFO:create_model() successfully completed......................................
2026-01-30 10:03:03,004:INFO:SubProcess create_model() end ==================================
2026-01-30 10:03:03,004:INFO:Creating metrics dataframe
2026-01-30 10:03:03,006:INFO:Initializing Random Forest Classifier
2026-01-30 10:03:03,006:INFO:Total runtime is 0.15534850756327312 minutes
2026-01-30 10:03:03,006:INFO:SubProcess create_model() called ==================================
2026-01-30 10:03:03,006:INFO:Initializing create_model()
2026-01-30 10:03:03,007:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03C57F050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:03:03,007:INFO:Checking exceptions
2026-01-30 10:03:03,007:INFO:Importing libraries
2026-01-30 10:03:03,007:INFO:Copying training dataset
2026-01-30 10:03:03,213:INFO:Defining folds
2026-01-30 10:03:03,213:INFO:Declaring metric variables
2026-01-30 10:03:03,213:INFO:Importing untrained model
2026-01-30 10:03:03,215:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:03:03,215:INFO:Starting cross validation
2026-01-30 10:03:03,216:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:03:23,840:INFO:Calculating mean and std
2026-01-30 10:03:23,842:INFO:Creating metrics dataframe
2026-01-30 10:03:23,844:INFO:Uploading results into container
2026-01-30 10:03:23,844:INFO:Uploading model into container now
2026-01-30 10:03:23,845:INFO:_master_model_container: 3
2026-01-30 10:03:23,845:INFO:_display_container: 2
2026-01-30 10:03:23,846:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:03:23,846:INFO:create_model() successfully completed......................................
2026-01-30 10:03:23,990:INFO:SubProcess create_model() end ==================================
2026-01-30 10:03:23,991:INFO:Creating metrics dataframe
2026-01-30 10:03:23,993:INFO:Initializing Light Gradient Boosting Machine
2026-01-30 10:03:23,993:INFO:Total runtime is 0.5051378766695658 minutes
2026-01-30 10:03:23,993:INFO:SubProcess create_model() called ==================================
2026-01-30 10:03:23,993:INFO:Initializing create_model()
2026-01-30 10:03:23,993:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03C57F050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:03:23,993:INFO:Checking exceptions
2026-01-30 10:03:23,993:INFO:Importing libraries
2026-01-30 10:03:23,993:INFO:Copying training dataset
2026-01-30 10:03:24,208:INFO:Defining folds
2026-01-30 10:03:24,209:INFO:Declaring metric variables
2026-01-30 10:03:24,209:INFO:Importing untrained model
2026-01-30 10:03:24,209:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:03:24,210:INFO:Starting cross validation
2026-01-30 10:03:24,210:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:03:29,704:INFO:Calculating mean and std
2026-01-30 10:03:29,705:INFO:Creating metrics dataframe
2026-01-30 10:03:29,707:INFO:Uploading results into container
2026-01-30 10:03:29,707:INFO:Uploading model into container now
2026-01-30 10:03:29,708:INFO:_master_model_container: 4
2026-01-30 10:03:29,708:INFO:_display_container: 2
2026-01-30 10:03:29,708:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:03:29,708:INFO:create_model() successfully completed......................................
2026-01-30 10:03:29,849:INFO:SubProcess create_model() end ==================================
2026-01-30 10:03:29,849:INFO:Creating metrics dataframe
2026-01-30 10:03:29,852:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-30 10:03:29,853:INFO:Initializing create_model()
2026-01-30 10:03:29,853:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:03:29,853:INFO:Checking exceptions
2026-01-30 10:03:29,854:INFO:Importing libraries
2026-01-30 10:03:29,854:INFO:Copying training dataset
2026-01-30 10:03:30,051:INFO:Defining folds
2026-01-30 10:03:30,051:INFO:Declaring metric variables
2026-01-30 10:03:30,051:INFO:Importing untrained model
2026-01-30 10:03:30,051:INFO:Declaring custom model
2026-01-30 10:03:30,052:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:03:30,052:INFO:Cross validation set to False
2026-01-30 10:03:30,052:INFO:Fitting Model
2026-01-30 10:03:40,854:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:03:40,855:INFO:create_model() successfully completed......................................
2026-01-30 10:03:41,013:INFO:Initializing create_model()
2026-01-30 10:03:41,014:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:03:41,014:INFO:Checking exceptions
2026-01-30 10:03:41,014:INFO:Importing libraries
2026-01-30 10:03:41,014:INFO:Copying training dataset
2026-01-30 10:03:41,243:INFO:Defining folds
2026-01-30 10:03:41,243:INFO:Declaring metric variables
2026-01-30 10:03:41,243:INFO:Importing untrained model
2026-01-30 10:03:41,243:INFO:Declaring custom model
2026-01-30 10:03:41,245:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:03:41,246:INFO:Cross validation set to False
2026-01-30 10:03:41,246:INFO:Fitting Model
2026-01-30 10:03:42,175:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 10:03:42,237:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014972 seconds.
2026-01-30 10:03:42,237:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 10:03:42,237:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 10:03:42,238:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 10:03:42,239:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 10:03:42,241:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 10:03:42,242:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 10:03:43,349:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:03:43,350:INFO:create_model() successfully completed......................................
2026-01-30 10:03:43,577:INFO:Initializing create_model()
2026-01-30 10:03:43,578:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:03:43,578:INFO:Checking exceptions
2026-01-30 10:03:43,579:INFO:Importing libraries
2026-01-30 10:03:43,579:INFO:Copying training dataset
2026-01-30 10:03:43,889:INFO:Defining folds
2026-01-30 10:03:43,889:INFO:Declaring metric variables
2026-01-30 10:03:43,890:INFO:Importing untrained model
2026-01-30 10:03:43,890:INFO:Declaring custom model
2026-01-30 10:03:43,890:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:03:43,891:INFO:Cross validation set to False
2026-01-30 10:03:43,891:INFO:Fitting Model
2026-01-30 10:03:46,873:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:03:46,874:INFO:create_model() successfully completed......................................
2026-01-30 10:03:47,018:INFO:_master_model_container: 4
2026-01-30 10:03:47,019:INFO:_display_container: 2
2026-01-30 10:03:47,020:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')]
2026-01-30 10:03:47,020:INFO:compare_models() successfully completed......................................
2026-01-30 10:03:47,026:INFO:Initializing tune_model()
2026-01-30 10:03:47,026:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 10:03:47,026:INFO:Checking exceptions
2026-01-30 10:03:47,105:INFO:Copying training dataset
2026-01-30 10:03:47,268:INFO:Checking base model
2026-01-30 10:03:47,269:INFO:Base model : Random Forest Classifier
2026-01-30 10:03:47,269:INFO:Declaring metric variables
2026-01-30 10:03:47,269:INFO:Defining Hyperparameters
2026-01-30 10:03:47,414:INFO:Tuning with n_jobs=-1
2026-01-30 10:03:47,414:INFO:Initializing RandomizedSearchCV
2026-01-30 10:06:42,417:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-30 10:06:42,418:INFO:Hyperparameter search completed
2026-01-30 10:06:42,419:INFO:SubProcess create_model() called ==================================
2026-01-30 10:06:42,420:INFO:Initializing create_model()
2026-01-30 10:06:42,420:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0CCB75350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': True})
2026-01-30 10:06:42,420:INFO:Checking exceptions
2026-01-30 10:06:42,420:INFO:Importing libraries
2026-01-30 10:06:42,420:INFO:Copying training dataset
2026-01-30 10:06:42,684:INFO:Defining folds
2026-01-30 10:06:42,685:INFO:Declaring metric variables
2026-01-30 10:06:42,685:INFO:Importing untrained model
2026-01-30 10:06:42,685:INFO:Declaring custom model
2026-01-30 10:06:42,686:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:06:42,686:INFO:Starting cross validation
2026-01-30 10:06:42,687:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:07:16,513:INFO:Calculating mean and std
2026-01-30 10:07:16,515:INFO:Creating metrics dataframe
2026-01-30 10:07:16,516:INFO:Finalizing model
2026-01-30 10:07:34,329:INFO:Uploading results into container
2026-01-30 10:07:34,330:INFO:Uploading model into container now
2026-01-30 10:07:34,332:INFO:_master_model_container: 5
2026-01-30 10:07:34,332:INFO:_display_container: 3
2026-01-30 10:07:34,332:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:07:34,332:INFO:create_model() successfully completed......................................
2026-01-30 10:07:34,497:INFO:SubProcess create_model() end ==================================
2026-01-30 10:07:34,497:INFO:choose_better activated
2026-01-30 10:07:34,498:INFO:SubProcess create_model() called ==================================
2026-01-30 10:07:34,498:INFO:Initializing create_model()
2026-01-30 10:07:34,498:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:07:34,498:INFO:Checking exceptions
2026-01-30 10:07:34,499:INFO:Importing libraries
2026-01-30 10:07:34,499:INFO:Copying training dataset
2026-01-30 10:07:34,748:INFO:Defining folds
2026-01-30 10:07:34,749:INFO:Declaring metric variables
2026-01-30 10:07:34,749:INFO:Importing untrained model
2026-01-30 10:07:34,749:INFO:Declaring custom model
2026-01-30 10:07:34,749:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:07:34,750:INFO:Starting cross validation
2026-01-30 10:07:34,750:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:07:59,024:INFO:Calculating mean and std
2026-01-30 10:07:59,025:INFO:Creating metrics dataframe
2026-01-30 10:07:59,027:INFO:Finalizing model
2026-01-30 10:08:10,681:INFO:Uploading results into container
2026-01-30 10:08:10,683:INFO:Uploading model into container now
2026-01-30 10:08:10,684:INFO:_master_model_container: 6
2026-01-30 10:08:10,684:INFO:_display_container: 4
2026-01-30 10:08:10,685:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:08:10,685:INFO:create_model() successfully completed......................................
2026-01-30 10:08:10,888:INFO:SubProcess create_model() end ==================================
2026-01-30 10:08:10,889:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9985
2026-01-30 10:08:10,890:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9894
2026-01-30 10:08:10,890:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-30 10:08:10,890:INFO:choose_better completed
2026-01-30 10:08:10,891:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 10:08:10,893:INFO:_master_model_container: 6
2026-01-30 10:08:10,893:INFO:_display_container: 3
2026-01-30 10:08:10,894:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:08:10,894:INFO:tune_model() successfully completed......................................
2026-01-30 10:08:11,076:INFO:Initializing tune_model()
2026-01-30 10:08:11,076:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 10:08:11,076:INFO:Checking exceptions
2026-01-30 10:08:11,199:INFO:Copying training dataset
2026-01-30 10:08:11,358:INFO:Checking base model
2026-01-30 10:08:11,359:INFO:Base model : Light Gradient Boosting Machine
2026-01-30 10:08:11,359:INFO:Declaring metric variables
2026-01-30 10:08:11,360:INFO:Defining Hyperparameters
2026-01-30 10:08:11,531:INFO:Tuning with n_jobs=-1
2026-01-30 10:08:11,531:INFO:Initializing RandomizedSearchCV
2026-01-30 10:09:01,031:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2026-01-30 10:09:01,033:INFO:Hyperparameter search completed
2026-01-30 10:09:01,033:INFO:SubProcess create_model() called ==================================
2026-01-30 10:09:01,035:INFO:Initializing create_model()
2026-01-30 10:09:01,035:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03CF7E090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2026-01-30 10:09:01,035:INFO:Checking exceptions
2026-01-30 10:09:01,035:INFO:Importing libraries
2026-01-30 10:09:01,036:INFO:Copying training dataset
2026-01-30 10:09:01,345:INFO:Defining folds
2026-01-30 10:09:01,345:INFO:Declaring metric variables
2026-01-30 10:09:01,346:INFO:Importing untrained model
2026-01-30 10:09:01,346:INFO:Declaring custom model
2026-01-30 10:09:01,347:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:09:01,348:INFO:Starting cross validation
2026-01-30 10:09:01,349:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:09:13,730:INFO:Calculating mean and std
2026-01-30 10:09:13,733:INFO:Creating metrics dataframe
2026-01-30 10:09:13,740:INFO:Finalizing model
2026-01-30 10:09:14,645:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 10:09:14,645:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 10:09:14,645:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 10:09:14,877:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 10:09:14,877:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 10:09:14,877:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 10:09:14,878:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 10:09:14,940:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014003 seconds.
2026-01-30 10:09:14,940:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 10:09:14,940:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 10:09:14,941:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 10:09:14,942:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 10:09:14,948:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 10:09:14,948:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 10:09:19,410:INFO:Uploading results into container
2026-01-30 10:09:19,413:INFO:Uploading model into container now
2026-01-30 10:09:19,414:INFO:_master_model_container: 7
2026-01-30 10:09:19,414:INFO:_display_container: 4
2026-01-30 10:09:19,415:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:09:19,415:INFO:create_model() successfully completed......................................
2026-01-30 10:09:19,632:INFO:SubProcess create_model() end ==================================
2026-01-30 10:09:19,633:INFO:choose_better activated
2026-01-30 10:09:19,634:INFO:SubProcess create_model() called ==================================
2026-01-30 10:09:19,635:INFO:Initializing create_model()
2026-01-30 10:09:19,636:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:09:19,636:INFO:Checking exceptions
2026-01-30 10:09:19,637:INFO:Importing libraries
2026-01-30 10:09:19,637:INFO:Copying training dataset
2026-01-30 10:09:19,909:INFO:Defining folds
2026-01-30 10:09:19,910:INFO:Declaring metric variables
2026-01-30 10:09:19,910:INFO:Importing untrained model
2026-01-30 10:09:19,910:INFO:Declaring custom model
2026-01-30 10:09:19,911:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:09:19,911:INFO:Starting cross validation
2026-01-30 10:09:19,912:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:09:26,041:INFO:Calculating mean and std
2026-01-30 10:09:26,043:INFO:Creating metrics dataframe
2026-01-30 10:09:26,046:INFO:Finalizing model
2026-01-30 10:09:27,142:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 10:09:27,225:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016146 seconds.
2026-01-30 10:09:27,225:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 10:09:27,225:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 10:09:27,226:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 10:09:27,227:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 10:09:27,230:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 10:09:27,230:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 10:09:28,396:INFO:Uploading results into container
2026-01-30 10:09:28,398:INFO:Uploading model into container now
2026-01-30 10:09:28,399:INFO:_master_model_container: 8
2026-01-30 10:09:28,399:INFO:_display_container: 5
2026-01-30 10:09:28,400:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:09:28,401:INFO:create_model() successfully completed......................................
2026-01-30 10:09:28,617:INFO:SubProcess create_model() end ==================================
2026-01-30 10:09:28,619:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9945
2026-01-30 10:09:28,620:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9987
2026-01-30 10:09:28,621:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2026-01-30 10:09:28,621:INFO:choose_better completed
2026-01-30 10:09:28,623:INFO:_master_model_container: 8
2026-01-30 10:09:28,624:INFO:_display_container: 4
2026-01-30 10:09:28,624:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:09:28,624:INFO:tune_model() successfully completed......................................
2026-01-30 10:09:28,801:INFO:Initializing tune_model()
2026-01-30 10:09:28,801:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 10:09:28,801:INFO:Checking exceptions
2026-01-30 10:09:28,898:INFO:Copying training dataset
2026-01-30 10:09:29,164:INFO:Checking base model
2026-01-30 10:09:29,164:INFO:Base model : Decision Tree Classifier
2026-01-30 10:09:29,165:INFO:Declaring metric variables
2026-01-30 10:09:29,165:INFO:Defining Hyperparameters
2026-01-30 10:09:29,365:INFO:Tuning with n_jobs=-1
2026-01-30 10:09:29,365:INFO:Initializing RandomizedSearchCV
2026-01-30 10:09:39,406:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 15, 'actual_estimator__criterion': 'gini'}
2026-01-30 10:09:39,408:INFO:Hyperparameter search completed
2026-01-30 10:09:39,409:INFO:SubProcess create_model() called ==================================
2026-01-30 10:09:39,411:INFO:Initializing create_model()
2026-01-30 10:09:39,412:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03C3AF350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 2, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 15, 'criterion': 'gini'})
2026-01-30 10:09:39,412:INFO:Checking exceptions
2026-01-30 10:09:39,412:INFO:Importing libraries
2026-01-30 10:09:39,412:INFO:Copying training dataset
2026-01-30 10:09:39,656:INFO:Defining folds
2026-01-30 10:09:39,657:INFO:Declaring metric variables
2026-01-30 10:09:39,657:INFO:Importing untrained model
2026-01-30 10:09:39,657:INFO:Declaring custom model
2026-01-30 10:09:39,658:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:09:39,658:INFO:Starting cross validation
2026-01-30 10:09:39,659:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:09:42,904:INFO:Calculating mean and std
2026-01-30 10:09:42,905:INFO:Creating metrics dataframe
2026-01-30 10:09:42,906:INFO:Finalizing model
2026-01-30 10:09:45,241:INFO:Uploading results into container
2026-01-30 10:09:45,242:INFO:Uploading model into container now
2026-01-30 10:09:45,243:INFO:_master_model_container: 9
2026-01-30 10:09:45,243:INFO:_display_container: 5
2026-01-30 10:09:45,243:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:09:45,244:INFO:create_model() successfully completed......................................
2026-01-30 10:09:45,454:INFO:SubProcess create_model() end ==================================
2026-01-30 10:09:45,455:INFO:choose_better activated
2026-01-30 10:09:45,455:INFO:SubProcess create_model() called ==================================
2026-01-30 10:09:45,455:INFO:Initializing create_model()
2026-01-30 10:09:45,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:09:45,455:INFO:Checking exceptions
2026-01-30 10:09:45,456:INFO:Importing libraries
2026-01-30 10:09:45,456:INFO:Copying training dataset
2026-01-30 10:09:45,705:INFO:Defining folds
2026-01-30 10:09:45,706:INFO:Declaring metric variables
2026-01-30 10:09:45,706:INFO:Importing untrained model
2026-01-30 10:09:45,706:INFO:Declaring custom model
2026-01-30 10:09:45,706:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:09:45,706:INFO:Starting cross validation
2026-01-30 10:09:45,707:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:09:50,230:INFO:Calculating mean and std
2026-01-30 10:09:50,231:INFO:Creating metrics dataframe
2026-01-30 10:09:50,234:INFO:Finalizing model
2026-01-30 10:09:53,817:INFO:Uploading results into container
2026-01-30 10:09:53,818:INFO:Uploading model into container now
2026-01-30 10:09:53,818:INFO:_master_model_container: 10
2026-01-30 10:09:53,818:INFO:_display_container: 6
2026-01-30 10:09:53,819:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:09:53,819:INFO:create_model() successfully completed......................................
2026-01-30 10:09:53,984:INFO:SubProcess create_model() end ==================================
2026-01-30 10:09:53,985:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.989
2026-01-30 10:09:53,985:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9826
2026-01-30 10:09:53,985:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-30 10:09:53,985:INFO:choose_better completed
2026-01-30 10:09:53,986:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 10:09:53,988:INFO:_master_model_container: 10
2026-01-30 10:09:53,988:INFO:_display_container: 5
2026-01-30 10:09:53,988:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:09:53,988:INFO:tune_model() successfully completed......................................
2026-01-30 10:09:54,185:INFO:Initializing predict_model()
2026-01-30 10:09:54,185:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A0C9F74040>)
2026-01-30 10:09:54,185:INFO:Checking exceptions
2026-01-30 10:09:54,185:INFO:Preloading libraries
2026-01-30 10:09:54,186:INFO:Set up data.
2026-01-30 10:09:54,221:INFO:Set up index.
2026-01-30 10:09:54,433:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\utils\generic.py:585: UserWarning: Traceback (most recent call last):
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\utils\generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\utils\generic.py", line 583, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.


2026-01-30 10:09:54,448:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.

2026-01-30 10:09:54,720:INFO:Initializing predict_model()
2026-01-30 10:09:54,720:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A0C9F747C0>)
2026-01-30 10:09:54,720:INFO:Checking exceptions
2026-01-30 10:09:54,721:INFO:Preloading libraries
2026-01-30 10:09:54,721:INFO:Set up data.
2026-01-30 10:09:54,747:INFO:Set up index.
2026-01-30 10:09:54,968:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\utils\generic.py:585: UserWarning: Traceback (most recent call last):
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\utils\generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\utils\generic.py", line 583, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.


2026-01-30 10:09:54,994:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.

2026-01-30 10:09:55,330:INFO:Initializing predict_model()
2026-01-30 10:09:55,331:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A06E646BD0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A0C9F74860>)
2026-01-30 10:09:55,331:INFO:Checking exceptions
2026-01-30 10:09:55,331:INFO:Preloading libraries
2026-01-30 10:09:55,331:INFO:Set up data.
2026-01-30 10:09:55,375:INFO:Set up index.
2026-01-30 10:09:55,458:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\utils\generic.py:585: UserWarning: Traceback (most recent call last):
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\utils\generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\utils\generic.py", line 583, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.


2026-01-30 10:09:55,491:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.

2026-01-30 10:11:37,314:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\3053220979.py:20: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-30 10:13:01,137:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\3424666871.py:20: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-30 10:13:03,486:INFO:PyCaret ClassificationExperiment
2026-01-30 10:13:03,486:INFO:Logging name: clf-default-name
2026-01-30 10:13:03,486:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-30 10:13:03,486:INFO:version 3.3.2
2026-01-30 10:13:03,486:INFO:Initializing setup()
2026-01-30 10:13:03,486:INFO:self.USI: e91e
2026-01-30 10:13:03,486:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'n_jobs_param', 'data', 'X', 'idx', 'y_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'USI', 'target_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'y_train', 'X_test', 'seed', 'gpu_param', 'gpu_n_jobs_param', 'y', 'logging_param', 'pipeline', 'fold_generator', 'exp_id'}
2026-01-30 10:13:03,487:INFO:Checking environment
2026-01-30 10:13:03,487:INFO:python_version: 3.11.11
2026-01-30 10:13:03,487:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-30 10:13:03,487:INFO:machine: AMD64
2026-01-30 10:13:03,487:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-30 10:13:03,487:INFO:Memory: svmem(total=34009374720, available=11281739776, percent=66.8, used=22727634944, free=11281739776)
2026-01-30 10:13:03,487:INFO:Physical Core: 12
2026-01-30 10:13:03,487:INFO:Logical Core: 16
2026-01-30 10:13:03,487:INFO:Checking libraries
2026-01-30 10:13:03,487:INFO:System:
2026-01-30 10:13:03,487:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-30 10:13:03,487:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-30 10:13:03,487:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-30 10:13:03,487:INFO:PyCaret required dependencies:
2026-01-30 10:13:03,487:INFO:                 pip: 25.0
2026-01-30 10:13:03,487:INFO:          setuptools: 75.8.0
2026-01-30 10:13:03,488:INFO:             pycaret: 3.3.2
2026-01-30 10:13:03,488:INFO:             IPython: 9.9.0
2026-01-30 10:13:03,489:INFO:          ipywidgets: 8.1.8
2026-01-30 10:13:03,489:INFO:                tqdm: 4.67.1
2026-01-30 10:13:03,489:INFO:               numpy: 1.26.4
2026-01-30 10:13:03,489:INFO:              pandas: 2.1.4
2026-01-30 10:13:03,489:INFO:              jinja2: 3.1.6
2026-01-30 10:13:03,489:INFO:               scipy: 1.11.4
2026-01-30 10:13:03,489:INFO:              joblib: 1.3.2
2026-01-30 10:13:03,489:INFO:             sklearn: 1.4.2
2026-01-30 10:13:03,489:INFO:                pyod: 2.0.6
2026-01-30 10:13:03,489:INFO:            imblearn: 0.14.1
2026-01-30 10:13:03,490:INFO:   category_encoders: 2.7.0
2026-01-30 10:13:03,490:INFO:            lightgbm: 4.6.0
2026-01-30 10:13:03,490:INFO:               numba: 0.62.1
2026-01-30 10:13:03,490:INFO:            requests: 2.32.3
2026-01-30 10:13:03,490:INFO:          matplotlib: 3.7.5
2026-01-30 10:13:03,490:INFO:          scikitplot: 0.3.7
2026-01-30 10:13:03,490:INFO:         yellowbrick: 1.5
2026-01-30 10:13:03,490:INFO:              plotly: 5.24.1
2026-01-30 10:13:03,490:INFO:    plotly-resampler: Not installed
2026-01-30 10:13:03,490:INFO:             kaleido: 1.2.0
2026-01-30 10:13:03,490:INFO:           schemdraw: 0.15
2026-01-30 10:13:03,490:INFO:         statsmodels: 0.14.6
2026-01-30 10:13:03,491:INFO:              sktime: 0.26.0
2026-01-30 10:13:03,491:INFO:               tbats: 1.1.3
2026-01-30 10:13:03,491:INFO:            pmdarima: 2.0.4
2026-01-30 10:13:03,491:INFO:              psutil: 7.2.1
2026-01-30 10:13:03,491:INFO:          markupsafe: 3.0.3
2026-01-30 10:13:03,491:INFO:             pickle5: Not installed
2026-01-30 10:13:03,491:INFO:         cloudpickle: 3.0.0
2026-01-30 10:13:03,491:INFO:         deprecation: 2.1.0
2026-01-30 10:13:03,491:INFO:              xxhash: 3.6.0
2026-01-30 10:13:03,491:INFO:           wurlitzer: Not installed
2026-01-30 10:13:03,492:INFO:PyCaret optional dependencies:
2026-01-30 10:13:03,492:INFO:                shap: 0.44.1
2026-01-30 10:13:03,492:INFO:           interpret: 0.7.3
2026-01-30 10:13:03,492:INFO:                umap: 0.5.7
2026-01-30 10:13:03,492:INFO:     ydata_profiling: 4.18.1
2026-01-30 10:13:03,492:INFO:  explainerdashboard: 0.5.1
2026-01-30 10:13:03,492:INFO:             autoviz: Not installed
2026-01-30 10:13:03,492:INFO:           fairlearn: 0.7.0
2026-01-30 10:13:03,493:INFO:          deepchecks: Not installed
2026-01-30 10:13:03,493:INFO:             xgboost: Not installed
2026-01-30 10:13:03,493:INFO:            catboost: 1.2.8
2026-01-30 10:13:03,493:INFO:              kmodes: 0.12.2
2026-01-30 10:13:03,493:INFO:             mlxtend: 0.23.4
2026-01-30 10:13:03,493:INFO:       statsforecast: 1.5.0
2026-01-30 10:13:03,493:INFO:        tune_sklearn: Not installed
2026-01-30 10:13:03,493:INFO:                 ray: Not installed
2026-01-30 10:13:03,493:INFO:            hyperopt: 0.2.7
2026-01-30 10:13:03,493:INFO:              optuna: 4.6.0
2026-01-30 10:13:03,493:INFO:               skopt: 0.10.2
2026-01-30 10:13:03,495:INFO:              mlflow: 3.8.1
2026-01-30 10:13:03,495:INFO:              gradio: 6.3.0
2026-01-30 10:13:03,495:INFO:             fastapi: 0.128.0
2026-01-30 10:13:03,495:INFO:             uvicorn: 0.40.0
2026-01-30 10:13:03,495:INFO:              m2cgen: 0.10.0
2026-01-30 10:13:03,495:INFO:           evidently: 0.4.40
2026-01-30 10:13:03,495:INFO:               fugue: 0.8.7
2026-01-30 10:13:03,496:INFO:           streamlit: Not installed
2026-01-30 10:13:03,496:INFO:             prophet: Not installed
2026-01-30 10:13:03,496:INFO:None
2026-01-30 10:13:03,496:INFO:Set up data.
2026-01-30 10:13:03,641:INFO:Set up folding strategy.
2026-01-30 10:13:03,641:INFO:Set up train/test split.
2026-01-30 10:13:03,878:INFO:Set up index.
2026-01-30 10:13:03,889:INFO:Assigning column types.
2026-01-30 10:13:04,052:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-30 10:13:04,083:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 10:13:04,084:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:13:04,104:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:13:04,104:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:13:04,137:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 10:13:04,137:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:13:04,158:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:13:04,159:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:13:04,160:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-30 10:13:04,192:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:13:04,211:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:13:04,212:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:13:04,245:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:13:04,265:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:13:04,267:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:13:04,267:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-30 10:13:04,317:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:13:04,318:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:13:04,370:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:13:04,370:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:13:04,372:INFO:Preparing preprocessing pipeline...
2026-01-30 10:13:04,402:INFO:Set up simple imputation.
2026-01-30 10:13:04,403:INFO:Set up feature normalization.
2026-01-30 10:13:04,721:INFO:Finished creating preprocessing pipeline.
2026-01-30 10:13:04,724:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'PAID_AMOUNT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdina...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-30 10:13:04,725:INFO:Creating final display dataframe.
2026-01-30 10:13:05,444:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape      (482669, 28)
4        Transformed data shape      (482669, 28)
5   Transformed train set shape      (337868, 28)
6    Transformed test set shape      (144801, 28)
7              Numeric features                24
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                 3
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              e91e
2026-01-30 10:13:05,496:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:13:05,496:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:13:05,551:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:13:05,551:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:13:05,552:INFO:setup() successfully completed in 2.08s...............
2026-01-30 10:13:05,552:INFO:Initializing compare_models()
2026-01-30 10:13:05,553:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-30 10:13:05,553:INFO:Checking exceptions
2026-01-30 10:13:05,678:INFO:Preparing display monitor
2026-01-30 10:13:05,681:INFO:Initializing Logistic Regression
2026-01-30 10:13:05,682:INFO:Total runtime is 1.659393310546875e-05 minutes
2026-01-30 10:13:05,682:INFO:SubProcess create_model() called ==================================
2026-01-30 10:13:05,682:INFO:Initializing create_model()
2026-01-30 10:13:05,682:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04EFD5490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:13:05,682:INFO:Checking exceptions
2026-01-30 10:13:05,682:INFO:Importing libraries
2026-01-30 10:13:05,682:INFO:Copying training dataset
2026-01-30 10:13:05,889:INFO:Defining folds
2026-01-30 10:13:05,889:INFO:Declaring metric variables
2026-01-30 10:13:05,889:INFO:Importing untrained model
2026-01-30 10:13:05,889:INFO:Logistic Regression Imported successfully
2026-01-30 10:13:05,889:INFO:Starting cross validation
2026-01-30 10:13:05,890:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:13:09,628:INFO:Calculating mean and std
2026-01-30 10:13:09,630:INFO:Creating metrics dataframe
2026-01-30 10:13:09,633:INFO:Uploading results into container
2026-01-30 10:13:09,634:INFO:Uploading model into container now
2026-01-30 10:13:09,635:INFO:_master_model_container: 1
2026-01-30 10:13:09,635:INFO:_display_container: 2
2026-01-30 10:13:09,636:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-30 10:13:09,636:INFO:create_model() successfully completed......................................
2026-01-30 10:13:09,814:INFO:SubProcess create_model() end ==================================
2026-01-30 10:13:09,814:INFO:Creating metrics dataframe
2026-01-30 10:13:09,816:INFO:Initializing Decision Tree Classifier
2026-01-30 10:13:09,816:INFO:Total runtime is 0.06890580654144286 minutes
2026-01-30 10:13:09,817:INFO:SubProcess create_model() called ==================================
2026-01-30 10:13:09,817:INFO:Initializing create_model()
2026-01-30 10:13:09,817:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04EFD5490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:13:09,817:INFO:Checking exceptions
2026-01-30 10:13:09,817:INFO:Importing libraries
2026-01-30 10:13:09,817:INFO:Copying training dataset
2026-01-30 10:13:10,037:INFO:Defining folds
2026-01-30 10:13:10,037:INFO:Declaring metric variables
2026-01-30 10:13:10,038:INFO:Importing untrained model
2026-01-30 10:13:10,038:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:13:10,039:INFO:Starting cross validation
2026-01-30 10:13:10,039:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:13:14,147:INFO:Calculating mean and std
2026-01-30 10:13:14,148:INFO:Creating metrics dataframe
2026-01-30 10:13:14,150:INFO:Uploading results into container
2026-01-30 10:13:14,150:INFO:Uploading model into container now
2026-01-30 10:13:14,150:INFO:_master_model_container: 2
2026-01-30 10:13:14,150:INFO:_display_container: 2
2026-01-30 10:13:14,151:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:13:14,151:INFO:create_model() successfully completed......................................
2026-01-30 10:13:14,327:INFO:SubProcess create_model() end ==================================
2026-01-30 10:13:14,327:INFO:Creating metrics dataframe
2026-01-30 10:13:14,330:INFO:Initializing Random Forest Classifier
2026-01-30 10:13:14,331:INFO:Total runtime is 0.1441625396410624 minutes
2026-01-30 10:13:14,331:INFO:SubProcess create_model() called ==================================
2026-01-30 10:13:14,331:INFO:Initializing create_model()
2026-01-30 10:13:14,331:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04EFD5490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:13:14,331:INFO:Checking exceptions
2026-01-30 10:13:14,331:INFO:Importing libraries
2026-01-30 10:13:14,331:INFO:Copying training dataset
2026-01-30 10:13:14,538:INFO:Defining folds
2026-01-30 10:13:14,538:INFO:Declaring metric variables
2026-01-30 10:13:14,539:INFO:Importing untrained model
2026-01-30 10:13:14,539:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:13:14,539:INFO:Starting cross validation
2026-01-30 10:13:14,540:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:13:36,189:INFO:Calculating mean and std
2026-01-30 10:13:36,192:INFO:Creating metrics dataframe
2026-01-30 10:13:36,193:INFO:Uploading results into container
2026-01-30 10:13:36,193:INFO:Uploading model into container now
2026-01-30 10:13:36,193:INFO:_master_model_container: 3
2026-01-30 10:13:36,193:INFO:_display_container: 2
2026-01-30 10:13:36,198:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:13:36,198:INFO:create_model() successfully completed......................................
2026-01-30 10:13:36,437:INFO:SubProcess create_model() end ==================================
2026-01-30 10:13:36,437:INFO:Creating metrics dataframe
2026-01-30 10:13:36,440:INFO:Initializing Light Gradient Boosting Machine
2026-01-30 10:13:36,440:INFO:Total runtime is 0.5126409689585367 minutes
2026-01-30 10:13:36,440:INFO:SubProcess create_model() called ==================================
2026-01-30 10:13:36,440:INFO:Initializing create_model()
2026-01-30 10:13:36,441:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04EFD5490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:13:36,441:INFO:Checking exceptions
2026-01-30 10:13:36,441:INFO:Importing libraries
2026-01-30 10:13:36,441:INFO:Copying training dataset
2026-01-30 10:13:36,705:INFO:Defining folds
2026-01-30 10:13:36,706:INFO:Declaring metric variables
2026-01-30 10:13:36,706:INFO:Importing untrained model
2026-01-30 10:13:36,707:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:13:36,707:INFO:Starting cross validation
2026-01-30 10:13:36,708:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:13:42,306:INFO:Calculating mean and std
2026-01-30 10:13:42,309:INFO:Creating metrics dataframe
2026-01-30 10:13:42,312:INFO:Uploading results into container
2026-01-30 10:13:42,313:INFO:Uploading model into container now
2026-01-30 10:13:42,314:INFO:_master_model_container: 4
2026-01-30 10:13:42,314:INFO:_display_container: 2
2026-01-30 10:13:42,315:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:13:42,315:INFO:create_model() successfully completed......................................
2026-01-30 10:13:42,578:INFO:SubProcess create_model() end ==================================
2026-01-30 10:13:42,578:INFO:Creating metrics dataframe
2026-01-30 10:13:42,582:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-30 10:13:42,584:INFO:Initializing create_model()
2026-01-30 10:13:42,584:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:13:42,584:INFO:Checking exceptions
2026-01-30 10:13:42,585:INFO:Importing libraries
2026-01-30 10:13:42,585:INFO:Copying training dataset
2026-01-30 10:13:42,890:INFO:Defining folds
2026-01-30 10:13:42,890:INFO:Declaring metric variables
2026-01-30 10:13:42,890:INFO:Importing untrained model
2026-01-30 10:13:42,890:INFO:Declaring custom model
2026-01-30 10:13:42,891:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:13:42,892:INFO:Cross validation set to False
2026-01-30 10:13:42,893:INFO:Fitting Model
2026-01-30 10:13:53,868:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:13:53,869:INFO:create_model() successfully completed......................................
2026-01-30 10:13:54,076:INFO:Initializing create_model()
2026-01-30 10:13:54,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:13:54,076:INFO:Checking exceptions
2026-01-30 10:13:54,078:INFO:Importing libraries
2026-01-30 10:13:54,078:INFO:Copying training dataset
2026-01-30 10:13:54,308:INFO:Defining folds
2026-01-30 10:13:54,308:INFO:Declaring metric variables
2026-01-30 10:13:54,309:INFO:Importing untrained model
2026-01-30 10:13:54,309:INFO:Declaring custom model
2026-01-30 10:13:54,311:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:13:54,311:INFO:Cross validation set to False
2026-01-30 10:13:54,311:INFO:Fitting Model
2026-01-30 10:13:55,388:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 10:13:55,454:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015382 seconds.
2026-01-30 10:13:55,454:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 10:13:55,455:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 10:13:55,455:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 10:13:55,456:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 10:13:55,460:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 10:13:55,460:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 10:13:56,695:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:13:56,696:INFO:create_model() successfully completed......................................
2026-01-30 10:13:56,955:INFO:Initializing create_model()
2026-01-30 10:13:56,955:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:13:56,955:INFO:Checking exceptions
2026-01-30 10:13:56,957:INFO:Importing libraries
2026-01-30 10:13:56,957:INFO:Copying training dataset
2026-01-30 10:13:57,220:INFO:Defining folds
2026-01-30 10:13:57,220:INFO:Declaring metric variables
2026-01-30 10:13:57,220:INFO:Importing untrained model
2026-01-30 10:13:57,220:INFO:Declaring custom model
2026-01-30 10:13:57,221:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:13:57,221:INFO:Cross validation set to False
2026-01-30 10:13:57,222:INFO:Fitting Model
2026-01-30 10:14:00,450:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:14:00,450:INFO:create_model() successfully completed......................................
2026-01-30 10:14:00,609:INFO:_master_model_container: 4
2026-01-30 10:14:00,609:INFO:_display_container: 2
2026-01-30 10:14:00,611:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')]
2026-01-30 10:14:00,611:INFO:compare_models() successfully completed......................................
2026-01-30 10:14:00,628:INFO:Initializing tune_model()
2026-01-30 10:14:00,628:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 10:14:00,628:INFO:Checking exceptions
2026-01-30 10:14:00,717:INFO:Copying training dataset
2026-01-30 10:14:00,887:INFO:Checking base model
2026-01-30 10:14:00,888:INFO:Base model : Random Forest Classifier
2026-01-30 10:14:00,888:INFO:Declaring metric variables
2026-01-30 10:14:00,889:INFO:Defining Hyperparameters
2026-01-30 10:14:01,045:INFO:Tuning with n_jobs=-1
2026-01-30 10:14:01,045:INFO:Initializing RandomizedSearchCV
2026-01-30 10:16:54,746:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-30 10:16:54,746:INFO:Hyperparameter search completed
2026-01-30 10:16:54,746:INFO:SubProcess create_model() called ==================================
2026-01-30 10:16:54,746:INFO:Initializing create_model()
2026-01-30 10:16:54,746:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04C86B010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': True})
2026-01-30 10:16:54,746:INFO:Checking exceptions
2026-01-30 10:16:54,746:INFO:Importing libraries
2026-01-30 10:16:54,746:INFO:Copying training dataset
2026-01-30 10:16:55,039:INFO:Defining folds
2026-01-30 10:16:55,039:INFO:Declaring metric variables
2026-01-30 10:16:55,039:INFO:Importing untrained model
2026-01-30 10:16:55,039:INFO:Declaring custom model
2026-01-30 10:16:55,039:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:16:55,039:INFO:Starting cross validation
2026-01-30 10:16:55,039:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:17:27,418:INFO:Calculating mean and std
2026-01-30 10:17:27,420:INFO:Creating metrics dataframe
2026-01-30 10:17:27,422:INFO:Finalizing model
2026-01-30 10:17:43,154:INFO:Uploading results into container
2026-01-30 10:17:43,155:INFO:Uploading model into container now
2026-01-30 10:17:43,156:INFO:_master_model_container: 5
2026-01-30 10:17:43,156:INFO:_display_container: 3
2026-01-30 10:17:43,158:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:17:43,158:INFO:create_model() successfully completed......................................
2026-01-30 10:17:43,328:INFO:SubProcess create_model() end ==================================
2026-01-30 10:17:43,328:INFO:choose_better activated
2026-01-30 10:17:43,328:INFO:SubProcess create_model() called ==================================
2026-01-30 10:17:43,329:INFO:Initializing create_model()
2026-01-30 10:17:43,329:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:17:43,329:INFO:Checking exceptions
2026-01-30 10:17:43,329:INFO:Importing libraries
2026-01-30 10:17:43,330:INFO:Copying training dataset
2026-01-30 10:17:43,543:INFO:Defining folds
2026-01-30 10:17:43,544:INFO:Declaring metric variables
2026-01-30 10:17:43,544:INFO:Importing untrained model
2026-01-30 10:17:43,544:INFO:Declaring custom model
2026-01-30 10:17:43,544:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:17:43,545:INFO:Starting cross validation
2026-01-30 10:17:43,545:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:18:06,409:INFO:Calculating mean and std
2026-01-30 10:18:06,410:INFO:Creating metrics dataframe
2026-01-30 10:18:06,411:INFO:Finalizing model
2026-01-30 10:18:17,025:INFO:Uploading results into container
2026-01-30 10:18:17,027:INFO:Uploading model into container now
2026-01-30 10:18:17,027:INFO:_master_model_container: 6
2026-01-30 10:18:17,028:INFO:_display_container: 4
2026-01-30 10:18:17,029:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:18:17,029:INFO:create_model() successfully completed......................................
2026-01-30 10:18:17,231:INFO:SubProcess create_model() end ==================================
2026-01-30 10:18:17,232:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9985
2026-01-30 10:18:17,232:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9894
2026-01-30 10:18:17,232:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-30 10:18:17,233:INFO:choose_better completed
2026-01-30 10:18:17,233:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 10:18:17,236:INFO:_master_model_container: 6
2026-01-30 10:18:17,236:INFO:_display_container: 3
2026-01-30 10:18:17,237:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:18:17,237:INFO:tune_model() successfully completed......................................
2026-01-30 10:18:17,407:INFO:Initializing tune_model()
2026-01-30 10:18:17,407:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 10:18:17,408:INFO:Checking exceptions
2026-01-30 10:18:17,487:INFO:Copying training dataset
2026-01-30 10:18:17,645:INFO:Checking base model
2026-01-30 10:18:17,646:INFO:Base model : Light Gradient Boosting Machine
2026-01-30 10:18:17,647:INFO:Declaring metric variables
2026-01-30 10:18:17,647:INFO:Defining Hyperparameters
2026-01-30 10:18:17,823:INFO:Tuning with n_jobs=-1
2026-01-30 10:18:17,823:INFO:Initializing RandomizedSearchCV
2026-01-30 10:19:02,500:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2026-01-30 10:19:02,501:INFO:Hyperparameter search completed
2026-01-30 10:19:02,502:INFO:SubProcess create_model() called ==================================
2026-01-30 10:19:02,505:INFO:Initializing create_model()
2026-01-30 10:19:02,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0D02B0E90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2026-01-30 10:19:02,506:INFO:Checking exceptions
2026-01-30 10:19:02,506:INFO:Importing libraries
2026-01-30 10:19:02,506:INFO:Copying training dataset
2026-01-30 10:19:02,908:INFO:Defining folds
2026-01-30 10:19:02,908:INFO:Declaring metric variables
2026-01-30 10:19:02,908:INFO:Importing untrained model
2026-01-30 10:19:02,909:INFO:Declaring custom model
2026-01-30 10:19:02,911:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:19:02,911:INFO:Starting cross validation
2026-01-30 10:19:02,912:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:19:14,173:INFO:Calculating mean and std
2026-01-30 10:19:14,174:INFO:Creating metrics dataframe
2026-01-30 10:19:14,174:INFO:Finalizing model
2026-01-30 10:19:14,938:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 10:19:14,938:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 10:19:14,938:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 10:19:15,152:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 10:19:15,154:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 10:19:15,154:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 10:19:15,154:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 10:19:15,207:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013022 seconds.
2026-01-30 10:19:15,207:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 10:19:15,207:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 10:19:15,209:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 10:19:15,210:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 10:19:15,215:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 10:19:15,215:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 10:19:18,895:INFO:Uploading results into container
2026-01-30 10:19:18,897:INFO:Uploading model into container now
2026-01-30 10:19:18,897:INFO:_master_model_container: 7
2026-01-30 10:19:18,899:INFO:_display_container: 4
2026-01-30 10:19:18,899:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:19:18,901:INFO:create_model() successfully completed......................................
2026-01-30 10:19:19,104:INFO:SubProcess create_model() end ==================================
2026-01-30 10:19:19,104:INFO:choose_better activated
2026-01-30 10:19:19,104:INFO:SubProcess create_model() called ==================================
2026-01-30 10:19:19,104:INFO:Initializing create_model()
2026-01-30 10:19:19,104:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:19:19,104:INFO:Checking exceptions
2026-01-30 10:19:19,104:INFO:Importing libraries
2026-01-30 10:19:19,104:INFO:Copying training dataset
2026-01-30 10:19:19,336:INFO:Defining folds
2026-01-30 10:19:19,336:INFO:Declaring metric variables
2026-01-30 10:19:19,336:INFO:Importing untrained model
2026-01-30 10:19:19,336:INFO:Declaring custom model
2026-01-30 10:19:19,336:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:19:19,336:INFO:Starting cross validation
2026-01-30 10:19:19,336:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:19:24,241:INFO:Calculating mean and std
2026-01-30 10:19:24,241:INFO:Creating metrics dataframe
2026-01-30 10:19:24,241:INFO:Finalizing model
2026-01-30 10:19:25,128:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 10:19:25,194:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012585 seconds.
2026-01-30 10:19:25,194:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 10:19:25,194:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 10:19:25,194:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 10:19:25,194:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 10:19:25,198:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 10:19:25,198:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 10:19:26,108:INFO:Uploading results into container
2026-01-30 10:19:26,108:INFO:Uploading model into container now
2026-01-30 10:19:26,110:INFO:_master_model_container: 8
2026-01-30 10:19:26,110:INFO:_display_container: 5
2026-01-30 10:19:26,110:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:19:26,110:INFO:create_model() successfully completed......................................
2026-01-30 10:19:26,330:INFO:SubProcess create_model() end ==================================
2026-01-30 10:19:26,330:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9945
2026-01-30 10:19:26,330:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9987
2026-01-30 10:19:26,330:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2026-01-30 10:19:26,330:INFO:choose_better completed
2026-01-30 10:19:26,330:INFO:_master_model_container: 8
2026-01-30 10:19:26,330:INFO:_display_container: 4
2026-01-30 10:19:26,330:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:19:26,330:INFO:tune_model() successfully completed......................................
2026-01-30 10:19:26,486:INFO:Initializing tune_model()
2026-01-30 10:19:26,486:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 10:19:26,486:INFO:Checking exceptions
2026-01-30 10:19:26,574:INFO:Copying training dataset
2026-01-30 10:19:26,721:INFO:Checking base model
2026-01-30 10:19:26,721:INFO:Base model : Decision Tree Classifier
2026-01-30 10:19:26,721:INFO:Declaring metric variables
2026-01-30 10:19:26,721:INFO:Defining Hyperparameters
2026-01-30 10:19:26,871:INFO:Tuning with n_jobs=-1
2026-01-30 10:19:26,871:INFO:Initializing RandomizedSearchCV
2026-01-30 10:19:35,453:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 15, 'actual_estimator__criterion': 'gini'}
2026-01-30 10:19:35,454:INFO:Hyperparameter search completed
2026-01-30 10:19:35,454:INFO:SubProcess create_model() called ==================================
2026-01-30 10:19:35,456:INFO:Initializing create_model()
2026-01-30 10:19:35,456:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C71DB810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 2, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 15, 'criterion': 'gini'})
2026-01-30 10:19:35,456:INFO:Checking exceptions
2026-01-30 10:19:35,456:INFO:Importing libraries
2026-01-30 10:19:35,456:INFO:Copying training dataset
2026-01-30 10:19:35,687:INFO:Defining folds
2026-01-30 10:19:35,687:INFO:Declaring metric variables
2026-01-30 10:19:35,687:INFO:Importing untrained model
2026-01-30 10:19:35,687:INFO:Declaring custom model
2026-01-30 10:19:35,687:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:19:35,687:INFO:Starting cross validation
2026-01-30 10:19:35,687:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:19:38,688:INFO:Calculating mean and std
2026-01-30 10:19:38,691:INFO:Creating metrics dataframe
2026-01-30 10:19:38,693:INFO:Finalizing model
2026-01-30 10:19:40,703:INFO:Uploading results into container
2026-01-30 10:19:40,703:INFO:Uploading model into container now
2026-01-30 10:19:40,703:INFO:_master_model_container: 9
2026-01-30 10:19:40,703:INFO:_display_container: 5
2026-01-30 10:19:40,703:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:19:40,703:INFO:create_model() successfully completed......................................
2026-01-30 10:19:40,853:INFO:SubProcess create_model() end ==================================
2026-01-30 10:19:40,853:INFO:choose_better activated
2026-01-30 10:19:40,853:INFO:SubProcess create_model() called ==================================
2026-01-30 10:19:40,853:INFO:Initializing create_model()
2026-01-30 10:19:40,853:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:19:40,853:INFO:Checking exceptions
2026-01-30 10:19:40,853:INFO:Importing libraries
2026-01-30 10:19:40,853:INFO:Copying training dataset
2026-01-30 10:19:41,053:INFO:Defining folds
2026-01-30 10:19:41,053:INFO:Declaring metric variables
2026-01-30 10:19:41,053:INFO:Importing untrained model
2026-01-30 10:19:41,053:INFO:Declaring custom model
2026-01-30 10:19:41,053:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:19:41,053:INFO:Starting cross validation
2026-01-30 10:19:41,053:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:19:44,805:INFO:Calculating mean and std
2026-01-30 10:19:44,808:INFO:Creating metrics dataframe
2026-01-30 10:19:44,810:INFO:Finalizing model
2026-01-30 10:19:47,703:INFO:Uploading results into container
2026-01-30 10:19:47,703:INFO:Uploading model into container now
2026-01-30 10:19:47,703:INFO:_master_model_container: 10
2026-01-30 10:19:47,703:INFO:_display_container: 6
2026-01-30 10:19:47,703:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:19:47,703:INFO:create_model() successfully completed......................................
2026-01-30 10:19:47,853:INFO:SubProcess create_model() end ==================================
2026-01-30 10:19:47,853:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.989
2026-01-30 10:19:47,853:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9826
2026-01-30 10:19:47,853:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-30 10:19:47,853:INFO:choose_better completed
2026-01-30 10:19:47,853:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 10:19:47,853:INFO:_master_model_container: 10
2026-01-30 10:19:47,853:INFO:_display_container: 5
2026-01-30 10:19:47,853:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:19:47,853:INFO:tune_model() successfully completed......................................
2026-01-30 10:19:48,047:INFO:Initializing predict_model()
2026-01-30 10:19:48,047:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0482014D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A06E850F40>)
2026-01-30 10:19:48,047:INFO:Checking exceptions
2026-01-30 10:19:48,047:INFO:Preloading libraries
2026-01-30 10:19:48,047:INFO:Set up data.
2026-01-30 10:21:10,305:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\3860568932.py:20: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-30 10:21:12,595:INFO:PyCaret ClassificationExperiment
2026-01-30 10:21:12,596:INFO:Logging name: clf-default-name
2026-01-30 10:21:12,596:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-30 10:21:12,596:INFO:version 3.3.2
2026-01-30 10:21:12,596:INFO:Initializing setup()
2026-01-30 10:21:12,596:INFO:self.USI: 145c
2026-01-30 10:21:12,598:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'n_jobs_param', 'data', 'X', 'idx', 'y_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'USI', 'target_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'y_train', 'X_test', 'seed', 'gpu_param', 'gpu_n_jobs_param', 'y', 'logging_param', 'pipeline', 'fold_generator', 'exp_id'}
2026-01-30 10:21:12,598:INFO:Checking environment
2026-01-30 10:21:12,598:INFO:python_version: 3.11.11
2026-01-30 10:21:12,599:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-30 10:21:12,599:INFO:machine: AMD64
2026-01-30 10:21:12,599:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-30 10:21:12,599:INFO:Memory: svmem(total=34009374720, available=10333499392, percent=69.6, used=23675875328, free=10333499392)
2026-01-30 10:21:12,600:INFO:Physical Core: 12
2026-01-30 10:21:12,600:INFO:Logical Core: 16
2026-01-30 10:21:12,600:INFO:Checking libraries
2026-01-30 10:21:12,600:INFO:System:
2026-01-30 10:21:12,600:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-30 10:21:12,600:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-30 10:21:12,601:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-30 10:21:12,602:INFO:PyCaret required dependencies:
2026-01-30 10:21:12,602:INFO:                 pip: 25.0
2026-01-30 10:21:12,602:INFO:          setuptools: 75.8.0
2026-01-30 10:21:12,602:INFO:             pycaret: 3.3.2
2026-01-30 10:21:12,602:INFO:             IPython: 9.9.0
2026-01-30 10:21:12,602:INFO:          ipywidgets: 8.1.8
2026-01-30 10:21:12,603:INFO:                tqdm: 4.67.1
2026-01-30 10:21:12,603:INFO:               numpy: 1.26.4
2026-01-30 10:21:12,603:INFO:              pandas: 2.1.4
2026-01-30 10:21:12,603:INFO:              jinja2: 3.1.6
2026-01-30 10:21:12,603:INFO:               scipy: 1.11.4
2026-01-30 10:21:12,603:INFO:              joblib: 1.3.2
2026-01-30 10:21:12,603:INFO:             sklearn: 1.4.2
2026-01-30 10:21:12,604:INFO:                pyod: 2.0.6
2026-01-30 10:21:12,604:INFO:            imblearn: 0.14.1
2026-01-30 10:21:12,604:INFO:   category_encoders: 2.7.0
2026-01-30 10:21:12,605:INFO:            lightgbm: 4.6.0
2026-01-30 10:21:12,606:INFO:               numba: 0.62.1
2026-01-30 10:21:12,606:INFO:            requests: 2.32.3
2026-01-30 10:21:12,606:INFO:          matplotlib: 3.7.5
2026-01-30 10:21:12,606:INFO:          scikitplot: 0.3.7
2026-01-30 10:21:12,606:INFO:         yellowbrick: 1.5
2026-01-30 10:21:12,606:INFO:              plotly: 5.24.1
2026-01-30 10:21:12,607:INFO:    plotly-resampler: Not installed
2026-01-30 10:21:12,607:INFO:             kaleido: 1.2.0
2026-01-30 10:21:12,607:INFO:           schemdraw: 0.15
2026-01-30 10:21:12,607:INFO:         statsmodels: 0.14.6
2026-01-30 10:21:12,607:INFO:              sktime: 0.26.0
2026-01-30 10:21:12,607:INFO:               tbats: 1.1.3
2026-01-30 10:21:12,607:INFO:            pmdarima: 2.0.4
2026-01-30 10:21:12,608:INFO:              psutil: 7.2.1
2026-01-30 10:21:12,608:INFO:          markupsafe: 3.0.3
2026-01-30 10:21:12,608:INFO:             pickle5: Not installed
2026-01-30 10:21:12,608:INFO:         cloudpickle: 3.0.0
2026-01-30 10:21:12,609:INFO:         deprecation: 2.1.0
2026-01-30 10:21:12,609:INFO:              xxhash: 3.6.0
2026-01-30 10:21:12,609:INFO:           wurlitzer: Not installed
2026-01-30 10:21:12,609:INFO:PyCaret optional dependencies:
2026-01-30 10:21:12,609:INFO:                shap: 0.44.1
2026-01-30 10:21:12,610:INFO:           interpret: 0.7.3
2026-01-30 10:21:12,610:INFO:                umap: 0.5.7
2026-01-30 10:21:12,610:INFO:     ydata_profiling: 4.18.1
2026-01-30 10:21:12,610:INFO:  explainerdashboard: 0.5.1
2026-01-30 10:21:12,610:INFO:             autoviz: Not installed
2026-01-30 10:21:12,610:INFO:           fairlearn: 0.7.0
2026-01-30 10:21:12,611:INFO:          deepchecks: Not installed
2026-01-30 10:21:12,611:INFO:             xgboost: Not installed
2026-01-30 10:21:12,611:INFO:            catboost: 1.2.8
2026-01-30 10:21:12,611:INFO:              kmodes: 0.12.2
2026-01-30 10:21:12,611:INFO:             mlxtend: 0.23.4
2026-01-30 10:21:12,611:INFO:       statsforecast: 1.5.0
2026-01-30 10:21:12,611:INFO:        tune_sklearn: Not installed
2026-01-30 10:21:12,611:INFO:                 ray: Not installed
2026-01-30 10:21:12,612:INFO:            hyperopt: 0.2.7
2026-01-30 10:21:12,612:INFO:              optuna: 4.6.0
2026-01-30 10:21:12,613:INFO:               skopt: 0.10.2
2026-01-30 10:21:12,613:INFO:              mlflow: 3.8.1
2026-01-30 10:21:12,613:INFO:              gradio: 6.3.0
2026-01-30 10:21:12,613:INFO:             fastapi: 0.128.0
2026-01-30 10:21:12,613:INFO:             uvicorn: 0.40.0
2026-01-30 10:21:12,613:INFO:              m2cgen: 0.10.0
2026-01-30 10:21:12,614:INFO:           evidently: 0.4.40
2026-01-30 10:21:12,614:INFO:               fugue: 0.8.7
2026-01-30 10:21:12,614:INFO:           streamlit: Not installed
2026-01-30 10:21:12,614:INFO:             prophet: Not installed
2026-01-30 10:21:12,615:INFO:None
2026-01-30 10:21:12,615:INFO:Set up data.
2026-01-30 10:21:12,766:INFO:Set up folding strategy.
2026-01-30 10:21:12,766:INFO:Set up train/test split.
2026-01-30 10:21:13,022:INFO:Set up index.
2026-01-30 10:21:13,033:INFO:Assigning column types.
2026-01-30 10:21:13,185:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-30 10:21:13,202:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 10:21:13,202:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:21:13,219:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:21:13,219:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:21:13,252:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 10:21:13,252:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:21:13,272:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:21:13,285:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:21:13,285:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-30 10:21:13,302:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:21:13,335:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:21:13,335:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:21:13,352:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:21:13,385:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:21:13,385:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:21:13,386:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-30 10:21:13,435:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:21:13,435:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:21:13,468:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:21:13,484:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:21:13,486:INFO:Preparing preprocessing pipeline...
2026-01-30 10:21:13,502:INFO:Set up simple imputation.
2026-01-30 10:21:13,502:INFO:Set up feature normalization.
2026-01-30 10:21:13,801:INFO:Finished creating preprocessing pipeline.
2026-01-30 10:21:13,806:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'PAID_AMOUNT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdina...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-30 10:21:13,806:INFO:Creating final display dataframe.
2026-01-30 10:21:14,469:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape      (482669, 28)
4        Transformed data shape      (482669, 28)
5   Transformed train set shape      (337868, 28)
6    Transformed test set shape      (144801, 28)
7              Numeric features                24
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                 3
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              145c
2026-01-30 10:21:14,519:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:21:14,519:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:21:14,575:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:21:14,576:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:21:14,577:INFO:setup() successfully completed in 1.99s...............
2026-01-30 10:21:14,577:INFO:Initializing compare_models()
2026-01-30 10:21:14,577:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-30 10:21:14,577:INFO:Checking exceptions
2026-01-30 10:21:14,752:INFO:Preparing display monitor
2026-01-30 10:21:14,756:INFO:Initializing Logistic Regression
2026-01-30 10:21:14,758:INFO:Total runtime is 3.84370485941569e-05 minutes
2026-01-30 10:21:14,758:INFO:SubProcess create_model() called ==================================
2026-01-30 10:21:14,758:INFO:Initializing create_model()
2026-01-30 10:21:14,759:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04D4BB5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:21:14,759:INFO:Checking exceptions
2026-01-30 10:21:14,759:INFO:Importing libraries
2026-01-30 10:21:14,759:INFO:Copying training dataset
2026-01-30 10:21:15,018:INFO:Defining folds
2026-01-30 10:21:15,035:INFO:Declaring metric variables
2026-01-30 10:21:15,035:INFO:Importing untrained model
2026-01-30 10:21:15,035:INFO:Logistic Regression Imported successfully
2026-01-30 10:21:15,035:INFO:Starting cross validation
2026-01-30 10:21:15,035:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:21:18,459:INFO:Calculating mean and std
2026-01-30 10:21:18,459:INFO:Creating metrics dataframe
2026-01-30 10:21:18,459:INFO:Uploading results into container
2026-01-30 10:21:18,459:INFO:Uploading model into container now
2026-01-30 10:21:18,459:INFO:_master_model_container: 1
2026-01-30 10:21:18,459:INFO:_display_container: 2
2026-01-30 10:21:18,459:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-30 10:21:18,459:INFO:create_model() successfully completed......................................
2026-01-30 10:21:18,684:INFO:SubProcess create_model() end ==================================
2026-01-30 10:21:18,689:INFO:Creating metrics dataframe
2026-01-30 10:21:18,693:INFO:Initializing Decision Tree Classifier
2026-01-30 10:21:18,693:INFO:Total runtime is 0.06562891801198324 minutes
2026-01-30 10:21:18,693:INFO:SubProcess create_model() called ==================================
2026-01-30 10:21:18,694:INFO:Initializing create_model()
2026-01-30 10:21:18,694:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04D4BB5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:21:18,694:INFO:Checking exceptions
2026-01-30 10:21:18,694:INFO:Importing libraries
2026-01-30 10:21:18,694:INFO:Copying training dataset
2026-01-30 10:21:18,918:INFO:Defining folds
2026-01-30 10:21:18,918:INFO:Declaring metric variables
2026-01-30 10:21:18,918:INFO:Importing untrained model
2026-01-30 10:21:18,918:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:21:18,918:INFO:Starting cross validation
2026-01-30 10:21:18,918:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:21:22,798:INFO:Calculating mean and std
2026-01-30 10:21:22,802:INFO:Creating metrics dataframe
2026-01-30 10:21:22,802:INFO:Uploading results into container
2026-01-30 10:21:22,802:INFO:Uploading model into container now
2026-01-30 10:21:22,802:INFO:_master_model_container: 2
2026-01-30 10:21:22,802:INFO:_display_container: 2
2026-01-30 10:21:22,802:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:21:22,802:INFO:create_model() successfully completed......................................
2026-01-30 10:21:22,968:INFO:SubProcess create_model() end ==================================
2026-01-30 10:21:22,968:INFO:Creating metrics dataframe
2026-01-30 10:21:22,984:INFO:Initializing Random Forest Classifier
2026-01-30 10:21:22,985:INFO:Total runtime is 0.13715004920959473 minutes
2026-01-30 10:21:22,985:INFO:SubProcess create_model() called ==================================
2026-01-30 10:21:22,985:INFO:Initializing create_model()
2026-01-30 10:21:22,985:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04D4BB5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:21:22,985:INFO:Checking exceptions
2026-01-30 10:21:22,985:INFO:Importing libraries
2026-01-30 10:21:22,985:INFO:Copying training dataset
2026-01-30 10:21:23,168:INFO:Defining folds
2026-01-30 10:21:23,184:INFO:Declaring metric variables
2026-01-30 10:21:23,184:INFO:Importing untrained model
2026-01-30 10:21:23,185:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:21:23,185:INFO:Starting cross validation
2026-01-30 10:21:23,185:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:21:42,090:INFO:Calculating mean and std
2026-01-30 10:21:42,093:INFO:Creating metrics dataframe
2026-01-30 10:21:42,096:INFO:Uploading results into container
2026-01-30 10:21:42,097:INFO:Uploading model into container now
2026-01-30 10:21:42,098:INFO:_master_model_container: 3
2026-01-30 10:21:42,098:INFO:_display_container: 2
2026-01-30 10:21:42,099:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:21:42,099:INFO:create_model() successfully completed......................................
2026-01-30 10:21:42,299:INFO:SubProcess create_model() end ==================================
2026-01-30 10:21:42,299:INFO:Creating metrics dataframe
2026-01-30 10:21:42,302:INFO:Initializing Light Gradient Boosting Machine
2026-01-30 10:21:42,302:INFO:Total runtime is 0.4591042995452881 minutes
2026-01-30 10:21:42,302:INFO:SubProcess create_model() called ==================================
2026-01-30 10:21:42,302:INFO:Initializing create_model()
2026-01-30 10:21:42,302:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04D4BB5D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:21:42,302:INFO:Checking exceptions
2026-01-30 10:21:42,302:INFO:Importing libraries
2026-01-30 10:21:42,302:INFO:Copying training dataset
2026-01-30 10:21:42,659:INFO:Defining folds
2026-01-30 10:21:42,659:INFO:Declaring metric variables
2026-01-30 10:21:42,660:INFO:Importing untrained model
2026-01-30 10:21:42,660:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:21:42,661:INFO:Starting cross validation
2026-01-30 10:21:42,662:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:21:47,834:INFO:Calculating mean and std
2026-01-30 10:21:47,834:INFO:Creating metrics dataframe
2026-01-30 10:21:47,834:INFO:Uploading results into container
2026-01-30 10:21:47,834:INFO:Uploading model into container now
2026-01-30 10:21:47,834:INFO:_master_model_container: 4
2026-01-30 10:21:47,834:INFO:_display_container: 2
2026-01-30 10:21:47,834:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:21:47,834:INFO:create_model() successfully completed......................................
2026-01-30 10:21:48,002:INFO:SubProcess create_model() end ==================================
2026-01-30 10:21:48,002:INFO:Creating metrics dataframe
2026-01-30 10:21:48,002:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-30 10:21:48,002:INFO:Initializing create_model()
2026-01-30 10:21:48,002:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:21:48,002:INFO:Checking exceptions
2026-01-30 10:21:48,002:INFO:Importing libraries
2026-01-30 10:21:48,002:INFO:Copying training dataset
2026-01-30 10:21:48,204:INFO:Defining folds
2026-01-30 10:21:48,204:INFO:Declaring metric variables
2026-01-30 10:21:48,204:INFO:Importing untrained model
2026-01-30 10:21:48,204:INFO:Declaring custom model
2026-01-30 10:21:48,204:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:21:48,204:INFO:Cross validation set to False
2026-01-30 10:21:48,204:INFO:Fitting Model
2026-01-30 10:21:57,854:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:21:57,854:INFO:create_model() successfully completed......................................
2026-01-30 10:21:58,035:INFO:Initializing create_model()
2026-01-30 10:21:58,037:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:21:58,037:INFO:Checking exceptions
2026-01-30 10:21:58,037:INFO:Importing libraries
2026-01-30 10:21:58,037:INFO:Copying training dataset
2026-01-30 10:21:58,220:INFO:Defining folds
2026-01-30 10:21:58,220:INFO:Declaring metric variables
2026-01-30 10:21:58,220:INFO:Importing untrained model
2026-01-30 10:21:58,220:INFO:Declaring custom model
2026-01-30 10:21:58,220:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:21:58,220:INFO:Cross validation set to False
2026-01-30 10:21:58,220:INFO:Fitting Model
2026-01-30 10:21:59,128:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 10:21:59,195:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012663 seconds.
2026-01-30 10:21:59,197:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 10:21:59,197:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 10:21:59,197:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 10:21:59,197:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 10:21:59,199:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 10:21:59,199:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 10:22:00,091:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:22:00,093:INFO:create_model() successfully completed......................................
2026-01-30 10:22:00,323:INFO:Initializing create_model()
2026-01-30 10:22:00,323:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:22:00,323:INFO:Checking exceptions
2026-01-30 10:22:00,323:INFO:Importing libraries
2026-01-30 10:22:00,323:INFO:Copying training dataset
2026-01-30 10:22:00,541:INFO:Defining folds
2026-01-30 10:22:00,541:INFO:Declaring metric variables
2026-01-30 10:22:00,541:INFO:Importing untrained model
2026-01-30 10:22:00,541:INFO:Declaring custom model
2026-01-30 10:22:00,541:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:22:00,541:INFO:Cross validation set to False
2026-01-30 10:22:00,541:INFO:Fitting Model
2026-01-30 10:22:03,792:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:22:03,792:INFO:create_model() successfully completed......................................
2026-01-30 10:22:03,961:INFO:_master_model_container: 4
2026-01-30 10:22:03,961:INFO:_display_container: 2
2026-01-30 10:22:03,962:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')]
2026-01-30 10:22:03,962:INFO:compare_models() successfully completed......................................
2026-01-30 10:22:03,981:INFO:Initializing tune_model()
2026-01-30 10:22:03,981:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 10:22:03,981:INFO:Checking exceptions
2026-01-30 10:22:04,054:INFO:Copying training dataset
2026-01-30 10:22:04,216:INFO:Checking base model
2026-01-30 10:22:04,216:INFO:Base model : Random Forest Classifier
2026-01-30 10:22:04,217:INFO:Declaring metric variables
2026-01-30 10:22:04,218:INFO:Defining Hyperparameters
2026-01-30 10:22:04,367:INFO:Tuning with n_jobs=-1
2026-01-30 10:22:04,367:INFO:Initializing RandomizedSearchCV
2026-01-30 10:24:50,387:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-30 10:24:50,387:INFO:Hyperparameter search completed
2026-01-30 10:24:50,387:INFO:SubProcess create_model() called ==================================
2026-01-30 10:24:50,387:INFO:Initializing create_model()
2026-01-30 10:24:50,387:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03CE1AC90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': True})
2026-01-30 10:24:50,387:INFO:Checking exceptions
2026-01-30 10:24:50,387:INFO:Importing libraries
2026-01-30 10:24:50,387:INFO:Copying training dataset
2026-01-30 10:24:50,615:INFO:Defining folds
2026-01-30 10:24:50,615:INFO:Declaring metric variables
2026-01-30 10:24:50,615:INFO:Importing untrained model
2026-01-30 10:24:50,615:INFO:Declaring custom model
2026-01-30 10:24:50,615:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:24:50,615:INFO:Starting cross validation
2026-01-30 10:24:50,615:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:25:23,142:INFO:Calculating mean and std
2026-01-30 10:25:23,143:INFO:Creating metrics dataframe
2026-01-30 10:25:23,145:INFO:Finalizing model
2026-01-30 10:25:39,015:INFO:Uploading results into container
2026-01-30 10:25:39,015:INFO:Uploading model into container now
2026-01-30 10:25:39,015:INFO:_master_model_container: 5
2026-01-30 10:25:39,025:INFO:_display_container: 3
2026-01-30 10:25:39,025:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:25:39,025:INFO:create_model() successfully completed......................................
2026-01-30 10:25:39,198:INFO:SubProcess create_model() end ==================================
2026-01-30 10:25:39,198:INFO:choose_better activated
2026-01-30 10:25:39,198:INFO:SubProcess create_model() called ==================================
2026-01-30 10:25:39,198:INFO:Initializing create_model()
2026-01-30 10:25:39,198:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:25:39,198:INFO:Checking exceptions
2026-01-30 10:25:39,214:INFO:Importing libraries
2026-01-30 10:25:39,214:INFO:Copying training dataset
2026-01-30 10:25:39,465:INFO:Defining folds
2026-01-30 10:25:39,465:INFO:Declaring metric variables
2026-01-30 10:25:39,465:INFO:Importing untrained model
2026-01-30 10:25:39,465:INFO:Declaring custom model
2026-01-30 10:25:39,465:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:25:39,465:INFO:Starting cross validation
2026-01-30 10:25:39,465:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:26:00,508:INFO:Calculating mean and std
2026-01-30 10:26:00,508:INFO:Creating metrics dataframe
2026-01-30 10:26:00,508:INFO:Finalizing model
2026-01-30 10:26:10,631:INFO:Uploading results into container
2026-01-30 10:26:10,631:INFO:Uploading model into container now
2026-01-30 10:26:10,631:INFO:_master_model_container: 6
2026-01-30 10:26:10,631:INFO:_display_container: 4
2026-01-30 10:26:10,631:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:26:10,631:INFO:create_model() successfully completed......................................
2026-01-30 10:26:10,814:INFO:SubProcess create_model() end ==================================
2026-01-30 10:26:10,814:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9985
2026-01-30 10:26:10,814:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9894
2026-01-30 10:26:10,814:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-30 10:26:10,814:INFO:choose_better completed
2026-01-30 10:26:10,814:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 10:26:10,814:INFO:_master_model_container: 6
2026-01-30 10:26:10,814:INFO:_display_container: 3
2026-01-30 10:26:10,814:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:26:10,814:INFO:tune_model() successfully completed......................................
2026-01-30 10:26:10,981:INFO:Initializing tune_model()
2026-01-30 10:26:10,981:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 10:26:10,981:INFO:Checking exceptions
2026-01-30 10:26:11,074:INFO:Copying training dataset
2026-01-30 10:26:11,198:INFO:Checking base model
2026-01-30 10:26:11,198:INFO:Base model : Light Gradient Boosting Machine
2026-01-30 10:26:11,213:INFO:Declaring metric variables
2026-01-30 10:26:11,213:INFO:Defining Hyperparameters
2026-01-30 10:26:11,364:INFO:Tuning with n_jobs=-1
2026-01-30 10:26:11,364:INFO:Initializing RandomizedSearchCV
2026-01-30 10:26:56,428:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2026-01-30 10:26:56,428:INFO:Hyperparameter search completed
2026-01-30 10:26:56,428:INFO:SubProcess create_model() called ==================================
2026-01-30 10:26:56,428:INFO:Initializing create_model()
2026-01-30 10:26:56,428:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04825E010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2026-01-30 10:26:56,428:INFO:Checking exceptions
2026-01-30 10:26:56,428:INFO:Importing libraries
2026-01-30 10:26:56,428:INFO:Copying training dataset
2026-01-30 10:26:56,682:INFO:Defining folds
2026-01-30 10:26:56,682:INFO:Declaring metric variables
2026-01-30 10:26:56,682:INFO:Importing untrained model
2026-01-30 10:26:56,682:INFO:Declaring custom model
2026-01-30 10:26:56,686:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:26:56,686:INFO:Starting cross validation
2026-01-30 10:26:56,686:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:27:07,423:INFO:Calculating mean and std
2026-01-30 10:27:07,423:INFO:Creating metrics dataframe
2026-01-30 10:27:07,431:INFO:Finalizing model
2026-01-30 10:27:08,197:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 10:27:08,197:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 10:27:08,197:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 10:27:08,445:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 10:27:08,445:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 10:27:08,445:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 10:27:08,447:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 10:27:08,513:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016019 seconds.
2026-01-30 10:27:08,513:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 10:27:08,513:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 10:27:08,515:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 10:27:08,516:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 10:27:08,520:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 10:27:08,522:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 10:27:12,001:INFO:Uploading results into container
2026-01-30 10:27:12,003:INFO:Uploading model into container now
2026-01-30 10:27:12,003:INFO:_master_model_container: 7
2026-01-30 10:27:12,005:INFO:_display_container: 4
2026-01-30 10:27:12,005:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:27:12,007:INFO:create_model() successfully completed......................................
2026-01-30 10:27:12,236:INFO:SubProcess create_model() end ==================================
2026-01-30 10:27:12,238:INFO:choose_better activated
2026-01-30 10:27:12,238:INFO:SubProcess create_model() called ==================================
2026-01-30 10:27:12,238:INFO:Initializing create_model()
2026-01-30 10:27:12,238:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:27:12,240:INFO:Checking exceptions
2026-01-30 10:27:12,240:INFO:Importing libraries
2026-01-30 10:27:12,240:INFO:Copying training dataset
2026-01-30 10:27:12,447:INFO:Defining folds
2026-01-30 10:27:12,447:INFO:Declaring metric variables
2026-01-30 10:27:12,447:INFO:Importing untrained model
2026-01-30 10:27:12,447:INFO:Declaring custom model
2026-01-30 10:27:12,447:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:27:12,447:INFO:Starting cross validation
2026-01-30 10:27:12,447:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:27:17,530:INFO:Calculating mean and std
2026-01-30 10:27:17,530:INFO:Creating metrics dataframe
2026-01-30 10:27:17,530:INFO:Finalizing model
2026-01-30 10:27:18,457:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 10:27:18,505:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014214 seconds.
2026-01-30 10:27:18,505:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 10:27:18,505:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 10:27:18,505:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 10:27:18,505:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 10:27:18,509:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 10:27:18,509:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 10:27:19,411:INFO:Uploading results into container
2026-01-30 10:27:19,411:INFO:Uploading model into container now
2026-01-30 10:27:19,413:INFO:_master_model_container: 8
2026-01-30 10:27:19,413:INFO:_display_container: 5
2026-01-30 10:27:19,414:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:27:19,414:INFO:create_model() successfully completed......................................
2026-01-30 10:27:19,630:INFO:SubProcess create_model() end ==================================
2026-01-30 10:27:19,630:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9945
2026-01-30 10:27:19,630:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9987
2026-01-30 10:27:19,630:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2026-01-30 10:27:19,630:INFO:choose_better completed
2026-01-30 10:27:19,646:INFO:_master_model_container: 8
2026-01-30 10:27:19,646:INFO:_display_container: 4
2026-01-30 10:27:19,646:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:27:19,646:INFO:tune_model() successfully completed......................................
2026-01-30 10:27:19,815:INFO:Initializing tune_model()
2026-01-30 10:27:19,815:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 10:27:19,815:INFO:Checking exceptions
2026-01-30 10:27:19,904:INFO:Copying training dataset
2026-01-30 10:27:20,064:INFO:Checking base model
2026-01-30 10:27:20,064:INFO:Base model : Decision Tree Classifier
2026-01-30 10:27:20,064:INFO:Declaring metric variables
2026-01-30 10:27:20,064:INFO:Defining Hyperparameters
2026-01-30 10:27:20,234:INFO:Tuning with n_jobs=-1
2026-01-30 10:27:20,234:INFO:Initializing RandomizedSearchCV
2026-01-30 10:27:29,011:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 15, 'actual_estimator__criterion': 'gini'}
2026-01-30 10:27:29,011:INFO:Hyperparameter search completed
2026-01-30 10:27:29,011:INFO:SubProcess create_model() called ==================================
2026-01-30 10:27:29,011:INFO:Initializing create_model()
2026-01-30 10:27:29,011:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03C4F3150>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 2, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 15, 'criterion': 'gini'})
2026-01-30 10:27:29,011:INFO:Checking exceptions
2026-01-30 10:27:29,011:INFO:Importing libraries
2026-01-30 10:27:29,011:INFO:Copying training dataset
2026-01-30 10:27:29,231:INFO:Defining folds
2026-01-30 10:27:29,231:INFO:Declaring metric variables
2026-01-30 10:27:29,231:INFO:Importing untrained model
2026-01-30 10:27:29,231:INFO:Declaring custom model
2026-01-30 10:27:29,233:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:27:29,233:INFO:Starting cross validation
2026-01-30 10:27:29,233:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:27:32,303:INFO:Calculating mean and std
2026-01-30 10:27:32,303:INFO:Creating metrics dataframe
2026-01-30 10:27:32,309:INFO:Finalizing model
2026-01-30 10:27:34,346:INFO:Uploading results into container
2026-01-30 10:27:34,346:INFO:Uploading model into container now
2026-01-30 10:27:34,346:INFO:_master_model_container: 9
2026-01-30 10:27:34,346:INFO:_display_container: 5
2026-01-30 10:27:34,346:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:27:34,346:INFO:create_model() successfully completed......................................
2026-01-30 10:27:34,498:INFO:SubProcess create_model() end ==================================
2026-01-30 10:27:34,498:INFO:choose_better activated
2026-01-30 10:27:34,498:INFO:SubProcess create_model() called ==================================
2026-01-30 10:27:34,498:INFO:Initializing create_model()
2026-01-30 10:27:34,498:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:27:34,498:INFO:Checking exceptions
2026-01-30 10:27:34,498:INFO:Importing libraries
2026-01-30 10:27:34,498:INFO:Copying training dataset
2026-01-30 10:27:34,732:INFO:Defining folds
2026-01-30 10:27:34,732:INFO:Declaring metric variables
2026-01-30 10:27:34,732:INFO:Importing untrained model
2026-01-30 10:27:34,732:INFO:Declaring custom model
2026-01-30 10:27:34,733:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:27:34,733:INFO:Starting cross validation
2026-01-30 10:27:34,734:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:27:38,519:INFO:Calculating mean and std
2026-01-30 10:27:38,520:INFO:Creating metrics dataframe
2026-01-30 10:27:38,520:INFO:Finalizing model
2026-01-30 10:27:41,735:INFO:Uploading results into container
2026-01-30 10:27:41,736:INFO:Uploading model into container now
2026-01-30 10:27:41,736:INFO:_master_model_container: 10
2026-01-30 10:27:41,736:INFO:_display_container: 6
2026-01-30 10:27:41,736:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:27:41,736:INFO:create_model() successfully completed......................................
2026-01-30 10:27:41,897:INFO:SubProcess create_model() end ==================================
2026-01-30 10:27:41,898:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.989
2026-01-30 10:27:41,898:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9826
2026-01-30 10:27:41,898:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-30 10:27:41,898:INFO:choose_better completed
2026-01-30 10:27:41,898:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 10:27:41,900:INFO:_master_model_container: 10
2026-01-30 10:27:41,901:INFO:_display_container: 5
2026-01-30 10:27:41,901:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:27:41,901:INFO:tune_model() successfully completed......................................
2026-01-30 10:27:42,069:INFO:Initializing predict_model()
2026-01-30 10:27:42,069:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C299D1D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A0C9F760C0>)
2026-01-30 10:27:42,069:INFO:Checking exceptions
2026-01-30 10:27:42,069:INFO:Preloading libraries
2026-01-30 10:27:42,069:INFO:Set up data.
2026-01-30 10:27:42,079:INFO:Set up index.
2026-01-30 10:27:42,613:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\sklearn\utils\_array_api.py:290: RuntimeWarning: invalid value encountered in cast

2026-01-30 10:29:40,062:WARNING:C:\Users\0021755\AppData\Local\Temp\ipykernel_26880\503664258.py:20: DtypeWarning: Columns (6,9,17,18,19,21,22,27,28,29,30,33) have mixed types. Specify dtype option on import or set low_memory=False.

2026-01-30 10:29:42,260:INFO:PyCaret ClassificationExperiment
2026-01-30 10:29:42,260:INFO:Logging name: clf-default-name
2026-01-30 10:29:42,260:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2026-01-30 10:29:42,260:INFO:version 3.3.2
2026-01-30 10:29:42,260:INFO:Initializing setup()
2026-01-30 10:29:42,260:INFO:self.USI: 16e5
2026-01-30 10:29:42,260:INFO:self._variable_keys: {'fold_groups_param', 'is_multiclass', 'n_jobs_param', 'data', 'X', 'idx', 'y_test', 'log_plots_param', 'html_param', 'fold_shuffle_param', 'USI', 'target_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'memory', 'exp_name_log', '_available_plots', 'y_train', 'X_test', 'seed', 'gpu_param', 'gpu_n_jobs_param', 'y', 'logging_param', 'pipeline', 'fold_generator', 'exp_id'}
2026-01-30 10:29:42,260:INFO:Checking environment
2026-01-30 10:29:42,260:INFO:python_version: 3.11.11
2026-01-30 10:29:42,260:INFO:python_build: ('main', 'Dec 11 2024 16:34:19')
2026-01-30 10:29:42,260:INFO:machine: AMD64
2026-01-30 10:29:42,260:INFO:platform: Windows-10-10.0.26100-SP0
2026-01-30 10:29:42,261:INFO:Memory: svmem(total=34009374720, available=9681879040, percent=71.5, used=24327495680, free=9681879040)
2026-01-30 10:29:42,261:INFO:Physical Core: 12
2026-01-30 10:29:42,261:INFO:Logical Core: 16
2026-01-30 10:29:42,261:INFO:Checking libraries
2026-01-30 10:29:42,261:INFO:System:
2026-01-30 10:29:42,261:INFO:    python: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]
2026-01-30 10:29:42,261:INFO:executable: c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\python.exe
2026-01-30 10:29:42,261:INFO:   machine: Windows-10-10.0.26100-SP0
2026-01-30 10:29:42,261:INFO:PyCaret required dependencies:
2026-01-30 10:29:42,261:INFO:                 pip: 25.0
2026-01-30 10:29:42,261:INFO:          setuptools: 75.8.0
2026-01-30 10:29:42,261:INFO:             pycaret: 3.3.2
2026-01-30 10:29:42,261:INFO:             IPython: 9.9.0
2026-01-30 10:29:42,261:INFO:          ipywidgets: 8.1.8
2026-01-30 10:29:42,261:INFO:                tqdm: 4.67.1
2026-01-30 10:29:42,261:INFO:               numpy: 1.26.4
2026-01-30 10:29:42,261:INFO:              pandas: 2.1.4
2026-01-30 10:29:42,261:INFO:              jinja2: 3.1.6
2026-01-30 10:29:42,261:INFO:               scipy: 1.11.4
2026-01-30 10:29:42,261:INFO:              joblib: 1.3.2
2026-01-30 10:29:42,261:INFO:             sklearn: 1.4.2
2026-01-30 10:29:42,262:INFO:                pyod: 2.0.6
2026-01-30 10:29:42,262:INFO:            imblearn: 0.14.1
2026-01-30 10:29:42,262:INFO:   category_encoders: 2.7.0
2026-01-30 10:29:42,262:INFO:            lightgbm: 4.6.0
2026-01-30 10:29:42,262:INFO:               numba: 0.62.1
2026-01-30 10:29:42,262:INFO:            requests: 2.32.3
2026-01-30 10:29:42,262:INFO:          matplotlib: 3.7.5
2026-01-30 10:29:42,263:INFO:          scikitplot: 0.3.7
2026-01-30 10:29:42,263:INFO:         yellowbrick: 1.5
2026-01-30 10:29:42,264:INFO:              plotly: 5.24.1
2026-01-30 10:29:42,264:INFO:    plotly-resampler: Not installed
2026-01-30 10:29:42,264:INFO:             kaleido: 1.2.0
2026-01-30 10:29:42,264:INFO:           schemdraw: 0.15
2026-01-30 10:29:42,264:INFO:         statsmodels: 0.14.6
2026-01-30 10:29:42,264:INFO:              sktime: 0.26.0
2026-01-30 10:29:42,264:INFO:               tbats: 1.1.3
2026-01-30 10:29:42,264:INFO:            pmdarima: 2.0.4
2026-01-30 10:29:42,264:INFO:              psutil: 7.2.1
2026-01-30 10:29:42,264:INFO:          markupsafe: 3.0.3
2026-01-30 10:29:42,264:INFO:             pickle5: Not installed
2026-01-30 10:29:42,264:INFO:         cloudpickle: 3.0.0
2026-01-30 10:29:42,264:INFO:         deprecation: 2.1.0
2026-01-30 10:29:42,264:INFO:              xxhash: 3.6.0
2026-01-30 10:29:42,264:INFO:           wurlitzer: Not installed
2026-01-30 10:29:42,264:INFO:PyCaret optional dependencies:
2026-01-30 10:29:42,264:INFO:                shap: 0.44.1
2026-01-30 10:29:42,264:INFO:           interpret: 0.7.3
2026-01-30 10:29:42,264:INFO:                umap: 0.5.7
2026-01-30 10:29:42,264:INFO:     ydata_profiling: 4.18.1
2026-01-30 10:29:42,265:INFO:  explainerdashboard: 0.5.1
2026-01-30 10:29:42,265:INFO:             autoviz: Not installed
2026-01-30 10:29:42,265:INFO:           fairlearn: 0.7.0
2026-01-30 10:29:42,265:INFO:          deepchecks: Not installed
2026-01-30 10:29:42,265:INFO:             xgboost: Not installed
2026-01-30 10:29:42,265:INFO:            catboost: 1.2.8
2026-01-30 10:29:42,265:INFO:              kmodes: 0.12.2
2026-01-30 10:29:42,265:INFO:             mlxtend: 0.23.4
2026-01-30 10:29:42,265:INFO:       statsforecast: 1.5.0
2026-01-30 10:29:42,265:INFO:        tune_sklearn: Not installed
2026-01-30 10:29:42,265:INFO:                 ray: Not installed
2026-01-30 10:29:42,265:INFO:            hyperopt: 0.2.7
2026-01-30 10:29:42,265:INFO:              optuna: 4.6.0
2026-01-30 10:29:42,265:INFO:               skopt: 0.10.2
2026-01-30 10:29:42,265:INFO:              mlflow: 3.8.1
2026-01-30 10:29:42,266:INFO:              gradio: 6.3.0
2026-01-30 10:29:42,266:INFO:             fastapi: 0.128.0
2026-01-30 10:29:42,266:INFO:             uvicorn: 0.40.0
2026-01-30 10:29:42,266:INFO:              m2cgen: 0.10.0
2026-01-30 10:29:42,266:INFO:           evidently: 0.4.40
2026-01-30 10:29:42,266:INFO:               fugue: 0.8.7
2026-01-30 10:29:42,266:INFO:           streamlit: Not installed
2026-01-30 10:29:42,266:INFO:             prophet: Not installed
2026-01-30 10:29:42,266:INFO:None
2026-01-30 10:29:42,266:INFO:Set up data.
2026-01-30 10:29:42,413:INFO:Set up folding strategy.
2026-01-30 10:29:42,413:INFO:Set up train/test split.
2026-01-30 10:29:42,631:INFO:Set up index.
2026-01-30 10:29:42,645:INFO:Assigning column types.
2026-01-30 10:29:42,800:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2026-01-30 10:29:42,830:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 10:29:42,830:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:29:42,849:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:29:42,849:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:29:42,882:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2026-01-30 10:29:42,882:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:29:42,906:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:29:42,906:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:29:42,906:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2026-01-30 10:29:42,944:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:29:42,961:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:29:42,961:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:29:43,000:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2026-01-30 10:29:43,022:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:29:43,022:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:29:43,024:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2026-01-30 10:29:43,078:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:29:43,078:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:29:43,144:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:29:43,144:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:29:43,145:INFO:Preparing preprocessing pipeline...
2026-01-30 10:29:43,177:INFO:Set up simple imputation.
2026-01-30 10:29:43,177:INFO:Set up feature normalization.
2026-01-30 10:29:43,473:INFO:Finished creating preprocessing pipeline.
2026-01-30 10:29:43,476:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'PAID_AMOUNT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdina...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2026-01-30 10:29:43,477:INFO:Creating final display dataframe.
2026-01-30 10:29:44,132:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target            target
2                   Target type            Binary
3           Original data shape      (482669, 28)
4        Transformed data shape      (482669, 28)
5   Transformed train set shape      (337868, 28)
6    Transformed test set shape      (144801, 28)
7              Numeric features                24
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                 3
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              16e5
2026-01-30 10:29:44,178:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:29:44,178:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:29:44,232:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2026-01-30 10:29:44,232:INFO:Soft dependency imported: catboost: 1.2.8
2026-01-30 10:29:44,232:INFO:setup() successfully completed in 1.99s...............
2026-01-30 10:29:44,232:INFO:Initializing compare_models()
2026-01-30 10:29:44,232:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, include=['lr', 'dt', 'rf', 'lightgbm'], exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, 'include': ['lr', 'dt', 'rf', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2026-01-30 10:29:44,232:INFO:Checking exceptions
2026-01-30 10:29:44,365:INFO:Preparing display monitor
2026-01-30 10:29:44,378:INFO:Initializing Logistic Regression
2026-01-30 10:29:44,378:INFO:Total runtime is 0.0 minutes
2026-01-30 10:29:44,378:INFO:SubProcess create_model() called ==================================
2026-01-30 10:29:44,378:INFO:Initializing create_model()
2026-01-30 10:29:44,378:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A053B26C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:29:44,378:INFO:Checking exceptions
2026-01-30 10:29:44,378:INFO:Importing libraries
2026-01-30 10:29:44,378:INFO:Copying training dataset
2026-01-30 10:29:44,595:INFO:Defining folds
2026-01-30 10:29:44,607:INFO:Declaring metric variables
2026-01-30 10:29:44,607:INFO:Importing untrained model
2026-01-30 10:29:44,610:INFO:Logistic Regression Imported successfully
2026-01-30 10:29:44,610:INFO:Starting cross validation
2026-01-30 10:29:44,611:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:29:48,600:INFO:Calculating mean and std
2026-01-30 10:29:48,602:INFO:Creating metrics dataframe
2026-01-30 10:29:48,606:INFO:Uploading results into container
2026-01-30 10:29:48,607:INFO:Uploading model into container now
2026-01-30 10:29:48,608:INFO:_master_model_container: 1
2026-01-30 10:29:48,608:INFO:_display_container: 2
2026-01-30 10:29:48,609:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2026-01-30 10:29:48,610:INFO:create_model() successfully completed......................................
2026-01-30 10:29:48,839:INFO:SubProcess create_model() end ==================================
2026-01-30 10:29:48,839:INFO:Creating metrics dataframe
2026-01-30 10:29:48,841:INFO:Initializing Decision Tree Classifier
2026-01-30 10:29:48,841:INFO:Total runtime is 0.07438475290934245 minutes
2026-01-30 10:29:48,841:INFO:SubProcess create_model() called ==================================
2026-01-30 10:29:48,841:INFO:Initializing create_model()
2026-01-30 10:29:48,843:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A053B26C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:29:48,843:INFO:Checking exceptions
2026-01-30 10:29:48,843:INFO:Importing libraries
2026-01-30 10:29:48,843:INFO:Copying training dataset
2026-01-30 10:29:49,049:INFO:Defining folds
2026-01-30 10:29:49,050:INFO:Declaring metric variables
2026-01-30 10:29:49,050:INFO:Importing untrained model
2026-01-30 10:29:49,051:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:29:49,051:INFO:Starting cross validation
2026-01-30 10:29:49,052:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:29:53,220:INFO:Calculating mean and std
2026-01-30 10:29:53,220:INFO:Creating metrics dataframe
2026-01-30 10:29:53,220:INFO:Uploading results into container
2026-01-30 10:29:53,230:INFO:Uploading model into container now
2026-01-30 10:29:53,230:INFO:_master_model_container: 2
2026-01-30 10:29:53,230:INFO:_display_container: 2
2026-01-30 10:29:53,230:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:29:53,230:INFO:create_model() successfully completed......................................
2026-01-30 10:29:53,397:INFO:SubProcess create_model() end ==================================
2026-01-30 10:29:53,397:INFO:Creating metrics dataframe
2026-01-30 10:29:53,397:INFO:Initializing Random Forest Classifier
2026-01-30 10:29:53,397:INFO:Total runtime is 0.15030624866485595 minutes
2026-01-30 10:29:53,397:INFO:SubProcess create_model() called ==================================
2026-01-30 10:29:53,412:INFO:Initializing create_model()
2026-01-30 10:29:53,412:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A053B26C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:29:53,412:INFO:Checking exceptions
2026-01-30 10:29:53,412:INFO:Importing libraries
2026-01-30 10:29:53,412:INFO:Copying training dataset
2026-01-30 10:29:53,640:INFO:Defining folds
2026-01-30 10:29:53,641:INFO:Declaring metric variables
2026-01-30 10:29:53,641:INFO:Importing untrained model
2026-01-30 10:29:53,642:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:29:53,642:INFO:Starting cross validation
2026-01-30 10:29:53,643:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:30:15,330:INFO:Calculating mean and std
2026-01-30 10:30:15,332:INFO:Creating metrics dataframe
2026-01-30 10:30:15,333:INFO:Uploading results into container
2026-01-30 10:30:15,334:INFO:Uploading model into container now
2026-01-30 10:30:15,334:INFO:_master_model_container: 3
2026-01-30 10:30:15,334:INFO:_display_container: 2
2026-01-30 10:30:15,335:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:30:15,335:INFO:create_model() successfully completed......................................
2026-01-30 10:30:15,528:INFO:SubProcess create_model() end ==================================
2026-01-30 10:30:15,528:INFO:Creating metrics dataframe
2026-01-30 10:30:15,530:INFO:Initializing Light Gradient Boosting Machine
2026-01-30 10:30:15,531:INFO:Total runtime is 0.5191914717356364 minutes
2026-01-30 10:30:15,531:INFO:SubProcess create_model() called ==================================
2026-01-30 10:30:15,531:INFO:Initializing create_model()
2026-01-30 10:30:15,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A053B26C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:30:15,531:INFO:Checking exceptions
2026-01-30 10:30:15,531:INFO:Importing libraries
2026-01-30 10:30:15,531:INFO:Copying training dataset
2026-01-30 10:30:15,731:INFO:Defining folds
2026-01-30 10:30:15,731:INFO:Declaring metric variables
2026-01-30 10:30:15,731:INFO:Importing untrained model
2026-01-30 10:30:15,731:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:30:15,731:INFO:Starting cross validation
2026-01-30 10:30:15,731:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:30:20,756:INFO:Calculating mean and std
2026-01-30 10:30:20,760:INFO:Creating metrics dataframe
2026-01-30 10:30:20,762:INFO:Uploading results into container
2026-01-30 10:30:20,762:INFO:Uploading model into container now
2026-01-30 10:30:20,764:INFO:_master_model_container: 4
2026-01-30 10:30:20,764:INFO:_display_container: 2
2026-01-30 10:30:20,764:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:30:20,764:INFO:create_model() successfully completed......................................
2026-01-30 10:30:20,931:INFO:SubProcess create_model() end ==================================
2026-01-30 10:30:20,931:INFO:Creating metrics dataframe
2026-01-30 10:30:20,931:WARNING:c:\Users\0021755\AppData\Local\anaconda3\envs\my_python311_env\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.

2026-01-30 10:30:20,931:INFO:Initializing create_model()
2026-01-30 10:30:20,931:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:30:20,931:INFO:Checking exceptions
2026-01-30 10:30:20,931:INFO:Importing libraries
2026-01-30 10:30:20,931:INFO:Copying training dataset
2026-01-30 10:30:21,158:INFO:Defining folds
2026-01-30 10:30:21,158:INFO:Declaring metric variables
2026-01-30 10:30:21,158:INFO:Importing untrained model
2026-01-30 10:30:21,159:INFO:Declaring custom model
2026-01-30 10:30:21,159:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:30:21,160:INFO:Cross validation set to False
2026-01-30 10:30:21,160:INFO:Fitting Model
2026-01-30 10:30:31,944:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:30:31,944:INFO:create_model() successfully completed......................................
2026-01-30 10:30:32,131:INFO:Initializing create_model()
2026-01-30 10:30:32,131:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:30:32,131:INFO:Checking exceptions
2026-01-30 10:30:32,131:INFO:Importing libraries
2026-01-30 10:30:32,131:INFO:Copying training dataset
2026-01-30 10:30:32,327:INFO:Defining folds
2026-01-30 10:30:32,327:INFO:Declaring metric variables
2026-01-30 10:30:32,327:INFO:Importing untrained model
2026-01-30 10:30:32,327:INFO:Declaring custom model
2026-01-30 10:30:32,327:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:30:32,327:INFO:Cross validation set to False
2026-01-30 10:30:32,327:INFO:Fitting Model
2026-01-30 10:30:33,228:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 10:30:33,294:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016880 seconds.
2026-01-30 10:30:33,294:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 10:30:33,294:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 10:30:33,295:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 10:30:33,296:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 10:30:33,298:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 10:30:33,299:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 10:30:34,233:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:30:34,233:INFO:create_model() successfully completed......................................
2026-01-30 10:30:34,476:INFO:Initializing create_model()
2026-01-30 10:30:34,476:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:30:34,476:INFO:Checking exceptions
2026-01-30 10:30:34,477:INFO:Importing libraries
2026-01-30 10:30:34,477:INFO:Copying training dataset
2026-01-30 10:30:34,677:INFO:Defining folds
2026-01-30 10:30:34,677:INFO:Declaring metric variables
2026-01-30 10:30:34,677:INFO:Importing untrained model
2026-01-30 10:30:34,677:INFO:Declaring custom model
2026-01-30 10:30:34,693:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:30:34,693:INFO:Cross validation set to False
2026-01-30 10:30:34,693:INFO:Fitting Model
2026-01-30 10:30:37,611:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:30:37,611:INFO:create_model() successfully completed......................................
2026-01-30 10:30:37,814:INFO:_master_model_container: 4
2026-01-30 10:30:37,814:INFO:_display_container: 2
2026-01-30 10:30:37,815:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')]
2026-01-30 10:30:37,815:INFO:compare_models() successfully completed......................................
2026-01-30 10:30:37,836:INFO:Initializing tune_model()
2026-01-30 10:30:37,836:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 10:30:37,836:INFO:Checking exceptions
2026-01-30 10:30:37,932:INFO:Copying training dataset
2026-01-30 10:30:38,088:INFO:Checking base model
2026-01-30 10:30:38,088:INFO:Base model : Random Forest Classifier
2026-01-30 10:30:38,089:INFO:Declaring metric variables
2026-01-30 10:30:38,089:INFO:Defining Hyperparameters
2026-01-30 10:30:38,295:INFO:Tuning with n_jobs=-1
2026-01-30 10:30:38,295:INFO:Initializing RandomizedSearchCV
2026-01-30 10:33:26,929:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2026-01-30 10:33:26,930:INFO:Hyperparameter search completed
2026-01-30 10:33:26,931:INFO:SubProcess create_model() called ==================================
2026-01-30 10:33:26,932:INFO:Initializing create_model()
2026-01-30 10:33:26,932:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A04D500ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'entropy', 'class_weight': {}, 'bootstrap': True})
2026-01-30 10:33:26,932:INFO:Checking exceptions
2026-01-30 10:33:26,932:INFO:Importing libraries
2026-01-30 10:33:26,932:INFO:Copying training dataset
2026-01-30 10:33:27,310:INFO:Defining folds
2026-01-30 10:33:27,311:INFO:Declaring metric variables
2026-01-30 10:33:27,311:INFO:Importing untrained model
2026-01-30 10:33:27,311:INFO:Declaring custom model
2026-01-30 10:33:27,313:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:33:27,313:INFO:Starting cross validation
2026-01-30 10:33:27,314:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:33:59,581:INFO:Calculating mean and std
2026-01-30 10:33:59,582:INFO:Creating metrics dataframe
2026-01-30 10:33:59,585:INFO:Finalizing model
2026-01-30 10:34:16,224:INFO:Uploading results into container
2026-01-30 10:34:16,225:INFO:Uploading model into container now
2026-01-30 10:34:16,225:INFO:_master_model_container: 5
2026-01-30 10:34:16,226:INFO:_display_container: 3
2026-01-30 10:34:16,227:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:34:16,227:INFO:create_model() successfully completed......................................
2026-01-30 10:34:16,435:INFO:SubProcess create_model() end ==================================
2026-01-30 10:34:16,435:INFO:choose_better activated
2026-01-30 10:34:16,436:INFO:SubProcess create_model() called ==================================
2026-01-30 10:34:16,436:INFO:Initializing create_model()
2026-01-30 10:34:16,436:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:34:16,436:INFO:Checking exceptions
2026-01-30 10:34:16,437:INFO:Importing libraries
2026-01-30 10:34:16,437:INFO:Copying training dataset
2026-01-30 10:34:16,707:INFO:Defining folds
2026-01-30 10:34:16,707:INFO:Declaring metric variables
2026-01-30 10:34:16,707:INFO:Importing untrained model
2026-01-30 10:34:16,707:INFO:Declaring custom model
2026-01-30 10:34:16,708:INFO:Random Forest Classifier Imported successfully
2026-01-30 10:34:16,708:INFO:Starting cross validation
2026-01-30 10:34:16,709:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:34:37,749:INFO:Calculating mean and std
2026-01-30 10:34:37,750:INFO:Creating metrics dataframe
2026-01-30 10:34:37,752:INFO:Finalizing model
2026-01-30 10:34:47,818:INFO:Uploading results into container
2026-01-30 10:34:47,819:INFO:Uploading model into container now
2026-01-30 10:34:47,819:INFO:_master_model_container: 6
2026-01-30 10:34:47,819:INFO:_display_container: 4
2026-01-30 10:34:47,820:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:34:47,820:INFO:create_model() successfully completed......................................
2026-01-30 10:34:48,011:INFO:SubProcess create_model() end ==================================
2026-01-30 10:34:48,012:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9985
2026-01-30 10:34:48,012:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='entropy', max_depth=9, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) result for AUC is 0.9894
2026-01-30 10:34:48,013:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False) is best model
2026-01-30 10:34:48,013:INFO:choose_better completed
2026-01-30 10:34:48,013:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 10:34:48,015:INFO:_master_model_container: 6
2026-01-30 10:34:48,015:INFO:_display_container: 3
2026-01-30 10:34:48,016:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2026-01-30 10:34:48,016:INFO:tune_model() successfully completed......................................
2026-01-30 10:34:48,194:INFO:Initializing tune_model()
2026-01-30 10:34:48,194:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 10:34:48,194:INFO:Checking exceptions
2026-01-30 10:34:48,280:INFO:Copying training dataset
2026-01-30 10:34:48,422:INFO:Checking base model
2026-01-30 10:34:48,423:INFO:Base model : Light Gradient Boosting Machine
2026-01-30 10:34:48,424:INFO:Declaring metric variables
2026-01-30 10:34:48,424:INFO:Defining Hyperparameters
2026-01-30 10:34:48,595:INFO:Tuning with n_jobs=-1
2026-01-30 10:34:48,595:INFO:Initializing RandomizedSearchCV
2026-01-30 10:35:31,506:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2026-01-30 10:35:31,508:INFO:Hyperparameter search completed
2026-01-30 10:35:31,509:INFO:SubProcess create_model() called ==================================
2026-01-30 10:35:31,511:INFO:Initializing create_model()
2026-01-30 10:35:31,511:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03D5BDD90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2026-01-30 10:35:31,511:INFO:Checking exceptions
2026-01-30 10:35:31,512:INFO:Importing libraries
2026-01-30 10:35:31,512:INFO:Copying training dataset
2026-01-30 10:35:31,895:INFO:Defining folds
2026-01-30 10:35:31,895:INFO:Declaring metric variables
2026-01-30 10:35:31,896:INFO:Importing untrained model
2026-01-30 10:35:31,897:INFO:Declaring custom model
2026-01-30 10:35:31,898:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:35:31,898:INFO:Starting cross validation
2026-01-30 10:35:31,899:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:35:42,866:INFO:Calculating mean and std
2026-01-30 10:35:42,867:INFO:Creating metrics dataframe
2026-01-30 10:35:42,869:INFO:Finalizing model
2026-01-30 10:35:43,596:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 10:35:43,596:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 10:35:43,596:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 10:35:43,809:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2026-01-30 10:35:43,809:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2026-01-30 10:35:43,809:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2026-01-30 10:35:43,810:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 10:35:43,858:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012089 seconds.
2026-01-30 10:35:43,859:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 10:35:43,859:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 10:35:43,859:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 10:35:43,860:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 10:35:43,865:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 10:35:43,865:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 10:35:47,739:INFO:Uploading results into container
2026-01-30 10:35:47,741:INFO:Uploading model into container now
2026-01-30 10:35:47,742:INFO:_master_model_container: 7
2026-01-30 10:35:47,742:INFO:_display_container: 4
2026-01-30 10:35:47,744:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:35:47,744:INFO:create_model() successfully completed......................................
2026-01-30 10:35:47,984:INFO:SubProcess create_model() end ==================================
2026-01-30 10:35:47,984:INFO:choose_better activated
2026-01-30 10:35:47,985:INFO:SubProcess create_model() called ==================================
2026-01-30 10:35:47,987:INFO:Initializing create_model()
2026-01-30 10:35:47,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:35:47,987:INFO:Checking exceptions
2026-01-30 10:35:47,988:INFO:Importing libraries
2026-01-30 10:35:47,988:INFO:Copying training dataset
2026-01-30 10:35:48,217:INFO:Defining folds
2026-01-30 10:35:48,217:INFO:Declaring metric variables
2026-01-30 10:35:48,218:INFO:Importing untrained model
2026-01-30 10:35:48,218:INFO:Declaring custom model
2026-01-30 10:35:48,218:INFO:Light Gradient Boosting Machine Imported successfully
2026-01-30 10:35:48,219:INFO:Starting cross validation
2026-01-30 10:35:48,219:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:35:53,108:INFO:Calculating mean and std
2026-01-30 10:35:53,109:INFO:Creating metrics dataframe
2026-01-30 10:35:53,113:INFO:Finalizing model
2026-01-30 10:35:54,065:INFO:[LightGBM] [Info] Number of positive: 146121, number of negative: 191747
2026-01-30 10:35:54,127:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011123 seconds.
2026-01-30 10:35:54,128:INFO:You can set `force_row_wise=true` to remove the overhead.
2026-01-30 10:35:54,128:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2026-01-30 10:35:54,128:INFO:[LightGBM] [Info] Total Bins 3123
2026-01-30 10:35:54,129:INFO:[LightGBM] [Info] Number of data points in the train set: 337868, number of used features: 27
2026-01-30 10:35:54,131:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.432480 -> initscore=-0.271742
2026-01-30 10:35:54,131:INFO:[LightGBM] [Info] Start training from score -0.271742
2026-01-30 10:35:55,217:INFO:Uploading results into container
2026-01-30 10:35:55,218:INFO:Uploading model into container now
2026-01-30 10:35:55,218:INFO:_master_model_container: 8
2026-01-30 10:35:55,218:INFO:_display_container: 5
2026-01-30 10:35:55,220:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:35:55,220:INFO:create_model() successfully completed......................................
2026-01-30 10:35:55,461:INFO:SubProcess create_model() end ==================================
2026-01-30 10:35:55,462:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9945
2026-01-30 10:35:55,462:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.9987
2026-01-30 10:35:55,463:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2026-01-30 10:35:55,463:INFO:choose_better completed
2026-01-30 10:35:55,465:INFO:_master_model_container: 8
2026-01-30 10:35:55,466:INFO:_display_container: 4
2026-01-30 10:35:55,467:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2026-01-30 10:35:55,467:INFO:tune_model() successfully completed......................................
2026-01-30 10:35:55,648:INFO:Initializing tune_model()
2026-01-30 10:35:55,649:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2026-01-30 10:35:55,649:INFO:Checking exceptions
2026-01-30 10:35:55,731:INFO:Copying training dataset
2026-01-30 10:35:55,861:INFO:Checking base model
2026-01-30 10:35:55,861:INFO:Base model : Decision Tree Classifier
2026-01-30 10:35:55,861:INFO:Declaring metric variables
2026-01-30 10:35:55,861:INFO:Defining Hyperparameters
2026-01-30 10:35:56,031:INFO:Tuning with n_jobs=-1
2026-01-30 10:35:56,032:INFO:Initializing RandomizedSearchCV
2026-01-30 10:36:04,537:INFO:best_params: {'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 15, 'actual_estimator__criterion': 'gini'}
2026-01-30 10:36:04,538:INFO:Hyperparameter search completed
2026-01-30 10:36:04,539:INFO:SubProcess create_model() called ==================================
2026-01-30 10:36:04,540:INFO:Initializing create_model()
2026-01-30 10:36:04,541:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A03CFFBBD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 2, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0001, 'max_features': 1.0, 'max_depth': 15, 'criterion': 'gini'})
2026-01-30 10:36:04,541:INFO:Checking exceptions
2026-01-30 10:36:04,541:INFO:Importing libraries
2026-01-30 10:36:04,541:INFO:Copying training dataset
2026-01-30 10:36:04,768:INFO:Defining folds
2026-01-30 10:36:04,768:INFO:Declaring metric variables
2026-01-30 10:36:04,768:INFO:Importing untrained model
2026-01-30 10:36:04,769:INFO:Declaring custom model
2026-01-30 10:36:04,769:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:36:04,769:INFO:Starting cross validation
2026-01-30 10:36:04,770:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:36:07,925:INFO:Calculating mean and std
2026-01-30 10:36:07,926:INFO:Creating metrics dataframe
2026-01-30 10:36:07,927:INFO:Finalizing model
2026-01-30 10:36:09,906:INFO:Uploading results into container
2026-01-30 10:36:09,907:INFO:Uploading model into container now
2026-01-30 10:36:09,908:INFO:_master_model_container: 9
2026-01-30 10:36:09,908:INFO:_display_container: 5
2026-01-30 10:36:09,909:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:36:09,909:INFO:create_model() successfully completed......................................
2026-01-30 10:36:10,078:INFO:SubProcess create_model() end ==================================
2026-01-30 10:36:10,079:INFO:choose_better activated
2026-01-30 10:36:10,079:INFO:SubProcess create_model() called ==================================
2026-01-30 10:36:10,079:INFO:Initializing create_model()
2026-01-30 10:36:10,079:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), fold=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2026-01-30 10:36:10,079:INFO:Checking exceptions
2026-01-30 10:36:10,080:INFO:Importing libraries
2026-01-30 10:36:10,080:INFO:Copying training dataset
2026-01-30 10:36:10,320:INFO:Defining folds
2026-01-30 10:36:10,320:INFO:Declaring metric variables
2026-01-30 10:36:10,320:INFO:Importing untrained model
2026-01-30 10:36:10,320:INFO:Declaring custom model
2026-01-30 10:36:10,321:INFO:Decision Tree Classifier Imported successfully
2026-01-30 10:36:10,321:INFO:Starting cross validation
2026-01-30 10:36:10,322:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1
2026-01-30 10:36:14,511:INFO:Calculating mean and std
2026-01-30 10:36:14,513:INFO:Creating metrics dataframe
2026-01-30 10:36:14,515:INFO:Finalizing model
2026-01-30 10:36:17,699:INFO:Uploading results into container
2026-01-30 10:36:17,699:INFO:Uploading model into container now
2026-01-30 10:36:17,700:INFO:_master_model_container: 10
2026-01-30 10:36:17,700:INFO:_display_container: 6
2026-01-30 10:36:17,700:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:36:17,700:INFO:create_model() successfully completed......................................
2026-01-30 10:36:17,869:INFO:SubProcess create_model() end ==================================
2026-01-30 10:36:17,869:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.989
2026-01-30 10:36:17,870:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=15, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=6,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') result for AUC is 0.9826
2026-01-30 10:36:17,870:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best') is best model
2026-01-30 10:36:17,870:INFO:choose_better completed
2026-01-30 10:36:17,870:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2026-01-30 10:36:17,873:INFO:_master_model_container: 10
2026-01-30 10:36:17,873:INFO:_display_container: 5
2026-01-30 10:36:17,873:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2026-01-30 10:36:17,873:INFO:tune_model() successfully completed......................................
2026-01-30 10:36:18,059:INFO:Initializing predict_model()
2026-01-30 10:36:18,060:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A03C59F240>)
2026-01-30 10:36:18,060:INFO:Checking exceptions
2026-01-30 10:36:18,060:INFO:Preloading libraries
2026-01-30 10:36:18,060:INFO:Set up data.
2026-01-30 10:36:18,072:INFO:Set up index.
2026-01-30 10:36:18,475:INFO:Initializing predict_model()
2026-01-30 10:36:18,475:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.5, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=250, n_jobs=-1, num_leaves=30, objective=None,
               random_state=42, reg_alpha=0.7, reg_lambda=2, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A06E850F40>)
2026-01-30 10:36:18,475:INFO:Checking exceptions
2026-01-30 10:36:18,476:INFO:Preloading libraries
2026-01-30 10:36:18,476:INFO:Set up data.
2026-01-30 10:36:18,489:INFO:Set up index.
2026-01-30 10:36:18,913:INFO:Initializing predict_model()
2026-01-30 10:36:18,915:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A03D1FF1A0>)
2026-01-30 10:36:18,915:INFO:Checking exceptions
2026-01-30 10:36:18,915:INFO:Preloading libraries
2026-01-30 10:36:18,915:INFO:Set up data.
2026-01-30 10:36:18,925:INFO:Set up index.
2026-01-30 10:36:19,330:INFO:Initializing plot_model()
2026-01-30 10:36:19,330:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 10:36:19,330:INFO:Checking exceptions
2026-01-30 10:36:19,448:INFO:Preloading libraries
2026-01-30 10:36:19,528:INFO:Copying training dataset
2026-01-30 10:36:19,528:INFO:Plot type: feature
2026-01-30 10:36:19,529:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 10:36:19,907:INFO:Visual Rendered Successfully
2026-01-30 10:36:20,081:INFO:plot_model() successfully completed......................................
2026-01-30 10:36:20,092:INFO:Initializing plot_model()
2026-01-30 10:36:20,093:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A03C48F790>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), plot=feature_all, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2026-01-30 10:36:20,093:INFO:Checking exceptions
2026-01-30 10:36:20,220:INFO:Preloading libraries
2026-01-30 10:36:20,282:INFO:Copying training dataset
2026-01-30 10:36:20,282:INFO:Plot type: feature_all
2026-01-30 10:36:20,502:WARNING:No coef_ found. Trying feature_importances_
2026-01-30 10:36:20,982:INFO:Visual Rendered Successfully
2026-01-30 10:36:21,156:INFO:plot_model() successfully completed......................................
2026-01-30 10:36:21,171:INFO:Initializing save_model()
2026-01-30 10:36:21,171:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), model_name=..\datos\04. Modelos\modelo_final_explicable, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\0021755\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'PAID_AMOUNT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdina...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2026-01-30 10:36:21,171:INFO:Adding model into prep_pipe
2026-01-30 10:36:21,288:INFO:..\datos\04. Modelos\modelo_final_explicable.pkl saved in current working directory
2026-01-30 10:36:21,295:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['NU_NOTA_MEDIA_ADMISION',
                                             'NU_NOTA_MEDIA_1_BACH__PC',
                                             'NU_RESULTADO_ADMISION_PUNTOS',
                                             'PAID_AMOUNT', 'CU_IMPORTE_TOTAL',
                                             'NU_PREFERENCIA',
                                             'PL_SITUACION_SOCIO_ECONOMICA',
                                             'FO_rentaFam_ges__c',
                                             'CU_precioOrdinario_def__c',
                                             'CU_precioAplicado_def__c',
                                             'PO...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=42, verbose=0,
                                        warm_start=False))],
         verbose=False)
2026-01-30 10:36:21,296:INFO:save_model() successfully completed......................................
