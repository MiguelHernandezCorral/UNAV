{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Uni√≥n y Limpieza de datos del Dataset  \n",
    "\n",
    "---\n",
    "\n",
    "**Objetivo del Notebook**  \n",
    "Limpieza de datos, columnas innecesarias y valores nulos/blancos \n",
    "\n",
    "**Contexto del an√°lisis**  \n",
    "- Dataset de muestra proporcionado + csv proporcionado unido en un √∫nico excel dataset\n",
    "- Enfoque en aprendizaje, validaci√≥n del pipeline y comprensi√≥n del proceso\n",
    "\n",
    "**Valor devuelto**  \n",
    "- Copia del Dataset de muestra proporcionado completamente limpio y √∫til \n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SCRIPT ¬∑ DATASET DE TRATAMIENTO DEFINITIVO FINAL\n",
    "# ============================================================\n",
    "# Objetivo:\n",
    "#   - Construir el dataset final de modelizaci√≥n a partir de Salesforce\n",
    "#   - Integrar informaci√≥n acad√©mica, econ√≥mica, actividades y tiempos\n",
    "#   - Controlar leakage de informaci√≥n futura\n",
    "#   - Dejar el dataset listo para an√°lisis y ML\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import crear_target, eliminar_columnas_na, calcular_tiempos_etapas, integrar_actividades_progresivo_por_curso, normalizar_plazo\n",
    "\n",
    "# Funciones auxiliares definidas en utils.py\n",
    "# - crear_target: construye la variable objetivo a partir del historial de etapas\n",
    "# - eliminar_columnas_na: elimina columnas con exceso de valores nulos\n",
    "# - calcular_tiempos_etapas: calcula duraci√≥n en cada etapa del funnel\n",
    "# - integrar_actividades_progresivo_por_curso: agrega actividades acumuladas\n",
    "\n",
    "# ============================================================\n",
    "# 1Ô∏è‚É£ CARGA DE DATOS\n",
    "# ============================================================\n",
    "# Se carga el Excel completo de Salesforce\n",
    "# Cada hoja corresponde a una entidad distinta\n",
    "# ============================================================\n",
    "\n",
    "ruta_excel = r\"..\\datos\\01. Datos originales\\DataSET_SF - V2.xlsx\"\n",
    "dfs = pd.read_excel(ruta_excel, sheet_name=None)\n",
    "\n",
    "# Asignar cada hoja a un dataframe independiente\n",
    "# El orden debe coincidir con el Excel original\n",
    "oportunidad = list(dfs.values())[0]\n",
    "cuenta = list(dfs.values())[1]\n",
    "ecb = list(dfs.values())[2]\n",
    "solicitud_ban = list(dfs.values())[3]\n",
    "casos = list(dfs.values())[4]\n",
    "correos = list(dfs.values())[5]\n",
    "historial_actividad = list(dfs.values())[6]\n",
    "historial_etapas = list(dfs.values())[7]\n",
    "\n",
    "# ============================================================\n",
    "# 2Ô∏è‚É£ LIMPIEZA INICIAL DE NAS Y COLUMNAS\n",
    "# ============================================================\n",
    "# Se eliminan columnas con un porcentaje de NA superior al umbral\n",
    "# Esto reduce ruido y dimensionalidad desde el inicio\n",
    "# ============================================================\n",
    "\n",
    "def eliminar_columnas_na(df, umbral=0.9):\n",
    "    \"\"\"Elimina columnas con m√°s de un umbral de valores NA\"\"\"\n",
    "    return df.loc[:, df.isna().mean() < umbral]\n",
    "\n",
    "\n",
    "# Limpieza gen√©rica (no modifica los dataframes originales)\n",
    "for df in [oportunidad, cuenta, ecb, solicitud_ban, casos, correos, historial_actividad, historial_etapas]:\n",
    "    df = eliminar_columnas_na(df)\n",
    "\n",
    "\n",
    "# Limpieza efectiva sobre los dataframes clave\n",
    "oportunidad = eliminar_columnas_na(oportunidad)\n",
    "cuenta = eliminar_columnas_na(cuenta)\n",
    "ecb = eliminar_columnas_na(ecb)\n",
    "\n",
    "# ============================================================\n",
    "# 3Ô∏è‚É£ CREACI√ìN DEL TARGET\n",
    "# ============================================================\n",
    "# Se construye la variable objetivo (target) usando el historial de etapas\n",
    "# ============================================================\n",
    "\n",
    "oportunidad = crear_target(oportunidad, historial_etapas)\n",
    "\n",
    "\n",
    "# Uni√≥n de oportunidad con datos de cuenta/persona\n",
    "# Se hace LEFT JOIN para no perder oportunidades\n",
    "\n",
    "df_unido = pd.merge(\n",
    "    oportunidad, \n",
    "    cuenta, \n",
    "    left_on='ACCOUNTID', \n",
    "    right_on='ID18', \n",
    "    how='left',\n",
    "    suffixes=('', '_cuenta')\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4Ô∏è‚É£ CONSTRUCCI√ìN VARIABLES DERIVADAS\n",
    "# ============================================================\n",
    "# Se crean variables explicativas a partir de campos originales\n",
    "# ============================================================\n",
    "\n",
    "# Normalizaci√≥n del plazo de admisi√≥n\n",
    "# Se agrupan valores heterog√©neos en categor√≠as consistentes\n",
    "def normalizar_plazo(x):\n",
    "    if pd.isna(x): return \"Rolling\"\n",
    "    x = str(x).strip().lower()\n",
    "    if \"dic\" in x: return \"Diciembre\"\n",
    "    if \"mar\" in x: return \"Marzo\"\n",
    "    return \"Otros\"\n",
    "\n",
    "df_unido['PLAZO_ADMISION_LIMPIO'] = df_unido['PL_PLAZO_ADMISION'].apply(normalizar_plazo)\n",
    "\n",
    "# Uni√≥n con informaci√≥n econ√≥mica (ECB)\n",
    "# Se incorporan precios y renta familiar\n",
    "ecb_vars = ['LK_oportunidad__c', 'FO_rentaFam_ges__c', 'CU_precioOrdinario_def__c', 'CU_precioAplicado_def__c']\n",
    "df_definitivo = pd.merge(\n",
    "    df_unido,\n",
    "    ecb[ecb_vars],\n",
    "    left_on='ID',\n",
    "    right_on='LK_oportunidad__c',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "\n",
    "## C√°lculo del porcentaje pagado final\n",
    "df_definitivo['PORCENTAJE_PAGADO_FINAL'] = (\n",
    "    df_definitivo['CU_precioAplicado_def__c'] \n",
    "    / df_definitivo['CU_precioOrdinario_def__c'] * 100\n",
    ")\n",
    "\n",
    "# Si el precio ordinario es 0 o negativo, el porcentaje pagado es 0\n",
    "df_definitivo.loc[\n",
    "    df_definitivo['CU_precioOrdinario_def__c'] <= 0,\n",
    "    'PORCENTAJE_PAGADO_FINAL'\n",
    "] = 0\n",
    "\n",
    "\n",
    "# Guardado intermedio (dataset de an√°lisis)\n",
    "ruta_salida = r\"..\\datos\\01. Datos originales\\dataset_analisis_final.csv\"\n",
    "df_definitivo.to_csv(ruta_salida, sep=\";\", index=False)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5Ô∏è‚É£ TIEMPO EN CADA ETAPA\n",
    "# ============================================================\n",
    "# Se calcula el tiempo pasado en cada etapa del funnel\n",
    "# ============================================================\n",
    "\n",
    "historial_etapas_tiempo = calcular_tiempos_etapas(historial_etapas)\n",
    "df_definitivo = historial_etapas_tiempo.merge(df_definitivo, left_on='LK_Oportunidad__c', right_on='ID', how='left')\n",
    "\n",
    "# ============================================================\n",
    "# 6Ô∏è‚É£ HISTORIAL DE ACTIVIDADES\n",
    "# ============================================================\n",
    "# Se integran actividades acumuladas por curso\n",
    "# Evita usar informaci√≥n futura respecto a la etapa\n",
    "# ============================================================\n",
    "\n",
    "df_definitivo = integrar_actividades_progresivo_por_curso(df_definitivo, historial_actividad)\n",
    "\n",
    "# ============================================================\n",
    "# 7Ô∏è‚É£ CONTROL DE INFORMACI√ìN FUTURA (LEAKAGE)\n",
    "# ============================================================\n",
    "# Se eliminan variables econ√≥micas si aparecen en etapas tempranas\n",
    "# ============================================================\n",
    "\n",
    "etapas_pago = ['Solicitud', 'Pruebas', 'Admisi√≥n acad√©mica']\n",
    "vars_pago = ['PAID_AMOUNT','MINIMUMPAYMENTPAYED','CU_precioAplicado_def__c','PORCENTAJE_PAGADO_FINAL']\n",
    "vars_pago = [v for v in vars_pago if v in df_definitivo.columns]\n",
    "\n",
    "mask_futuro = (df_definitivo['PL_Etapa__c'].isin(etapas_pago)) & (df_definitivo[vars_pago].notna().any(axis=1))\n",
    "df_definitivo.loc[mask_futuro, vars_pago] = np.nan\n",
    "\n",
    "# ============================================================\n",
    "# 8Ô∏è‚É£ SELECCI√ìN VARIABLES FINALES\n",
    "# ============================================================\n",
    "# Se define expl√≠citamente el conjunto final de variables\n",
    "# ============================================================\n",
    "columnas_seleccionadas = [\n",
    "    'ACCOUNTID', 'ID','ID18__PC', 'target', 'desmatriculado', 'PL_CURSO_ACADEMICO', 'CH_NACIONAL',\n",
    "    'NU_NOTA_MEDIA_ADMISION', 'NU_NOTA_MEDIA_1_BACH__PC', 'CH_PRUEBAS_CALIFICADAS', \n",
    "    'NU_RESULTADO_ADMISION_PUNTOS', 'PL_RESOLUCION_DEFINITIVA', 'TITULACION', 'CENTROENSENANZA',\n",
    "    'MINIMUMPAYMENTPAYED', 'PAID_AMOUNT', 'PAID_PERCENT', 'CH_PAGO_SUPERIOR', \n",
    "    'CH_MATRICULA_SUJETA_BECA', 'CH_AYUDA_FINANCIACION', 'CU_IMPORTE_TOTAL',\n",
    "    'CH_VISITACAMPUS__PC', 'CH_ENTREVISTA_PERSONAL__PC', 'ACC_DTT_FECHAULTIMAACTIVIDAD', \n",
    "    'NU_PREFERENCIA', 'STAGENAME', 'PL_SUBETAPA',\n",
    "    'CH_HIJO_EMPLEADO__PC', 'CH_HIJO_PROFESOR_ASOCIADO__PC', 'CH_HERMANOS_ESTUDIANDO_UNAV__P', \n",
    "    'CH_HIJO_MEDICO__PC', 'YEARPERSONBIRTHDATE', 'NAMEX', 'CH_FAMILIA_NUMEROSA__PC', \n",
    "    'PL_SITUACION_SOCIO_ECONOMICA', 'LEADSOURCE', 'PL_ORIGEN_DE_SOLICITUD', \n",
    "    'PL_PLAZO_ADMISION', 'RECORDTYPENAME','PLAZO_ADMISION_LIMPIO','FO_rentaFam_ges__c','CU_precioOrdinario_def__c',\n",
    "    'CU_precioAplicado_def__c','PORCENTAJE_PAGADO_FINAL','tiempo_etapa_dias','tiempo_entre_etapas_dias','num_asistencias_acum', 'num_solicitudes_acum',\n",
    "    'CH_ALUMNO__PC', 'CH_ESTUDIANTE__PC', 'CH_ANTIGUO_ALUMNO__PC',\n",
    "    'CH_ALUMNI__PC', 'CH_ANTIGUOALUMNO_INTERCAMBIO',\n",
    "    'CH_HIJO_ANTIGUO_ALUMNO__PC'\n",
    "]\n",
    "\n",
    "#columnas_finales = [c for c in columnas_finales if c in df_definitivo.columns]\n",
    "df_definitivo = df_definitivo[columnas_seleccionadas]\n",
    "\n",
    "# ============================================================\n",
    "# 9Ô∏è‚É£ GUARDAR DATASET TRATAMIENTO DEFINITIVO\n",
    "# ============================================================\n",
    "\n",
    "ruta_salida = r\"..\\datos\\01. Datos originales\\dataset_tratamiento_final.csv\"\n",
    "df_definitivo.to_csv(ruta_salida, sep=\";\", index=False)\n",
    "\n",
    "print(f\"‚úÖ Dataset de tratamiento definitivo guardado en: {ruta_salida}\")\n",
    "print(f\"Dimensiones: {df_definitivo.shape}\")\n",
    "df_definitivo.head()\n",
    "\n",
    "# ==============================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_python311_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
