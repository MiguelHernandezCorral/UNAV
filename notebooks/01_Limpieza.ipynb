{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Uni√≥n y Limpieza de datos del Dataset  \n",
    "\n",
    "---\n",
    "\n",
    "**Objetivo del Notebook**  \n",
    "Limpieza de datos, columnas innecesarias y valores nulos/blancos \n",
    "\n",
    "**Contexto del an√°lisis**  \n",
    "- Dataset de muestra proporcionado + csv proporcionado unido en un √∫nico excel dataset\n",
    "- Enfoque en aprendizaje, validaci√≥n del pipeline y comprensi√≥n del proceso\n",
    "\n",
    "**Valor devuelto**  \n",
    "- Copia del Dataset de muestra proporcionado completamente limpio y √∫til \n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay un total de 15470 matr√≠culas formalizadas. Un 22.03% del total de oportunidades\n",
      "Hay un total de 1495 desmatriculados. Un 9.66% del total de matriculados\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\0021755\\OneDrive - ViewNext\\proyectoUNAV\\gitUNAV\\UNAV\\notebooks\\utils.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oportunidad['target'] = oportunidad['ID'].apply(\n",
      "c:\\Users\\0021755\\OneDrive - ViewNext\\proyectoUNAV\\gitUNAV\\UNAV\\notebooks\\utils.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oportunidad['desmatriculado'] = oportunidad['ID'].apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando 536604 filas con l√≥gica de curso y progresi√≥n temporal...\n",
      "Cruzando datos por ID18__PC y Curso Acad√©mico...\n",
      "Aplicando filtro temporal progresivo...\n",
      "Agrupando resultados...\n",
      "Consolidando en el DataFrame maestro...\n",
      "‚úÖ Proceso completado.\n",
      "‚úÖ Dataset de tratamiento definitivo guardado en: ..\\datos\\01. Datos originales\\dataset_tratamiento_final.csv\n",
      "Dimensiones: (536604, 54)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACCOUNTID</th>\n",
       "      <th>ID</th>\n",
       "      <th>ID18__PC</th>\n",
       "      <th>target</th>\n",
       "      <th>desmatriculado</th>\n",
       "      <th>PL_CURSO_ACADEMICO</th>\n",
       "      <th>CH_NACIONAL</th>\n",
       "      <th>NU_NOTA_MEDIA_ADMISION</th>\n",
       "      <th>NU_NOTA_MEDIA_1_BACH__PC</th>\n",
       "      <th>CH_PRUEBAS_CALIFICADAS</th>\n",
       "      <th>...</th>\n",
       "      <th>tiempo_etapa_dias</th>\n",
       "      <th>tiempo_entre_etapas_dias</th>\n",
       "      <th>num_asistencias_acum</th>\n",
       "      <th>num_solicitudes_acum</th>\n",
       "      <th>CH_ALUMNO__PC</th>\n",
       "      <th>CH_ESTUDIANTE__PC</th>\n",
       "      <th>CH_ANTIGUO_ALUMNO__PC</th>\n",
       "      <th>CH_ALUMNI__PC</th>\n",
       "      <th>CH_ANTIGUOALUMNO_INTERCAMBIO</th>\n",
       "      <th>CH_HIJO_ANTIGUO_ALUMNO__PC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001w000001X8jDhAAJ</td>\n",
       "      <td>0061r00000yz6vuAAA</td>\n",
       "      <td>003w000001knzGTAAY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022/2023</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001w000001X8jDhAAJ</td>\n",
       "      <td>0061r00000yz6vuAAA</td>\n",
       "      <td>003w000001knzGTAAY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022/2023</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001w000001X8jDhAAJ</td>\n",
       "      <td>0061r00000yz6vuAAA</td>\n",
       "      <td>003w000001knzGTAAY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022/2023</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001w000001X8jDhAAJ</td>\n",
       "      <td>0061r00000yz6vuAAA</td>\n",
       "      <td>003w000001knzGTAAY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022/2023</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001w000001X8jDhAAJ</td>\n",
       "      <td>0061r00000yz6vuAAA</td>\n",
       "      <td>003w000001knzGTAAY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022/2023</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ACCOUNTID                  ID            ID18__PC  target  \\\n",
       "0  001w000001X8jDhAAJ  0061r00000yz6vuAAA  003w000001knzGTAAY     0.0   \n",
       "1  001w000001X8jDhAAJ  0061r00000yz6vuAAA  003w000001knzGTAAY     0.0   \n",
       "2  001w000001X8jDhAAJ  0061r00000yz6vuAAA  003w000001knzGTAAY     0.0   \n",
       "3  001w000001X8jDhAAJ  0061r00000yz6vuAAA  003w000001knzGTAAY     0.0   \n",
       "4  001w000001X8jDhAAJ  0061r00000yz6vuAAA  003w000001knzGTAAY     0.0   \n",
       "\n",
       "   desmatriculado PL_CURSO_ACADEMICO CH_NACIONAL  NU_NOTA_MEDIA_ADMISION  \\\n",
       "0             0.0          2022/2023        True                     NaN   \n",
       "1             0.0          2022/2023        True                     NaN   \n",
       "2             0.0          2022/2023        True                     NaN   \n",
       "3             0.0          2022/2023        True                     NaN   \n",
       "4             0.0          2022/2023        True                     NaN   \n",
       "\n",
       "   NU_NOTA_MEDIA_1_BACH__PC CH_PRUEBAS_CALIFICADAS  ...  tiempo_etapa_dias  \\\n",
       "0                       6.0                  False  ...                  0   \n",
       "1                       6.0                  False  ...                  0   \n",
       "2                       6.0                  False  ...                  0   \n",
       "3                       6.0                  False  ...                  0   \n",
       "4                       6.0                  False  ...                  0   \n",
       "\n",
       "  tiempo_entre_etapas_dias num_asistencias_acum num_solicitudes_acum  \\\n",
       "0                        0                    0                    0   \n",
       "1                        0                    0                    0   \n",
       "2                        0                    0                    0   \n",
       "3                        0                    0                    0   \n",
       "4                        0                    0                    0   \n",
       "\n",
       "   CH_ALUMNO__PC  CH_ESTUDIANTE__PC  CH_ANTIGUO_ALUMNO__PC CH_ALUMNI__PC  \\\n",
       "0          False               True                  False         False   \n",
       "1          False               True                  False         False   \n",
       "2          False               True                  False         False   \n",
       "3          False               True                  False         False   \n",
       "4          False               True                  False         False   \n",
       "\n",
       "  CH_ANTIGUOALUMNO_INTERCAMBIO CH_HIJO_ANTIGUO_ALUMNO__PC  \n",
       "0                        False                      False  \n",
       "1                        False                      False  \n",
       "2                        False                      False  \n",
       "3                        False                      False  \n",
       "4                        False                      False  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SCRIPT ¬∑ DATASET DE TRATAMIENTO DEFINITIVO FINAL\n",
    "# ============================================================\n",
    "# Objetivo:\n",
    "#   - Construir el dataset final de modelizaci√≥n a partir de Salesforce\n",
    "#   - Integrar informaci√≥n acad√©mica, econ√≥mica, actividades y tiempos\n",
    "#   - Controlar leakage de informaci√≥n futura\n",
    "#   - Dejar el dataset listo para an√°lisis y ML\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#\n",
    "import utils\n",
    "import importlib\n",
    "importlib.reload(utils) # Esto es √∫til si est√°s editando el archivo utils.py a la vez\n",
    "\n",
    "# Importa las funciones espec√≠ficas al espacio de nombres global\n",
    "from utils import (\n",
    "    crear_target, \n",
    "    eliminar_columnas_na, \n",
    "    calcular_tiempos_etapas, \n",
    "    integrar_actividades_progresivo_por_curso,\n",
    "    limpiar_historial_por_hitos  # <-- Aseg√∫rate de que est√© aqu√≠\n",
    ")\n",
    "# Funciones auxiliares definidas en utils.py\n",
    "# - crear_target: construye la variable objetivo a partir del historial de etapas\n",
    "# - eliminar_columnas_na: elimina columnas con exceso de valores nulos\n",
    "# - calcular_tiempos_etapas: calcula duraci√≥n en cada etapa del funnel\n",
    "# - integrar_actividades_progresivo_por_curso: agrega actividades acumuladas\n",
    "\n",
    "# ============================================================\n",
    "# 1Ô∏è‚É£ CARGA DE DATOS\n",
    "# ============================================================\n",
    "# Se carga el Excel completo de Salesforce\n",
    "# Cada hoja corresponde a una entidad distinta\n",
    "# ============================================================\n",
    "\n",
    "ruta_excel = r\"C:\\Users\\0017655\\Downloads\\DataSET_SF - V2.xlsx\"\n",
    "dfs = pd.read_excel(ruta_excel, sheet_name=None)\n",
    "\n",
    "# Asignar cada hoja a un dataframe independiente\n",
    "# El orden debe coincidir con el Excel original\n",
    "oportunidad = list(dfs.values())[0]\n",
    "cuenta = list(dfs.values())[1]\n",
    "ecb = list(dfs.values())[2]\n",
    "solicitud_ban = list(dfs.values())[3]\n",
    "casos = list(dfs.values())[4]\n",
    "correos = list(dfs.values())[5]\n",
    "historial_actividad = list(dfs.values())[6]\n",
    "historial_etapas = list(dfs.values())[7]\n",
    "\n",
    "# ============================================================\n",
    "# 2Ô∏è‚É£ LIMPIEZA INICIAL DE NAS Y COLUMNAS\n",
    "# ============================================================\n",
    "# Se eliminan columnas con un porcentaje de NA superior al umbral\n",
    "# Esto reduce ruido y dimensionalidad desde el inicio\n",
    "# ============================================================\n",
    "\n",
    "def eliminar_columnas_na(df, umbral=0.9):\n",
    "    \"\"\"Elimina columnas con m√°s de un umbral de valores NA\"\"\"\n",
    "    return df.loc[:, df.isna().mean() < umbral]\n",
    "\n",
    "\n",
    "# Limpieza gen√©rica (no modifica los dataframes originales)\n",
    "for df in [oportunidad, cuenta, ecb, solicitud_ban, casos, correos, historial_actividad, historial_etapas]:\n",
    "    df = eliminar_columnas_na(df)\n",
    "\n",
    "\n",
    "# Limpieza efectiva sobre los dataframes clave\n",
    "oportunidad = eliminar_columnas_na(oportunidad)\n",
    "cuenta = eliminar_columnas_na(cuenta)\n",
    "ecb = eliminar_columnas_na(ecb)\n",
    "\n",
    "# ============================================================\n",
    "# 3Ô∏è‚É£ CREACI√ìN DEL TARGET\n",
    "# ============================================================\n",
    "# Se construye la variable objetivo (target) usando el historial de etapas\n",
    "# ============================================================\n",
    "\n",
    "oportunidad = crear_target(oportunidad, historial_etapas)\n",
    "\n",
    "\n",
    "# Uni√≥n de oportunidad con datos de cuenta/persona\n",
    "# Se hace LEFT JOIN para no perder oportunidades\n",
    "\n",
    "df_unido = pd.merge(\n",
    "    oportunidad, \n",
    "    cuenta, \n",
    "    left_on='ACCOUNTID', \n",
    "    right_on='ID18', \n",
    "    how='left',\n",
    "    suffixes=('', '_cuenta')\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4Ô∏è‚É£ CONSTRUCCI√ìN VARIABLES DERIVADAS\n",
    "# ============================================================\n",
    "# Se crean variables explicativas a partir de campos originales\n",
    "# ============================================================\n",
    "\n",
    "# Normalizaci√≥n del plazo de admisi√≥n\n",
    "# Se agrupan valores heterog√©neos en categor√≠as consistentes\n",
    "def normalizar_plazo(x):\n",
    "    if pd.isna(x): return \"Rolling\"\n",
    "    x = str(x).strip().lower()\n",
    "    if \"dic\" in x: return \"Diciembre\"\n",
    "    if \"mar\" in x: return \"Marzo\"\n",
    "    return \"Otros\"\n",
    "\n",
    "df_unido['PLAZO_ADMISION_LIMPIO'] = df_unido['PL_PLAZO_ADMISION'].apply(normalizar_plazo)\n",
    "\n",
    "# Uni√≥n con informaci√≥n econ√≥mica (ECB)\n",
    "# Se incorporan precios y renta familiar\n",
    "ecb_vars = ['LK_oportunidad__c', 'FO_rentaFam_ges__c', 'CU_precioOrdinario_def__c', 'CU_precioAplicado_def__c']\n",
    "df_definitivo = pd.merge(\n",
    "    df_unido,\n",
    "    ecb[ecb_vars],\n",
    "    left_on='ID',\n",
    "    right_on='LK_oportunidad__c',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "\n",
    "## C√°lculo del porcentaje pagado final\n",
    "df_definitivo['PORCENTAJE_PAGADO_FINAL'] = (\n",
    "    df_definitivo['CU_precioAplicado_def__c'] \n",
    "    / df_definitivo['CU_precioOrdinario_def__c'] * 100\n",
    ")\n",
    "\n",
    "# Si el precio ordinario es 0 o negativo, el porcentaje pagado es 0\n",
    "df_definitivo.loc[\n",
    "    df_definitivo['CU_precioOrdinario_def__c'] <= 0,\n",
    "    'PORCENTAJE_PAGADO_FINAL'\n",
    "] = 0\n",
    "\n",
    "\n",
    "# Guardado intermedio (dataset de an√°lisis)\n",
    "ruta_salida = r\"C:\\Users\\0017655\\Downloads\\dataset_analisis_final.csv\"\n",
    "df_definitivo.to_csv(ruta_salida, sep=\";\", index=False)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5Ô∏è‚É£ TIEMPO EN CADA ETAPA\n",
    "# ============================================================\n",
    "# Se calcula el tiempo pasado en cada etapa del funnel\n",
    "# ============================================================\n",
    "\n",
    "historial_etapas_tiempo = calcular_tiempos_etapas(historial_etapas)\n",
    "\n",
    "# Nuevo########3\n",
    "# ============================================================\n",
    "# 5Ô∏è‚É£ TIEMPO EN CADA ETAPA (CORREGIDO)\n",
    "# ============================================================\n",
    "\n",
    "# Calculamos los tiempos\n",
    "historial_etapas_tiempo = calcular_tiempos_etapas(historial_etapas)\n",
    "\n",
    "# Eliminamos las columnas de etapa est√°ticas del dataframe unido para que no choquen \n",
    "# con las din√°micas del historial\n",
    "cols_a_eliminar = ['STAGENAME', 'PL_SUBETAPA']\n",
    "df_definitivo_temp = df_definitivo.drop(columns=[c for c in cols_a_eliminar if c in df_definitivo.columns])\n",
    "\n",
    "# Ahora unimos: La base es el historial (muchas filas) y traemos los datos de la oportunidad (fijos)\n",
    "df_final_expandido = pd.merge(\n",
    "    historial_etapas_tiempo, \n",
    "    df_definitivo_temp, \n",
    "    left_on='LK_Oportunidad__c', \n",
    "    right_on='ID', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_final_expandido = limpiar_historial_por_hitos(historial_etapas_tiempo, df_definitivo_temp)\n",
    "\n",
    "# Actualizamos la referencia\n",
    "df_definitivo = df_final_expandido\n",
    "\n",
    "############\n",
    "\n",
    "#df_definitivo = historial_etapas_tiempo.merge(df_definitivo, left_on='LK_Oportunidad__c', right_on='ID', how='left')\n",
    "\n",
    "# ============================================================\n",
    "# 6Ô∏è‚É£ HISTORIAL DE ACTIVIDADES\n",
    "# ============================================================\n",
    "# Se integran actividades acumuladas por curso\n",
    "# Evita usar informaci√≥n futura respecto a la etapa\n",
    "# ============================================================\n",
    "\n",
    "df_definitivo = integrar_actividades_progresivo_por_curso(df_definitivo, historial_actividad)\n",
    "\n",
    "# ============================================================\n",
    "# 7Ô∏è‚É£ CONTROL DE INFORMACI√ìN FUTURA (LEAKAGE)\n",
    "# ============================================================\n",
    "# Se eliminan variables econ√≥micas si aparecen en etapas tempranas\n",
    "# ============================================================\n",
    "\n",
    "#etapas_pago = ['Solicitud', 'Pruebas', 'Admisi√≥n acad√©mica']\n",
    "#vars_pago = ['PAID_AMOUNT','MINIMUMPAYMENTPAYED','CU_precioAplicado_def__c','PORCENTAJE_PAGADO_FINAL']\n",
    "#vars_pago = [v for v in vars_pago if v in df_definitivo.columns]\n",
    "#\n",
    "#mask_futuro = (df_definitivo['PL_Etapa__c'].isin(etapas_pago)) & (df_definitivo[vars_pago].notna().any(axis=1))\n",
    "#df_definitivo.loc[mask_futuro, vars_pago] = np.nan\n",
    "\n",
    "# ============================================================\n",
    "# 8Ô∏è‚É£ SELECCI√ìN VARIABLES FINALES\n",
    "# ============================================================\n",
    "# Se define expl√≠citamente el conjunto final de variables\n",
    "# ============================================================\n",
    "columnas_seleccionadas = [\n",
    "    'ACCOUNTID', 'ID','ID18__PC', 'target', 'desmatriculado', 'PL_CURSO_ACADEMICO', 'CH_NACIONAL',\n",
    "    'NU_NOTA_MEDIA_ADMISION', 'NU_NOTA_MEDIA_1_BACH__PC', 'CH_PRUEBAS_CALIFICADAS', \n",
    "    'NU_RESULTADO_ADMISION_PUNTOS', 'PL_RESOLUCION_DEFINITIVA', 'TITULACION', 'CENTROENSENANZA',\n",
    "    'MINIMUMPAYMENTPAYED', 'PAID_AMOUNT', 'PAID_PERCENT', 'CH_PAGO_SUPERIOR', \n",
    "    'CH_MATRICULA_SUJETA_BECA', 'CH_AYUDA_FINANCIACION', 'CU_IMPORTE_TOTAL',\n",
    "    'CH_VISITACAMPUS__PC', 'CH_ENTREVISTA_PERSONAL__PC', 'ACC_DTT_FECHAULTIMAACTIVIDAD', \n",
    "    'NU_PREFERENCIA', 'PL_Etapa__c', 'PL_Subetapa__c',\n",
    "    'CH_HIJO_EMPLEADO__PC', 'CH_HIJO_PROFESOR_ASOCIADO__PC', 'CH_HERMANOS_ESTUDIANDO_UNAV__P', \n",
    "    'CH_HIJO_MEDICO__PC', 'YEARPERSONBIRTHDATE', 'NAMEX', 'CH_FAMILIA_NUMEROSA__PC', \n",
    "    'PL_SITUACION_SOCIO_ECONOMICA', 'LEADSOURCE', 'PL_ORIGEN_DE_SOLICITUD', \n",
    "    'PL_PLAZO_ADMISION', 'RECORDTYPENAME','PLAZO_ADMISION_LIMPIO','FO_rentaFam_ges__c','CU_precioOrdinario_def__c',\n",
    "    'CU_precioAplicado_def__c','PORCENTAJE_PAGADO_FINAL','tiempo_etapa_dias','tiempo_entre_etapas_dias','num_asistencias_acum', 'num_solicitudes_acum',\n",
    "    'CH_ALUMNO__PC', 'CH_ESTUDIANTE__PC', 'CH_ANTIGUO_ALUMNO__PC',\n",
    "    'CH_ALUMNI__PC', 'CH_ANTIGUOALUMNO_INTERCAMBIO',\n",
    "    'CH_HIJO_ANTIGUO_ALUMNO__PC','CreatedDate'\n",
    "]\n",
    "\n",
    "#columnas_finales = [c for c in columnas_finales if c in df_definitivo.columns]\n",
    "df_definitivo = df_definitivo[columnas_seleccionadas]\n",
    "\n",
    "# ============================================================\n",
    "# 9Ô∏è‚É£ GUARDAR DATASET TRATAMIENTO DEFINITIVO\n",
    "# ============================================================\n",
    "\n",
    "ruta_salida = r\"C:\\Users\\0017655\\Downloads\\dataset_tratamiento_final.csv\"\n",
    "df_definitivo.to_csv(ruta_salida, sep=\";\", index=False)\n",
    "\n",
    "print(f\"‚úÖ Dataset de tratamiento definitivo guardado en: {ruta_salida}\")\n",
    "print(f\"Dimensiones: {df_definitivo.shape}\")\n",
    "df_definitivo.head()\n",
    "\n",
    "# ==============================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_python311_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
